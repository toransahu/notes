{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"","title":"Home"},{"location":"Blockchain/","text":"Introduction Trade-offs Terminologies Components Block Features Applications Facts Frameworks Workflow FAQ Multichain Installation Getting Started Nodes On Different Servers Node 1 Initial Setup on Server 1 Node 2 Connection with Node 1 on Server 2 Back on Server 1 Back on Server 2 Delete a Chain Nodes On Same Server Node 1 Initial Setup Node 2 Connection with Node 1 Introduction # Trade-offs # Public vs Private Security vs Performance Terminologies # Genesis Consensus Proof-of-Work Proof-of-Stake Proof of Byzantine Fault Tollerance Black Node/Block Orphan Block (Purple) Immutable distributed Ledger Double Spending Node Any computer that connects to the Bitcoin network is called a node every mining computer, every computer that has a bitcoin wallet and by special sites that give blockchain monitor services Full Node Nodes that fully verify all of the rules of Bitcoin Full nodes download every block and transaction and check them against Bitcoin's consensus rules Merkle Tree Hash of transaction in a block Keys Source Private Key (64): Assiged to node on joining network Public Key (34): same as above but can be publiced, same as bitcoin QR code balances in wallet are fetched from bitcoin address, which is public key of the wallet Components # Transactions commits changes to the blockchain contains signature of owner of address many transactions inside a block Blocks conatins an ordered bunch of transactions timestamps the transactions, are immutable each block references the previous block Block # Hash Data Previous Hash Features # Encryption of data Proof-of-work History Decentralized Data Trust in Data No Intermediaries Network Type Public Private Authentication peers signs the transaction with their private key Applications # Banking & Money Transfer Healthcare All types of document management Land / Real State Owner's Doc Transfer Deeds Land History Certificates Birth Caste Marriage Death Contracts Governance All the govt. data Voting Voter Registration Voter Identification Electronic Voting Cloud Storage Digital Twin Energy management Online Music Retail Shops Crowdfunding Startups Govt. & Contractor Avoid Intermediaters Advocate Bank Other 3rd Parties Blockchain + AI Decentralized AI platform Facts # data commited to ledger cann't be changed Frameworks # Source1: https://medium.com/hyperlegendary/6-blockchain-frameworks-to-build-enterprise-blockchain-how-to-choose-them-2b7d50ba275c Source2: https://www.blockchain-council.org/blockchain/list-of-best-open-source-blockchain-platforms/ Hyperledger (active Consumer): https://github.com/hyperledger/composer/ Ethereum: https://github.com/ethereum MultiChain: https://github.com/MultiChain , https://www.multichain.com OpenBlockChain : https://github.com/openblockchain Eris Workflow # genesis few transactions by few peoples transactions stored temporary in transaction pool many miners try to solve for candidate block candidate block is the next block going to be added to the blockchain a block can store a limited amount of transactions (1MB, in Bitcoin Hard Cash 8MB, 500 transactions etc.) they will take the all transaction data and create hash from that by making chnages in nonce any one miner won the race he will broadcast the hash/new to the network rest of the miners will validate the calculated hash there are some math like value of hash should be less than target source: http://learnmeabitcoin.com/guide/blocks) or a simple math for example, hash should start with 0000 if validations succeed, all the FAQ # how data changes reaches to the leader how leader'd PoW are verified where the new block will get added if one leader solved the problem what is the mathematical problem to be solved how many transactions in single block when is new block created and why? how creation/updation in doc will be validated, before audit? how to avoid false data entry by doctors? how to add real time data like, pulse, heartbit directly from device? include IoT? who are PoW validators? Are the other miners? who are ledger keepers? are they miners? Multichain # Installation # su ( enter root password ) cd /tmp wget https://www.multichain.com/download/multichain-1.0.5.tar.gz tar -xvzf multichain-1.0.5.tar.gz cd multichain-1.0.5 mv multichaind multichain-cli multichain-util /usr/local/bin ( to make easily accessible on the command line ) exit ( to return to your regular user ) Getting Started # Nodes On Different Servers # Node 1 Initial Setup on Server 1 # Run #Create chain1 multichain-util create chain1 Output MultiChain 1 .0.5 Utilities ( latest protocol 10011 ) Blockchain parameter set was successfully generated. You can edit it in /home/toran/node1/chain1/params.dat before running multichaind for the first time. To generate blockchain please run \"multichaind chain1 -daemon\" . Run #Initialize Blockchain with genesis block multichaind chain1 -daemon Output MultiChain 1 .0.5 Daemon ( latest protocol 10011 ) Starting up node... Looking for genesis block... Genesis block found Other nodes can connect to this node using: multichaind chain1@192.168.1.100:6725 Listening for API requests on port 6724 ( local only - see rpcallowip setting ) Node ready. Node 2 Connection with Node 1 on Server 2 # Run multichaind chain1@192.168.1.100:6725 # aws node multichaind -datadir = /home/toran/node2 -port = 10255 -rpcport = 10254 mychain@34.254.186.152:6821 -daemon Output MultiChain 1 .0.5 Daemon ( latest protocol 10011 ) Retrieving blockchain parameters from the seed node 192 .168.1.100:6725 ... Blockchain successfully initialized. Please ask blockchain admin or user having activate permission to let you connect and/or transact: multichain-cli chain1 grant 1UcDevL9XAeEeHu5qtjBqcdXTsLfELW3nHt5YR connect multichain-cli chain1 grant 1UcDevL9XAeEeHu5qtjBqcdXTsLfELW3nHt5YR connect,send,receive Back on Server 1 # Run multichain-cli chain1 grant 1UcDevL9XAeEeHu5qtjBqcdXTsLfELW3nHt5YR connect Back on Server 2 # Run #Now try reconnecting again multichaind chain1 -daemon Delete a Chain # #Stop it running multichain-cli chain1 stop #Delete its directory sudo rm -r ~/.multichain/chain1 Nodes On Same Server # Node 1 Initial Setup # Run mkdir /home/toran/node1 multichain-util create chain1 -datadir = /home/toran/node1 Output MultiChain 1 .0.5 Utilities ( latest protocol 10011 ) Blockchain parameter set was successfully generated. You can edit it in /home/toran/node1/chain1/params.dat before running multichaind for the first time. To generate blockchain please run \"multichaind chain1 -daemon\" . Run multichaind chain1 -daemon -datadir = /home/toran/node1 Output MultiChain 1 .0.5 Daemon ( latest protocol 10011 ) Starting up node... Looking for genesis block... Genesis block found Other nodes can connect to this node using: multichaind chain1@192.168.1.100:6725 Listening for API requests on port 6724 ( local only - see rpcallowip setting ) Node ready. Node 2 Connection with Node 1 # Syntax: multichaind -datadir=<your_path_to_multichain2nd_directory> -port=10255 -rpcport=10254 chain0 -daemon Run mkdir /home/toran/node2 multichaind chain1@<chain1-ip>:<chain1-port> -datadir = /home/toran/node2 Output MultiChain 1 .0.5 Daemon ( latest protocol 10011 ) Retrieving blockchain parameters from the seed node 192 .168.1.100:6725 ... Blockchain successfully initialized. Please ask blockchain admin or user having activate permission to let you connect and/or transact: multichain-cli chain1 grant 1UcDevL9XAeEeHu5qtjBqcdXTsLfELW3nHt5YR connect multichain-cli chain1 grant 1UcDevL9XAeEeHu5qtjBqcdXTsLfELW3nHt5YR connect,send,receive Run multichain-cli chain1 -datadir = /home/toran/node1 grant 1UcDevL9XAeEeHu5qtjBqcdXTsLfELW3nHt5YR connect Commands in Interactive Mode sudo mkdir ~/.multichain/chain1 multichain-cli chain1 -datadir=/home/toran/node1 multichaind -datadir=/home/toran/node2 -port=10255 -rpcport=10254 mychain@34.254.186.152:6821 -daemon multichain-cli mychain -datadir=/home/toran/node2 allow port range in aws instance, like 1000-9999 in all multichain nodes aws instace while running the node chain@ip:port, this port is used in cli while API port is used in python/code multichain-cli -datadir=/home/ubuntu/toran-aws block-chain create stream \"scheme\" true connect multichaind -datadir=/home/ubuntu/vin-aws-new block-chain@13.232.100.99:2657 IP: vin-new: 34.255.8.211 tom: 13.232.130.184 my: 13.232.100.99","title":"Blockchain"},{"location":"Blockchain/#introduction","text":"","title":"Introduction"},{"location":"Blockchain/#trade-offs","text":"Public vs Private Security vs Performance","title":"Trade-offs"},{"location":"Blockchain/#terminologies","text":"Genesis Consensus Proof-of-Work Proof-of-Stake Proof of Byzantine Fault Tollerance Black Node/Block Orphan Block (Purple) Immutable distributed Ledger Double Spending Node Any computer that connects to the Bitcoin network is called a node every mining computer, every computer that has a bitcoin wallet and by special sites that give blockchain monitor services Full Node Nodes that fully verify all of the rules of Bitcoin Full nodes download every block and transaction and check them against Bitcoin's consensus rules Merkle Tree Hash of transaction in a block Keys Source Private Key (64): Assiged to node on joining network Public Key (34): same as above but can be publiced, same as bitcoin QR code balances in wallet are fetched from bitcoin address, which is public key of the wallet","title":"Terminologies"},{"location":"Blockchain/#components","text":"Transactions commits changes to the blockchain contains signature of owner of address many transactions inside a block Blocks conatins an ordered bunch of transactions timestamps the transactions, are immutable each block references the previous block","title":"Components"},{"location":"Blockchain/#block","text":"Hash Data Previous Hash","title":"Block"},{"location":"Blockchain/#features","text":"Encryption of data Proof-of-work History Decentralized Data Trust in Data No Intermediaries Network Type Public Private Authentication peers signs the transaction with their private key","title":"Features"},{"location":"Blockchain/#applications","text":"Banking & Money Transfer Healthcare All types of document management Land / Real State Owner's Doc Transfer Deeds Land History Certificates Birth Caste Marriage Death Contracts Governance All the govt. data Voting Voter Registration Voter Identification Electronic Voting Cloud Storage Digital Twin Energy management Online Music Retail Shops Crowdfunding Startups Govt. & Contractor Avoid Intermediaters Advocate Bank Other 3rd Parties Blockchain + AI Decentralized AI platform","title":"Applications"},{"location":"Blockchain/#facts","text":"data commited to ledger cann't be changed","title":"Facts"},{"location":"Blockchain/#frameworks","text":"Source1: https://medium.com/hyperlegendary/6-blockchain-frameworks-to-build-enterprise-blockchain-how-to-choose-them-2b7d50ba275c Source2: https://www.blockchain-council.org/blockchain/list-of-best-open-source-blockchain-platforms/ Hyperledger (active Consumer): https://github.com/hyperledger/composer/ Ethereum: https://github.com/ethereum MultiChain: https://github.com/MultiChain , https://www.multichain.com OpenBlockChain : https://github.com/openblockchain Eris","title":"Frameworks"},{"location":"Blockchain/#workflow","text":"genesis few transactions by few peoples transactions stored temporary in transaction pool many miners try to solve for candidate block candidate block is the next block going to be added to the blockchain a block can store a limited amount of transactions (1MB, in Bitcoin Hard Cash 8MB, 500 transactions etc.) they will take the all transaction data and create hash from that by making chnages in nonce any one miner won the race he will broadcast the hash/new to the network rest of the miners will validate the calculated hash there are some math like value of hash should be less than target source: http://learnmeabitcoin.com/guide/blocks) or a simple math for example, hash should start with 0000 if validations succeed, all the","title":"Workflow"},{"location":"Blockchain/#faq","text":"how data changes reaches to the leader how leader'd PoW are verified where the new block will get added if one leader solved the problem what is the mathematical problem to be solved how many transactions in single block when is new block created and why? how creation/updation in doc will be validated, before audit? how to avoid false data entry by doctors? how to add real time data like, pulse, heartbit directly from device? include IoT? who are PoW validators? Are the other miners? who are ledger keepers? are they miners?","title":"FAQ"},{"location":"Blockchain/#multichain","text":"","title":"Multichain"},{"location":"Blockchain/#installation","text":"su ( enter root password ) cd /tmp wget https://www.multichain.com/download/multichain-1.0.5.tar.gz tar -xvzf multichain-1.0.5.tar.gz cd multichain-1.0.5 mv multichaind multichain-cli multichain-util /usr/local/bin ( to make easily accessible on the command line ) exit ( to return to your regular user )","title":"Installation"},{"location":"Blockchain/#getting-started","text":"","title":"Getting Started"},{"location":"Blockchain/#nodes-on-different-servers","text":"","title":"Nodes On Different Servers"},{"location":"Blockchain/#node-1-initial-setup-on-server-1","text":"Run #Create chain1 multichain-util create chain1 Output MultiChain 1 .0.5 Utilities ( latest protocol 10011 ) Blockchain parameter set was successfully generated. You can edit it in /home/toran/node1/chain1/params.dat before running multichaind for the first time. To generate blockchain please run \"multichaind chain1 -daemon\" . Run #Initialize Blockchain with genesis block multichaind chain1 -daemon Output MultiChain 1 .0.5 Daemon ( latest protocol 10011 ) Starting up node... Looking for genesis block... Genesis block found Other nodes can connect to this node using: multichaind chain1@192.168.1.100:6725 Listening for API requests on port 6724 ( local only - see rpcallowip setting ) Node ready.","title":"Node 1 Initial Setup on Server 1"},{"location":"Blockchain/#node-2-connection-with-node-1-on-server-2","text":"Run multichaind chain1@192.168.1.100:6725 # aws node multichaind -datadir = /home/toran/node2 -port = 10255 -rpcport = 10254 mychain@34.254.186.152:6821 -daemon Output MultiChain 1 .0.5 Daemon ( latest protocol 10011 ) Retrieving blockchain parameters from the seed node 192 .168.1.100:6725 ... Blockchain successfully initialized. Please ask blockchain admin or user having activate permission to let you connect and/or transact: multichain-cli chain1 grant 1UcDevL9XAeEeHu5qtjBqcdXTsLfELW3nHt5YR connect multichain-cli chain1 grant 1UcDevL9XAeEeHu5qtjBqcdXTsLfELW3nHt5YR connect,send,receive","title":"Node 2 Connection with Node 1 on Server 2"},{"location":"Blockchain/#back-on-server-1","text":"Run multichain-cli chain1 grant 1UcDevL9XAeEeHu5qtjBqcdXTsLfELW3nHt5YR connect","title":"Back on Server 1"},{"location":"Blockchain/#back-on-server-2","text":"Run #Now try reconnecting again multichaind chain1 -daemon","title":"Back on Server 2"},{"location":"Blockchain/#delete-a-chain","text":"#Stop it running multichain-cli chain1 stop #Delete its directory sudo rm -r ~/.multichain/chain1","title":"Delete  a Chain"},{"location":"Blockchain/#nodes-on-same-server","text":"","title":"Nodes On Same Server"},{"location":"Blockchain/#node-1-initial-setup","text":"Run mkdir /home/toran/node1 multichain-util create chain1 -datadir = /home/toran/node1 Output MultiChain 1 .0.5 Utilities ( latest protocol 10011 ) Blockchain parameter set was successfully generated. You can edit it in /home/toran/node1/chain1/params.dat before running multichaind for the first time. To generate blockchain please run \"multichaind chain1 -daemon\" . Run multichaind chain1 -daemon -datadir = /home/toran/node1 Output MultiChain 1 .0.5 Daemon ( latest protocol 10011 ) Starting up node... Looking for genesis block... Genesis block found Other nodes can connect to this node using: multichaind chain1@192.168.1.100:6725 Listening for API requests on port 6724 ( local only - see rpcallowip setting ) Node ready.","title":"Node 1 Initial Setup"},{"location":"Blockchain/#node-2-connection-with-node-1","text":"Syntax: multichaind -datadir=<your_path_to_multichain2nd_directory> -port=10255 -rpcport=10254 chain0 -daemon Run mkdir /home/toran/node2 multichaind chain1@<chain1-ip>:<chain1-port> -datadir = /home/toran/node2 Output MultiChain 1 .0.5 Daemon ( latest protocol 10011 ) Retrieving blockchain parameters from the seed node 192 .168.1.100:6725 ... Blockchain successfully initialized. Please ask blockchain admin or user having activate permission to let you connect and/or transact: multichain-cli chain1 grant 1UcDevL9XAeEeHu5qtjBqcdXTsLfELW3nHt5YR connect multichain-cli chain1 grant 1UcDevL9XAeEeHu5qtjBqcdXTsLfELW3nHt5YR connect,send,receive Run multichain-cli chain1 -datadir = /home/toran/node1 grant 1UcDevL9XAeEeHu5qtjBqcdXTsLfELW3nHt5YR connect Commands in Interactive Mode sudo mkdir ~/.multichain/chain1 multichain-cli chain1 -datadir=/home/toran/node1 multichaind -datadir=/home/toran/node2 -port=10255 -rpcport=10254 mychain@34.254.186.152:6821 -daemon multichain-cli mychain -datadir=/home/toran/node2 allow port range in aws instance, like 1000-9999 in all multichain nodes aws instace while running the node chain@ip:port, this port is used in cli while API port is used in python/code multichain-cli -datadir=/home/ubuntu/toran-aws block-chain create stream \"scheme\" true connect multichaind -datadir=/home/ubuntu/vin-aws-new block-chain@13.232.100.99:2657 IP: vin-new: 34.255.8.211 tom: 13.232.130.184 my: 13.232.100.99","title":"Node 2 Connection with Node 1"},{"location":"Git/","text":"Intro What? Why? Terminologies master origin remote url Setup & Config config CRLF, LF, CR Windows Only Linux/Mac Only If Both Inspection & Comparision diff Compare local with remote branch diff-tree List all the files in a commit show List all the files in a commit Commands init --bare clone pull add rm commit push checkout status log reflog reset Uses Branching Merging merge Vs rebase merge rebase: rebase one branch on the top of another Reverting back to old commits Reseting Modify last commit Message Modify a particular commit Squashing last x commits into one Misc Travis CI (Continue Integration) Prerequisites Steps to Integrate CI command to install dependencies command to run tests Setup SSH key Generate or Get ssh key Generate Set paraphrase Get Add the key to the ssh-agent Start Add Provide paraphrase Add the public key to your VCS portal settings Copy hash of public key Paste in settings Update remotes with ssh url Intro # Book Ref Cheatsheet What? # Why? # As a collaboration tool As a version control tool Terminologies # master # origin # remote # url # Setup & Config # config # CRLF, LF, CR # Windows Only # Then turn off automatical convertions, and stick to CRLF only git config --global core.autocrlf false Linux/Mac Only # If on LF system, then do this to convert any CRLF to LF but not LF to CRLF git config --global core.autocrlf input If Both # Then set this in Windows system only auto-converting CRLF line endings into LF when you add a file to the index and vice versa when it checks out code onto your filesystem hence Git will be having LF but windows filesystem will always have CRLF git config --global core.autocrlf true Inspection & Comparision # diff # Compare local with remote branch # git diff <masterbranch_path> <remotebranch_path> #or git diff master origin/master diff-tree # List all the files in a commit # git diff-tree --no-commit-id --name-only -r bd61ad98 show # List all the files in a commit # git show --pretty=\"\" --name-only bd61ad98 Commands # init # --bare # Source: http://www.saintsjd.com/2011/01/what-is-a-bare-git-repository/ clone # Normal Way git clone url:repo Clone a specific release git clone url:repo --branch <tag#> pull # git pull origin master git pull origin master -f git pull --rebase origin master add # rm # commit # commit -m \"message\" commit --amend to re-phrase the commit message; iff commit has not been pushed push # checkout # status # log # To see in descriptive format git log --graph --decorate --oneline where: --graph: shows flow --decorate: shows branch names --oneline: compact description in single line reflog # To see in short reset # Uses # Branching # Lets say you have 2 branches: master dev Options: create a new branch dev git checkout -b dev dev is active git checkout dev master is active git checkout master dev is active & incorporate master in it git checkout dev git merge master master is active & incorporate dev in it git checkout master git merge dev delete a local branch if completely merged git branch -d dev delete a local branch if not merged git branch -D dev delete a remote branch git push origin :dev Rename your local branch. If you are on the branch you want to rename: git branch -m new-name If you are on a different branch: git branch -m old-name new-name Delete the old-name remote branch and push the new-name local branch. git push origin :old-name new-name Reset the upstream branch for the new-name local branch. Switch to the branch and then: git push origin -u new-name Golden rules first incorporate master into dev check compatibility/bugs/conflicts & resolve them now incorporate/merge dev in master Merging # merge Vs rebase # Both are used for same purpose but with different approach Integrates changes from one branch to another merge # Lets say, if you're woring on a feature in a dedicated branch. And someone makes a commit in master branch and you want to pull those changes to your feature branch, i.e. A---B---C feature / D---E---F---G master here A,B,C are commits in feature. F,G are new commits in master then: git checkout feature git merge master Or in one line git merge master feature This will create a new commit in feature branch called as \"merge commit\" and feature branch will have same history as master (but not vice-versa) i.e. A---B---C---(*) feature / / D---E---F---G---H master here (*) is merge commit Very active master branch can pollute the feature branch. rebase: # Alternative to merging rebases feature branch onto master branch git checkout feature git rebase master shifts the entire feature branch to tip/(latest node) of the master branch. i.e. A'--B'--C' feature / D---E---F---G master here A',B',C' are brand new commits instead of creating \"merge commit\", it creates brand new commits in feature branch for all the commits created earlier on the feature branch (the changes will same, but with new commit infos) i.e. re-writes branch history Benifits over merge gives cleaner history log by avoiding un-necessary \"merge commits\" results in perfectly linear project history Golden rules to use rebase : * never use rebase on any public branch: Means, don't rebase the master branch onto feature branch (it is opposite of rebasing feature branch onto master branch). It will create a brand new commit/history in master branch which will affect other developers. rebase one branch on the top of another # Branch-1 Branch-2 X--Y A--B--C / / D---E---F---G---H master After rebaseing Branch-1 on the top of Branch-2 A--B--C--X--Y Branch-1 / A--B--C Branch-2 / D---E---F---G---H master git checkout branch1 git rebase branch2 Reverting back to old commits # https://stackoverflow.com/questions/4114095/how-to-revert-a-git-repository-to-a-previous-commit Reseting # git checkout <branch> git reflog pick the commit_sha one prior to the the incident git reset --hard <commit_sha> --hard Matches the working tree and index to that of the tree being switched to. Any changes to tracked files in the working tree since <commit> are lost. git reset --merge <commit_sha> or git reset --merge <head_count> --merge Resets the index to match the tree recorded by the named commit, and updates the files that are different between the named commit and the current commit in the working tree. Modify last commit Message # git commit -a -m Modify a particular commit # If you want to modify files at commit git rebase -i <SHA> You will get a editor opened up with list of all the commits prior to that. Change the pick to edit for that particular commit . Save & close the editor. Make changes to your files. After that add or rm files. If you want to change the commit msg also then git commit -a Then continue rebasing git rebase --continue Squashing last x commits into one # If you want to squash last X commits into single commit then git rebase -i HEAD~X You will get a editor opened up with list of all the X commits. Change the pick to s for all the commits except the oldest one into which you want to merge all the lastest. Save & close the editor. Again you'll get an editor with list & order of all the squashed commits. (if you want you can change the commit msgs at this moment) Then continue rebasing git rebase --continue Done. Misc # Travis CI (Continue Integration) # Continuous Integration is the practice of merging in small code changes frequently - rather than merging in a large change at the end of a development cycle. The goal is to build healthier software by developing and testing in smaller increments. Source Prerequisites # To start using Travis CI, make sure you have all of the following: GitHub login Project hosted as a repository on GitHub Working code in your project Working build or test script Steps to Integrate CI # Using github login to TravisCI.org for public repositories TravisCI.com for private repositories Enable the repo in CI portal Add .travis.yml file to the repo to tell Travis CI what to do e.g. ```yaml language: python python: - \"3.6.4\" command to install dependencies # install: # - pip install -r requirements.pip - pip install pipenv - \"pipenv install --dev\" command to run tests # script: # - pytest src/test.py # or py.test for Python versions 3.5 and below - pipenv run pytest src/test.py # or py.test for Python versions 3.5 and below ``` Infrastructure options ```yaml os: linux dist: trusty sudo: enabled ``` Add the .travis.yml file to git, commit and push, to trigger a Travis CI build Travis only runs builds on the commits you push after you\u2019ve enabled the repository in Travis CI. check the build page embbed build status on github page Setup SSH key # Generate or Get ssh key # Generate # ssh-keygen Set paraphrase # Get # ls ~/.ssh Add the key to the ssh-agent # Start # eval ` ssh-agent ` Add # ssh-add ~/.ssh/<private_key_file> where is generally id_rsa Provide paraphrase # Add the public key to your VCS portal settings # Copy hash of public key # cat ~/.ssh/id_rsa.pub or xclip -sel clip ~/.ssh/id_rsa.pub Paste in settings # Update remotes with ssh url # git remote rm origin git remote add origin git@bitbucket.org:toransahu/ethereal-machines-backend.git","title":"Git"},{"location":"Git/#intro","text":"Book Ref Cheatsheet","title":"Intro"},{"location":"Git/#what","text":"","title":"What?"},{"location":"Git/#why","text":"As a collaboration tool As a version control tool","title":"Why?"},{"location":"Git/#terminologies","text":"","title":"Terminologies"},{"location":"Git/#master","text":"","title":"master"},{"location":"Git/#origin","text":"","title":"origin"},{"location":"Git/#remote","text":"","title":"remote"},{"location":"Git/#url","text":"","title":"url"},{"location":"Git/#setup-config","text":"","title":"Setup &amp; Config"},{"location":"Git/#config","text":"","title":"config"},{"location":"Git/#crlf-lf-cr","text":"","title":"CRLF, LF, CR"},{"location":"Git/#windows-only","text":"Then turn off automatical convertions, and stick to CRLF only git config --global core.autocrlf false","title":"Windows Only"},{"location":"Git/#linuxmac-only","text":"If on LF system, then do this to convert any CRLF to LF but not LF to CRLF git config --global core.autocrlf input","title":"Linux/Mac Only"},{"location":"Git/#if-both","text":"Then set this in Windows system only auto-converting CRLF line endings into LF when you add a file to the index and vice versa when it checks out code onto your filesystem hence Git will be having LF but windows filesystem will always have CRLF git config --global core.autocrlf true","title":"If Both"},{"location":"Git/#inspection-comparision","text":"","title":"Inspection &amp; Comparision"},{"location":"Git/#diff","text":"","title":"diff"},{"location":"Git/#compare-local-with-remote-branch","text":"git diff <masterbranch_path> <remotebranch_path> #or git diff master origin/master","title":"Compare local with remote branch"},{"location":"Git/#diff-tree","text":"","title":"diff-tree"},{"location":"Git/#list-all-the-files-in-a-commit","text":"git diff-tree --no-commit-id --name-only -r bd61ad98","title":"List all the files in a commit"},{"location":"Git/#show","text":"","title":"show"},{"location":"Git/#list-all-the-files-in-a-commit_1","text":"git show --pretty=\"\" --name-only bd61ad98","title":"List all the files in a commit"},{"location":"Git/#commands","text":"","title":"Commands"},{"location":"Git/#init","text":"","title":"init"},{"location":"Git/#-bare","text":"Source: http://www.saintsjd.com/2011/01/what-is-a-bare-git-repository/","title":"--bare"},{"location":"Git/#clone","text":"Normal Way git clone url:repo Clone a specific release git clone url:repo --branch <tag#>","title":"clone"},{"location":"Git/#pull","text":"git pull origin master git pull origin master -f git pull --rebase origin master","title":"pull"},{"location":"Git/#add","text":"","title":"add"},{"location":"Git/#rm","text":"","title":"rm"},{"location":"Git/#commit","text":"commit -m \"message\" commit --amend to re-phrase the commit message; iff commit has not been pushed","title":"commit"},{"location":"Git/#push","text":"","title":"push"},{"location":"Git/#checkout","text":"","title":"checkout"},{"location":"Git/#status","text":"","title":"status"},{"location":"Git/#log","text":"To see in descriptive format git log --graph --decorate --oneline where: --graph: shows flow --decorate: shows branch names --oneline: compact description in single line","title":"log"},{"location":"Git/#reflog","text":"To see in short","title":"reflog"},{"location":"Git/#reset","text":"","title":"reset"},{"location":"Git/#uses","text":"","title":"Uses"},{"location":"Git/#branching","text":"Lets say you have 2 branches: master dev Options: create a new branch dev git checkout -b dev dev is active git checkout dev master is active git checkout master dev is active & incorporate master in it git checkout dev git merge master master is active & incorporate dev in it git checkout master git merge dev delete a local branch if completely merged git branch -d dev delete a local branch if not merged git branch -D dev delete a remote branch git push origin :dev Rename your local branch. If you are on the branch you want to rename: git branch -m new-name If you are on a different branch: git branch -m old-name new-name Delete the old-name remote branch and push the new-name local branch. git push origin :old-name new-name Reset the upstream branch for the new-name local branch. Switch to the branch and then: git push origin -u new-name Golden rules first incorporate master into dev check compatibility/bugs/conflicts & resolve them now incorporate/merge dev in master","title":"Branching"},{"location":"Git/#merging","text":"","title":"Merging"},{"location":"Git/#merge-vs-rebase","text":"Both are used for same purpose but with different approach Integrates changes from one branch to another","title":"merge Vs rebase"},{"location":"Git/#merge","text":"Lets say, if you're woring on a feature in a dedicated branch. And someone makes a commit in master branch and you want to pull those changes to your feature branch, i.e. A---B---C feature / D---E---F---G master here A,B,C are commits in feature. F,G are new commits in master then: git checkout feature git merge master Or in one line git merge master feature This will create a new commit in feature branch called as \"merge commit\" and feature branch will have same history as master (but not vice-versa) i.e. A---B---C---(*) feature / / D---E---F---G---H master here (*) is merge commit Very active master branch can pollute the feature branch.","title":"merge"},{"location":"Git/#rebase","text":"Alternative to merging rebases feature branch onto master branch git checkout feature git rebase master shifts the entire feature branch to tip/(latest node) of the master branch. i.e. A'--B'--C' feature / D---E---F---G master here A',B',C' are brand new commits instead of creating \"merge commit\", it creates brand new commits in feature branch for all the commits created earlier on the feature branch (the changes will same, but with new commit infos) i.e. re-writes branch history Benifits over merge gives cleaner history log by avoiding un-necessary \"merge commits\" results in perfectly linear project history Golden rules to use rebase : * never use rebase on any public branch: Means, don't rebase the master branch onto feature branch (it is opposite of rebasing feature branch onto master branch). It will create a brand new commit/history in master branch which will affect other developers.","title":"rebase:"},{"location":"Git/#rebase-one-branch-on-the-top-of-another","text":"Branch-1 Branch-2 X--Y A--B--C / / D---E---F---G---H master After rebaseing Branch-1 on the top of Branch-2 A--B--C--X--Y Branch-1 / A--B--C Branch-2 / D---E---F---G---H master git checkout branch1 git rebase branch2","title":"rebase one branch on the top of another"},{"location":"Git/#reverting-back-to-old-commits","text":"https://stackoverflow.com/questions/4114095/how-to-revert-a-git-repository-to-a-previous-commit","title":"Reverting back to old commits"},{"location":"Git/#reseting","text":"git checkout <branch> git reflog pick the commit_sha one prior to the the incident git reset --hard <commit_sha> --hard Matches the working tree and index to that of the tree being switched to. Any changes to tracked files in the working tree since <commit> are lost. git reset --merge <commit_sha> or git reset --merge <head_count> --merge Resets the index to match the tree recorded by the named commit, and updates the files that are different between the named commit and the current commit in the working tree.","title":"Reseting"},{"location":"Git/#modify-last-commit-message","text":"git commit -a -m","title":"Modify last commit Message"},{"location":"Git/#modify-a-particular-commit","text":"If you want to modify files at commit git rebase -i <SHA> You will get a editor opened up with list of all the commits prior to that. Change the pick to edit for that particular commit . Save & close the editor. Make changes to your files. After that add or rm files. If you want to change the commit msg also then git commit -a Then continue rebasing git rebase --continue","title":"Modify a particular commit"},{"location":"Git/#squashing-last-x-commits-into-one","text":"If you want to squash last X commits into single commit then git rebase -i HEAD~X You will get a editor opened up with list of all the X commits. Change the pick to s for all the commits except the oldest one into which you want to merge all the lastest. Save & close the editor. Again you'll get an editor with list & order of all the squashed commits. (if you want you can change the commit msgs at this moment) Then continue rebasing git rebase --continue Done.","title":"Squashing last x commits into one"},{"location":"Git/#misc","text":"","title":"Misc"},{"location":"Git/#travis-ci-continue-integration","text":"Continuous Integration is the practice of merging in small code changes frequently - rather than merging in a large change at the end of a development cycle. The goal is to build healthier software by developing and testing in smaller increments. Source","title":"Travis CI (Continue Integration)"},{"location":"Git/#prerequisites","text":"To start using Travis CI, make sure you have all of the following: GitHub login Project hosted as a repository on GitHub Working code in your project Working build or test script","title":"Prerequisites"},{"location":"Git/#steps-to-integrate-ci","text":"Using github login to TravisCI.org for public repositories TravisCI.com for private repositories Enable the repo in CI portal Add .travis.yml file to the repo to tell Travis CI what to do e.g. ```yaml language: python python: - \"3.6.4\"","title":"Steps to Integrate CI"},{"location":"Git/#command-to-install-dependencies","text":"install: # - pip install -r requirements.pip - pip install pipenv - \"pipenv install --dev\"","title":"command to install dependencies"},{"location":"Git/#command-to-run-tests","text":"script: # - pytest src/test.py # or py.test for Python versions 3.5 and below - pipenv run pytest src/test.py # or py.test for Python versions 3.5 and below ``` Infrastructure options ```yaml os: linux dist: trusty sudo: enabled ``` Add the .travis.yml file to git, commit and push, to trigger a Travis CI build Travis only runs builds on the commits you push after you\u2019ve enabled the repository in Travis CI. check the build page embbed build status on github page","title":"command to run tests"},{"location":"Git/#setup-ssh-key","text":"","title":"Setup SSH key"},{"location":"Git/#generate-or-get-ssh-key","text":"","title":"Generate or Get ssh key"},{"location":"Git/#generate","text":"ssh-keygen","title":"Generate"},{"location":"Git/#set-paraphrase","text":"","title":"Set paraphrase"},{"location":"Git/#get","text":"ls ~/.ssh","title":"Get"},{"location":"Git/#add-the-key-to-the-ssh-agent","text":"","title":"Add the key to the ssh-agent"},{"location":"Git/#start","text":"eval ` ssh-agent `","title":"Start"},{"location":"Git/#add_1","text":"ssh-add ~/.ssh/<private_key_file> where is generally id_rsa","title":"Add"},{"location":"Git/#provide-paraphrase","text":"","title":"Provide paraphrase"},{"location":"Git/#add-the-public-key-to-your-vcs-portal-settings","text":"","title":"Add the public key to your VCS portal settings"},{"location":"Git/#copy-hash-of-public-key","text":"cat ~/.ssh/id_rsa.pub or xclip -sel clip ~/.ssh/id_rsa.pub","title":"Copy hash of public key"},{"location":"Git/#paste-in-settings","text":"","title":"Paste in settings"},{"location":"Git/#update-remotes-with-ssh-url","text":"git remote rm origin git remote add origin git@bitbucket.org:toransahu/ethereal-machines-backend.git","title":"Update remotes with ssh url"},{"location":"Maths/","text":"Maths Arithmetic Progrssion Intro Geometric Progression Intro Maths # Arithmetic Progrssion # Intro # Lets take series 1, 3, 5, 9, ..... nth here 1, 1+2, 1 + (2+2), 1 + (2+2+2), ..... i.e. a + a+d, a+2d, a+3d,...... for n series a + a+d, a+2d, a+3d,......, a + (n-1)d So, a = initial number == 1 d = difference == 2 nth or last term = l = a + (n-1)d l = a + (n-1)d Sum of AP = sum of a + a+d, a+2d, a+3d,......, a + (n-1)d = a + a+d + a+2d + a+3d + ......+ a+(n-1)d = a*n + d(1 + 2 + 3 +....+ n-1) i.e. S_n = an + \\frac{d(n-1)n}{2} S_n = an + \\frac{d(n-1)n}{2} S_n = \\frac{1}{2}n(2a+ (n-1)d) S_n = \\frac{1}{2}n(2a+ (n-1)d) S_n = \\frac{1}{2}n(a+l) S_n = \\frac{1}{2}n(a+l) Geometric Progression # Intro # Lets take a series 2, 6, 18, 54, .... 2, 6, 18, 54, .... i.e. 2, 2 \\times 3, 2 \\times 3^2, 2 \\times 3^3, ... 2, 2 \\times 3, 2 \\times 3^2, 2 \\times 3^3, ... a, a \\times r, 2 \\times r^2, 2 \\times r^3, ... a, a \\times r, 2 \\times r^2, 2 \\times r^3, ... where a a is first term, and r r is ratio So, n^{th} n^{th} term = a \\times r^{n-1} a \\times r^{n-1} Sum of the GP S_n = a + a r + 2 r^2 + 2 r^3 + ... + a r^{n-1} S_n = a + a r + 2 r^2 + 2 r^3 + ... + a r^{n-1} rS_n = a r + 2 r^2 + 2 r^3 + 2 r^4 + ... + a r^{n} rS_n = a r + 2 r^2 + 2 r^3 + 2 r^4 + ... + a r^{n} ------------------- ------------------- S_n - rS_n = a - a r^n S_n - rS_n = a - a r^n S_n (1 - r) = a (1 - r^n) S_n (1 - r) = a (1 - r^n) S_n = \\frac{a (1 - r^n)}{(1 - r)} S_n = \\frac{a (1 - r^n)}{(1 - r)} S_{\\infty} = \\frac{a} {(1 - r)} S_{\\infty} = \\frac{a} {(1 - r)}","title":"Maths"},{"location":"Maths/#maths","text":"","title":"Maths"},{"location":"Maths/#arithmetic-progrssion","text":"","title":"Arithmetic Progrssion"},{"location":"Maths/#intro","text":"Lets take series 1, 3, 5, 9, ..... nth here 1, 1+2, 1 + (2+2), 1 + (2+2+2), ..... i.e. a + a+d, a+2d, a+3d,...... for n series a + a+d, a+2d, a+3d,......, a + (n-1)d So, a = initial number == 1 d = difference == 2 nth or last term = l = a + (n-1)d l = a + (n-1)d Sum of AP = sum of a + a+d, a+2d, a+3d,......, a + (n-1)d = a + a+d + a+2d + a+3d + ......+ a+(n-1)d = a*n + d(1 + 2 + 3 +....+ n-1) i.e. S_n = an + \\frac{d(n-1)n}{2} S_n = an + \\frac{d(n-1)n}{2} S_n = \\frac{1}{2}n(2a+ (n-1)d) S_n = \\frac{1}{2}n(2a+ (n-1)d) S_n = \\frac{1}{2}n(a+l) S_n = \\frac{1}{2}n(a+l)","title":"Intro"},{"location":"Maths/#geometric-progression","text":"","title":"Geometric Progression"},{"location":"Maths/#intro_1","text":"Lets take a series 2, 6, 18, 54, .... 2, 6, 18, 54, .... i.e. 2, 2 \\times 3, 2 \\times 3^2, 2 \\times 3^3, ... 2, 2 \\times 3, 2 \\times 3^2, 2 \\times 3^3, ... a, a \\times r, 2 \\times r^2, 2 \\times r^3, ... a, a \\times r, 2 \\times r^2, 2 \\times r^3, ... where a a is first term, and r r is ratio So, n^{th} n^{th} term = a \\times r^{n-1} a \\times r^{n-1} Sum of the GP S_n = a + a r + 2 r^2 + 2 r^3 + ... + a r^{n-1} S_n = a + a r + 2 r^2 + 2 r^3 + ... + a r^{n-1} rS_n = a r + 2 r^2 + 2 r^3 + 2 r^4 + ... + a r^{n} rS_n = a r + 2 r^2 + 2 r^3 + 2 r^4 + ... + a r^{n} ------------------- ------------------- S_n - rS_n = a - a r^n S_n - rS_n = a - a r^n S_n (1 - r) = a (1 - r^n) S_n (1 - r) = a (1 - r^n) S_n = \\frac{a (1 - r^n)}{(1 - r)} S_n = \\frac{a (1 - r^n)}{(1 - r)} S_{\\infty} = \\frac{a} {(1 - r)} S_{\\infty} = \\frac{a} {(1 - r)}","title":"Intro"},{"location":"Projects/","text":"Numbers Classic Algorithms Graph Data Structures Text Numbers # Find PI to the Nth Digit - Enter a number and have the program generate PI up to that many decimal places. Keep a limit to how far the program will go. Find e to the Nth Digit - Just like the previous problem, but with e instead of PI. Enter a number and have the program generate e up to that many decimal places. Keep a limit to how far the program will go. Fibonacci Sequence - Enter a number and have the program generate the Fibonacci sequence to that number or to the Nth number. Prime Factorization - Have the user enter a number and find all Prime Factors (if there are any) and display them. Next Prime Number - Have the program find prime numbers until the user chooses to stop asking for the next one. Find Cost of Tile to Cover W x H Floor - Calculate the total cost of tile it would take to cover a floor plan of width and height, using a cost entered by the user. Mortgage Calculator - Calculate the monthly payments of a fixed term mortgage over given Nth terms at a given interest rate. Also figure out how long it will take the user to pay back the loan. For added complexity, add an option for users to select the compounding interval (Monthly, Weekly, Daily, Continually). Change Return Program - The user enters a cost and then the amount of money given. The program will figure out the change and the number of quarters, dimes, nickels, pennies needed for the change. Binary to Decimal and Back Converter - Develop a converter to convert a decimal number to binary or a binary number to its decimal equivalent. Calculator - A simple calculator to do basic operators. Make it a scientific calculator for added complexity. Unit Converter (temp, currency, volume, mass and more) - Converts various units between one another. The user enters the type of unit being entered, the type of unit they want to convert to and then the value. The program will then make the conversion. Alarm Clock - A simple clock where it plays a sound after X number of minutes/seconds or at a particular time. Distance Between Two Cities - Calculates the distance between two cities and allows the user to specify a unit of distance. This program may require finding coordinates for the cities like latitude and longitude. Credit Card Validator - Takes in a credit card number from a common credit card vendor (Visa, MasterCard, American Express, Discoverer) and validates it to make sure that it is a valid number (look into how credit cards use a checksum). Tax Calculator - Asks the user to enter a cost and either a country or state tax. It then returns the tax plus the total cost with tax. Factorial Finder - The Factorial of a positive integer, n, is defined as the product of the sequence n, n-1, n-2, ...1 and the factorial of zero, 0, is defined as being 1. Solve this using both loops and recursion. Complex Number Algebra - Show addition, multiplication, negation, and inversion of complex numbers in separate functions. (Subtraction and division operations can be made with pairs of these operations.) Print the results for each operation tested. Happy Numbers - A happy number is defined by the following process. Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers, while those that do not end in 1 are unhappy numbers. Display an example of your output here. Find first 8 happy numbers. Number Names - Show how to spell out a number in English. You can use a preexisting implementation or roll your own, but you should support inputs up to at least one million (or the maximum value of your language's default bounded integer type, if that's less). Optional: Support for inputs other than positive integers (like zero, negative integers, and floating-point numbers). Coin Flip Simulation - Write some code that simulates flipping a single coin however many times the user decides. The code should record the outcomes and count the number of tails and heads. Limit Calculator - Ask the user to enter f(x) and the limit value, then return the value of the limit statement Optional: Make the calculator capable of supporting infinite limits. Fast Exponentiation - Ask the user to enter 2 integers a and b and output a^b (i.e. pow(a,b)) in O(lg n) time complexity. Classic Algorithms # Collatz Conjecture - Start with a number n > 1. Find the number of steps it takes to reach one using the following process: If n is even, divide it by 2. If n is odd, multiply it by 3 and add 1. Sorting - Implement two types of sorting algorithms: Merge sort and bubble sort. Closest pair problem - The closest pair of points problem or closest pair problem is a problem of computational geometry: given n points in metric space, find a pair of points with the smallest distance between them. Sieve of Eratosthenes - The sieve of Eratosthenes is one of the most efficient ways to find all of the smaller primes (below 10 million or so). Graph # Graph from links - Create a program that will create a graph or network from a series of links. Eulerian Path - Create a program which will take as an input a graph and output either a Eulerian path or a Eulerian cycle, or state that it is not possible. A Eulerian Path starts at one node and traverses every edge of a graph through every node and finishes at another node. A Eulerian cycle is a eulerian Path that starts and finishes at the same node. Connected Graph - Create a program which takes a graph as an input and outputs whether every node is connected or not. Dijkstra\u00e2\u0080\u0099s Algorithm - Create a program that finds the shortest path through a graph using its edges. Minimum Spanning Tree - Create a program which takes a connected, undirected graph with weights and outputs the minimum spanning tree of the graph i.e., a subgraph that is a tree, contains all the vertices, and the sum of its weights is the least possible. Data Structures # Inverted index - An Inverted Index is a data structure used to create full text search. Given a set of text files, implement a program to create an inverted index. Also create a user interface to do a search using that inverted index which returns a list of files that contain the query term / terms. The search index can be in memory. Text # Fizz Buzz - Write a program that prints the numbers from 1 to 100. But for multiples of three print \u00e2\u0080\u009cFizz\u00e2\u0080\u009d instead of the number and for the multiples of five print \u00e2\u0080\u009cBuzz\u00e2\u0080\u009d. For numbers which are multiples of both three and five print \u00e2\u0080\u009cFizzBuzz\u00e2\u0080\u009d. Reverse a String - Enter a string and the program will reverse it and print it out. Pig Latin - Pig Latin is a game of alterations played on the English language game. To create the Pig Latin form of an English word the initial consonant sound is transposed to the end of the word and an ay is affixed (Ex.: \"banana\" would yield anana-bay). Read Wikipedia for more information on rules. Count Vowels - Enter a string and the program counts the number of vowels in the text. For added complexity have it report a sum of each vowel found. Check if Palindrome - Checks if the string entered by the user is a palindrome. That is that it reads the same forwards as backwards like \u00e2\u0080\u009cracecar\u00e2\u0080\u009d Count Words in a String - Counts the number of individual words in a string. For added complexity read these strings in from a text file and generate a summary. Text Editor - Notepad style application that can open, edit, and save text documents. Optional: Add syntax highlighting and other features. RSS Feed Creator - Given a link to RSS/Atom Feed, get all posts and display them. Quote Tracker (market symbols etc) - A program which can go out and check the current value of stocks for a list of symbols entered by the user. The user can set how often the stocks are checked. For CLI, show whether the stock has moved up or down. Optional: If GUI, the program can show green up and red down arrows to show which direction the stock value has moved. Guestbook / Journal - A simple application that allows people to add comments or write journal entries. It can allow comments or not and timestamps for all entries. Could also be made into a shout box. Optional: Deploy it on Google App Engine or Heroku or any other PaaS (if possible, of course). Vigenere / Vernam / Ceasar Ciphers - Functions for encrypting and decrypting data messages. Then send them to a friend. Regex Query Tool - A tool that allows the user to enter a text string and then in a separate control enter a regex pattern. It will run the regular expression against the source text and return any matches or flag errors in the regular expression. Networking FTP Program - A file transfer program which can transfer files back and forth from a remote web sever. Bandwidth Monitor - A small utility program that tracks how much data you have uploaded and downloaded from the net during the course of your current online session. See if you can find out what periods of the day you use more and less and generate a report or graph that shows it. Port Scanner - Enter an IP address and a port range where the program will then attempt to find open ports on the given computer by connecting to each of them. On any successful connections mark the port as open. Mail Checker (POP3 / IMAP) - The user enters various account information include web server and IP, protocol type (POP3 or IMAP) and the application will check for email at a given interval. Country from IP Lookup - Enter an IP address and find the country that IP is registered in. Optional: Find the Ip automatically. Whois Search Tool - Enter an IP or host address and have it look it up through whois and return the results to you. Site Checker with Time Scheduling - An application that attempts to connect to a website or server every so many minutes or a given time and check if it is up. If it is down, it will notify you by email or by posting a notice on screen. Classes Product Inventory Project - Create an application which manages an inventory of products. Create a product class which has a price, id, and quantity on hand. Then create an inventory class which keeps track of various products and can sum up the inventory value. Airline / Hotel Reservation System - Create a reservation system which books airline seats or hotel rooms. It charges various rates for particular sections of the plane or hotel. Example, first class is going to cost more than coach. Hotel rooms have penthouse suites which cost more. Keep track of when rooms will be available and can be scheduled. Company Manager - Create an hierarchy of classes - abstract class Employee and subclasses HourlyEmployee, SalariedEmployee, Manager and Executive. Every one's pay is calculated differently, research a bit about it. After you've established an employee hierarchy, create a Company class that allows you to manage the employees. You should be able to hire, fire and raise employees. Bank Account Manager - Create a class called Account which will be an abstract class for three other classes called CheckingAccount, SavingsAccount and BusinessAccount. Manage credits and debits from these accounts through an ATM style program. Patient / Doctor Scheduler - Create a patient class and a doctor class. Have a doctor that can handle multiple patients and setup a scheduling program where a doctor can only handle 16 patients during an 8 hr work day. Recipe Creator and Manager - Create a recipe class with ingredients and a put them in a recipe manager program that organizes them into categories like deserts, main courses or by ingredients like chicken, beef, soups, pies etc. Image Gallery - Create an image abstract class and then a class that inherits from it for each image type. Put them in a program which displays them in a gallery style format for viewing. Shape Area and Perimeter Classes - Create an abstract class called Shape and then inherit from it other shapes like diamond, rectangle, circle, triangle etc. Then have each class override the area and perimeter functionality to handle each shape type. Flower Shop Ordering To Go - Create a flower shop application which deals in flower objects and use those flower objects in a bouquet object which can then be sold. Keep track of the number of objects and when you may need to order more. Family Tree Creator - Create a class called Person which will have a name, when they were born and when (and if) they died. Allow the user to create these Person classes and put them into a family tree structure. Print out the tree to the screen. Threading Create A Progress Bar for Downloads - Create a progress bar for applications that can keep track of a download in progress. The progress bar will be on a separate thread and will communicate with the main thread using delegates. Bulk Thumbnail Creator - Picture processing can take a bit of time for some transformations. Especially if the image is large. Create an image program which can take hundreds of images and converts them to a specified size in the background thread while you do other things. For added complexity, have one thread handling re-sizing, have another bulk renaming of thumbnails etc. Web Page Scraper - Create an application which connects to a site and pulls out all links, or images, and saves them to a list. Optional: Organize the indexed content and don\u00e2\u0080\u0099t allow duplicates. Have it put the results into an easily searchable index file. Online White Board - Create an application which allows you to draw pictures, write notes and use various colors to flesh out ideas for projects. Optional: Add feature to invite friends to collaborate on a white board online. Get Atomic Time from Internet Clock - This program will get the true atomic time from an atomic time clock on the Internet. Use any one of the atomic clocks returned by a simple Google search. Fetch Current Weather - Get the current weather for a given zip/postal code. Optional: Try locating the user automatically. Scheduled Auto Login and Action - Make an application which logs into a given site on a schedule and invokes a certain action and then logs out. This can be useful for checking web mail, posting regular content, or getting info for other applications and saving it to your computer. E-Card Generator - Make a site that allows people to generate their own little e-cards and send them to other people. Do not use Flash. Use a picture library and perhaps insightful mottos or quotes. Content Management System - Create a content management system (CMS) like Joomla, Drupal, PHP Nuke etc. Start small. Optional: Allow for the addition of modules/addons. Web Board (Forum) - Create a forum for you and your buddies to post, administer and share thoughts and ideas. CAPTCHA Maker - Ever see those images with letters a numbers when you signup for a service and then asks you to enter what you see? It keeps web bots from automatically signing up and spamming. Try creating one yourself for online forms. Files Quiz Maker - Make an application which takes various questions from a file, picked randomly, and puts together a quiz for students. Each quiz can be different and then reads a key to grade the quizzes. Sort Excel/CSV File Utility - Reads a file of records, sorts them, and then writes them back to the file. Allow the user to choose various sort style and sorting based on a particular field. Create Zip File Maker - The user enters various files from different directories and the program zips them up into a zip file. Optional: Apply actual compression to the files. Start with Huffman Algorithm. PDF Generator - An application which can read in a text file, html file or some other file and generates a PDF file out of it. Great for a web based service where the user uploads the file and the program returns a PDF of the file. Optional: Deploy on GAE or Heroku if possible. Mp3 Tagger - Modify and add ID3v1 tags to MP3 files. See if you can also add in the album art into the MP3 file\u00e2\u0080\u0099s header as well as other ID3v2 tags. Code Snippet Manager - Another utility program that allows coders to put in functions, classes or other tidbits to save for use later. Organized by the type of snippet or language the coder can quickly look up code. Optional: For extra practice try adding syntax highlighting based on the language. Databases SQL Query Analyzer - A utility application which a user can enter a query and have it run against a local database and look for ways to make it more efficient. Remote SQL Tool - A utility that can execute queries on remote servers from your local computer across the Internet. It should take in a remote host, user name and password, run the query and return the results. Report Generator - Create a utility that generates a report based on some tables in a database. Generates a sales reports based on the order/order details tables or sums up the days current database activity. Event Scheduler and Calendar - Make an application which allows the user to enter a date and time of an event, event notes and then schedule those events on a calendar. The user can then browse the calendar or search the calendar for specific events. Optional: Allow the application to create re-occurrence events that reoccur every day, week, month, year etc. Budget Tracker - Write an application that keeps track of a household\u00e2\u0080\u0099s budget. The user can add expenses, income, and recurring costs to find out how much they are saving or losing over a period of time. Optional: Allow the user to specify a date range and see the net flow of money in and out of the house budget for that time period. TV Show Tracker - Got a favorite show you don\u00e2\u0080\u0099t want to miss? Don\u00e2\u0080\u0099t have a PVR or want to be able to find the show to then PVR it later? Make an application which can search various online TV Guide sites, locate the shows/times/channels and add them to a database application. The database/website then can send you email reminders that a show is about to start and which channel it will be on. Travel Planner System - Make a system that allows users to put together their own little travel itinerary and keep track of the airline / hotel arrangements, points of interest, budget and schedule. Graphics and Multimedia Slide Show - Make an application that shows various pictures in a slide show format. Optional: Try adding various effects like fade in/out, star wipe and window blinds transitions. Stream Video from Online - Try to create your own online streaming video player. Mp3 Player - A simple program for playing your favorite music files. Add features you think are missing from your favorite music player. Watermarking Application - Have some pictures you want copyright protected? Add your own logo or text lightly across the background so that no one can simply steal your graphics off your site. Make a program that will add this watermark to the picture. Optional: Use threading to process multiple images simultaneously. Turtle Graphics - This is a common project where you create a floor of 20 x 20 squares. Using various commands you tell a turtle to draw a line on the floor. You have move forward, left or right, lift or drop pen etc. Do a search online for \"Turtle Graphics\" for more information. Optional: Allow the program to read in the list of commands from a file. GIF Creator A program that puts together multiple images (PNGs, JPGs, TIFFs) to make a smooth GIF that can be exported. Optional: Make the program convert small video files to GIFs as well. Security Caesar cipher - Implement a Caesar cipher, both encoding and decoding. The key is an integer from 1 to 25. This cipher rotates the letters of the alphabet (A to Z). The encoding replaces each letter with the 1st to 25th next letter in the alphabet (wrapping Z to A). So key 2 encrypts \"HI\" to \"JK\", but key 20 encrypts \"HI\" to \"BC\". This simple \"monoalphabetic substitution cipher\" provides almost no security, because an attacker who has the encoded message can either use frequency analysis to guess the key, or just try all 25 keys.","title":"Projects"},{"location":"Projects/#numbers","text":"Find PI to the Nth Digit - Enter a number and have the program generate PI up to that many decimal places. Keep a limit to how far the program will go. Find e to the Nth Digit - Just like the previous problem, but with e instead of PI. Enter a number and have the program generate e up to that many decimal places. Keep a limit to how far the program will go. Fibonacci Sequence - Enter a number and have the program generate the Fibonacci sequence to that number or to the Nth number. Prime Factorization - Have the user enter a number and find all Prime Factors (if there are any) and display them. Next Prime Number - Have the program find prime numbers until the user chooses to stop asking for the next one. Find Cost of Tile to Cover W x H Floor - Calculate the total cost of tile it would take to cover a floor plan of width and height, using a cost entered by the user. Mortgage Calculator - Calculate the monthly payments of a fixed term mortgage over given Nth terms at a given interest rate. Also figure out how long it will take the user to pay back the loan. For added complexity, add an option for users to select the compounding interval (Monthly, Weekly, Daily, Continually). Change Return Program - The user enters a cost and then the amount of money given. The program will figure out the change and the number of quarters, dimes, nickels, pennies needed for the change. Binary to Decimal and Back Converter - Develop a converter to convert a decimal number to binary or a binary number to its decimal equivalent. Calculator - A simple calculator to do basic operators. Make it a scientific calculator for added complexity. Unit Converter (temp, currency, volume, mass and more) - Converts various units between one another. The user enters the type of unit being entered, the type of unit they want to convert to and then the value. The program will then make the conversion. Alarm Clock - A simple clock where it plays a sound after X number of minutes/seconds or at a particular time. Distance Between Two Cities - Calculates the distance between two cities and allows the user to specify a unit of distance. This program may require finding coordinates for the cities like latitude and longitude. Credit Card Validator - Takes in a credit card number from a common credit card vendor (Visa, MasterCard, American Express, Discoverer) and validates it to make sure that it is a valid number (look into how credit cards use a checksum). Tax Calculator - Asks the user to enter a cost and either a country or state tax. It then returns the tax plus the total cost with tax. Factorial Finder - The Factorial of a positive integer, n, is defined as the product of the sequence n, n-1, n-2, ...1 and the factorial of zero, 0, is defined as being 1. Solve this using both loops and recursion. Complex Number Algebra - Show addition, multiplication, negation, and inversion of complex numbers in separate functions. (Subtraction and division operations can be made with pairs of these operations.) Print the results for each operation tested. Happy Numbers - A happy number is defined by the following process. Starting with any positive integer, replace the number by the sum of the squares of its digits, and repeat the process until the number equals 1 (where it will stay), or it loops endlessly in a cycle which does not include 1. Those numbers for which this process ends in 1 are happy numbers, while those that do not end in 1 are unhappy numbers. Display an example of your output here. Find first 8 happy numbers. Number Names - Show how to spell out a number in English. You can use a preexisting implementation or roll your own, but you should support inputs up to at least one million (or the maximum value of your language's default bounded integer type, if that's less). Optional: Support for inputs other than positive integers (like zero, negative integers, and floating-point numbers). Coin Flip Simulation - Write some code that simulates flipping a single coin however many times the user decides. The code should record the outcomes and count the number of tails and heads. Limit Calculator - Ask the user to enter f(x) and the limit value, then return the value of the limit statement Optional: Make the calculator capable of supporting infinite limits. Fast Exponentiation - Ask the user to enter 2 integers a and b and output a^b (i.e. pow(a,b)) in O(lg n) time complexity.","title":"Numbers"},{"location":"Projects/#classic-algorithms","text":"Collatz Conjecture - Start with a number n > 1. Find the number of steps it takes to reach one using the following process: If n is even, divide it by 2. If n is odd, multiply it by 3 and add 1. Sorting - Implement two types of sorting algorithms: Merge sort and bubble sort. Closest pair problem - The closest pair of points problem or closest pair problem is a problem of computational geometry: given n points in metric space, find a pair of points with the smallest distance between them. Sieve of Eratosthenes - The sieve of Eratosthenes is one of the most efficient ways to find all of the smaller primes (below 10 million or so).","title":"Classic Algorithms"},{"location":"Projects/#graph","text":"Graph from links - Create a program that will create a graph or network from a series of links. Eulerian Path - Create a program which will take as an input a graph and output either a Eulerian path or a Eulerian cycle, or state that it is not possible. A Eulerian Path starts at one node and traverses every edge of a graph through every node and finishes at another node. A Eulerian cycle is a eulerian Path that starts and finishes at the same node. Connected Graph - Create a program which takes a graph as an input and outputs whether every node is connected or not. Dijkstra\u00e2\u0080\u0099s Algorithm - Create a program that finds the shortest path through a graph using its edges. Minimum Spanning Tree - Create a program which takes a connected, undirected graph with weights and outputs the minimum spanning tree of the graph i.e., a subgraph that is a tree, contains all the vertices, and the sum of its weights is the least possible.","title":"Graph"},{"location":"Projects/#data-structures","text":"Inverted index - An Inverted Index is a data structure used to create full text search. Given a set of text files, implement a program to create an inverted index. Also create a user interface to do a search using that inverted index which returns a list of files that contain the query term / terms. The search index can be in memory.","title":"Data Structures"},{"location":"Projects/#text","text":"Fizz Buzz - Write a program that prints the numbers from 1 to 100. But for multiples of three print \u00e2\u0080\u009cFizz\u00e2\u0080\u009d instead of the number and for the multiples of five print \u00e2\u0080\u009cBuzz\u00e2\u0080\u009d. For numbers which are multiples of both three and five print \u00e2\u0080\u009cFizzBuzz\u00e2\u0080\u009d. Reverse a String - Enter a string and the program will reverse it and print it out. Pig Latin - Pig Latin is a game of alterations played on the English language game. To create the Pig Latin form of an English word the initial consonant sound is transposed to the end of the word and an ay is affixed (Ex.: \"banana\" would yield anana-bay). Read Wikipedia for more information on rules. Count Vowels - Enter a string and the program counts the number of vowels in the text. For added complexity have it report a sum of each vowel found. Check if Palindrome - Checks if the string entered by the user is a palindrome. That is that it reads the same forwards as backwards like \u00e2\u0080\u009cracecar\u00e2\u0080\u009d Count Words in a String - Counts the number of individual words in a string. For added complexity read these strings in from a text file and generate a summary. Text Editor - Notepad style application that can open, edit, and save text documents. Optional: Add syntax highlighting and other features. RSS Feed Creator - Given a link to RSS/Atom Feed, get all posts and display them. Quote Tracker (market symbols etc) - A program which can go out and check the current value of stocks for a list of symbols entered by the user. The user can set how often the stocks are checked. For CLI, show whether the stock has moved up or down. Optional: If GUI, the program can show green up and red down arrows to show which direction the stock value has moved. Guestbook / Journal - A simple application that allows people to add comments or write journal entries. It can allow comments or not and timestamps for all entries. Could also be made into a shout box. Optional: Deploy it on Google App Engine or Heroku or any other PaaS (if possible, of course). Vigenere / Vernam / Ceasar Ciphers - Functions for encrypting and decrypting data messages. Then send them to a friend. Regex Query Tool - A tool that allows the user to enter a text string and then in a separate control enter a regex pattern. It will run the regular expression against the source text and return any matches or flag errors in the regular expression. Networking FTP Program - A file transfer program which can transfer files back and forth from a remote web sever. Bandwidth Monitor - A small utility program that tracks how much data you have uploaded and downloaded from the net during the course of your current online session. See if you can find out what periods of the day you use more and less and generate a report or graph that shows it. Port Scanner - Enter an IP address and a port range where the program will then attempt to find open ports on the given computer by connecting to each of them. On any successful connections mark the port as open. Mail Checker (POP3 / IMAP) - The user enters various account information include web server and IP, protocol type (POP3 or IMAP) and the application will check for email at a given interval. Country from IP Lookup - Enter an IP address and find the country that IP is registered in. Optional: Find the Ip automatically. Whois Search Tool - Enter an IP or host address and have it look it up through whois and return the results to you. Site Checker with Time Scheduling - An application that attempts to connect to a website or server every so many minutes or a given time and check if it is up. If it is down, it will notify you by email or by posting a notice on screen. Classes Product Inventory Project - Create an application which manages an inventory of products. Create a product class which has a price, id, and quantity on hand. Then create an inventory class which keeps track of various products and can sum up the inventory value. Airline / Hotel Reservation System - Create a reservation system which books airline seats or hotel rooms. It charges various rates for particular sections of the plane or hotel. Example, first class is going to cost more than coach. Hotel rooms have penthouse suites which cost more. Keep track of when rooms will be available and can be scheduled. Company Manager - Create an hierarchy of classes - abstract class Employee and subclasses HourlyEmployee, SalariedEmployee, Manager and Executive. Every one's pay is calculated differently, research a bit about it. After you've established an employee hierarchy, create a Company class that allows you to manage the employees. You should be able to hire, fire and raise employees. Bank Account Manager - Create a class called Account which will be an abstract class for three other classes called CheckingAccount, SavingsAccount and BusinessAccount. Manage credits and debits from these accounts through an ATM style program. Patient / Doctor Scheduler - Create a patient class and a doctor class. Have a doctor that can handle multiple patients and setup a scheduling program where a doctor can only handle 16 patients during an 8 hr work day. Recipe Creator and Manager - Create a recipe class with ingredients and a put them in a recipe manager program that organizes them into categories like deserts, main courses or by ingredients like chicken, beef, soups, pies etc. Image Gallery - Create an image abstract class and then a class that inherits from it for each image type. Put them in a program which displays them in a gallery style format for viewing. Shape Area and Perimeter Classes - Create an abstract class called Shape and then inherit from it other shapes like diamond, rectangle, circle, triangle etc. Then have each class override the area and perimeter functionality to handle each shape type. Flower Shop Ordering To Go - Create a flower shop application which deals in flower objects and use those flower objects in a bouquet object which can then be sold. Keep track of the number of objects and when you may need to order more. Family Tree Creator - Create a class called Person which will have a name, when they were born and when (and if) they died. Allow the user to create these Person classes and put them into a family tree structure. Print out the tree to the screen. Threading Create A Progress Bar for Downloads - Create a progress bar for applications that can keep track of a download in progress. The progress bar will be on a separate thread and will communicate with the main thread using delegates. Bulk Thumbnail Creator - Picture processing can take a bit of time for some transformations. Especially if the image is large. Create an image program which can take hundreds of images and converts them to a specified size in the background thread while you do other things. For added complexity, have one thread handling re-sizing, have another bulk renaming of thumbnails etc. Web Page Scraper - Create an application which connects to a site and pulls out all links, or images, and saves them to a list. Optional: Organize the indexed content and don\u00e2\u0080\u0099t allow duplicates. Have it put the results into an easily searchable index file. Online White Board - Create an application which allows you to draw pictures, write notes and use various colors to flesh out ideas for projects. Optional: Add feature to invite friends to collaborate on a white board online. Get Atomic Time from Internet Clock - This program will get the true atomic time from an atomic time clock on the Internet. Use any one of the atomic clocks returned by a simple Google search. Fetch Current Weather - Get the current weather for a given zip/postal code. Optional: Try locating the user automatically. Scheduled Auto Login and Action - Make an application which logs into a given site on a schedule and invokes a certain action and then logs out. This can be useful for checking web mail, posting regular content, or getting info for other applications and saving it to your computer. E-Card Generator - Make a site that allows people to generate their own little e-cards and send them to other people. Do not use Flash. Use a picture library and perhaps insightful mottos or quotes. Content Management System - Create a content management system (CMS) like Joomla, Drupal, PHP Nuke etc. Start small. Optional: Allow for the addition of modules/addons. Web Board (Forum) - Create a forum for you and your buddies to post, administer and share thoughts and ideas. CAPTCHA Maker - Ever see those images with letters a numbers when you signup for a service and then asks you to enter what you see? It keeps web bots from automatically signing up and spamming. Try creating one yourself for online forms. Files Quiz Maker - Make an application which takes various questions from a file, picked randomly, and puts together a quiz for students. Each quiz can be different and then reads a key to grade the quizzes. Sort Excel/CSV File Utility - Reads a file of records, sorts them, and then writes them back to the file. Allow the user to choose various sort style and sorting based on a particular field. Create Zip File Maker - The user enters various files from different directories and the program zips them up into a zip file. Optional: Apply actual compression to the files. Start with Huffman Algorithm. PDF Generator - An application which can read in a text file, html file or some other file and generates a PDF file out of it. Great for a web based service where the user uploads the file and the program returns a PDF of the file. Optional: Deploy on GAE or Heroku if possible. Mp3 Tagger - Modify and add ID3v1 tags to MP3 files. See if you can also add in the album art into the MP3 file\u00e2\u0080\u0099s header as well as other ID3v2 tags. Code Snippet Manager - Another utility program that allows coders to put in functions, classes or other tidbits to save for use later. Organized by the type of snippet or language the coder can quickly look up code. Optional: For extra practice try adding syntax highlighting based on the language. Databases SQL Query Analyzer - A utility application which a user can enter a query and have it run against a local database and look for ways to make it more efficient. Remote SQL Tool - A utility that can execute queries on remote servers from your local computer across the Internet. It should take in a remote host, user name and password, run the query and return the results. Report Generator - Create a utility that generates a report based on some tables in a database. Generates a sales reports based on the order/order details tables or sums up the days current database activity. Event Scheduler and Calendar - Make an application which allows the user to enter a date and time of an event, event notes and then schedule those events on a calendar. The user can then browse the calendar or search the calendar for specific events. Optional: Allow the application to create re-occurrence events that reoccur every day, week, month, year etc. Budget Tracker - Write an application that keeps track of a household\u00e2\u0080\u0099s budget. The user can add expenses, income, and recurring costs to find out how much they are saving or losing over a period of time. Optional: Allow the user to specify a date range and see the net flow of money in and out of the house budget for that time period. TV Show Tracker - Got a favorite show you don\u00e2\u0080\u0099t want to miss? Don\u00e2\u0080\u0099t have a PVR or want to be able to find the show to then PVR it later? Make an application which can search various online TV Guide sites, locate the shows/times/channels and add them to a database application. The database/website then can send you email reminders that a show is about to start and which channel it will be on. Travel Planner System - Make a system that allows users to put together their own little travel itinerary and keep track of the airline / hotel arrangements, points of interest, budget and schedule. Graphics and Multimedia Slide Show - Make an application that shows various pictures in a slide show format. Optional: Try adding various effects like fade in/out, star wipe and window blinds transitions. Stream Video from Online - Try to create your own online streaming video player. Mp3 Player - A simple program for playing your favorite music files. Add features you think are missing from your favorite music player. Watermarking Application - Have some pictures you want copyright protected? Add your own logo or text lightly across the background so that no one can simply steal your graphics off your site. Make a program that will add this watermark to the picture. Optional: Use threading to process multiple images simultaneously. Turtle Graphics - This is a common project where you create a floor of 20 x 20 squares. Using various commands you tell a turtle to draw a line on the floor. You have move forward, left or right, lift or drop pen etc. Do a search online for \"Turtle Graphics\" for more information. Optional: Allow the program to read in the list of commands from a file. GIF Creator A program that puts together multiple images (PNGs, JPGs, TIFFs) to make a smooth GIF that can be exported. Optional: Make the program convert small video files to GIFs as well. Security Caesar cipher - Implement a Caesar cipher, both encoding and decoding. The key is an integer from 1 to 25. This cipher rotates the letters of the alphabet (A to Z). The encoding replaces each letter with the 1st to 25th next letter in the alphabet (wrapping Z to A). So key 2 encrypts \"HI\" to \"JK\", but key 20 encrypts \"HI\" to \"BC\". This simple \"monoalphabetic substitution cipher\" provides almost no security, because an attacker who has the encoded message can either use frequency analysis to guess the key, or just try all 25 keys.","title":"Text"},{"location":"android/","text":"Android Debug adb Issue: no permission Root Magisk Android # Debug # adb # Issue: no permission # When i try: adb devices i get the result: List of devices attached ???????????? no permissions Then I tried to restart the Adb server sudo adb kill-server and then sudo adb start-server then connected the device, turn Debugging on and type adb devices Still any issue? then follow this Root # Magisk # Source: - https://www.didgeridoohan.com/magisk if failing to flash .zip (due to signature verification) --> uncheck sign verification before flash","title":"Android"},{"location":"android/#android","text":"","title":"Android"},{"location":"android/#debug","text":"","title":"Debug"},{"location":"android/#adb","text":"","title":"adb"},{"location":"android/#issue-no-permission","text":"When i try: adb devices i get the result: List of devices attached ???????????? no permissions Then I tried to restart the Adb server sudo adb kill-server and then sudo adb start-server then connected the device, turn Debugging on and type adb devices Still any issue? then follow this","title":"Issue: no permission"},{"location":"android/#root","text":"","title":"Root"},{"location":"android/#magisk","text":"Source: - https://www.didgeridoohan.com/magisk if failing to flash .zip (due to signature verification) --> uncheck sign verification before flash","title":"Magisk"},{"location":"linux/","text":"Bash Scripting AWK include/source/import String Comparison Sub-String Comparison If, elif, else, fi Switch Case UNIX Commands mv all files/dir to a subdir Get System Informations Set deafult shell xclip ls prefixed commands find Set hostname 1. at /etc/hosts 2. at /etc/hostname 3. then tell the machine CPU Info CPU Temperature IP Related ssh In case of AWS EC2 SSH sftp sshfs Device connected to the Network dd (Disk Dump) commands Create a backup Restore a backup Clone a hard disk Transfer a disk image Create an iso image of a CD/DVD Burn an iso image of a CD/DVD Rescue a file that contains bad blocks Create your own bootloader Create a backup of your MBR Restore a backup of your MBR Mount dd image of and entire disk When the hard disk has errors Network Clone Network speed test Links Task Autorun/Automation Daemons Shells Graphical Cron Jobs Intro Syntax Operations Type Operators misc Services .desktop file using /etc/rc.local using /etc/init.d Disk Related fdisk lsblk blkid df du GRUB Edit grub configs grub update Reboot into other OS Problems & Solutions Make Anaconda Python Default If cinnamon freezes sudo: unable to resolve host Ray: Connection timed out nemo context menu \"open in terminal\" not working Speedup mouse scroll Utilities Multitouch Gesture Battery Monitor Battery Optimization SATA Power Management PowerTop by Intel (Recommanded) TLP (Emergency) Mono Install Verify Thinkpad Touchpad Middle Button Install Config Finger Print Reader Installation Uninstallation ZSH oh-my-zsh VIM Vundle Using Vundle VIM as Python IDE Tmux Tmux Package Manager Tmux Plugins: Commands Load .bashrc with tmux KeyBoard Custom Shortcuts Bindings Emulate right click from keyboard Backup & Restore Cinnamon settings Raspberry Pi OS Raspbian with RPD Desktop Raspbian Lite (without GUI) Install Desktop for Lite Enable ssh & enter SSID/WiFi details without keyboard Ubuntu Core/Snap Windows IoT Display Touch Screeen Config Backup Image from Burnt Image On a different linux PC using USB. In Raspberry Itself using rsync Network Drive Mount (sshfs) Remote Audio bluetooth Way 1 Way 2 wifi enable ssh from card set wifi/ssid from card wifi to ethernet Bash Scripting # AWK # https://www.gnu.org/software/gawk/manual/gawk.html include/source/import # https://gist.github.com/toransahu/0a816af786b7d0b98ab1e7079bf0426f String Comparison # use = or == keep proper square spacing between operators & brackets (most imp) use double quote for strings and variables sometime we need to use brackets to access env variables https://gist.github.com/toransahu/4fd3abc369bb5c8a1ee424af07cb1563 Sub-String Comparison # string = \" $( hostname ) \" substr = \"mint\" if [ -z \" ${ string ##* $substr * } \" ] ; then https://gist.github.com/toransahu/f812260a37947a299c5c26adddfa4cfa If, elif, else, fi # Source: https://ryanstutorials.net/bash-scripting-tutorial/bash-if-statements.php Switch Case # https://www.shellscript.sh/case.html UNIX Commands # mv all files/dir to a subdir # BASH https://askubuntu.com/questions/91740/how-to-move-all-files-in-current-folder-to-subfolder TODO: zsh setopt extended_glob mv Get System Informations # Set deafult shell # sudo chsh -s /bin/zsh then logout In Github:linux-tweaks/guides xclip # xclip -sel clip <file> ls prefixed commands # ls lsA lsblk lscpu lshw lsipc lslogins lsof lspcmcia lss16toppm lsusb lsa lsattr lsb_release lsdiff lsinitramfs lslocks lsmod lspci lspgpot lss3 find # find <dir> <type> <test> <expression> <action> find /Ray/ -type f -name \"*.pyc\" -delete Set hostname # 1. at /etc/hosts # 127.0.1.1 mint-ThinkPad-L440 2. at /etc/hostname # write mint-ThinkPad-L440 3. then tell the machine # sudo hostname mint-ThinkPad-L440 CPU Info # cat flags /proc/cpuinfo CPU Temperature # sudo apt-get install lm-sensors After installation type the following in terminal sudo sensors-detect You may also need to run sudo service kmod start It will ask you few questions. Answer Yes for all of them. Finally to get your CPU temperature type sensors in your terminal. sensors IP Related # ifconfig ip addr hostname -I ssh # ssh pi@192.168.1.108 In case of AWS EC2 SSH # Connection freezes frequently on inactivity - source https://www.quora.com/Why-does-ssh-to-amazon-ec2-instance-gets-frozen-after-sometime - Solution - sudo vim /etc/ssh/ssh_config - add TCPKeepAlive yes - add ServerAliveInterval 5 where 5 is minute - sudo service sshd restart sftp # sftp pi@192.168.1.108 put local_file get remote_file files will upload/download @ home sshfs # sudo mkdir /mnt/pi sudo sshfs -o allow_other pi@192.168.1.108:/ /mnt/pi/ Device connected to the Network # nmap -sP 192 .168.1.0/24 dd (Disk Dump) commands # Create a backup # dd if=/dev/sda of=/opt/backup_sda.img Restore a backup # dd if=/opt/backup_sda.img of=/dev/sda Clone a hard disk # dd if=/dev/sdb of=/dev/sdc Transfer a disk image # dd if=/dev/sdb | ssh root@target \"(cat > backup.img)\" Create an iso image of a CD/DVD # dd if=/dev/cdrom of=cdimage.iso Burn an iso image of a CD/DVD # dd if=cdimage.iso of=/dev/cdrom obs=32k seek=0 Rescue a file that contains bad blocks # dd if=movie.avi of=rescued_movie.avi conv=noerror Create your own bootloader # dd conv=notrunc if=bootloader of=qemu.img Create a backup of your MBR # dd if=/dev/sdb of=mbr_backup bs=512 count=1 Restore a backup of your MBR # dd if=mbr_backup of=/dev/sdb bs=512 count=1 Mount dd image of and entire disk # You must use the start number of the partition. fdisk -u -l disk_image Disk /mnt/storage/disk_image: 0 MB, 0 bytes255 heads, 63 sectors/track, 0 cylinders, total 0 sectors Units = sectors of 1 * 512 = 512 bytesDisk identifier: 0x41172ba5 Device Boot Start End Blocks Id System /mnt/storage/disk_image1 63 64259 32098 + de Dell Utility /mnt/storage/disk_image2 * 64260 78108029 39021885 7 HPFS/NTFS Partition 2 has different physical/logical endings:phys =( 1023 , 254 , 63 ) logical =( 4861 , 254 , 63 ) Then take the start of the partition that you want to edit, 64260 (disk_image2) in this case, and multiply it by 512 Ex: 512 * 64260 = 32901120 mount -o loop,offset=32901120 -t auto /mnt/storage/disk_image /mnt/image_partition_2 When the hard disk has errors # Get the dd_rescue tool dd_rescue /dev/sdb /opt/backup_sdb.img Network Clone # Destination: nc -l -p 2222 | dd of=/dev/sda bs=16M Source: dd if=/dev/sda bs=16M | nc Destination 2222 Network speed test # dd if=/dev/zero bs=1M count=100 | ssh user@machine 'cat > /dev/null' Links # Symbolic link ln -s original link Hard Link ln original link Task Autorun/Automation # src1 : https://developer.toradex.com/knowledge-base/how-to-autorun-application-at-the-start-up-in-linux Daemons # Shells # Graphical # Cron Jobs # Intro # The cron service (daemon) runs in the background and constantly checks the /etc/crontab file, and /etc/cron.*/ directories. It also checks the /var/spool/cron/ directory. Source create cron job crontab -e and edit the opened file add your task (in cron format) or, create a new cron job under /etc/cron.*/ add your task (in cron format) Syntax # SHELL = /bin/bash PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin MAILTO = \"\" 1 2 3 4 5 /path/to/command arg1 arg2 # or 1 2 3 4 5 /root/backup.sh ` to automate tasks based on time like on boot: @reboot hourly: @hourly or \u201c0 * * \u201d daily : @daily or @midnight or \u201c0 0 * \u201d weekly: @weekly or \u201c0 0 * * 0\u201d monthly: @monthly or \u201c0 0 1 * *\u201d yearly: @yearly or @annually or \u201c0 0 1 1 *\u201d command to be executed | | | | | | | | | ----- Day of week (0 - 7) (Sunday=0 or 7) | | | ------- Month (1 - 12) | | --------- Day of month (1 - 31) | ----------- Hour (0 - 23) ------------- Minute (0 - 59) Operations # start: sudo service cron start stop: sudo service cron stop restart: sudo service cron restart status: sudo service cron status list: crontab -l or crontab -u USERNAME -l delete all: crontab -r or crontab -u USERNAME -r Type # System Level need to define USERNAME 1 2 3 4 5 USERNAME /path/to/command arg1 arg2 User Level by default takes USERNAME of creator 1 2 3 4 5 /path/to/command arg1 arg2 Operators # asterisk (*) every [minute/hour/day/month/day of week] comma (,) list of values like, on this days: 1,2,3,4,5 dash (-) range like, on this days: 1-5 seperator (/) stepper like, */2 in hour field means: every 2 hours misc # print names of all valid files: run-parts --list /etc/cron.d print script names which would run, but don't run them: run-parts --test /etc/cron.d Services # .desktop file # Works on boot put .desktop file with some script in ~/.config/autostart/ write script like [ Desktop Entry ] Type = Application Exec = sh /home/toran/Applications/linux_tweaks/LowBatterySound/LowBattery.sh X-GNOME-Autostart-enabled = false NoDisplay = false Hidden = false Name [ en_IN ]= Low Battery Warning Comment [ en_IN ]= Warning sound on battery less than 15 % X-GNOME-Autostart-Delay = 20 using /etc/rc.local # using /etc/init.d # Disk Related # fdisk # manupulate disk partition table list devices: sudo fdisk -l lsblk # lists block devices blkid # locate/ print block device attributes df # reports filesystem disk space usage du # estimate file space usage Summarize disk usage of the set of FILEs, recursively for directories. GRUB # Edit grub configs # vim /etc/default/grub grub update # sudo update-grub Reboot into other OS # sudo grub-reboot 2 Problems & Solutions # Make Anaconda Python Default # put following in .bashrc or .zshrc # added by Anaconda3 installer export PATH=\"/home/toran/anaconda3/bin:$PATH\" If cinnamon freezes # go to tty0 or tty1 using Alt + Ctrl + F1 or F2 login type w and enter look under FROM column, where row is related to cinnamon session note the value for that cell, in my case its :0 (with colon) note type export DISPLAY=:0 cinnamon & and enter sudo: unable to resolve host Ray: Connection timed out # Two things to check (assuming your machine is called my-machine, you can change this as appropriate): That the /etc/hostname file contains just the name of the machine. That /etc/hosts has an entry for localhost. It should have something like: 127 .0.0.1 localhost.localdomain localhost 127 .0.1.1 my-machine - If either of these files aren't correct (since you can't sudo), you may have to reboot the machine into recovery mode and make the modifications, then reboot to your usual environment. nemo context menu \"open in terminal\" not working # source: https://forums.linuxmint.com/viewtopic.php?t=204933 gsettings set org.cinnamon.desktop.default-applications.terminal exec mate-terminal Speedup mouse scroll # Source: https://forums.linuxmint.com/viewtopic.php?t=221526 sudo apt install imwheel then use mousewheel.sh to adjust the speed. Utilities # Multitouch Gesture # src: https://github.com/toransahu/libinput-gestures - by bulletmark sudo gpasswd -a toran input sudo apt-get install xdotool wmctrl libinput-tools git clone http://github.com/toransahu/libinput-gestures cd libinput-gestures sudo ./libinput-gestures-setup install cd ~/libinput-gestures #edit the created libinput-gestures.conf: vim libinput-gestures.conf #set following: gesture swipe down xdotool key ctrl+alt+Up gesture swipe up xdotool key ctrl+alt+Down gesture swipe right xdotool key ctrl+super+Left gesture swipe left xdotool key ctrl+super+Right sudo make install (or sudo ./libinput-gestures-setup install) libinput-gestures-setup autostart libinput-gestures-setup start Battery Monitor # Source: http://battery-monitor.maateen.me/ Battery Optimization # SATA Power Management # source: https://askubuntu.com/questions/809127/how-to-turn-off-one-of-sata-hdds-installed-in-the-computer-to-save-power Using hdparm utility. It allows you to control your hard drives' power settings, apart from benchmarking and other stuff. put the disk into standby mode whenever you access the disk, it should automatically wake up and work back again hdparm -y /dev/sdX deeper resting mode may need to restart your computer in order to make the HDD work again hdparm -Y /dev/sdX PowerTop by Intel (Recommanded) # sudo apt-get update sudo apt-get install powertop sudo powertop --auto-tune sudo powertop --calibrate TLP (Emergency) # Source: https://linrunner.de/en/tlp/docs/tlp-linux-advanced-power-management.html sudo apt install tlp #restart #or sudo tlp start Mono # Install # https://www.mono-project.com/download/stable/#download-lin Verify # Source: https://www.mono-project.com/docs/getting-started/mono-basics/ Scripts: Thinkpad Touchpad Middle Button # Install # sudo apt install xserver-xorg-input-libinput Config # restart alter touchpad setting and choose use multiple fingers in click actions Finger Print Reader # src: https://launchpad.net/~fingerprint/+archive/ubuntu/fingerprint-gui Installation # First of all, if you have installed Fingerprint GUI manually before, get rid of it completely. Remove all binaries, shared libraries, any other files and undo all the changes you have made to your system config files (especially to files under /etc/pam.d/). Add this PPA to your sources: sudo add-apt-repository ppa:fingerprint/fingerprint-gui sudo apt-get update Install the packages: sudo apt-get install libbsapi policykit-1-fingerprint-gui fingerprint-gui Log out of your session and log back in (we need the new session defaults to be picked up). Uninstallation # sudo apt-get install policykit-1-gnome sudo apt-get remove fingerprint-gui ZSH # sudo apt install zsh oh-my-zsh # sh -c \" $( curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh ) \" #OR sh -c \" $( wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O - ) \" VIM # Vundle # VIM plugin manager (VIM + Bundle) install from : https://github.com/VundleVim/Vundle.vim i.e. git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim Using Vundle # Mention bundle names (as a github repo) in .vimrc file Plugin 'VundleVim/Vundle.vim' Plugin 'morhetz/gruvbox' Plugin 'itchyny/lightline.vim' Plugin 'itchyny/vim-gitbranch' Plugin 'scrooloose/nerdtree.git' Plugin 'aperezdc/vim-template' Plugin 'davidhalter/jedi-vim' Plugin 'editorconfig/editorconfig-vim' Plugin 'tpope/vim-abolish' Install using command :PluginInstall VIM as Python IDE # Source: http://chrisstrelioff.ws/sandbox/2016/09/21/vim_and_vundle_on_ubuntu_16_04.html ~/.vimrc & ~/.editorconfig config files @ https://gist.github.com/toransahu/66c69903649f3d417d8ba4dc78324f60 cheat sheet: https://gist.github.com/toransahu/4a921c6fb73274479dbdfbcfe6dda483 Tmux # Tmux Package Manager # Source: https://github.com/tmux-plugins/tpm ~/.tmux.conf : https://gist.github.com/toransahu/53a523d973a212f52ce53474417e01b1 Tmux Plugins: # Sidebar: https://tmuxcheatsheet.com/tmux-plugins-tools/?full_name=tmux-plugins%2Ftmux-sidebar Commands # abbr. prefix: ctrl + b help: ctrl + b ? select, copy, paste within tmux enter scroll mode: ctrl + b [ enter select mode: ctrl + space move cursor to select text copy to tmux buffer: alt + w copy to system clip: ctrl + b - y paste to any tmux: ctrl + b ] create/split pane vertical split: prefix % hor split: prefix \" convert a pane to window: prefix ! move to pane: prefix arrows close current pane: prefix x Load .bashrc with tmux # By default tmux runs a login shell. When bash is invoked as an interactive login shell, it looks for ~/.bash_profile, ~/.bash_login, and ~/.profile. So you have to put source ~/.bashrc in one of those files. Another way to solve this issue is to put in your file .tmux.conf the line: set-option -g default-shell \"/bin/bash\" KeyBoard Custom Shortcuts Bindings # Emulate right click from keyboard # install xdotool sudo apt install xdotool bind keyboard shortcut with command: xdotool click 3 Backup & Restore Cinnamon settings # sudo apt install dconf-cli #backup dconf dump /org/cinnamon/ > cinnamon_backup #restore dconf load /org/cinnamon/ < cinnamon_backup #reset to default dconf reset -f /org/cinnamon/ Raspberry Pi # OS # Raspbian with RPD Desktop # prepare https://www.raspberrypi.org/forums/viewtopic.php?t=135316 Raspbian Lite (without GUI) # Install Desktop for Lite # Source: https://www.raspberrypi.org/forums/viewtopic.php?t=133691 Enable ssh & enter SSID/WiFi details without keyboard # Source: https://medium.com/@danidudas/install-raspbian-jessie-lite-and-setup-wi-fi-without-access-to-command-line-or-using-the-network-97f065af722e Ubuntu Core/Snap # Windows IoT # Display # Touch Screeen Config # 5 inch capacitive 800*480 /boot/config.txt framebuffer_width = 800 framebuffer_height = 480 hdmi_force_hotplug = 1 hdmi_group = 2 hdmi_mode = 87 hdmi_cvt 800 480 60 6 0 0 0 Backup Image from Burnt Image # On a different linux PC using USB. # It won't work on the raspi!, it will get trapped in infinit loop #list disk sudo fdisk -l #backup SD card sudo dd bs = 4M if = /dev/sdb | gzip > /home/your_username/image ` date +%d%m%y ` .gz #restore the backup on SD card sudo gzip -dc /home/your_username/image.gz | dd bs = 4M of = /dev/sdb In Raspberry Itself using rsync # Network Drive Mount (sshfs) # #Install SSHFS sudo apt-get install sshfs #First, create a directory on your host computer: mkdir pi #Then mount the Raspberry Pi's filesystem to this location: sudo sshfs -o allow_other pi@192.168.1.124:/ pi #Now enter this directory as if it is a regular folder; you should be able to see and access the contents of the Raspberry Pi: cd pi/ ls Remote Audio # bluetooth # Way 1 # sudo apt-get install bluetooth blueman bluez python-gobject python-gobject-2 pulseaudio-module-bluetooth sudo systemctl status bluetooth pulseaudio --start https://gist.github.com/mill1000/74c7473ee3b4a5b13f6325e9994ff84c https://raspberrypi.stackexchange.com/questions/48140/raspberry-pi-3-connecting-to-bluetooth-audio-device-on-raspbian-jessie https://markus.jarvisalo.dy.fi/2017/12/making-the-raspberry-pi-3-a-bluetooth-audio-receiver/ Way 2 # https://www.instructables.com/id/Turn-your-Raspberry-Pi-into-a-Portable-Bluetooth-A/ $ sudo vim /var/lib/bluetooth/00:1A:7D:DA:71:11/config wifi # shareport https://thepi.io/how-to-set-up-a-raspberry-pi-airplay-receiver/ enable ssh from card # put empty ssh file inside /boot/ set wifi/ssid from card # change inside /etc/network/interface auto lo iface lo inet loopback iface eth0 inet dhcp allow-hotplug wlan0 auto wlan0 iface wlan0 inet dhcp wpa-ssid \"Connecting...\" wpa-psk \"PrideValencia_A704\" wifi to ethernet # src: https://www.instructables.com/id/Share-WiFi-With-Ethernet-Port-on-a-Raspberry-Pi/ sudo apt install dnsmasq -y cd wget https://raw.githubusercontent.com/arpitjindal97/raspbian-recipes/master/wifi-to-eth-route.sh chmod +x ~/wifi-to-eth-route.sh sudo crontab -e @reboot bash /home/pi/wifi-to-eth-route.sh & # add it to crontab file","title":"Linux"},{"location":"linux/#bash-scripting","text":"","title":"Bash Scripting"},{"location":"linux/#awk","text":"https://www.gnu.org/software/gawk/manual/gawk.html","title":"AWK"},{"location":"linux/#includesourceimport","text":"https://gist.github.com/toransahu/0a816af786b7d0b98ab1e7079bf0426f","title":"include/source/import"},{"location":"linux/#string-comparison","text":"use = or == keep proper square spacing between operators & brackets (most imp) use double quote for strings and variables sometime we need to use brackets to access env variables https://gist.github.com/toransahu/4fd3abc369bb5c8a1ee424af07cb1563","title":"String Comparison"},{"location":"linux/#sub-string-comparison","text":"string = \" $( hostname ) \" substr = \"mint\" if [ -z \" ${ string ##* $substr * } \" ] ; then https://gist.github.com/toransahu/f812260a37947a299c5c26adddfa4cfa","title":"Sub-String Comparison"},{"location":"linux/#if-elif-else-fi","text":"Source: https://ryanstutorials.net/bash-scripting-tutorial/bash-if-statements.php","title":"If, elif, else, fi"},{"location":"linux/#switch-case","text":"https://www.shellscript.sh/case.html","title":"Switch Case"},{"location":"linux/#unix-commands","text":"","title":"UNIX Commands"},{"location":"linux/#mv-all-filesdir-to-a-subdir","text":"BASH https://askubuntu.com/questions/91740/how-to-move-all-files-in-current-folder-to-subfolder TODO: zsh setopt extended_glob mv","title":"mv all files/dir to a subdir"},{"location":"linux/#get-system-informations","text":"","title":"Get System Informations"},{"location":"linux/#set-deafult-shell","text":"sudo chsh -s /bin/zsh then logout In Github:linux-tweaks/guides","title":"Set deafult shell"},{"location":"linux/#xclip","text":"xclip -sel clip <file>","title":"xclip"},{"location":"linux/#ls-prefixed-commands","text":"ls lsA lsblk lscpu lshw lsipc lslogins lsof lspcmcia lss16toppm lsusb lsa lsattr lsb_release lsdiff lsinitramfs lslocks lsmod lspci lspgpot lss3","title":"ls prefixed commands"},{"location":"linux/#find","text":"find <dir> <type> <test> <expression> <action> find /Ray/ -type f -name \"*.pyc\" -delete","title":"find"},{"location":"linux/#set-hostname","text":"","title":"Set hostname"},{"location":"linux/#1-at-etchosts","text":"127.0.1.1 mint-ThinkPad-L440","title":"1. at /etc/hosts"},{"location":"linux/#2-at-etchostname","text":"write mint-ThinkPad-L440","title":"2. at /etc/hostname"},{"location":"linux/#3-then-tell-the-machine","text":"sudo hostname mint-ThinkPad-L440","title":"3. then tell the machine"},{"location":"linux/#cpu-info","text":"cat flags /proc/cpuinfo","title":"CPU Info"},{"location":"linux/#cpu-temperature","text":"sudo apt-get install lm-sensors After installation type the following in terminal sudo sensors-detect You may also need to run sudo service kmod start It will ask you few questions. Answer Yes for all of them. Finally to get your CPU temperature type sensors in your terminal. sensors","title":"CPU Temperature"},{"location":"linux/#ip-related","text":"ifconfig ip addr hostname -I","title":"IP Related"},{"location":"linux/#ssh","text":"ssh pi@192.168.1.108","title":"ssh"},{"location":"linux/#in-case-of-aws-ec2-ssh","text":"Connection freezes frequently on inactivity - source https://www.quora.com/Why-does-ssh-to-amazon-ec2-instance-gets-frozen-after-sometime - Solution - sudo vim /etc/ssh/ssh_config - add TCPKeepAlive yes - add ServerAliveInterval 5 where 5 is minute - sudo service sshd restart","title":"In case of AWS EC2 SSH"},{"location":"linux/#sftp","text":"sftp pi@192.168.1.108 put local_file get remote_file files will upload/download @ home","title":"sftp"},{"location":"linux/#sshfs","text":"sudo mkdir /mnt/pi sudo sshfs -o allow_other pi@192.168.1.108:/ /mnt/pi/","title":"sshfs"},{"location":"linux/#device-connected-to-the-network","text":"nmap -sP 192 .168.1.0/24","title":"Device connected to the Network"},{"location":"linux/#dd-disk-dump-commands","text":"","title":"dd (Disk Dump) commands"},{"location":"linux/#create-a-backup","text":"dd if=/dev/sda of=/opt/backup_sda.img","title":"Create a backup"},{"location":"linux/#restore-a-backup","text":"dd if=/opt/backup_sda.img of=/dev/sda","title":"Restore a backup"},{"location":"linux/#clone-a-hard-disk","text":"dd if=/dev/sdb of=/dev/sdc","title":"Clone a hard disk"},{"location":"linux/#transfer-a-disk-image","text":"dd if=/dev/sdb | ssh root@target \"(cat > backup.img)\"","title":"Transfer a disk image"},{"location":"linux/#create-an-iso-image-of-a-cddvd","text":"dd if=/dev/cdrom of=cdimage.iso","title":"Create an iso image of a CD/DVD"},{"location":"linux/#burn-an-iso-image-of-a-cddvd","text":"dd if=cdimage.iso of=/dev/cdrom obs=32k seek=0","title":"Burn an iso image of a CD/DVD"},{"location":"linux/#rescue-a-file-that-contains-bad-blocks","text":"dd if=movie.avi of=rescued_movie.avi conv=noerror","title":"Rescue a file that contains bad blocks"},{"location":"linux/#create-your-own-bootloader","text":"dd conv=notrunc if=bootloader of=qemu.img","title":"Create your own bootloader"},{"location":"linux/#create-a-backup-of-your-mbr","text":"dd if=/dev/sdb of=mbr_backup bs=512 count=1","title":"Create a backup of your MBR"},{"location":"linux/#restore-a-backup-of-your-mbr","text":"dd if=mbr_backup of=/dev/sdb bs=512 count=1","title":"Restore a backup of your MBR"},{"location":"linux/#mount-dd-image-of-and-entire-disk","text":"You must use the start number of the partition. fdisk -u -l disk_image Disk /mnt/storage/disk_image: 0 MB, 0 bytes255 heads, 63 sectors/track, 0 cylinders, total 0 sectors Units = sectors of 1 * 512 = 512 bytesDisk identifier: 0x41172ba5 Device Boot Start End Blocks Id System /mnt/storage/disk_image1 63 64259 32098 + de Dell Utility /mnt/storage/disk_image2 * 64260 78108029 39021885 7 HPFS/NTFS Partition 2 has different physical/logical endings:phys =( 1023 , 254 , 63 ) logical =( 4861 , 254 , 63 ) Then take the start of the partition that you want to edit, 64260 (disk_image2) in this case, and multiply it by 512 Ex: 512 * 64260 = 32901120 mount -o loop,offset=32901120 -t auto /mnt/storage/disk_image /mnt/image_partition_2","title":"Mount dd image of and entire disk"},{"location":"linux/#when-the-hard-disk-has-errors","text":"Get the dd_rescue tool dd_rescue /dev/sdb /opt/backup_sdb.img","title":"When the hard disk has errors"},{"location":"linux/#network-clone","text":"Destination: nc -l -p 2222 | dd of=/dev/sda bs=16M Source: dd if=/dev/sda bs=16M | nc Destination 2222","title":"Network Clone"},{"location":"linux/#network-speed-test","text":"dd if=/dev/zero bs=1M count=100 | ssh user@machine 'cat > /dev/null'","title":"Network speed test"},{"location":"linux/#links","text":"Symbolic link ln -s original link Hard Link ln original link","title":"Links"},{"location":"linux/#task-autorunautomation","text":"src1 : https://developer.toradex.com/knowledge-base/how-to-autorun-application-at-the-start-up-in-linux","title":"Task Autorun/Automation"},{"location":"linux/#daemons","text":"","title":"Daemons"},{"location":"linux/#shells","text":"","title":"Shells"},{"location":"linux/#graphical","text":"","title":"Graphical"},{"location":"linux/#cron-jobs","text":"","title":"Cron Jobs"},{"location":"linux/#intro","text":"The cron service (daemon) runs in the background and constantly checks the /etc/crontab file, and /etc/cron.*/ directories. It also checks the /var/spool/cron/ directory. Source create cron job crontab -e and edit the opened file add your task (in cron format) or, create a new cron job under /etc/cron.*/ add your task (in cron format)","title":"Intro"},{"location":"linux/#syntax","text":"SHELL = /bin/bash PATH = /usr/local/sbin:/usr/local/bin:/sbin:/bin:/usr/sbin:/usr/bin MAILTO = \"\" 1 2 3 4 5 /path/to/command arg1 arg2 # or 1 2 3 4 5 /root/backup.sh ` to automate tasks based on time like on boot: @reboot hourly: @hourly or \u201c0 * * \u201d daily : @daily or @midnight or \u201c0 0 * \u201d weekly: @weekly or \u201c0 0 * * 0\u201d monthly: @monthly or \u201c0 0 1 * *\u201d yearly: @yearly or @annually or \u201c0 0 1 1 *\u201d command to be executed | | | | | | | | | ----- Day of week (0 - 7) (Sunday=0 or 7) | | | ------- Month (1 - 12) | | --------- Day of month (1 - 31) | ----------- Hour (0 - 23) ------------- Minute (0 - 59)","title":"Syntax"},{"location":"linux/#operations","text":"start: sudo service cron start stop: sudo service cron stop restart: sudo service cron restart status: sudo service cron status list: crontab -l or crontab -u USERNAME -l delete all: crontab -r or crontab -u USERNAME -r","title":"Operations"},{"location":"linux/#type","text":"System Level need to define USERNAME 1 2 3 4 5 USERNAME /path/to/command arg1 arg2 User Level by default takes USERNAME of creator 1 2 3 4 5 /path/to/command arg1 arg2","title":"Type"},{"location":"linux/#operators","text":"asterisk (*) every [minute/hour/day/month/day of week] comma (,) list of values like, on this days: 1,2,3,4,5 dash (-) range like, on this days: 1-5 seperator (/) stepper like, */2 in hour field means: every 2 hours","title":"Operators"},{"location":"linux/#misc","text":"print names of all valid files: run-parts --list /etc/cron.d print script names which would run, but don't run them: run-parts --test /etc/cron.d","title":"misc"},{"location":"linux/#services","text":"","title":"Services"},{"location":"linux/#desktop-file","text":"Works on boot put .desktop file with some script in ~/.config/autostart/ write script like [ Desktop Entry ] Type = Application Exec = sh /home/toran/Applications/linux_tweaks/LowBatterySound/LowBattery.sh X-GNOME-Autostart-enabled = false NoDisplay = false Hidden = false Name [ en_IN ]= Low Battery Warning Comment [ en_IN ]= Warning sound on battery less than 15 % X-GNOME-Autostart-Delay = 20","title":".desktop file"},{"location":"linux/#using-etcrclocal","text":"","title":"using /etc/rc.local"},{"location":"linux/#using-etcinitd","text":"","title":"using /etc/init.d"},{"location":"linux/#disk-related","text":"","title":"Disk Related"},{"location":"linux/#fdisk","text":"manupulate disk partition table list devices: sudo fdisk -l","title":"fdisk"},{"location":"linux/#lsblk","text":"lists block devices","title":"lsblk"},{"location":"linux/#blkid","text":"locate/ print block device attributes","title":"blkid"},{"location":"linux/#df","text":"reports filesystem disk space usage","title":"df"},{"location":"linux/#du","text":"estimate file space usage Summarize disk usage of the set of FILEs, recursively for directories.","title":"du"},{"location":"linux/#grub","text":"","title":"GRUB"},{"location":"linux/#edit-grub-configs","text":"vim /etc/default/grub","title":"Edit grub configs"},{"location":"linux/#grub-update","text":"sudo update-grub","title":"grub update"},{"location":"linux/#reboot-into-other-os","text":"sudo grub-reboot 2","title":"Reboot into other OS"},{"location":"linux/#problems-solutions","text":"","title":"Problems &amp; Solutions"},{"location":"linux/#make-anaconda-python-default","text":"put following in .bashrc or .zshrc # added by Anaconda3 installer export PATH=\"/home/toran/anaconda3/bin:$PATH\"","title":"Make Anaconda Python Default"},{"location":"linux/#if-cinnamon-freezes","text":"go to tty0 or tty1 using Alt + Ctrl + F1 or F2 login type w and enter look under FROM column, where row is related to cinnamon session note the value for that cell, in my case its :0 (with colon) note type export DISPLAY=:0 cinnamon & and enter","title":"If cinnamon freezes"},{"location":"linux/#sudo-unable-to-resolve-host-ray-connection-timed-out","text":"Two things to check (assuming your machine is called my-machine, you can change this as appropriate): That the /etc/hostname file contains just the name of the machine. That /etc/hosts has an entry for localhost. It should have something like: 127 .0.0.1 localhost.localdomain localhost 127 .0.1.1 my-machine - If either of these files aren't correct (since you can't sudo), you may have to reboot the machine into recovery mode and make the modifications, then reboot to your usual environment.","title":"sudo: unable to resolve host Ray: Connection timed out"},{"location":"linux/#nemo-context-menu-open-in-terminal-not-working","text":"source: https://forums.linuxmint.com/viewtopic.php?t=204933 gsettings set org.cinnamon.desktop.default-applications.terminal exec mate-terminal","title":"nemo context menu \"open in terminal\" not working"},{"location":"linux/#speedup-mouse-scroll","text":"Source: https://forums.linuxmint.com/viewtopic.php?t=221526 sudo apt install imwheel then use mousewheel.sh to adjust the speed.","title":"Speedup mouse scroll"},{"location":"linux/#utilities","text":"","title":"Utilities"},{"location":"linux/#multitouch-gesture","text":"src: https://github.com/toransahu/libinput-gestures - by bulletmark sudo gpasswd -a toran input sudo apt-get install xdotool wmctrl libinput-tools git clone http://github.com/toransahu/libinput-gestures cd libinput-gestures sudo ./libinput-gestures-setup install cd ~/libinput-gestures #edit the created libinput-gestures.conf: vim libinput-gestures.conf #set following: gesture swipe down xdotool key ctrl+alt+Up gesture swipe up xdotool key ctrl+alt+Down gesture swipe right xdotool key ctrl+super+Left gesture swipe left xdotool key ctrl+super+Right sudo make install (or sudo ./libinput-gestures-setup install) libinput-gestures-setup autostart libinput-gestures-setup start","title":"Multitouch Gesture"},{"location":"linux/#battery-monitor","text":"Source: http://battery-monitor.maateen.me/","title":"Battery Monitor"},{"location":"linux/#battery-optimization","text":"","title":"Battery Optimization"},{"location":"linux/#sata-power-management","text":"source: https://askubuntu.com/questions/809127/how-to-turn-off-one-of-sata-hdds-installed-in-the-computer-to-save-power Using hdparm utility. It allows you to control your hard drives' power settings, apart from benchmarking and other stuff. put the disk into standby mode whenever you access the disk, it should automatically wake up and work back again hdparm -y /dev/sdX deeper resting mode may need to restart your computer in order to make the HDD work again hdparm -Y /dev/sdX","title":"SATA Power Management"},{"location":"linux/#powertop-by-intel-recommanded","text":"sudo apt-get update sudo apt-get install powertop sudo powertop --auto-tune sudo powertop --calibrate","title":"PowerTop by Intel (Recommanded)"},{"location":"linux/#tlp-emergency","text":"Source: https://linrunner.de/en/tlp/docs/tlp-linux-advanced-power-management.html sudo apt install tlp #restart #or sudo tlp start","title":"TLP (Emergency)"},{"location":"linux/#mono","text":"","title":"Mono"},{"location":"linux/#install","text":"https://www.mono-project.com/download/stable/#download-lin","title":"Install"},{"location":"linux/#verify","text":"Source: https://www.mono-project.com/docs/getting-started/mono-basics/ Scripts:","title":"Verify"},{"location":"linux/#thinkpad-touchpad-middle-button","text":"","title":"Thinkpad Touchpad Middle Button"},{"location":"linux/#install_1","text":"sudo apt install xserver-xorg-input-libinput","title":"Install"},{"location":"linux/#config","text":"restart alter touchpad setting and choose use multiple fingers in click actions","title":"Config"},{"location":"linux/#finger-print-reader","text":"src: https://launchpad.net/~fingerprint/+archive/ubuntu/fingerprint-gui","title":"Finger Print Reader"},{"location":"linux/#installation","text":"First of all, if you have installed Fingerprint GUI manually before, get rid of it completely. Remove all binaries, shared libraries, any other files and undo all the changes you have made to your system config files (especially to files under /etc/pam.d/). Add this PPA to your sources: sudo add-apt-repository ppa:fingerprint/fingerprint-gui sudo apt-get update Install the packages: sudo apt-get install libbsapi policykit-1-fingerprint-gui fingerprint-gui Log out of your session and log back in (we need the new session defaults to be picked up).","title":"Installation"},{"location":"linux/#uninstallation","text":"sudo apt-get install policykit-1-gnome sudo apt-get remove fingerprint-gui","title":"Uninstallation"},{"location":"linux/#zsh","text":"sudo apt install zsh","title":"ZSH"},{"location":"linux/#oh-my-zsh","text":"sh -c \" $( curl -fsSL https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh ) \" #OR sh -c \" $( wget https://raw.githubusercontent.com/robbyrussell/oh-my-zsh/master/tools/install.sh -O - ) \"","title":"oh-my-zsh"},{"location":"linux/#vim","text":"","title":"VIM"},{"location":"linux/#vundle","text":"VIM plugin manager (VIM + Bundle) install from : https://github.com/VundleVim/Vundle.vim i.e. git clone https://github.com/VundleVim/Vundle.vim.git ~/.vim/bundle/Vundle.vim","title":"Vundle"},{"location":"linux/#using-vundle","text":"Mention bundle names (as a github repo) in .vimrc file Plugin 'VundleVim/Vundle.vim' Plugin 'morhetz/gruvbox' Plugin 'itchyny/lightline.vim' Plugin 'itchyny/vim-gitbranch' Plugin 'scrooloose/nerdtree.git' Plugin 'aperezdc/vim-template' Plugin 'davidhalter/jedi-vim' Plugin 'editorconfig/editorconfig-vim' Plugin 'tpope/vim-abolish' Install using command :PluginInstall","title":"Using Vundle"},{"location":"linux/#vim-as-python-ide","text":"Source: http://chrisstrelioff.ws/sandbox/2016/09/21/vim_and_vundle_on_ubuntu_16_04.html ~/.vimrc & ~/.editorconfig config files @ https://gist.github.com/toransahu/66c69903649f3d417d8ba4dc78324f60 cheat sheet: https://gist.github.com/toransahu/4a921c6fb73274479dbdfbcfe6dda483","title":"VIM as Python IDE"},{"location":"linux/#tmux","text":"","title":"Tmux"},{"location":"linux/#tmux-package-manager","text":"Source: https://github.com/tmux-plugins/tpm ~/.tmux.conf : https://gist.github.com/toransahu/53a523d973a212f52ce53474417e01b1","title":"Tmux Package Manager"},{"location":"linux/#tmux-plugins","text":"Sidebar: https://tmuxcheatsheet.com/tmux-plugins-tools/?full_name=tmux-plugins%2Ftmux-sidebar","title":"Tmux Plugins:"},{"location":"linux/#commands","text":"abbr. prefix: ctrl + b help: ctrl + b ? select, copy, paste within tmux enter scroll mode: ctrl + b [ enter select mode: ctrl + space move cursor to select text copy to tmux buffer: alt + w copy to system clip: ctrl + b - y paste to any tmux: ctrl + b ] create/split pane vertical split: prefix % hor split: prefix \" convert a pane to window: prefix ! move to pane: prefix arrows close current pane: prefix x","title":"Commands"},{"location":"linux/#load-bashrc-with-tmux","text":"By default tmux runs a login shell. When bash is invoked as an interactive login shell, it looks for ~/.bash_profile, ~/.bash_login, and ~/.profile. So you have to put source ~/.bashrc in one of those files. Another way to solve this issue is to put in your file .tmux.conf the line: set-option -g default-shell \"/bin/bash\"","title":"Load .bashrc with tmux"},{"location":"linux/#keyboard-custom-shortcuts-bindings","text":"","title":"KeyBoard Custom Shortcuts Bindings"},{"location":"linux/#emulate-right-click-from-keyboard","text":"install xdotool sudo apt install xdotool bind keyboard shortcut with command: xdotool click 3","title":"Emulate right click from keyboard"},{"location":"linux/#backup-restore-cinnamon-settings","text":"sudo apt install dconf-cli #backup dconf dump /org/cinnamon/ > cinnamon_backup #restore dconf load /org/cinnamon/ < cinnamon_backup #reset to default dconf reset -f /org/cinnamon/","title":"Backup &amp; Restore Cinnamon settings"},{"location":"linux/#raspberry-pi","text":"","title":"Raspberry Pi"},{"location":"linux/#os","text":"","title":"OS"},{"location":"linux/#raspbian-with-rpd-desktop","text":"prepare https://www.raspberrypi.org/forums/viewtopic.php?t=135316","title":"Raspbian with RPD Desktop"},{"location":"linux/#raspbian-lite-without-gui","text":"","title":"Raspbian Lite (without GUI)"},{"location":"linux/#install-desktop-for-lite","text":"Source: https://www.raspberrypi.org/forums/viewtopic.php?t=133691","title":"Install Desktop for Lite"},{"location":"linux/#enable-ssh-enter-ssidwifi-details-without-keyboard","text":"Source: https://medium.com/@danidudas/install-raspbian-jessie-lite-and-setup-wi-fi-without-access-to-command-line-or-using-the-network-97f065af722e","title":"Enable ssh &amp; enter SSID/WiFi details without keyboard"},{"location":"linux/#ubuntu-coresnap","text":"","title":"Ubuntu Core/Snap"},{"location":"linux/#windows-iot","text":"","title":"Windows IoT"},{"location":"linux/#display","text":"","title":"Display"},{"location":"linux/#touch-screeen-config","text":"5 inch capacitive 800*480 /boot/config.txt framebuffer_width = 800 framebuffer_height = 480 hdmi_force_hotplug = 1 hdmi_group = 2 hdmi_mode = 87 hdmi_cvt 800 480 60 6 0 0 0","title":"Touch Screeen Config"},{"location":"linux/#backup-image-from-burnt-image","text":"","title":"Backup Image from Burnt Image"},{"location":"linux/#on-a-different-linux-pc-using-usb","text":"It won't work on the raspi!, it will get trapped in infinit loop #list disk sudo fdisk -l #backup SD card sudo dd bs = 4M if = /dev/sdb | gzip > /home/your_username/image ` date +%d%m%y ` .gz #restore the backup on SD card sudo gzip -dc /home/your_username/image.gz | dd bs = 4M of = /dev/sdb","title":"On a different linux PC using USB."},{"location":"linux/#in-raspberry-itself-using-rsync","text":"","title":"In Raspberry Itself using rsync"},{"location":"linux/#network-drive-mount-sshfs","text":"#Install SSHFS sudo apt-get install sshfs #First, create a directory on your host computer: mkdir pi #Then mount the Raspberry Pi's filesystem to this location: sudo sshfs -o allow_other pi@192.168.1.124:/ pi #Now enter this directory as if it is a regular folder; you should be able to see and access the contents of the Raspberry Pi: cd pi/ ls","title":"Network Drive Mount (sshfs)"},{"location":"linux/#remote-audio","text":"","title":"Remote Audio"},{"location":"linux/#bluetooth","text":"","title":"bluetooth"},{"location":"linux/#way-1","text":"sudo apt-get install bluetooth blueman bluez python-gobject python-gobject-2 pulseaudio-module-bluetooth sudo systemctl status bluetooth pulseaudio --start https://gist.github.com/mill1000/74c7473ee3b4a5b13f6325e9994ff84c https://raspberrypi.stackexchange.com/questions/48140/raspberry-pi-3-connecting-to-bluetooth-audio-device-on-raspbian-jessie https://markus.jarvisalo.dy.fi/2017/12/making-the-raspberry-pi-3-a-bluetooth-audio-receiver/","title":"Way 1"},{"location":"linux/#way-2","text":"https://www.instructables.com/id/Turn-your-Raspberry-Pi-into-a-Portable-Bluetooth-A/ $ sudo vim /var/lib/bluetooth/00:1A:7D:DA:71:11/config","title":"Way 2"},{"location":"linux/#wifi","text":"shareport https://thepi.io/how-to-set-up-a-raspberry-pi-airplay-receiver/","title":"wifi"},{"location":"linux/#enable-ssh-from-card","text":"put empty ssh file inside /boot/","title":"enable ssh from card"},{"location":"linux/#set-wifissid-from-card","text":"change inside /etc/network/interface auto lo iface lo inet loopback iface eth0 inet dhcp allow-hotplug wlan0 auto wlan0 iface wlan0 inet dhcp wpa-ssid \"Connecting...\" wpa-psk \"PrideValencia_A704\"","title":"set wifi/ssid  from card"},{"location":"linux/#wifi-to-ethernet","text":"src: https://www.instructables.com/id/Share-WiFi-With-Ethernet-Port-on-a-Raspberry-Pi/ sudo apt install dnsmasq -y cd wget https://raw.githubusercontent.com/arpitjindal97/raspbian-recipes/master/wifi-to-eth-route.sh chmod +x ~/wifi-to-eth-route.sh sudo crontab -e @reboot bash /home/pi/wifi-to-eth-route.sh & # add it to crontab file","title":"wifi to ethernet"},{"location":"api/GraphQL/","text":"Intro REST vs GraphQL Terminologies Schema Field Explore Forming Calls With GraphQL Authenticating with GraphQL The GraphQL endpoint Communicating with GraphQL About query and mutation operations Working with variables Query Mutation Intro # An architectural and conceptual improvement over REST. GraphQL is a data query language developed internally by Facebook in 2012 before being publicly released in 2015. It provides an alternative to REST and ad-hoc webservice architectures. REST vs GraphQL # Lets say, we are consuming Facebook API A typical nested field data distribution: FACEBOOK | |------ USERS | |------- TORAN | |----- INFO | | | | | | | |----- ASSETS | | - GraphQL can retrieve various fields from different endpoint routes in fewer or single query - whereas REST requires multiple calls for each fields - e.g. - REST Terminologies # Schema # Field # # Explore # Forming Calls With GraphQL # Authenticating with GraphQL # The GraphQL endpoint # Communicating with GraphQL # About query and mutation operations # Working with variables # Query # Mutation #","title":"GraphQL"},{"location":"api/GraphQL/#intro","text":"An architectural and conceptual improvement over REST. GraphQL is a data query language developed internally by Facebook in 2012 before being publicly released in 2015. It provides an alternative to REST and ad-hoc webservice architectures.","title":"Intro"},{"location":"api/GraphQL/#rest-vs-graphql","text":"Lets say, we are consuming Facebook API A typical nested field data distribution: FACEBOOK | |------ USERS | |------- TORAN | |----- INFO | | | | | | | |----- ASSETS | | - GraphQL can retrieve various fields from different endpoint routes in fewer or single query - whereas REST requires multiple calls for each fields - e.g. - REST","title":"REST vs GraphQL"},{"location":"api/GraphQL/#terminologies","text":"","title":"Terminologies"},{"location":"api/GraphQL/#schema","text":"","title":"Schema"},{"location":"api/GraphQL/#field","text":"","title":"Field"},{"location":"api/GraphQL/#_1","text":"","title":""},{"location":"api/GraphQL/#explore","text":"","title":"Explore"},{"location":"api/GraphQL/#forming-calls-with-graphql","text":"","title":"Forming Calls With GraphQL"},{"location":"api/GraphQL/#authenticating-with-graphql","text":"","title":"Authenticating with GraphQL"},{"location":"api/GraphQL/#the-graphql-endpoint","text":"","title":"The GraphQL endpoint"},{"location":"api/GraphQL/#communicating-with-graphql","text":"","title":"Communicating with GraphQL"},{"location":"api/GraphQL/#about-query-and-mutation-operations","text":"","title":"About query and mutation operations"},{"location":"api/GraphQL/#working-with-variables","text":"","title":"Working with variables"},{"location":"api/GraphQL/#query","text":"","title":"Query"},{"location":"api/GraphQL/#mutation","text":"","title":"Mutation"},{"location":"api/REST/","text":"","title":"REST"},{"location":"behavioural/FAQ/","text":"About Yourself? # \u2713 \u2715 Name Parents name, Siblings, DoB District Village (unless not unique) Highest edu School Past work experience Hobbies Married Note # stress / expose the area you want to intiate/direct the discussion on Why we? # Realities # \u2713 \u2715 Power/Money diverse work/multiple hats, learning to contribute in project/product/pusporse X financial stability/security social reputation relocation Note # should be simple Disclosable realities # \u2713 \u2715 Offer service Why we choose you? # due to the qualities Qualities # apptitude dicision making analytical skill logical/reasoning ability scientific temperament values integrity objectivity/neutrality compassion hard work perseverance patience technical - tbd # Strength # I.Q. # objectivity / neutral / natural justice dicision making ability quick correct hardworking patience perseverance tolerance planning & execution E.Q. # empathy / compassion / sensitivity balance friends vs family work vs family life thoughts quick leaner curious focus / target creative expressions health consious discipline Notes # Avoid being super human In limit / range Approach civil service values creativity Weakness # workaholic over-sensitive self discipline control / carelessness sleep cycle diet control routine / time management gaming introvert [social smartness] shy submissive artistic expressions painting calligraphy music [E.Q.] anger one-sided decision not able to mugup things / not a man of facts / man of concepts Notes # Avoid illegalities Avoid characteristical ones Avoid insensitive statements Which are rectifiable in-progess","title":"About Yourself?"},{"location":"behavioural/FAQ/#about-yourself","text":"\u2713 \u2715 Name Parents name, Siblings, DoB District Village (unless not unique) Highest edu School Past work experience Hobbies Married","title":"About Yourself?"},{"location":"behavioural/FAQ/#note","text":"stress / expose the area you want to intiate/direct the discussion on","title":"Note"},{"location":"behavioural/FAQ/#why-we","text":"","title":"Why we?"},{"location":"behavioural/FAQ/#realities","text":"\u2713 \u2715 Power/Money diverse work/multiple hats, learning to contribute in project/product/pusporse X financial stability/security social reputation relocation","title":"Realities"},{"location":"behavioural/FAQ/#note_1","text":"should be simple","title":"Note"},{"location":"behavioural/FAQ/#disclosable-realities","text":"\u2713 \u2715 Offer service","title":"Disclosable realities"},{"location":"behavioural/FAQ/#why-we-choose-you","text":"due to the qualities","title":"Why we choose you?"},{"location":"behavioural/FAQ/#qualities","text":"apptitude dicision making analytical skill logical/reasoning ability scientific temperament values integrity objectivity/neutrality compassion hard work perseverance patience technical","title":"Qualities"},{"location":"behavioural/FAQ/#-tbd","text":"","title":"- tbd"},{"location":"behavioural/FAQ/#strength","text":"","title":"Strength"},{"location":"behavioural/FAQ/#iq","text":"objectivity / neutral / natural justice dicision making ability quick correct hardworking patience perseverance tolerance planning & execution","title":"I.Q."},{"location":"behavioural/FAQ/#eq","text":"empathy / compassion / sensitivity balance friends vs family work vs family life thoughts quick leaner curious focus / target creative expressions health consious discipline","title":"E.Q."},{"location":"behavioural/FAQ/#notes","text":"Avoid being super human In limit / range Approach civil service values creativity","title":"Notes"},{"location":"behavioural/FAQ/#weakness","text":"workaholic over-sensitive self discipline control / carelessness sleep cycle diet control routine / time management gaming introvert [social smartness] shy submissive artistic expressions painting calligraphy music [E.Q.] anger one-sided decision not able to mugup things / not a man of facts / man of concepts","title":"Weakness"},{"location":"behavioural/FAQ/#notes_1","text":"Avoid illegalities Avoid characteristical ones Avoid insensitive statements Which are rectifiable in-progess","title":"Notes"},{"location":"cs-fundamentals/Algo/","text":"Dynamic Programing Intro Memoization Tabulation Examples Edit Distance Knapsack problem 0/1 Knapsack Problem 0/1 Knapsack Problem (with repetition of items) Knapsack Problem (with fractional items) Matrix Chain Multiplication Longest Common Substring Longest Common Subsequence Longest Increasing Monotonical Subsequence Rod Cutting Searching Algorithms Types 1. Linear 2. Binary 3. Jump 4. Interpolation 5. Exponential 6. Ternary Sorting Algorithms Types 1. Bubble Sort: 2. Selection Sort: 3. Insertion Sort: 4. Merge Sort 5. Quick Sort Recursive(arr,left,right): 5.1 Quick Sort Iterative: 6. Heap Sort 7. Bucket Sort 8. Counting Sort 9. Radix Sort. 10. Tim sort Quick Sort Vs Merge Sort Tree Algorithms Depth First Search (DFS) Breadth First Search (BFS) / Level order traversal Graph Algorithms Depth First Search (DFS) Breadth First Search (BFS) / Level order traversal Iterative Deepening Depth First Search (Depth Limited Search) A* Search Ternary Search Meet in the middle Strongly Connected Components (SCC) Bipartite Matching Kruskal Minimum Cost Spanning Tree Algorithm Prim's Minumum Cost Spanning Tree Dijkstra's Algorithm for Shortest Paths Floyd-Warshall Algorithm for Shortest Paths Bellman-Ford Algorithm Edmonds-Karp Algorithm Hungarian Algorithm Sweep Line Algorithm Graham scan Tarjan's Algorithm Knuth-Morris-Pratt Algorithm Z algorithm Hill Climbing Topological Sort Number Theory Modular Arithmetic Fermat\u2019s Theorem Chinese Remainder Theorem(CRT) Euclidian Method for GCD Logarithmic Exponentiation Sieve of Eratosthenes Euler\u2019s Totient Function Geometric Algorithms 2D Rotation and Scale Matrices 2D Rotation and Translation Matrices 2D Changing Coordinate Systems 3D Rotation and Scale Matrices 3D Changing Coordinate Systems Greedy Algorithms Elementary cases : Fractional Knapsack Problem, Task Scheduling Data Compression using Huffman Trees Activity Selection Misc Recursion Huffman Coding Regex Algorithm (Pattern Matching and Parsing) Hashing- Hash Functions Monotone Chains Algorithm Coordinate Compression Ford-Fulkerson Method Preflow-Push Algorithm Dinic's Algorithm Monte Carlo method or Metropolis Algorithm Krylov Subspace Iteration Method Householder Matrix Decomposition QR Algorithm Fast Fourier Transform Integer Relation Detection Algorithm Fast Multipole algorithm MinMax Algorithm Divide and Conquer Algorithm References Dynamic Programing # Intro # Memoization # Top - Down approach in a subproblem tree Intro divides a big problem into subproblems starts solving smallest problem first; approaching root of problem memoize/cache the solved subproblems for repeated/same subproblems, utilizes the cache/memoization table uses recursion Pros easy implementation Cons recusrsion stach could be deeper and that might create stack-overflow/memory issue Extra memo table fills up in bottom to top order Tabulation # Bottom - Up approach in a subproblem tree Intro Understands a root problem and finds subproblems to that starts solving subproblems (in a particular order which approaches the root problem, like smallest to bigger, 1 to 100 etc.) in iterative way store the answer to those subproblems in a table Pros avoids recursion stack issue suitable for extremly complicated problems suitable where optimization is concern because it gives flexibility of command over coding style Cons need more rigid thinking ahead of time to find the ordering of subproblems so that we do not need to backtrack and solve a smaller problem in order to solve a larger problem Extra table fills up in top to bottom order Examples # Edit Distance # Knapsack problem # 0/1 Knapsack Problem # 0/1 Knapsack Problem (with repetition of items) # Knapsack Problem (with fractional items) # Matrix Chain Multiplication # Longest Common Substring # Longest Common Subsequence # Longest Increasing Monotonical Subsequence # Rod Cutting # Searching Algorithms # Types # 1. Linear # 2. Binary # Pre-requisites: Sorted array of numbers (integers/floats) Method : Divide and search (conquer) Equation: T(n) = T(n/2) + O(1) Time Complexity: $ O(log n) $ Implementaion: Recursive Auxilary Space: $ O(log n) $ recursion call stack space Iterative Auxilary Space: $ O(1) $ 3. Jump # Pre-requisites: Sorted array of numbers Desc: Enhancement over linear search. Jumps a step (of m) --by index-- and search, if it was searching value 52 and found 55 then will jump a step back and start linear search from that index. Similar to linear search. Recurrence Equation: Total number of comparision in worst case: (n/m) + (m-1) i.e. (total number of jumps + linear search within one step) Best value of m = \\sqrt(n) m = \\sqrt(n) Time Complexity: $ O(\\sqrt(n))$ i.e. between O(linear) & O(binary) Auxiliary Space : O(1) 4. Interpolation # Pre-requisites: Sorted array Desc: Enhancement over Binary search. Enhancement: Pivot is calculated based on interpolation, i.e. Pivot = $ left + \\frac{(right - left)} { (arr[right] - arr[left]) (e - arr[left])} $ Time Complexity: $ O(log log n) $ (if elements are uniformaly distributed) Worst case: O(n) Auxilary space: $ O(1) $ 5. Exponential # Pre-requisites: Sorted array Desc: Enhancement over binary search. Enhancement: Find a range where element is present, and then do binary search found range. Range: Start with subarray of size 1 and chech if last element of subarray is greater than 'e'. If not, then increment size by two times Equation: Time Complexity: O(log n) Auxilary Space: O(1) (if used iterative binary search) Advantage: Better to use if array is infinite (Unbounded Searches/ Unbounded Binary Search) 6. Ternary # Pre-requisites: Sorted array Desc: Divide and Conquer + Linear search Same as binary search. When searching space gets shorter, use linear search according to precision = right-left Time Complexity: O(log 3 n) Auxilary Space: Iterative = O(1) Recursive = O(log 3 n) recursive stack space Application: Unimodel Functions Sorting Algorithms # Types # 1. Bubble Sort: # Description: Swapping adjacent elements if there are in wrong orders. Time Complexity: Always O(n 2 ) (even for sorted arrays) Can be optimized for sorted array 2. Selection Sort: # Description: Pulls a minimum element from unsorted-subarray and appends infront of the array (as a sorted sub-array) Time Complexity: O(n 2 ) (all cases) Auxilary Space: O(1) 3. Insertion Sort: # Description: Keep first element on left side, start one by one from 2nd element (lets say ith element). Compare the picked element (ith) with all the elements in left sub-array (i.e. with i-1 th to 0 th ). If LHS sub-array element is greater than i element, then shift that element right by one index. Repeat for all LHS elements. Fill the empty cell with picked element. Time Complexity: Best Case: O(n); if array is as small as n=1 or array is already sorted Avg Case: Theta(n 2 )) Worst Case: O(n 2 ) Auxilary Space: O(1) 4. Merge Sort # Description: Split the array in Binary fashion, till you get minimum/single entity Start merging 2 single entities --> you'll get 2 sorted sub-array --> merge both Continue merging till end Merge Function: Merges two sorted sub-arrays by using an extra space of O(n). Begin from 0th index of both sub-array (using pointers like i,j), do comparision in temporary (un-touched) array Make changes in original array till both i & j reaches the end of the sub-array Time Complexity: Merge: O(n) Merge Sort: Best Case: O(nlogn) Avg Case: O(nlogn) Worst Case: O(nlogn) Auxiliary Space: Merge: O(n) Merge Sort: O(n) + O(1) Algorithmic Paradigm: Divide and Conquer Implementations: Recursive only Sorting In Place: Yes (No in a typical implementation) Applications: Sorting linkedlist in O(nlogn) Inversion Count Problem (i.e. in an array Ei>Ej>Ek where i<j<k ) In External Sorting 5. Quick Sort Recursive(arr,left,right): # Description: Partition the array about a pivot: re-arrange smaller elements in LHS & greater elements in RHS of pivot Return partitioned index (i.e. index of pivot after re-arrangement) Re-call quicksort for sub-array smaller than pivot Re-call quicksort for sub-array greater than pivot Partition Function(arr,left,right): Desc: Pick pivot is any preferable fashion: First element Last element Mean Randon Find index of pivot element in array by counting number of elements smaller than it + re-arranges elements smaller than pivot to left (and greater to right) in original Array. Swap pivot element with element at that index return the pivot/partioning index Returns: Partitioning Index (Re-calculated index of pivot) Time Complexity: O(n) Auxilary Space: O(1) Time Complexity: Best Case: O(nlogn) (Occurs when pivot element is middle element value-wise) Avg Case: O(nlogn) Worst Case: O(n2) (Occurs when pivot element is either smaller or larger element) Auxilary Space: O(1) Algorithm Paradigm: Divide and Conquer Implementation: Recursive (Generally) and Iterative In-Place: Yes (because auxilary space O(n)) Recurrence Relation: Best Case: T(n) = O(n) + 2*T(n/2) == O(nlogn) Avg Case: T(n) = O(n) + 2*T(n/2) == O(nlogn) Worst Case: T(n) = O(n) + T(n-1) == O(n 2 ) Applications: In case of memory limitation this algo is used Advantages: One of the fastest algo for avg case Does not need additional memory, i.e. In-place processing/sorting Disadvantages: Worst case complexity O(n2) speed is not guaranteed 5.1 Quick Sort Iterative: # Description: Use tha same Partition technique Instead of re-calling the quick_sort function, use stack to keep track of left and right indexes of the sub-arrays (LHS & RHS of partition_idx) found after partition. Keep doing this while stack is not empty. At the end partition() will arrange all the elements at their perfect index. 6. Heap Sort # Desc: Make max heap using heapify(). To do so, start from last leaf and make max heap till root node. Loop from last leaf to second node. Swap last leaf with root node in max heap Heapify the sub-tree (by ignoring last leaf) at root node till the loop covers all the nodes except the root node Pre-requisites: Useful: When there is time (Quick's problem) and space (Merge's problem) bound Advantage: Worst case upper bound is O(nlogn) with only O(1) auxilary space Applications: Sort a nearly sorted (or K sorted) array k largest(or smallest) elements in an array Time Complexity: O(heapify) * O(n) = O(nlogn) Auxilary Space: O(1) In-Place: Yes Implementation: Recursive (Heapify) Algorithm Paradigm: Comparision Based Data Structure: Array + Complete Binary Tree Stable: Not in general Note: Quick & Merge are better in practice. 7. Bucket Sort # Pre-requisites: Standard: A uniform distributed input array in a range of [0,1). CLRS. Generalized: A uniform distributed input array in a range of non negative integers + floats. [0, k). Efficient Hash Function (specially in case of \"Generalized\" implementation. Desc: Hashing: hash_table_size or number of buckets: = size of input array; Standard OR = int(sqrt(size)); Generalized hash_func() = (element/MAX)* (hash_table_size) Condition: if i < k then hash(i) < hash(k) Partion inp array on the basis of hash function, store then in right bucket/array Sort each array using Insertionsort Merge all sorted arrays into one. Useful: When input is uniformly distributed over a positive range Advantage: Sorting in O(n) Applications: When input is uniformly distributed over a positive range Recurrence Equation: \\theta(n) + n.O(2 - 1/n) \\theta(n) + n.O(2 - 1/n) Time Complexity: Best: Omega(n) == \\Omega(n) \\Omega(n) Avg: Theta(n) Worst: Theta(n2); When all the elements fall under single bucket Auxilary Space: O(bucket size) == O(n) O(bucket size) == O(n) In-Place: No Implementation: Iterative Algorithm Paradigm: Hashing, Partion Data Structure: Hashtable, Array Stable: Yes Note: If input is not uniformally distributed, but also bucketsort may still run in linear time. CLRS. Why Insertion sort is used here? How overall time complexity of bucketsort is still O(n) then? Following Standard way: As, input is uniformly distributed, On avg each bucket/array will have 1 elements (k/k=1), some may have zero and some may have multiple with same value. And as insertionsort's best case is O(n) (if array size is 1). Hence overall its O(n) 8. Counting Sort # Pre-requisites (Standard): Elements should be Non Negative Integers Over a range of 0 to k where k < size of array to maintain O(n) Desc: For each element X in the input array find the number of elements smaller than X. Steps: Store counts of each element in a counting array Add previous count to current count, to find index of last occurence of that element Reverse Iterate over input array & pick index of the element from counting array Put the element in output array and decrement the count by 1 Useful: same as pre-requisites Advantage: Sorting in O(n + k) Applications: Same as pre-requisites As a subroutine in Radix Sort Time Complexity: Best: Omega(n + k) Avg: Theta(n + k) Worst: O(n + k) Auxilary Space: O(counting + output array) == O(n + k) In-Place: No Implementation: Iterative Algorithm Paradigm: Partial Hashing Data Structure: Hashtable, Array Stable: Yes (order of elements with same value in input array maintains same order in output) Comparion Sort: No Note: Can be extended to sort negative integers also 9. Radix Sort. # Pre-requisites (Standard): input array have non negative integers range should be 0 to n__c where c is some constant & numbers are represented in base n or each number takes only log2(n) bits Desc: for 1 to d: where d is most significant digit position of MAX element in inp array do counting sort on array (considering current digit of each iteration) Useful: same as prerequisites Advantage: Better worst case performance than bucket sort's Worst case Applications: Card sorting machine Recurrence Equation: n*O(n + k) == O(n + k) Time Complexity: Best Case: Omega(n + k) Avg Case: theta(n + k) Worst Case: O(n + k) Auxilary Space: d O(counting array + output array) = d O(n + k) In-Place: No Implementation: Iterative Algorithm Paradigm: Partial Hashing Data Structure: Hashtable, array Stable: Yes Comparion Sort: No Note: 10. Tim sort # Quick Sort Vs Merge Sort # Merge sort is preferred over Quick sort when: Sorting a linkedlist: Quick sort is preferred over Merge sort when: There is memory limitation Tree Algorithms # Depth First Search (DFS) # Breadth First Search (BFS) / Level order traversal # Graph Algorithms # Depth First Search (DFS) # Breadth First Search (BFS) / Level order traversal # Iterative Deepening Depth First Search (Depth Limited Search) # A* Search # Ternary Search # Meet in the middle # Strongly Connected Components (SCC) # Bipartite Matching # Kruskal Minimum Cost Spanning Tree Algorithm # Prim's Minumum Cost Spanning Tree # Dijkstra's Algorithm for Shortest Paths # Floyd-Warshall Algorithm for Shortest Paths # Bellman-Ford Algorithm # Edmonds-Karp Algorithm # Hungarian Algorithm # Sweep Line Algorithm # Graham scan # Tarjan's Algorithm # Knuth-Morris-Pratt Algorithm # Z algorithm # Hill Climbing # Topological Sort # Number Theory # Modular Arithmetic # Fermat\u2019s Theorem # Chinese Remainder Theorem(CRT) # Euclidian Method for GCD # Logarithmic Exponentiation # Sieve of Eratosthenes # Euler\u2019s Totient Function # Geometric Algorithms # 2D Rotation and Scale Matrices # 2D Rotation and Translation Matrices # 2D Changing Coordinate Systems # 3D Rotation and Scale Matrices # 3D Changing Coordinate Systems # Greedy Algorithms # Elementary cases : Fractional Knapsack Problem, Task Scheduling # Data Compression using Huffman Trees # Activity Selection # Misc # Recursion # Huffman Coding # Regex Algorithm (Pattern Matching and Parsing) # Hashing- Hash Functions # Monotone Chains Algorithm # Coordinate Compression # Ford-Fulkerson Method # Preflow-Push Algorithm # Dinic's Algorithm # Monte Carlo method or Metropolis Algorithm # Krylov Subspace Iteration Method # Householder Matrix Decomposition # QR Algorithm # Fast Fourier Transform # Integer Relation Detection Algorithm # Fast Multipole algorithm # MinMax Algorithm # Divide and Conquer Algorithm # References # https://gist.github.com/toransahu/bb1c9f1cd6490ff29c42fa229e827a2a","title":"Algo"},{"location":"cs-fundamentals/Algo/#dynamic-programing","text":"","title":"Dynamic Programing"},{"location":"cs-fundamentals/Algo/#intro","text":"","title":"Intro"},{"location":"cs-fundamentals/Algo/#memoization","text":"Top - Down approach in a subproblem tree Intro divides a big problem into subproblems starts solving smallest problem first; approaching root of problem memoize/cache the solved subproblems for repeated/same subproblems, utilizes the cache/memoization table uses recursion Pros easy implementation Cons recusrsion stach could be deeper and that might create stack-overflow/memory issue Extra memo table fills up in bottom to top order","title":"Memoization"},{"location":"cs-fundamentals/Algo/#tabulation","text":"Bottom - Up approach in a subproblem tree Intro Understands a root problem and finds subproblems to that starts solving subproblems (in a particular order which approaches the root problem, like smallest to bigger, 1 to 100 etc.) in iterative way store the answer to those subproblems in a table Pros avoids recursion stack issue suitable for extremly complicated problems suitable where optimization is concern because it gives flexibility of command over coding style Cons need more rigid thinking ahead of time to find the ordering of subproblems so that we do not need to backtrack and solve a smaller problem in order to solve a larger problem Extra table fills up in top to bottom order","title":"Tabulation"},{"location":"cs-fundamentals/Algo/#examples","text":"","title":"Examples"},{"location":"cs-fundamentals/Algo/#edit-distance","text":"","title":"Edit Distance"},{"location":"cs-fundamentals/Algo/#knapsack-problem","text":"","title":"Knapsack problem"},{"location":"cs-fundamentals/Algo/#01-knapsack-problem","text":"","title":"0/1 Knapsack Problem"},{"location":"cs-fundamentals/Algo/#01-knapsack-problem-with-repetition-of-items","text":"","title":"0/1 Knapsack Problem (with repetition of items)"},{"location":"cs-fundamentals/Algo/#knapsack-problem-with-fractional-items","text":"","title":"Knapsack Problem (with fractional items)"},{"location":"cs-fundamentals/Algo/#matrix-chain-multiplication","text":"","title":"Matrix Chain Multiplication"},{"location":"cs-fundamentals/Algo/#longest-common-substring","text":"","title":"Longest Common Substring"},{"location":"cs-fundamentals/Algo/#longest-common-subsequence","text":"","title":"Longest Common Subsequence"},{"location":"cs-fundamentals/Algo/#longest-increasing-monotonical-subsequence","text":"","title":"Longest Increasing Monotonical Subsequence"},{"location":"cs-fundamentals/Algo/#rod-cutting","text":"","title":"Rod Cutting"},{"location":"cs-fundamentals/Algo/#searching-algorithms","text":"","title":"Searching Algorithms"},{"location":"cs-fundamentals/Algo/#types","text":"","title":"Types"},{"location":"cs-fundamentals/Algo/#1-linear","text":"","title":"1. Linear"},{"location":"cs-fundamentals/Algo/#2-binary","text":"Pre-requisites: Sorted array of numbers (integers/floats) Method : Divide and search (conquer) Equation: T(n) = T(n/2) + O(1) Time Complexity: $ O(log n) $ Implementaion: Recursive Auxilary Space: $ O(log n) $ recursion call stack space Iterative Auxilary Space: $ O(1) $","title":"2. Binary"},{"location":"cs-fundamentals/Algo/#3-jump","text":"Pre-requisites: Sorted array of numbers Desc: Enhancement over linear search. Jumps a step (of m) --by index-- and search, if it was searching value 52 and found 55 then will jump a step back and start linear search from that index. Similar to linear search. Recurrence Equation: Total number of comparision in worst case: (n/m) + (m-1) i.e. (total number of jumps + linear search within one step) Best value of m = \\sqrt(n) m = \\sqrt(n) Time Complexity: $ O(\\sqrt(n))$ i.e. between O(linear) & O(binary) Auxiliary Space : O(1)","title":"3. Jump"},{"location":"cs-fundamentals/Algo/#4-interpolation","text":"Pre-requisites: Sorted array Desc: Enhancement over Binary search. Enhancement: Pivot is calculated based on interpolation, i.e. Pivot = $ left + \\frac{(right - left)} { (arr[right] - arr[left]) (e - arr[left])} $ Time Complexity: $ O(log log n) $ (if elements are uniformaly distributed) Worst case: O(n) Auxilary space: $ O(1) $","title":"4. Interpolation"},{"location":"cs-fundamentals/Algo/#5-exponential","text":"Pre-requisites: Sorted array Desc: Enhancement over binary search. Enhancement: Find a range where element is present, and then do binary search found range. Range: Start with subarray of size 1 and chech if last element of subarray is greater than 'e'. If not, then increment size by two times Equation: Time Complexity: O(log n) Auxilary Space: O(1) (if used iterative binary search) Advantage: Better to use if array is infinite (Unbounded Searches/ Unbounded Binary Search)","title":"5. Exponential"},{"location":"cs-fundamentals/Algo/#6-ternary","text":"Pre-requisites: Sorted array Desc: Divide and Conquer + Linear search Same as binary search. When searching space gets shorter, use linear search according to precision = right-left Time Complexity: O(log 3 n) Auxilary Space: Iterative = O(1) Recursive = O(log 3 n) recursive stack space Application: Unimodel Functions","title":"6.  Ternary"},{"location":"cs-fundamentals/Algo/#sorting-algorithms","text":"","title":"Sorting Algorithms"},{"location":"cs-fundamentals/Algo/#types_1","text":"","title":"Types"},{"location":"cs-fundamentals/Algo/#1-bubble-sort","text":"Description: Swapping adjacent elements if there are in wrong orders. Time Complexity: Always O(n 2 ) (even for sorted arrays) Can be optimized for sorted array","title":"1. Bubble Sort:"},{"location":"cs-fundamentals/Algo/#2-selection-sort","text":"Description: Pulls a minimum element from unsorted-subarray and appends infront of the array (as a sorted sub-array) Time Complexity: O(n 2 ) (all cases) Auxilary Space: O(1)","title":"2. Selection Sort:"},{"location":"cs-fundamentals/Algo/#3-insertion-sort","text":"Description: Keep first element on left side, start one by one from 2nd element (lets say ith element). Compare the picked element (ith) with all the elements in left sub-array (i.e. with i-1 th to 0 th ). If LHS sub-array element is greater than i element, then shift that element right by one index. Repeat for all LHS elements. Fill the empty cell with picked element. Time Complexity: Best Case: O(n); if array is as small as n=1 or array is already sorted Avg Case: Theta(n 2 )) Worst Case: O(n 2 ) Auxilary Space: O(1)","title":"3. Insertion Sort:"},{"location":"cs-fundamentals/Algo/#4-merge-sort","text":"Description: Split the array in Binary fashion, till you get minimum/single entity Start merging 2 single entities --> you'll get 2 sorted sub-array --> merge both Continue merging till end Merge Function: Merges two sorted sub-arrays by using an extra space of O(n). Begin from 0th index of both sub-array (using pointers like i,j), do comparision in temporary (un-touched) array Make changes in original array till both i & j reaches the end of the sub-array Time Complexity: Merge: O(n) Merge Sort: Best Case: O(nlogn) Avg Case: O(nlogn) Worst Case: O(nlogn) Auxiliary Space: Merge: O(n) Merge Sort: O(n) + O(1) Algorithmic Paradigm: Divide and Conquer Implementations: Recursive only Sorting In Place: Yes (No in a typical implementation) Applications: Sorting linkedlist in O(nlogn) Inversion Count Problem (i.e. in an array Ei>Ej>Ek where i<j<k ) In External Sorting","title":"4. Merge Sort"},{"location":"cs-fundamentals/Algo/#5-quick-sort-recursivearrleftright","text":"Description: Partition the array about a pivot: re-arrange smaller elements in LHS & greater elements in RHS of pivot Return partitioned index (i.e. index of pivot after re-arrangement) Re-call quicksort for sub-array smaller than pivot Re-call quicksort for sub-array greater than pivot Partition Function(arr,left,right): Desc: Pick pivot is any preferable fashion: First element Last element Mean Randon Find index of pivot element in array by counting number of elements smaller than it + re-arranges elements smaller than pivot to left (and greater to right) in original Array. Swap pivot element with element at that index return the pivot/partioning index Returns: Partitioning Index (Re-calculated index of pivot) Time Complexity: O(n) Auxilary Space: O(1) Time Complexity: Best Case: O(nlogn) (Occurs when pivot element is middle element value-wise) Avg Case: O(nlogn) Worst Case: O(n2) (Occurs when pivot element is either smaller or larger element) Auxilary Space: O(1) Algorithm Paradigm: Divide and Conquer Implementation: Recursive (Generally) and Iterative In-Place: Yes (because auxilary space O(n)) Recurrence Relation: Best Case: T(n) = O(n) + 2*T(n/2) == O(nlogn) Avg Case: T(n) = O(n) + 2*T(n/2) == O(nlogn) Worst Case: T(n) = O(n) + T(n-1) == O(n 2 ) Applications: In case of memory limitation this algo is used Advantages: One of the fastest algo for avg case Does not need additional memory, i.e. In-place processing/sorting Disadvantages: Worst case complexity O(n2) speed is not guaranteed","title":"5. Quick Sort Recursive(arr,left,right):"},{"location":"cs-fundamentals/Algo/#51-quick-sort-iterative","text":"Description: Use tha same Partition technique Instead of re-calling the quick_sort function, use stack to keep track of left and right indexes of the sub-arrays (LHS & RHS of partition_idx) found after partition. Keep doing this while stack is not empty. At the end partition() will arrange all the elements at their perfect index.","title":"5.1 Quick Sort Iterative:"},{"location":"cs-fundamentals/Algo/#6-heap-sort","text":"Desc: Make max heap using heapify(). To do so, start from last leaf and make max heap till root node. Loop from last leaf to second node. Swap last leaf with root node in max heap Heapify the sub-tree (by ignoring last leaf) at root node till the loop covers all the nodes except the root node Pre-requisites: Useful: When there is time (Quick's problem) and space (Merge's problem) bound Advantage: Worst case upper bound is O(nlogn) with only O(1) auxilary space Applications: Sort a nearly sorted (or K sorted) array k largest(or smallest) elements in an array Time Complexity: O(heapify) * O(n) = O(nlogn) Auxilary Space: O(1) In-Place: Yes Implementation: Recursive (Heapify) Algorithm Paradigm: Comparision Based Data Structure: Array + Complete Binary Tree Stable: Not in general Note: Quick & Merge are better in practice.","title":"6. Heap Sort"},{"location":"cs-fundamentals/Algo/#7-bucket-sort","text":"Pre-requisites: Standard: A uniform distributed input array in a range of [0,1). CLRS. Generalized: A uniform distributed input array in a range of non negative integers + floats. [0, k). Efficient Hash Function (specially in case of \"Generalized\" implementation. Desc: Hashing: hash_table_size or number of buckets: = size of input array; Standard OR = int(sqrt(size)); Generalized hash_func() = (element/MAX)* (hash_table_size) Condition: if i < k then hash(i) < hash(k) Partion inp array on the basis of hash function, store then in right bucket/array Sort each array using Insertionsort Merge all sorted arrays into one. Useful: When input is uniformly distributed over a positive range Advantage: Sorting in O(n) Applications: When input is uniformly distributed over a positive range Recurrence Equation: \\theta(n) + n.O(2 - 1/n) \\theta(n) + n.O(2 - 1/n) Time Complexity: Best: Omega(n) == \\Omega(n) \\Omega(n) Avg: Theta(n) Worst: Theta(n2); When all the elements fall under single bucket Auxilary Space: O(bucket size) == O(n) O(bucket size) == O(n) In-Place: No Implementation: Iterative Algorithm Paradigm: Hashing, Partion Data Structure: Hashtable, Array Stable: Yes Note: If input is not uniformally distributed, but also bucketsort may still run in linear time. CLRS. Why Insertion sort is used here? How overall time complexity of bucketsort is still O(n) then? Following Standard way: As, input is uniformly distributed, On avg each bucket/array will have 1 elements (k/k=1), some may have zero and some may have multiple with same value. And as insertionsort's best case is O(n) (if array size is 1). Hence overall its O(n)","title":"7. Bucket Sort"},{"location":"cs-fundamentals/Algo/#8-counting-sort","text":"Pre-requisites (Standard): Elements should be Non Negative Integers Over a range of 0 to k where k < size of array to maintain O(n) Desc: For each element X in the input array find the number of elements smaller than X. Steps: Store counts of each element in a counting array Add previous count to current count, to find index of last occurence of that element Reverse Iterate over input array & pick index of the element from counting array Put the element in output array and decrement the count by 1 Useful: same as pre-requisites Advantage: Sorting in O(n + k) Applications: Same as pre-requisites As a subroutine in Radix Sort Time Complexity: Best: Omega(n + k) Avg: Theta(n + k) Worst: O(n + k) Auxilary Space: O(counting + output array) == O(n + k) In-Place: No Implementation: Iterative Algorithm Paradigm: Partial Hashing Data Structure: Hashtable, Array Stable: Yes (order of elements with same value in input array maintains same order in output) Comparion Sort: No Note: Can be extended to sort negative integers also","title":"8. Counting Sort"},{"location":"cs-fundamentals/Algo/#9-radix-sort","text":"Pre-requisites (Standard): input array have non negative integers range should be 0 to n__c where c is some constant & numbers are represented in base n or each number takes only log2(n) bits Desc: for 1 to d: where d is most significant digit position of MAX element in inp array do counting sort on array (considering current digit of each iteration) Useful: same as prerequisites Advantage: Better worst case performance than bucket sort's Worst case Applications: Card sorting machine Recurrence Equation: n*O(n + k) == O(n + k) Time Complexity: Best Case: Omega(n + k) Avg Case: theta(n + k) Worst Case: O(n + k) Auxilary Space: d O(counting array + output array) = d O(n + k) In-Place: No Implementation: Iterative Algorithm Paradigm: Partial Hashing Data Structure: Hashtable, array Stable: Yes Comparion Sort: No Note:","title":"9. Radix Sort."},{"location":"cs-fundamentals/Algo/#10-tim-sort","text":"","title":"10. Tim sort"},{"location":"cs-fundamentals/Algo/#quick-sort-vs-merge-sort","text":"Merge sort is preferred over Quick sort when: Sorting a linkedlist: Quick sort is preferred over Merge sort when: There is memory limitation","title":"Quick Sort Vs Merge Sort"},{"location":"cs-fundamentals/Algo/#tree-algorithms","text":"","title":"Tree Algorithms"},{"location":"cs-fundamentals/Algo/#depth-first-search-dfs","text":"","title":"Depth First Search (DFS)"},{"location":"cs-fundamentals/Algo/#breadth-first-search-bfs-level-order-traversal","text":"","title":"Breadth First Search (BFS) / Level order traversal"},{"location":"cs-fundamentals/Algo/#graph-algorithms","text":"","title":"Graph Algorithms"},{"location":"cs-fundamentals/Algo/#depth-first-search-dfs_1","text":"","title":"Depth First Search (DFS)"},{"location":"cs-fundamentals/Algo/#breadth-first-search-bfs-level-order-traversal_1","text":"","title":"Breadth First Search (BFS) / Level order traversal"},{"location":"cs-fundamentals/Algo/#iterative-deepening-depth-first-search-depth-limited-search","text":"","title":"Iterative Deepening Depth First Search (Depth Limited Search)"},{"location":"cs-fundamentals/Algo/#a-search","text":"","title":"A* Search"},{"location":"cs-fundamentals/Algo/#ternary-search","text":"","title":"Ternary Search"},{"location":"cs-fundamentals/Algo/#meet-in-the-middle","text":"","title":"Meet in the middle"},{"location":"cs-fundamentals/Algo/#strongly-connected-components-scc","text":"","title":"Strongly Connected Components (SCC)"},{"location":"cs-fundamentals/Algo/#bipartite-matching","text":"","title":"Bipartite Matching"},{"location":"cs-fundamentals/Algo/#kruskal-minimum-cost-spanning-tree-algorithm","text":"","title":"Kruskal Minimum Cost Spanning Tree Algorithm"},{"location":"cs-fundamentals/Algo/#prims-minumum-cost-spanning-tree","text":"","title":"Prim's Minumum Cost Spanning Tree"},{"location":"cs-fundamentals/Algo/#dijkstras-algorithm-for-shortest-paths","text":"","title":"Dijkstra's Algorithm for Shortest Paths"},{"location":"cs-fundamentals/Algo/#floyd-warshall-algorithm-for-shortest-paths","text":"","title":"Floyd-Warshall Algorithm for Shortest Paths"},{"location":"cs-fundamentals/Algo/#bellman-ford-algorithm","text":"","title":"Bellman-Ford Algorithm"},{"location":"cs-fundamentals/Algo/#edmonds-karp-algorithm","text":"","title":"Edmonds-Karp Algorithm"},{"location":"cs-fundamentals/Algo/#hungarian-algorithm","text":"","title":"Hungarian Algorithm"},{"location":"cs-fundamentals/Algo/#sweep-line-algorithm","text":"","title":"Sweep Line Algorithm"},{"location":"cs-fundamentals/Algo/#graham-scan","text":"","title":"Graham scan"},{"location":"cs-fundamentals/Algo/#tarjans-algorithm","text":"","title":"Tarjan's Algorithm"},{"location":"cs-fundamentals/Algo/#knuth-morris-pratt-algorithm","text":"","title":"Knuth-Morris-Pratt Algorithm"},{"location":"cs-fundamentals/Algo/#z-algorithm","text":"","title":"Z algorithm"},{"location":"cs-fundamentals/Algo/#hill-climbing","text":"","title":"Hill Climbing"},{"location":"cs-fundamentals/Algo/#topological-sort","text":"","title":"Topological Sort"},{"location":"cs-fundamentals/Algo/#number-theory","text":"","title":"Number Theory"},{"location":"cs-fundamentals/Algo/#modular-arithmetic","text":"","title":"Modular Arithmetic"},{"location":"cs-fundamentals/Algo/#fermats-theorem","text":"","title":"Fermat\u2019s Theorem"},{"location":"cs-fundamentals/Algo/#chinese-remainder-theoremcrt","text":"","title":"Chinese Remainder Theorem(CRT)"},{"location":"cs-fundamentals/Algo/#euclidian-method-for-gcd","text":"","title":"Euclidian Method for GCD"},{"location":"cs-fundamentals/Algo/#logarithmic-exponentiation","text":"","title":"Logarithmic Exponentiation"},{"location":"cs-fundamentals/Algo/#sieve-of-eratosthenes","text":"","title":"Sieve of Eratosthenes"},{"location":"cs-fundamentals/Algo/#eulers-totient-function","text":"","title":"Euler\u2019s Totient Function"},{"location":"cs-fundamentals/Algo/#geometric-algorithms","text":"","title":"Geometric Algorithms"},{"location":"cs-fundamentals/Algo/#2d-rotation-and-scale-matrices","text":"","title":"2D Rotation and Scale Matrices"},{"location":"cs-fundamentals/Algo/#2d-rotation-and-translation-matrices","text":"","title":"2D Rotation and Translation Matrices"},{"location":"cs-fundamentals/Algo/#2d-changing-coordinate-systems","text":"","title":"2D Changing Coordinate Systems"},{"location":"cs-fundamentals/Algo/#3d-rotation-and-scale-matrices","text":"","title":"3D Rotation and Scale Matrices"},{"location":"cs-fundamentals/Algo/#3d-changing-coordinate-systems","text":"","title":"3D Changing Coordinate Systems"},{"location":"cs-fundamentals/Algo/#greedy-algorithms","text":"","title":"Greedy Algorithms"},{"location":"cs-fundamentals/Algo/#elementary-cases-fractional-knapsack-problem-task-scheduling","text":"","title":"Elementary cases : Fractional Knapsack Problem, Task Scheduling"},{"location":"cs-fundamentals/Algo/#data-compression-using-huffman-trees","text":"","title":"Data Compression using Huffman Trees"},{"location":"cs-fundamentals/Algo/#activity-selection","text":"","title":"Activity Selection"},{"location":"cs-fundamentals/Algo/#misc","text":"","title":"Misc"},{"location":"cs-fundamentals/Algo/#recursion","text":"","title":"Recursion"},{"location":"cs-fundamentals/Algo/#huffman-coding","text":"","title":"Huffman Coding"},{"location":"cs-fundamentals/Algo/#regex-algorithm-pattern-matching-and-parsing","text":"","title":"Regex Algorithm (Pattern Matching and Parsing)"},{"location":"cs-fundamentals/Algo/#hashing-hash-functions","text":"","title":"Hashing- Hash Functions"},{"location":"cs-fundamentals/Algo/#monotone-chains-algorithm","text":"","title":"Monotone Chains Algorithm"},{"location":"cs-fundamentals/Algo/#coordinate-compression","text":"","title":"Coordinate Compression"},{"location":"cs-fundamentals/Algo/#ford-fulkerson-method","text":"","title":"Ford-Fulkerson Method"},{"location":"cs-fundamentals/Algo/#preflow-push-algorithm","text":"","title":"Preflow-Push Algorithm"},{"location":"cs-fundamentals/Algo/#dinics-algorithm","text":"","title":"Dinic's Algorithm"},{"location":"cs-fundamentals/Algo/#monte-carlo-method-or-metropolis-algorithm","text":"","title":"Monte Carlo method or Metropolis Algorithm"},{"location":"cs-fundamentals/Algo/#krylov-subspace-iteration-method","text":"","title":"Krylov Subspace Iteration Method"},{"location":"cs-fundamentals/Algo/#householder-matrix-decomposition","text":"","title":"Householder Matrix Decomposition"},{"location":"cs-fundamentals/Algo/#qr-algorithm","text":"","title":"QR Algorithm"},{"location":"cs-fundamentals/Algo/#fast-fourier-transform","text":"","title":"Fast Fourier Transform"},{"location":"cs-fundamentals/Algo/#integer-relation-detection-algorithm","text":"","title":"Integer Relation Detection Algorithm"},{"location":"cs-fundamentals/Algo/#fast-multipole-algorithm","text":"","title":"Fast Multipole algorithm"},{"location":"cs-fundamentals/Algo/#minmax-algorithm","text":"","title":"MinMax Algorithm"},{"location":"cs-fundamentals/Algo/#divide-and-conquer-algorithm","text":"","title":"Divide and Conquer Algorithm"},{"location":"cs-fundamentals/Algo/#references","text":"https://gist.github.com/toransahu/bb1c9f1cd6490ff29c42fa229e827a2a","title":"References"},{"location":"cs-fundamentals/CS-Dictionary/","text":"CS Dictionary General i368 amd64 CRUD module package library api framework sdk ide toolkit markup lang JSON YAML Web SaaS PaaS IaaS CSS LESS Sass CDN RWD (Responsive Web Design) Mobile First UI Design/Front-end Framework JS Framework HTTP HTTP Request Methods CSRF : Cross Site Request Forgery Web Server Web Apllication WSGI: Web Server Gateway Interface Web Service Web API Appication Without web API Appication Without web API Infrastructure Nginx: Gunicorn: Celery: Redis: Supervisor: CS Dictionary # General # i368 # genereally refers a 32bit processor Intel 80368: First 32bit CPU amd64 # genereally refers a 64bit processor 64bit CPU architecture invented by amd CRUD # create, read, update, delete SQL: insert, select, update, delete HTTP: Used in RESTful API: PUT/POST, GET, PUT/POST/PATCH, DELETE DDS: Data Distribution Service: write, read/take, write, despose module # a file containing codes package # collection of modules library # A bunch of code which simplifies functions/methods for quick use. to help you do things more quickly/easily offer one area of functionality api # application programming interface the interface to the library that you can call to ask it to do things for you framework # is a big library or group of libraries that provides many services supplies a complete base on which you build your own code sdk # software development kit is a library or group of libraries with extra tool applications, data files and sample code ide # integrated development environment text editor with additional support for developing,compiling and debugging applications. e.g Eclipse, Visual Studio. toolkit # is like an SDK with more focus on providing tools and applications than on just code libraries markup lang # Markup language is a paradigm/system to annotate a document in a way that is syntactically distinguishable from the text. e.g. (X)HTML: (Extensible)Hypertext ML, XML: Extensible ML, (La)TeX: (Lamport)TeX JSON # JavaScript object notation YAML # stands for \"YAML Ain't Markup Language\" YAML is to configuration what markdown is to markup YAML is a human-readable data serialization language commonly used for configuration files, but could be used in many applications where data is being stored (e.g. debugging output) data is being transmitted (e.g. document headers). Uses python style indentation, [], {} Superset of JSON YAML is case sensitive. Can contain unix/linux commands Web # SaaS # Software as a service Gmail, Google apps, Cisco WebEx PaaS # Platform as a service heroku, Travis CI, Circle CI IaaS # Infrastructure as a service AWS, MS Azure, CSS # cascading style sheet a style sheet language used for describing presentation of a document written in a markup language. LESS # CSS preprocessor: scripting language that extends CSS Leaner CSS CSS Dry Implemented in JavaScript Extension: .less Sass # CSS preprocessor: scripting language that extends CSS Syntactically Awesome style sheet CSS Dry implemented in Ruby Extension: .scss CDN # Content Delivery Network a system of distributed servers/network that deliver pages and other web content to a user based on geographical locations of the user to provide highspeed delivery Working: When a user request a page that is a part of CDN, then request goes to the central server and redirects the request to nearby server RWD (Responsive Web Design) # A web designing approach crafting site to provide an optimal viewing experience easy reading and navigation with a minimum of resizing, panning, and scrolling across a wide range of device (from mobile phones, tablets to desktop screens) Mobile First # A paradigm for creating UX design UX for mobile devices first than other because users prefer mobiles nowadays UI Design/Front-end Framework # eg. Bootstrap, Foundation, Pure includes CSS, HTML for typography, icons, forms, buttons, tables, layout grids, navigation. includes JS also support for responsive JS Framework # e.g. AngularJS, ReactJS, JavaScript framework for building CRUD centric AJAX style web applications features 2-way data binding, deep linking, routing, transition animations and a lot lot more HTTP # Hyper text transfer protocol base protocol the internet is built on a request and response system client sends a request to endpoint and endpoint responds e.g. a browser accessing a web server, an app accessing an API HTTP Request Methods # Used for sending and retrieving HTML form data. GET Default sends request by enclosing all the data into url string The request/response have HTTP header only Parameters are visible Parameters remains in history Hackable Not Secure Restriction in data length, 2048 chars, depends on browser can be cached Should be used for case when state of system/data is not going to be changed unsuitable for sending password POST sends request by enclosing all the data into The request/response have HTTP header & HTTP body HTTP body contains message in URLEncoded format PUT DELETE CSRF : Cross Site Request Forgery # A Cross-site request forgery hole is when a malicious site can cause a visitor's browser to make a request to your server that causes a change on the server. The server thinks that because the request comes with the user's cookies, the user wanted to submit that form. Web Server # a software, not a machine which stores code recieves requests from client/browser returns response, but doesn't create response so, it talks to web application Web Apllication # creates response based on urls passes response to web server WSGI: Web Server Gateway Interface # an interface between web server & application contains some statements, set of rules its not a software/library/framework WSGI compliant server will able to communicate with a WSGI compliant web app in WSGI, WSGI application has to be callable & it needs o be given to web server, so web server can call web application whenever it receives a request Web Service # a piece of software available over internet and can be ustilized by some other softwares using standard messaging system XML. Web API # Application Programming Interface In web world its synonym to 'web services' used by client apps to retrieve and update data Appication Without web API # Appication Without web API # - Source: https://knpuniversity.com/screencast/rest/rest https://blogs.msdn.microsoft.com/martinkearn/2015/01/05/introduction-to-rest-and-net-web-api/ http://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm Infrastructure # (Nginx, Gunicorn, RabbitMQ, Celery, Redis, memcached, apache, WSGI) (load balancer, web accelerator, cache, database, task queue, etc.) Nginx: # An HTTP and Reverse Proxy Server Gunicorn: # A WSGI HTTP server Celery: # A tool for asynchronous processing with Python Redis: # A message broker Supervisor: # A process control system for unix","title":"CS Dictionary"},{"location":"cs-fundamentals/CS-Dictionary/#cs-dictionary","text":"","title":"CS Dictionary"},{"location":"cs-fundamentals/CS-Dictionary/#general","text":"","title":"General"},{"location":"cs-fundamentals/CS-Dictionary/#i368","text":"genereally refers a 32bit processor Intel 80368: First 32bit CPU","title":"i368"},{"location":"cs-fundamentals/CS-Dictionary/#amd64","text":"genereally refers a 64bit processor 64bit CPU architecture invented by amd","title":"amd64"},{"location":"cs-fundamentals/CS-Dictionary/#crud","text":"create, read, update, delete SQL: insert, select, update, delete HTTP: Used in RESTful API: PUT/POST, GET, PUT/POST/PATCH, DELETE DDS: Data Distribution Service: write, read/take, write, despose","title":"CRUD"},{"location":"cs-fundamentals/CS-Dictionary/#module","text":"a file containing codes","title":"module"},{"location":"cs-fundamentals/CS-Dictionary/#package","text":"collection of modules","title":"package"},{"location":"cs-fundamentals/CS-Dictionary/#library","text":"A bunch of code which simplifies functions/methods for quick use. to help you do things more quickly/easily offer one area of functionality","title":"library"},{"location":"cs-fundamentals/CS-Dictionary/#api","text":"application programming interface the interface to the library that you can call to ask it to do things for you","title":"api"},{"location":"cs-fundamentals/CS-Dictionary/#framework","text":"is a big library or group of libraries that provides many services supplies a complete base on which you build your own code","title":"framework"},{"location":"cs-fundamentals/CS-Dictionary/#sdk","text":"software development kit is a library or group of libraries with extra tool applications, data files and sample code","title":"sdk"},{"location":"cs-fundamentals/CS-Dictionary/#ide","text":"integrated development environment text editor with additional support for developing,compiling and debugging applications. e.g Eclipse, Visual Studio.","title":"ide"},{"location":"cs-fundamentals/CS-Dictionary/#toolkit","text":"is like an SDK with more focus on providing tools and applications than on just code libraries","title":"toolkit"},{"location":"cs-fundamentals/CS-Dictionary/#markup-lang","text":"Markup language is a paradigm/system to annotate a document in a way that is syntactically distinguishable from the text. e.g. (X)HTML: (Extensible)Hypertext ML, XML: Extensible ML, (La)TeX: (Lamport)TeX","title":"markup lang"},{"location":"cs-fundamentals/CS-Dictionary/#json","text":"JavaScript object notation","title":"JSON"},{"location":"cs-fundamentals/CS-Dictionary/#yaml","text":"stands for \"YAML Ain't Markup Language\" YAML is to configuration what markdown is to markup YAML is a human-readable data serialization language commonly used for configuration files, but could be used in many applications where data is being stored (e.g. debugging output) data is being transmitted (e.g. document headers). Uses python style indentation, [], {} Superset of JSON YAML is case sensitive. Can contain unix/linux commands","title":"YAML"},{"location":"cs-fundamentals/CS-Dictionary/#web","text":"","title":"Web"},{"location":"cs-fundamentals/CS-Dictionary/#saas","text":"Software as a service Gmail, Google apps, Cisco WebEx","title":"SaaS"},{"location":"cs-fundamentals/CS-Dictionary/#paas","text":"Platform as a service heroku, Travis CI, Circle CI","title":"PaaS"},{"location":"cs-fundamentals/CS-Dictionary/#iaas","text":"Infrastructure as a service AWS, MS Azure,","title":"IaaS"},{"location":"cs-fundamentals/CS-Dictionary/#css","text":"cascading style sheet a style sheet language used for describing presentation of a document written in a markup language.","title":"CSS"},{"location":"cs-fundamentals/CS-Dictionary/#less","text":"CSS preprocessor: scripting language that extends CSS Leaner CSS CSS Dry Implemented in JavaScript Extension: .less","title":"LESS"},{"location":"cs-fundamentals/CS-Dictionary/#sass","text":"CSS preprocessor: scripting language that extends CSS Syntactically Awesome style sheet CSS Dry implemented in Ruby Extension: .scss","title":"Sass"},{"location":"cs-fundamentals/CS-Dictionary/#cdn","text":"Content Delivery Network a system of distributed servers/network that deliver pages and other web content to a user based on geographical locations of the user to provide highspeed delivery Working: When a user request a page that is a part of CDN, then request goes to the central server and redirects the request to nearby server","title":"CDN"},{"location":"cs-fundamentals/CS-Dictionary/#rwd-responsive-web-design","text":"A web designing approach crafting site to provide an optimal viewing experience easy reading and navigation with a minimum of resizing, panning, and scrolling across a wide range of device (from mobile phones, tablets to desktop screens)","title":"RWD (Responsive Web Design)"},{"location":"cs-fundamentals/CS-Dictionary/#mobile-first","text":"A paradigm for creating UX design UX for mobile devices first than other because users prefer mobiles nowadays","title":"Mobile First"},{"location":"cs-fundamentals/CS-Dictionary/#ui-designfront-end-framework","text":"eg. Bootstrap, Foundation, Pure includes CSS, HTML for typography, icons, forms, buttons, tables, layout grids, navigation. includes JS also support for responsive","title":"UI Design/Front-end Framework"},{"location":"cs-fundamentals/CS-Dictionary/#js-framework","text":"e.g. AngularJS, ReactJS, JavaScript framework for building CRUD centric AJAX style web applications features 2-way data binding, deep linking, routing, transition animations and a lot lot more","title":"JS Framework"},{"location":"cs-fundamentals/CS-Dictionary/#http","text":"Hyper text transfer protocol base protocol the internet is built on a request and response system client sends a request to endpoint and endpoint responds e.g. a browser accessing a web server, an app accessing an API","title":"HTTP"},{"location":"cs-fundamentals/CS-Dictionary/#http-request-methods","text":"Used for sending and retrieving HTML form data. GET Default sends request by enclosing all the data into url string The request/response have HTTP header only Parameters are visible Parameters remains in history Hackable Not Secure Restriction in data length, 2048 chars, depends on browser can be cached Should be used for case when state of system/data is not going to be changed unsuitable for sending password POST sends request by enclosing all the data into The request/response have HTTP header & HTTP body HTTP body contains message in URLEncoded format PUT DELETE","title":"HTTP Request Methods"},{"location":"cs-fundamentals/CS-Dictionary/#csrf-cross-site-request-forgery","text":"A Cross-site request forgery hole is when a malicious site can cause a visitor's browser to make a request to your server that causes a change on the server. The server thinks that because the request comes with the user's cookies, the user wanted to submit that form.","title":"CSRF : Cross Site Request Forgery"},{"location":"cs-fundamentals/CS-Dictionary/#web-server","text":"a software, not a machine which stores code recieves requests from client/browser returns response, but doesn't create response so, it talks to web application","title":"Web Server"},{"location":"cs-fundamentals/CS-Dictionary/#web-apllication","text":"creates response based on urls passes response to web server","title":"Web Apllication"},{"location":"cs-fundamentals/CS-Dictionary/#wsgi-web-server-gateway-interface","text":"an interface between web server & application contains some statements, set of rules its not a software/library/framework WSGI compliant server will able to communicate with a WSGI compliant web app in WSGI, WSGI application has to be callable & it needs o be given to web server, so web server can call web application whenever it receives a request","title":"WSGI: Web Server Gateway Interface"},{"location":"cs-fundamentals/CS-Dictionary/#web-service","text":"a piece of software available over internet and can be ustilized by some other softwares using standard messaging system XML.","title":"Web Service"},{"location":"cs-fundamentals/CS-Dictionary/#web-api","text":"Application Programming Interface In web world its synonym to 'web services' used by client apps to retrieve and update data","title":"Web API"},{"location":"cs-fundamentals/CS-Dictionary/#appication-without-web-api","text":"","title":"Appication Without web API"},{"location":"cs-fundamentals/CS-Dictionary/#appication-without-web-api_1","text":"- Source: https://knpuniversity.com/screencast/rest/rest https://blogs.msdn.microsoft.com/martinkearn/2015/01/05/introduction-to-rest-and-net-web-api/ http://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm","title":"Appication Without web API"},{"location":"cs-fundamentals/CS-Dictionary/#infrastructure","text":"(Nginx, Gunicorn, RabbitMQ, Celery, Redis, memcached, apache, WSGI) (load balancer, web accelerator, cache, database, task queue, etc.)","title":"Infrastructure"},{"location":"cs-fundamentals/CS-Dictionary/#nginx","text":"An HTTP and Reverse Proxy Server","title":"Nginx:"},{"location":"cs-fundamentals/CS-Dictionary/#gunicorn","text":"A WSGI HTTP server","title":"Gunicorn:"},{"location":"cs-fundamentals/CS-Dictionary/#celery","text":"A tool for asynchronous processing with Python","title":"Celery:"},{"location":"cs-fundamentals/CS-Dictionary/#redis","text":"A message broker","title":"Redis:"},{"location":"cs-fundamentals/CS-Dictionary/#supervisor","text":"A process control system for unix","title":"Supervisor:"},{"location":"cs-fundamentals/Code/","text":"Introduction # Readability # Maintainability # Testability # Measurements & Metrics # Cognitive Complexity # Thomas J. McCabe Ref: 1. https://blog.sonarsource.com/cognitive-complexity-because-testability-understandability 1. https://www.sonarsource.com/docs/CognitiveComplexity.pdf 1. https://medium.com/takeaway-tech/insights-in-cyclomatic-and-cognitive-complexity-in-your-application-58922ae59e80 Cyclomatic Complexity # Map Factory Pattern Strategy Pattern Command Pattern Repository Pattern Rule Engine","title":"Introduction"},{"location":"cs-fundamentals/Code/#introduction","text":"","title":"Introduction"},{"location":"cs-fundamentals/Code/#readability","text":"","title":"Readability"},{"location":"cs-fundamentals/Code/#maintainability","text":"","title":"Maintainability"},{"location":"cs-fundamentals/Code/#testability","text":"","title":"Testability"},{"location":"cs-fundamentals/Code/#measurements-metrics","text":"","title":"Measurements &amp; Metrics"},{"location":"cs-fundamentals/Code/#cognitive-complexity","text":"Thomas J. McCabe Ref: 1. https://blog.sonarsource.com/cognitive-complexity-because-testability-understandability 1. https://www.sonarsource.com/docs/CognitiveComplexity.pdf 1. https://medium.com/takeaway-tech/insights-in-cyclomatic-and-cognitive-complexity-in-your-application-58922ae59e80","title":"Cognitive Complexity"},{"location":"cs-fundamentals/Code/#cyclomatic-complexity","text":"Map Factory Pattern Strategy Pattern Command Pattern Repository Pattern Rule Engine","title":"Cyclomatic Complexity"},{"location":"cs-fundamentals/DBMS/","text":"Basics ACID Transaction Rollback Cascade Keys Primary Key Composite Key Foreign Key Candidate Key Super Key Dependencies Functional Dependency: Partial Dependency: Transitive Dependency: Normalization Intro Anamolies Types 0 NF: Un Normalized Form 1 NF (E. F. Codd - 1971) ORACLE PL/SQL Introduction DB Increase DB size? Tablespace & Datafiles?? DB instance? Schema? Table, Temporary Tables, & View Clauses Joins Subprograms Package Stored Procedure & Function In-Built Functions Aggregation Functions Analytical Functions Window Function LAG/LEAD Functions How to optimize a query? a SP? a Func? Index? Why? Type? How/Implementation? Cursor? What? Why? How? When? Type? Trigger Jobs? Dynamic SQL? Generally Asked MySQL Install Run Help chage root password Database Install test_db Install Sakila db prepared by mysql GRANTS To see databases To create a database To use a database Tables To see tables Subprograms Aggregation Functions Analytical Functions Window Function PostgreSQL Introduction Installation Using PostgreSQL Roles and Databases Switching Over to the postgres Account Accessing a Postgres Prompt Without Switching Accounts Create a New Role Create a New Database Basics # ACID # Atomicity: All or nothing Consistency: One state to another valid state (according to rulesets, constraints defined) Isolation: concurrency control. multiple transaction should sequentially executed Durability: Changes should persist Transaction # a unit of work performed within a database management system independent of other transactions generally represents any change in a database 2 Purposes: provide reliability, can be recovered on failure isolation from other programs accessing DB concurrently to avoid errors Rollback # Cascade # Keys # Primary Key # A primary is a single column value used to identify a database record uniquely. It has following attributes: A primary key cannot be NULL A primary key value must be unique The primary key values cannot be changed The primary key must be given a value when a new record is inserted. Composite Key # A composite key is a primary key composed of multiple columns used to identify a record uniquely Foreign Key # A key which is refering to a primary key of another table Candidate Key # Candidate for the primary key. Means Whichever combination of columns can uniquely identify a record are the candidate keys. Super Key # Superset of all the candidate key. Means a set which contains all the columns from all the candidate keys. Dependencies # Functional Dependency: # Partial Dependency: # Transitive Dependency: # Normalization # Intro # A technique of organizing data in DB A systematic approach to decomposing tables to eliminate data redundancy & undesired characteristics like: Insertion Anamolies Update Anamolies Deletion Anamolies Multi step process Normalization is used for mainly two purposes: Eliminating redundant(useless) data. Ensuring data dependencies make sense i.e data is logically stored. Note: In most practical applications, normalization achieves its best in 3rd Normal Form. Anamolies # Insertion Anamoly Suppose for a new admission, we have a Student id, name, and address of a student but if the student has not opted for any subjects yet then we have to insert NULL there, leading to Insertion Anamoly. Update Anamoly To update the address of a student who occurs twice or more than twice in a table, we will have to update S_Address column in all the rows, else data will become inconsistent. Deletion Anamoly If a student has only one subject and temporarily he drops it. When we delete that row, entire student record will be deleted along with it. Types # 0 NF: Un Normalized Form # Multi Valued Cells like Unit Code 1 NF (E. F. Codd - 1971) # First normal form enforces these criteria: Eliminate repeating groups in individual tables. Create a separate table for each set of related data. Identify each set of related data with a primary/composite key Rules Atomic (i.e. indivisible) / single values in each cell. Means no set of values in a single cell. Values stored in a column should be of the same domain i.e. No repeating group/column/attribute. like Telephone 1, Telephone 2 All the columns in a table should have unique names. No repeating rows/records. In other way: For a set of values, create multiple rows/records for each individual values in the set. Or, Identify each row/records by a primary key/composite primary key Disadvantage: Using the First Normal Form, data redundancy increases, as there will be many columns with same data in multiple rows but each row as a whole will be unique. $$ Table: 1-NF $$ $$ Table: Still in 1-NF $$ 2 NF Be in 1 NF There must not be a Partial Dependency $$ Table: 2-NF $$ 3 NF BCNF ORACLE PL/SQL # Introduction # DB # Consist of tablespace and tablespaces consists datafiles Increase DB size? # Increase size of data file Add new data file to existing table space Add new table space with atleast one datafile in it Datafile with dynamic extension ALTER DATABASE DATAFILE < DATAFILE1 . ORA > AUTOEXTEND ON NEXT 20 M MAZSIZE 1000 M ; Tablespace & Datafiles?? # Oracle Database stores data logically in tablespaces and physically in datafiles associated with the corresponding tablespace. Oracle DB consist of at least two logical storage unit SYSTEM (Default created, either locally or dictionary managed) SYSAUX ( Auxiliary to SYSTEM) TEMP (optional, required when SYSTEM is locally managed) src: https://docs.oracle.com/cd/B28359_01/server.111/b28318/physical.htm#CNCPT401 DB instance? # db is collection datafiles on server. DB instance is the allocated memory & collection of precesses running on the server when db server starts. db instances manages datafiles. db instance serves the data in datafiles to db users. Schema? # organization of data as a blueprint of how the database is constructed (divided into database tables, packages, functions, views etc) i.e. schema objects. An Oracle database associates a separate schema with each database user schema objects includes: tables, views, sequences, synonyms, indexes, clusters, database links, snapshots, procedures, functions, packages non-schema objects: users, roles, contexts, directory objects Table, Temporary Tables, & View # Table: a preliminary storage for storing data and information in RDBMS a collection of related data entries and it consists of columns and rows Syntax: CREATE TABLE table_1 AS ( Col1 NUMBER ); View: It is a saved SELECT query. It is a virtual table, which does not exist as stored data values in db (unless its indexed view) Advantages: It can join tables to create some complex statical query to use frequently Does not takes extra space to store values can be used as security mechanism: i.e. only read access, no edit access Types: View Indexed View: Used to create index on view Only useful when view is created by joining various tables, otherwise no diff in a indexed view * table Takes space same as tables Syntax: CREATE VIEW view_1 as SELECT statement ; Temporary Table: Oracle can create temp tables to store session specific or transaction specific data data does not persists after session/transaction definition persits? Yes Syntax: SQL CREATE GLOBAL TEMPORARY TABLE table_1 (col1 VARCHAR2); Clauses: ON COMMIT PRESERVE ROWS: Used when: need to hold intermediate data If the amount of data to be processed or utilized from your PL/SQL procedure is too large to fit comfortably in a PL/SQL table Note: A TRUNCATE command issued in transaction/session specific temporary table truncates data in its own session/tranxn. Does not affect other session/trnxn. What can be created on temporary tables: Index View Triggers Clauses # FROM Where Optional part of SELECT, DELETE, ALTER, UPDATE Where clause restricts/filters result of a SELECT, DELETE, ALTER, UPDATE queries Having Having clause restricts/filters result of a \"select query with GROUP BY\" [1] Applied to each groups of grouped table If there is no GROUP BY clause then HAVING applies to whole table (table is treated as a single group) The SELECT query cannot refer directly to any COLUMN not mentioned in GROUP BY clause, It can however refer to constants, aggregates. [2] Aggregate in HAVING do not need to appear in SELECT Subquery can be used in HAVING [3] e.g. [ 1 ] SELECT emp_no , max ( salary ) m , min ( salary ) min_salary FROM salaries group by emp_no having m > 70000 ; [ 2 ] SELECT emp_no , salary m FROM salaries having m > 70000 ; [ 3 ] SELECT emp_no , max ( salary ) m FROM salaries group by emp_no having m > ( SELECT avg ( salary ) from salaries ); ORDER BY To specify the order in which row should appear Optional to use with SELECT, INSERT, CREATE VIEW Meaningless in sub-queries Order: DESC, ASC Uses: Using Correlation Name: SQL SELECT first_col AS f from tab_1 ORDER BY f; Using Column number SQL SELECT emp_no, salary, addr from tab_1 ORDER BY 1,2,3; Using function SQL SELECT i, len from measure ORDER BY sin(i); Using NULL order SQL SELECT i, len from measure ORDER BY NULLS LAST; GROUP BY Optional part of SELECT The SELECT query cannot refer directly to any COLUMN not mentioned in GROUP BY clause, It can however refer to constants, aggregates. Typically used with AGGREGATE functions FOR UPDATE Optional part of SELECT query Syntax: SELECT A, B, C FROM T_1 FOR UPDATE Use: In cursors to make them updatable. WITH Materialization technique same as View & Temporary tables known as subquery factoring Useful when subqueries are used multiple times e.g. PLSQL WITH sum_sales AS ( select sum(quantity) all_sales from stores ), number_stores AS ( select count(*) nbr_stores from stores ), sales_by_store AS ( select store_name, sum(quantity) store_sales from store natural join sales ) SELECT store_name FROM store, sum_sales, number_stores, sales_by_store where store_sales > (all_sales / nbr_stores); USING Used in JOIN inplace of ON e.g. SELECT * FROM COUNTRIES JOIN CITIES USING ( COUNTRY ); where COUNTRY column should exist in both the tables. * CONSTRAINT * Optional part of CREATE/ ALTER table. * Level: * Column level: Column-level constraints (except for check constraints) refer to only one column * Table level: Table constraints allow you to specify more than one column in a PRIMARY KEY, UNIQUE, CHECK, or FOREIGN KEY constraint definition * Types: * NOT NULL: Column level, * PRIMARY KEY: Both level, nameable * FOREIGN KEY: Both level, nameable * CHECK: Both level, nameable, [DISABLE] keyword to disable * UNIQUE: Both level, nameable * e.g.: CREATE TABLE suppliers ( supplier_id numeric ( 4 ) NOT NULL CONSTRAINT unq_supplier_id UNIQUE , supplier_name varchar2 ( 50 ) NOT NULL , CONSTRAINT check_supplier_name CHECK ( supplier_name = upper ( supplier_name )), CONSTRAINT pk_supplier_id PRIMARY KEY ); Joins # Used to combine & then retrieve data from multiple tables or views Types: Equijoin: Joins 2 tables on the basis of equality of 2 columns PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM A, B where A.col3 = B.col4; * Self Join * Join a table with itself with the help of alias PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM Salary AS A JOIN Salary AS B ON A.col3 = B.col4; * Cartesian Product * Joins 2 tables without any condition PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM A, B; * Inner Join (Join) * Simple join * Returns all rows that satisfy the join condition PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM A JOIN B on ON A.col3 = B.col4; * Left Outer Join (Left Join) * Returns all rows that satisfy the join condition and also returns some or all of those rows from left table for which join condition didn't worked PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM A LEFT [OUTER] JOIN B ON A.col3 = B.col4; SELECT A.col1, A.col2, B.col1, B.col2 FROM A LEFT [OUTER]JOIN B WHERE A.col3(+) = B.col4; Right Outer Join (Right Join) Returns all rows that satisfy the join condition and also returns some or all of those rows from right table for which join condition didn't worked PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM A RIGHT [OUTER] JOIN B ON A.col3 = B.col4; SELECT A.col1, A.col2, B.col1, B.col2 FROM A, B WHERE A.col3 = B.col4(+); Full Outer Join (Full Join) Returns all rows that satisfy the join condition and also returns some or all of those rows from both the table for which join condition didn't worked PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM A FULL JOIN B on ON A.col3 = B.col4; * Anti Join * Returns rows from the table with does not exists in other table * Using NOT IN clause SELECT * FROM employees WHERE department_id NOT IN (SELECT department_id FROM departments WHERE location_id = 1700) ORDER BY last_name; Semi Join Returns rows from table that satisfies EXISTS subquery condition SELECT * FROM departments WHERE EXISTS (SELECT * FROM employees WHERE departments.department_id = employees.department_id AND employees.salary > 2500) ORDER BY department_name; Subprograms # Subprograms are the building blocks of modular, maintainable applications. e.g. : Package, Procedure, Function Package # A schema object that groups logically related PL/SQL types, variables, and subprograms Packages usually have two parts, a specification (spec): The specification is the interface to the package. It declares the types/collection types, variables, constants, exceptions, cursors, subprograms, and overloaded subprograms that can be referenced from outside the package. a body: The body defines the queries for the cursors and the code for the subprograms. Advantages: Modularity Easy application Design Information Hiding: Public, Private Better performance: The whole package gets loaded into memory after first call Syntax: ```PLSQL CREATE PACKAGE emp_bonus AS TYPE EmpRecTyp IS RECORD (employees%ROWTYPE); PROCEDURE calc_bonus (date_hired employees.hire_date%TYPE); CURSOR desc_salary RETURN EmpRecTyp; FUNCTION hire_employee (last_name VARCHAR2, first_name VARCHAR2) RETURN NUMBER; END emp_bonus; / CREATE PACKAGE BODY emp_bonus AS PROCEDURE calc_bonus (date_hired employees.hire_date%TYPE, salary NUMBER) IS BEGIN DBMS_OUTPUT.PUT_LINE('Employees hired on ' || date_hired || ' get bonus.'); IF salary <= 0 THEN RAISE invalid_salary EXCEPTION; END IF; EXCEPTION WHEN invalid_salary THEN DBMS_OUTPUT.PUT_LINE('Invalid salary input!'); WHEN Others THEN RAISE; END; CURSOR desc_salary RETURN EmpRecTyp IS SELECT employee_id, salary FROM employees ORDER BY salary DESC; FUNCTION hire_employee (last_name VARCHAR2, first_name VARCHAR2) RETURN NUMBER IS new_emp_id NUMBER; BEGIN NULL; RETURN new_emp_id; END hire_employee; END emp_bonus; / ``` Stored Procedure & Function # Schema level subprograms/program unit/ commonly used codes stored in database Procedure Function Stored Procedures can call functions. Functions cannot call stored Procedures. Can have select statements as well as DML statements Cannot use DML statements Can use both table variables as well as temporary table in it. Cannot use temp tables Procedures cannot be utilized in a select statement Function can be embedded in a select statement. Procedure can return multiple OUT values(max. 1024) Function returns 1 value only however it can be collection datatype Syntax Procedure CREATE OR REPLACE PROCEDURE ADD_EVALUATION ( evaluation_id IN NUMBER, employee_id IN NUMBER, evaluation_date IN DATE, job_id IN VARCHAR2, manager_id OUT NUMBER, department_id OUT NUMBER ) AS BEGIN NULL; END ADD_EVALUATION; Function CREATE OR REPLACE FUNCTION calculate_score ( cat IN VARCHAR2 , score IN NUMBER , weight IN NUMBER ) RETURN NUMBER AS BEGIN RETURN NULL; END calculate_score; In-Built Functions # Aggregation Functions # Max, Min, Count, Sum Analytical Functions # Top? Last? Rank? Window Function # over() LAG/LEAD Functions # How to optimize a query? a SP? a Func? # Index? Why? Type? How/Implementation? # Cursor? What? Why? How? When? Type? # Trigger # Jobs? # Dynamic SQL? # Generally Asked # second highest salary, query emp, dept, city import excel to table Employees with third highest salary @ address Pune? Tables: Employees, Address, Salary? delete vs drop vs truncate MySQL # Install # sudo apt install mysql-server Run # sudo mysql -u root -p #default password for root is \"password\" if you get : ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2) then check service mysql start Default password for root is: password Help # mysql> help; or \\h chage root password # sudo mysqladmin password <new password> Database # Install test_db # sakila employees source: https://github.com/toransahu/test_db Install Sakila db prepared by mysql # wget http://downloads.mysql.com/docs/sakila-db.tar.gz tar -xzf sakila-db.tar.gz cd sakila-db mysql -u root -p < sakila-schema.sql mysql -u root -p < sakila-data.sql GRANTS # GRANT ALL PRIVILEGES ON * . * TO 'username' @ 'localhost' IDENTIFIED BY 'password' ; To see databases # mysql> show databases; To create a database # mysql> create database <db_name>; Query OK, 1 row affected (0.00 sec) To use a database # mysql> use <db_name>; Tables # To see tables # show tables; Subprograms # Aggregation Functions # Analytical Functions # MySQL doesn't have Analytical Functions while it is in MSSQL Oracle PostgreSQL MariaDB Window Function # over() PostgreSQL # Simple Doc: https://medium.com/coding-blocks/creating-user-database-and-adding-access-on-postgresql-8bfcd2f4a91e Introduction # Relational database management systems are a key component of many web sites and applications. They provide a structured way to store, organize, and access information. PostgreSQL, or Postgres, is a relational database management system that provides an implementation of the SQL querying language. It is a popular choice for many small and large projects and has the advantage of being standards-compliant and having many advanced features like reliable transactions and concurrency without read locks. In this guide, we will demonstrate how to install Postgres on an Ubuntu 16.04 VPS instance and go over some basic ways to use it. Installation # Ubuntu's default repositories contain Postgres packages, so we can install these easily using the apt packaging system. Since this is our first time using apt in this session, we need to refresh our local package index. We can then install the Postgres package and a -contrib package that adds some additional utilities and functionality: sudo apt-get update sudo apt-get install postgresql postgresql-contrib Now that our software is installed, we can go over how it works and how it may be different from similar database management systems you may have used. Using PostgreSQL Roles and Databases # By default, Postgres uses a concept called \"roles\" to handle in authentication and authorization. These are, in some ways, similar to regular Unix-style accounts, but Postgres does not distinguish between users and groups and instead prefers the more flexible term \"role\". Upon installation Postgres is set up to use ident authentication, which means that it associates Postgres roles with a matching Unix/Linux system account. If a role exists within Postgres, a Unix/Linux username with the same name will be able to sign in as that role. There are a few ways to utilize this account to access Postgres. Switching Over to the postgres Account # The installation procedure created a user account called postgres that is associated with the default Postgres role. In order to use Postgres, we can log into that account. Switch over to the postgres account on your server by typing: sudo -i -u postgres You can now access a Postgres prompt immediately by typing: psql You will be logged in and able to interact with the database management system right away. Exit out of the PostgreSQL prompt by typing: \\q You should now be back in the postgres Linux command prompt. Accessing a Postgres Prompt Without Switching Accounts # You can also run the command you'd like with the postgres account directly with sudo. For instance, in the last example, we just wanted to get to a Postgres prompt. We could do this in one step by running the single command psql as the postgres user with sudo like this: sudo -u postgres psql This will log you directly into Postgres without the intermediary bash shell in between. Again, you can exit the interactive Postgres session by typing: \\q Create a New Role # Currently, we just have the postgres role configured within the database. We can create new roles from the command line with the createrole command. The --interactive flag will prompt you for the necessary values. If you are logged in as the postgres account, you can create a new user by typing: createuser --interactive If, instead, you prefer to use sudo for each command without switching from your normal account, you can type: sudo -u postgres createuser --interactive The script will prompt you with some choices and, based on your responses, execute the correct Postgres commands to create a user to your specifications. Output Enter name of role to add: sammy Shall the new role be a superuser? (y/n) y You can get more control by passing some additional flags. Check out the options by looking at the man page: man createuser Create a New Database # By default, another assumption that the Postgres authentication system makes is that there will be an database with the same name as the role being used to login, which the role has access to. So if in the last section, we created a user called sammy, that role will attempt to connect to a database which is also called sammy by default. You can create the appropriate database with the createdb command. If you are logged in as the postgres account, you would type something like: createdb sammy If, instead, you prefer to use sudo for each command without switching from your normal account, you would type: sudo -u postgres createdb sammy Open a Postgres Prompt with the New Role To log in with ident based authentication, you'll need a Linux user with the same name as your Postgres role and database. If you don't have a matching Linux user available, you can create one with the adduser command. You will have to do this from an account with sudo privileges (not logged in as the postgres user): sudo adduser sammy Once you have the appropriate account available, you can either switch over and connect to the database by typing: sudo -i -u sammy psql Or, you can do this inline: sudo -u sammy psql You will be logged in automatically assuming that all of the components have been properly configured. If you want your user to connect to a different database, you can do so by specifying the database like this: psql -d postgres Once logged in, you can get check your current connection information by typing: \\conninfo Output You are connected to database \"sammy\" as user \"sammy\" via socket in \"/var/run/postgresql\" at port \"5432\". This can be useful if you are connecting to non-default databases or with non-default users. Create and Delete Tables Now that you know how to connect to the PostgreSQL database system, we can to go over how to complete some basic tasks. First, we can create a table to store some data. Let's create a table that describes playground equipment. The basic syntax for this command is something like this: CREATE TABLE table_name ( column_name1 col_type (field_length) column_constraints, column_name2 col_type (field_length), column_name3 col_type (field_length) ); As you can see, we give the table a name, and then define the columns that we want, as well as the column type and the max length of the field data. We can also optionally add table constraints for each column. You can learn more about how to create and manage tables in Postgres here. For our purposes, we're going to create a simple table like this: CREATE TABLE playground ( equip_id serial PRIMARY KEY, type varchar (50) NOT NULL, color varchar (25) NOT NULL, location varchar(25) check (location in ('north', 'south', 'west', 'east', 'northeast', 'southeast', 'southwest', 'northwest')), install_date date ); We have made a playground table that inventories the equipment that we have. This starts with an equipment ID, which is of the serial type. This data type is an auto-incrementing integer. We have given this column the constraint of primary key which means that the values must be unique and not null. For two of our columns (equip_id and install_date), we have not given a field length. This is because some column types don't require a set length because the length is implied by the type. We then give columns for the equipment type and color, each of which cannot be empty. We create a location column and create a constraint that requires the value to be one of eight possible values. The last column is a date column that records the date that we installed the equipment. We can see our new table by typing: \\d Output List of relations Schema | Name | Type | Owner --------+-------------------------+----------+------- public | playground | table | sammy public | playground_equip_id_seq | sequence | sammy (2 rows) Our playground table is here, but we also have something called playground_equip_id_seq that is of the type sequence. This is a representation of the serial type we gave our equip_id column. This keeps track of the next number in the sequence and is created automatically for columns of this type. If you want to see just the table without the sequence, you can type: \\dt Output List of relations Schema | Name | Type | Owner --------+------------+-------+------- public | playground | table | sammy (1 row) Add, Query, and Delete Data in a Table Now that we have a table, we can insert some data into it. Let's add a slide and a swing. We do this by calling the table we're wanting to add to, naming the columns and then providing data for each column. Our slide and swing could be added like this: INSERT INTO playground (type, color, location, install_date) VALUES ('slide', 'blue', 'south', '2014-04-28'); INSERT INTO playground (type, color, location, install_date) VALUES ('swing', 'yellow', 'northwest', '2010-08-16'); You should take care when entering the data to avoid a few common hangups. First, keep in mind that the column names should not be quoted, but the column values that you're entering do need quotes. Another thing to keep in mind is that we do not enter a value for the equip_id column. This is because this is auto-generated whenever a new row in the table is created. We can then get back the information we've added by typing: SELECT * FROM playground; Output equip_id | type | color | location | install_date ----------+-------+--------+-----------+-------------- 1 | slide | blue | south | 2014-04-28 2 | swing | yellow | northwest | 2010-08-16 (2 rows) Here, you can see that our equip_id has been filled in successfully and that all of our other data has been organized correctly. If the slide on the playground breaks and we have to remove it, we can also remove the row from our table by typing: DELETE FROM playground WHERE type = 'slide'; If we query our table again, we will see our slide is no longer a part of the table: SELECT * FROM playground; Output equip_id | type | color | location | install_date ----------+-------+--------+-----------+-------------- 2 | swing | yellow | northwest | 2010-08-16 (1 row) How To Add and Delete Columns from a Table If we want to modify a table after it has been created to add an additional column, we can do that easily. We can add a column to show the last maintenance visit for each piece of equipment by typing: ALTER TABLE playground ADD last_maint date; If you view your table information again, you will see the new column has been added (but no data has been entered): SELECT * FROM playground; Output equip_id | type | color | location | install_date | last_maint ----------+-------+--------+-----------+--------------+------------ 2 | swing | yellow | northwest | 2010-08-16 | (1 row) We can delete a column just as easily. If we find that our work crew uses a separate tool to keep track of maintenance history, we can get rid of the column here by typing: ALTER TABLE playground DROP last_maint; How To Update Data in a Table We know how to add records to a table and how to delete them, but we haven't covered how to modify existing entries yet. You can update the values of an existing entry by querying for the record you want and setting the column to the value you wish to use. We can query for the \"swing\" record (this will match every swing in our table) and change its color to \"red\". This could be useful if we gave the swing set a paint job: UPDATE playground SET color = 'red' WHERE type = 'swing'; We can verify that the operation was successful by querying our data again: SELECT * FROM playground; Output equip_id | type | color | location | install_date ----------+-------+-------+-----------+-------------- 2 | swing | red | northwest | 2010-08-16 (1 row) As you can see, our slide is now registered as being red. Source","title":"DBMS"},{"location":"cs-fundamentals/DBMS/#basics","text":"","title":"Basics"},{"location":"cs-fundamentals/DBMS/#acid","text":"Atomicity: All or nothing Consistency: One state to another valid state (according to rulesets, constraints defined) Isolation: concurrency control. multiple transaction should sequentially executed Durability: Changes should persist","title":"ACID"},{"location":"cs-fundamentals/DBMS/#transaction","text":"a unit of work performed within a database management system independent of other transactions generally represents any change in a database 2 Purposes: provide reliability, can be recovered on failure isolation from other programs accessing DB concurrently to avoid errors","title":"Transaction"},{"location":"cs-fundamentals/DBMS/#rollback","text":"","title":"Rollback"},{"location":"cs-fundamentals/DBMS/#cascade","text":"","title":"Cascade"},{"location":"cs-fundamentals/DBMS/#keys","text":"","title":"Keys"},{"location":"cs-fundamentals/DBMS/#primary-key","text":"A primary is a single column value used to identify a database record uniquely. It has following attributes: A primary key cannot be NULL A primary key value must be unique The primary key values cannot be changed The primary key must be given a value when a new record is inserted.","title":"Primary Key"},{"location":"cs-fundamentals/DBMS/#composite-key","text":"A composite key is a primary key composed of multiple columns used to identify a record uniquely","title":"Composite Key"},{"location":"cs-fundamentals/DBMS/#foreign-key","text":"A key which is refering to a primary key of another table","title":"Foreign Key"},{"location":"cs-fundamentals/DBMS/#candidate-key","text":"Candidate for the primary key. Means Whichever combination of columns can uniquely identify a record are the candidate keys.","title":"Candidate Key"},{"location":"cs-fundamentals/DBMS/#super-key","text":"Superset of all the candidate key. Means a set which contains all the columns from all the candidate keys.","title":"Super Key"},{"location":"cs-fundamentals/DBMS/#dependencies","text":"","title":"Dependencies"},{"location":"cs-fundamentals/DBMS/#functional-dependency","text":"","title":"Functional Dependency:"},{"location":"cs-fundamentals/DBMS/#partial-dependency","text":"","title":"Partial Dependency:"},{"location":"cs-fundamentals/DBMS/#transitive-dependency","text":"","title":"Transitive Dependency:"},{"location":"cs-fundamentals/DBMS/#normalization","text":"","title":"Normalization"},{"location":"cs-fundamentals/DBMS/#intro","text":"A technique of organizing data in DB A systematic approach to decomposing tables to eliminate data redundancy & undesired characteristics like: Insertion Anamolies Update Anamolies Deletion Anamolies Multi step process Normalization is used for mainly two purposes: Eliminating redundant(useless) data. Ensuring data dependencies make sense i.e data is logically stored. Note: In most practical applications, normalization achieves its best in 3rd Normal Form.","title":"Intro"},{"location":"cs-fundamentals/DBMS/#anamolies","text":"Insertion Anamoly Suppose for a new admission, we have a Student id, name, and address of a student but if the student has not opted for any subjects yet then we have to insert NULL there, leading to Insertion Anamoly. Update Anamoly To update the address of a student who occurs twice or more than twice in a table, we will have to update S_Address column in all the rows, else data will become inconsistent. Deletion Anamoly If a student has only one subject and temporarily he drops it. When we delete that row, entire student record will be deleted along with it.","title":"Anamolies"},{"location":"cs-fundamentals/DBMS/#types","text":"","title":"Types"},{"location":"cs-fundamentals/DBMS/#0-nf-un-normalized-form","text":"Multi Valued Cells like Unit Code","title":"0 NF: Un Normalized Form"},{"location":"cs-fundamentals/DBMS/#1-nf-e-f-codd-1971","text":"First normal form enforces these criteria: Eliminate repeating groups in individual tables. Create a separate table for each set of related data. Identify each set of related data with a primary/composite key Rules Atomic (i.e. indivisible) / single values in each cell. Means no set of values in a single cell. Values stored in a column should be of the same domain i.e. No repeating group/column/attribute. like Telephone 1, Telephone 2 All the columns in a table should have unique names. No repeating rows/records. In other way: For a set of values, create multiple rows/records for each individual values in the set. Or, Identify each row/records by a primary key/composite primary key Disadvantage: Using the First Normal Form, data redundancy increases, as there will be many columns with same data in multiple rows but each row as a whole will be unique. $$ Table: 1-NF $$ $$ Table: Still in 1-NF $$ 2 NF Be in 1 NF There must not be a Partial Dependency $$ Table: 2-NF $$ 3 NF BCNF","title":"1 NF (E. F. Codd - 1971)"},{"location":"cs-fundamentals/DBMS/#oracle-plsql","text":"","title":"ORACLE PL/SQL"},{"location":"cs-fundamentals/DBMS/#introduction","text":"","title":"Introduction"},{"location":"cs-fundamentals/DBMS/#db","text":"Consist of tablespace and tablespaces consists datafiles","title":"DB"},{"location":"cs-fundamentals/DBMS/#increase-db-size","text":"Increase size of data file Add new data file to existing table space Add new table space with atleast one datafile in it Datafile with dynamic extension ALTER DATABASE DATAFILE < DATAFILE1 . ORA > AUTOEXTEND ON NEXT 20 M MAZSIZE 1000 M ;","title":"Increase DB size?"},{"location":"cs-fundamentals/DBMS/#tablespace-datafiles","text":"Oracle Database stores data logically in tablespaces and physically in datafiles associated with the corresponding tablespace. Oracle DB consist of at least two logical storage unit SYSTEM (Default created, either locally or dictionary managed) SYSAUX ( Auxiliary to SYSTEM) TEMP (optional, required when SYSTEM is locally managed) src: https://docs.oracle.com/cd/B28359_01/server.111/b28318/physical.htm#CNCPT401","title":"Tablespace &amp; Datafiles??"},{"location":"cs-fundamentals/DBMS/#db-instance","text":"db is collection datafiles on server. DB instance is the allocated memory & collection of precesses running on the server when db server starts. db instances manages datafiles. db instance serves the data in datafiles to db users.","title":"DB instance?"},{"location":"cs-fundamentals/DBMS/#schema","text":"organization of data as a blueprint of how the database is constructed (divided into database tables, packages, functions, views etc) i.e. schema objects. An Oracle database associates a separate schema with each database user schema objects includes: tables, views, sequences, synonyms, indexes, clusters, database links, snapshots, procedures, functions, packages non-schema objects: users, roles, contexts, directory objects","title":"Schema?"},{"location":"cs-fundamentals/DBMS/#table-temporary-tables-view","text":"Table: a preliminary storage for storing data and information in RDBMS a collection of related data entries and it consists of columns and rows Syntax: CREATE TABLE table_1 AS ( Col1 NUMBER ); View: It is a saved SELECT query. It is a virtual table, which does not exist as stored data values in db (unless its indexed view) Advantages: It can join tables to create some complex statical query to use frequently Does not takes extra space to store values can be used as security mechanism: i.e. only read access, no edit access Types: View Indexed View: Used to create index on view Only useful when view is created by joining various tables, otherwise no diff in a indexed view * table Takes space same as tables Syntax: CREATE VIEW view_1 as SELECT statement ; Temporary Table: Oracle can create temp tables to store session specific or transaction specific data data does not persists after session/transaction definition persits? Yes Syntax: SQL CREATE GLOBAL TEMPORARY TABLE table_1 (col1 VARCHAR2); Clauses: ON COMMIT PRESERVE ROWS: Used when: need to hold intermediate data If the amount of data to be processed or utilized from your PL/SQL procedure is too large to fit comfortably in a PL/SQL table Note: A TRUNCATE command issued in transaction/session specific temporary table truncates data in its own session/tranxn. Does not affect other session/trnxn. What can be created on temporary tables: Index View Triggers","title":"Table, Temporary Tables, &amp; View"},{"location":"cs-fundamentals/DBMS/#clauses","text":"FROM Where Optional part of SELECT, DELETE, ALTER, UPDATE Where clause restricts/filters result of a SELECT, DELETE, ALTER, UPDATE queries Having Having clause restricts/filters result of a \"select query with GROUP BY\" [1] Applied to each groups of grouped table If there is no GROUP BY clause then HAVING applies to whole table (table is treated as a single group) The SELECT query cannot refer directly to any COLUMN not mentioned in GROUP BY clause, It can however refer to constants, aggregates. [2] Aggregate in HAVING do not need to appear in SELECT Subquery can be used in HAVING [3] e.g. [ 1 ] SELECT emp_no , max ( salary ) m , min ( salary ) min_salary FROM salaries group by emp_no having m > 70000 ; [ 2 ] SELECT emp_no , salary m FROM salaries having m > 70000 ; [ 3 ] SELECT emp_no , max ( salary ) m FROM salaries group by emp_no having m > ( SELECT avg ( salary ) from salaries ); ORDER BY To specify the order in which row should appear Optional to use with SELECT, INSERT, CREATE VIEW Meaningless in sub-queries Order: DESC, ASC Uses: Using Correlation Name: SQL SELECT first_col AS f from tab_1 ORDER BY f; Using Column number SQL SELECT emp_no, salary, addr from tab_1 ORDER BY 1,2,3; Using function SQL SELECT i, len from measure ORDER BY sin(i); Using NULL order SQL SELECT i, len from measure ORDER BY NULLS LAST; GROUP BY Optional part of SELECT The SELECT query cannot refer directly to any COLUMN not mentioned in GROUP BY clause, It can however refer to constants, aggregates. Typically used with AGGREGATE functions FOR UPDATE Optional part of SELECT query Syntax: SELECT A, B, C FROM T_1 FOR UPDATE Use: In cursors to make them updatable. WITH Materialization technique same as View & Temporary tables known as subquery factoring Useful when subqueries are used multiple times e.g. PLSQL WITH sum_sales AS ( select sum(quantity) all_sales from stores ), number_stores AS ( select count(*) nbr_stores from stores ), sales_by_store AS ( select store_name, sum(quantity) store_sales from store natural join sales ) SELECT store_name FROM store, sum_sales, number_stores, sales_by_store where store_sales > (all_sales / nbr_stores); USING Used in JOIN inplace of ON e.g. SELECT * FROM COUNTRIES JOIN CITIES USING ( COUNTRY ); where COUNTRY column should exist in both the tables. * CONSTRAINT * Optional part of CREATE/ ALTER table. * Level: * Column level: Column-level constraints (except for check constraints) refer to only one column * Table level: Table constraints allow you to specify more than one column in a PRIMARY KEY, UNIQUE, CHECK, or FOREIGN KEY constraint definition * Types: * NOT NULL: Column level, * PRIMARY KEY: Both level, nameable * FOREIGN KEY: Both level, nameable * CHECK: Both level, nameable, [DISABLE] keyword to disable * UNIQUE: Both level, nameable * e.g.: CREATE TABLE suppliers ( supplier_id numeric ( 4 ) NOT NULL CONSTRAINT unq_supplier_id UNIQUE , supplier_name varchar2 ( 50 ) NOT NULL , CONSTRAINT check_supplier_name CHECK ( supplier_name = upper ( supplier_name )), CONSTRAINT pk_supplier_id PRIMARY KEY );","title":"Clauses"},{"location":"cs-fundamentals/DBMS/#joins","text":"Used to combine & then retrieve data from multiple tables or views Types: Equijoin: Joins 2 tables on the basis of equality of 2 columns PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM A, B where A.col3 = B.col4; * Self Join * Join a table with itself with the help of alias PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM Salary AS A JOIN Salary AS B ON A.col3 = B.col4; * Cartesian Product * Joins 2 tables without any condition PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM A, B; * Inner Join (Join) * Simple join * Returns all rows that satisfy the join condition PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM A JOIN B on ON A.col3 = B.col4; * Left Outer Join (Left Join) * Returns all rows that satisfy the join condition and also returns some or all of those rows from left table for which join condition didn't worked PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM A LEFT [OUTER] JOIN B ON A.col3 = B.col4; SELECT A.col1, A.col2, B.col1, B.col2 FROM A LEFT [OUTER]JOIN B WHERE A.col3(+) = B.col4; Right Outer Join (Right Join) Returns all rows that satisfy the join condition and also returns some or all of those rows from right table for which join condition didn't worked PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM A RIGHT [OUTER] JOIN B ON A.col3 = B.col4; SELECT A.col1, A.col2, B.col1, B.col2 FROM A, B WHERE A.col3 = B.col4(+); Full Outer Join (Full Join) Returns all rows that satisfy the join condition and also returns some or all of those rows from both the table for which join condition didn't worked PLSQL SELECT A.col1, A.col2, B.col1, B.col2 FROM A FULL JOIN B on ON A.col3 = B.col4; * Anti Join * Returns rows from the table with does not exists in other table * Using NOT IN clause SELECT * FROM employees WHERE department_id NOT IN (SELECT department_id FROM departments WHERE location_id = 1700) ORDER BY last_name; Semi Join Returns rows from table that satisfies EXISTS subquery condition SELECT * FROM departments WHERE EXISTS (SELECT * FROM employees WHERE departments.department_id = employees.department_id AND employees.salary > 2500) ORDER BY department_name;","title":"Joins"},{"location":"cs-fundamentals/DBMS/#subprograms","text":"Subprograms are the building blocks of modular, maintainable applications. e.g. : Package, Procedure, Function","title":"Subprograms"},{"location":"cs-fundamentals/DBMS/#package","text":"A schema object that groups logically related PL/SQL types, variables, and subprograms Packages usually have two parts, a specification (spec): The specification is the interface to the package. It declares the types/collection types, variables, constants, exceptions, cursors, subprograms, and overloaded subprograms that can be referenced from outside the package. a body: The body defines the queries for the cursors and the code for the subprograms. Advantages: Modularity Easy application Design Information Hiding: Public, Private Better performance: The whole package gets loaded into memory after first call Syntax: ```PLSQL CREATE PACKAGE emp_bonus AS TYPE EmpRecTyp IS RECORD (employees%ROWTYPE); PROCEDURE calc_bonus (date_hired employees.hire_date%TYPE); CURSOR desc_salary RETURN EmpRecTyp; FUNCTION hire_employee (last_name VARCHAR2, first_name VARCHAR2) RETURN NUMBER; END emp_bonus; / CREATE PACKAGE BODY emp_bonus AS PROCEDURE calc_bonus (date_hired employees.hire_date%TYPE, salary NUMBER) IS BEGIN DBMS_OUTPUT.PUT_LINE('Employees hired on ' || date_hired || ' get bonus.'); IF salary <= 0 THEN RAISE invalid_salary EXCEPTION; END IF; EXCEPTION WHEN invalid_salary THEN DBMS_OUTPUT.PUT_LINE('Invalid salary input!'); WHEN Others THEN RAISE; END; CURSOR desc_salary RETURN EmpRecTyp IS SELECT employee_id, salary FROM employees ORDER BY salary DESC; FUNCTION hire_employee (last_name VARCHAR2, first_name VARCHAR2) RETURN NUMBER IS new_emp_id NUMBER; BEGIN NULL; RETURN new_emp_id; END hire_employee; END emp_bonus; / ```","title":"Package"},{"location":"cs-fundamentals/DBMS/#stored-procedure-function","text":"Schema level subprograms/program unit/ commonly used codes stored in database Procedure Function Stored Procedures can call functions. Functions cannot call stored Procedures. Can have select statements as well as DML statements Cannot use DML statements Can use both table variables as well as temporary table in it. Cannot use temp tables Procedures cannot be utilized in a select statement Function can be embedded in a select statement. Procedure can return multiple OUT values(max. 1024) Function returns 1 value only however it can be collection datatype Syntax Procedure CREATE OR REPLACE PROCEDURE ADD_EVALUATION ( evaluation_id IN NUMBER, employee_id IN NUMBER, evaluation_date IN DATE, job_id IN VARCHAR2, manager_id OUT NUMBER, department_id OUT NUMBER ) AS BEGIN NULL; END ADD_EVALUATION; Function CREATE OR REPLACE FUNCTION calculate_score ( cat IN VARCHAR2 , score IN NUMBER , weight IN NUMBER ) RETURN NUMBER AS BEGIN RETURN NULL; END calculate_score;","title":"Stored Procedure &amp; Function"},{"location":"cs-fundamentals/DBMS/#in-built-functions","text":"","title":"In-Built Functions"},{"location":"cs-fundamentals/DBMS/#aggregation-functions","text":"Max, Min, Count, Sum","title":"Aggregation Functions"},{"location":"cs-fundamentals/DBMS/#analytical-functions","text":"Top? Last? Rank?","title":"Analytical Functions"},{"location":"cs-fundamentals/DBMS/#window-function","text":"over()","title":"Window Function"},{"location":"cs-fundamentals/DBMS/#laglead-functions","text":"","title":"LAG/LEAD Functions"},{"location":"cs-fundamentals/DBMS/#how-to-optimize-a-query-a-sp-a-func","text":"","title":"How to optimize a query? a SP? a Func?"},{"location":"cs-fundamentals/DBMS/#index-why-type-howimplementation","text":"","title":"Index? Why? Type? How/Implementation?"},{"location":"cs-fundamentals/DBMS/#cursor-what-why-how-when-type","text":"","title":"Cursor?  What? Why? How? When? Type?"},{"location":"cs-fundamentals/DBMS/#trigger","text":"","title":"Trigger"},{"location":"cs-fundamentals/DBMS/#jobs","text":"","title":"Jobs?"},{"location":"cs-fundamentals/DBMS/#dynamic-sql","text":"","title":"Dynamic SQL?"},{"location":"cs-fundamentals/DBMS/#generally-asked","text":"second highest salary, query emp, dept, city import excel to table Employees with third highest salary @ address Pune? Tables: Employees, Address, Salary? delete vs drop vs truncate","title":"Generally Asked"},{"location":"cs-fundamentals/DBMS/#mysql","text":"","title":"MySQL"},{"location":"cs-fundamentals/DBMS/#install","text":"sudo apt install mysql-server","title":"Install"},{"location":"cs-fundamentals/DBMS/#run","text":"sudo mysql -u root -p #default password for root is \"password\" if you get : ERROR 2002 (HY000): Can't connect to local MySQL server through socket '/var/run/mysqld/mysqld.sock' (2) then check service mysql start Default password for root is: password","title":"Run"},{"location":"cs-fundamentals/DBMS/#help","text":"mysql> help; or \\h","title":"Help"},{"location":"cs-fundamentals/DBMS/#chage-root-password","text":"sudo mysqladmin password <new password>","title":"chage root password"},{"location":"cs-fundamentals/DBMS/#database","text":"","title":"Database"},{"location":"cs-fundamentals/DBMS/#install-test_db","text":"sakila employees source: https://github.com/toransahu/test_db","title":"Install test_db"},{"location":"cs-fundamentals/DBMS/#install-sakila-db-prepared-by-mysql","text":"wget http://downloads.mysql.com/docs/sakila-db.tar.gz tar -xzf sakila-db.tar.gz cd sakila-db mysql -u root -p < sakila-schema.sql mysql -u root -p < sakila-data.sql","title":"Install Sakila db prepared by mysql"},{"location":"cs-fundamentals/DBMS/#grants","text":"GRANT ALL PRIVILEGES ON * . * TO 'username' @ 'localhost' IDENTIFIED BY 'password' ;","title":"GRANTS"},{"location":"cs-fundamentals/DBMS/#to-see-databases","text":"mysql> show databases;","title":"To see databases"},{"location":"cs-fundamentals/DBMS/#to-create-a-database","text":"mysql> create database <db_name>; Query OK, 1 row affected (0.00 sec)","title":"To create a database"},{"location":"cs-fundamentals/DBMS/#to-use-a-database","text":"mysql> use <db_name>;","title":"To use a database"},{"location":"cs-fundamentals/DBMS/#tables","text":"","title":"Tables"},{"location":"cs-fundamentals/DBMS/#to-see-tables","text":"show tables;","title":"To see tables"},{"location":"cs-fundamentals/DBMS/#subprograms_1","text":"","title":"Subprograms"},{"location":"cs-fundamentals/DBMS/#aggregation-functions_1","text":"","title":"Aggregation Functions"},{"location":"cs-fundamentals/DBMS/#analytical-functions_1","text":"MySQL doesn't have Analytical Functions while it is in MSSQL Oracle PostgreSQL MariaDB","title":"Analytical Functions"},{"location":"cs-fundamentals/DBMS/#window-function_1","text":"over()","title":"Window Function"},{"location":"cs-fundamentals/DBMS/#postgresql","text":"Simple Doc: https://medium.com/coding-blocks/creating-user-database-and-adding-access-on-postgresql-8bfcd2f4a91e","title":"PostgreSQL"},{"location":"cs-fundamentals/DBMS/#introduction_1","text":"Relational database management systems are a key component of many web sites and applications. They provide a structured way to store, organize, and access information. PostgreSQL, or Postgres, is a relational database management system that provides an implementation of the SQL querying language. It is a popular choice for many small and large projects and has the advantage of being standards-compliant and having many advanced features like reliable transactions and concurrency without read locks. In this guide, we will demonstrate how to install Postgres on an Ubuntu 16.04 VPS instance and go over some basic ways to use it.","title":"Introduction"},{"location":"cs-fundamentals/DBMS/#installation","text":"Ubuntu's default repositories contain Postgres packages, so we can install these easily using the apt packaging system. Since this is our first time using apt in this session, we need to refresh our local package index. We can then install the Postgres package and a -contrib package that adds some additional utilities and functionality: sudo apt-get update sudo apt-get install postgresql postgresql-contrib Now that our software is installed, we can go over how it works and how it may be different from similar database management systems you may have used.","title":"Installation"},{"location":"cs-fundamentals/DBMS/#using-postgresql-roles-and-databases","text":"By default, Postgres uses a concept called \"roles\" to handle in authentication and authorization. These are, in some ways, similar to regular Unix-style accounts, but Postgres does not distinguish between users and groups and instead prefers the more flexible term \"role\". Upon installation Postgres is set up to use ident authentication, which means that it associates Postgres roles with a matching Unix/Linux system account. If a role exists within Postgres, a Unix/Linux username with the same name will be able to sign in as that role. There are a few ways to utilize this account to access Postgres.","title":"Using PostgreSQL Roles and Databases"},{"location":"cs-fundamentals/DBMS/#switching-over-to-the-postgres-account","text":"The installation procedure created a user account called postgres that is associated with the default Postgres role. In order to use Postgres, we can log into that account. Switch over to the postgres account on your server by typing: sudo -i -u postgres You can now access a Postgres prompt immediately by typing: psql You will be logged in and able to interact with the database management system right away. Exit out of the PostgreSQL prompt by typing: \\q You should now be back in the postgres Linux command prompt.","title":"Switching Over to the postgres Account"},{"location":"cs-fundamentals/DBMS/#accessing-a-postgres-prompt-without-switching-accounts","text":"You can also run the command you'd like with the postgres account directly with sudo. For instance, in the last example, we just wanted to get to a Postgres prompt. We could do this in one step by running the single command psql as the postgres user with sudo like this: sudo -u postgres psql This will log you directly into Postgres without the intermediary bash shell in between. Again, you can exit the interactive Postgres session by typing: \\q","title":"Accessing a Postgres Prompt Without Switching Accounts"},{"location":"cs-fundamentals/DBMS/#create-a-new-role","text":"Currently, we just have the postgres role configured within the database. We can create new roles from the command line with the createrole command. The --interactive flag will prompt you for the necessary values. If you are logged in as the postgres account, you can create a new user by typing: createuser --interactive If, instead, you prefer to use sudo for each command without switching from your normal account, you can type: sudo -u postgres createuser --interactive The script will prompt you with some choices and, based on your responses, execute the correct Postgres commands to create a user to your specifications. Output Enter name of role to add: sammy Shall the new role be a superuser? (y/n) y You can get more control by passing some additional flags. Check out the options by looking at the man page: man createuser","title":"Create a New Role"},{"location":"cs-fundamentals/DBMS/#create-a-new-database","text":"By default, another assumption that the Postgres authentication system makes is that there will be an database with the same name as the role being used to login, which the role has access to. So if in the last section, we created a user called sammy, that role will attempt to connect to a database which is also called sammy by default. You can create the appropriate database with the createdb command. If you are logged in as the postgres account, you would type something like: createdb sammy If, instead, you prefer to use sudo for each command without switching from your normal account, you would type: sudo -u postgres createdb sammy Open a Postgres Prompt with the New Role To log in with ident based authentication, you'll need a Linux user with the same name as your Postgres role and database. If you don't have a matching Linux user available, you can create one with the adduser command. You will have to do this from an account with sudo privileges (not logged in as the postgres user): sudo adduser sammy Once you have the appropriate account available, you can either switch over and connect to the database by typing: sudo -i -u sammy psql Or, you can do this inline: sudo -u sammy psql You will be logged in automatically assuming that all of the components have been properly configured. If you want your user to connect to a different database, you can do so by specifying the database like this: psql -d postgres Once logged in, you can get check your current connection information by typing: \\conninfo Output You are connected to database \"sammy\" as user \"sammy\" via socket in \"/var/run/postgresql\" at port \"5432\". This can be useful if you are connecting to non-default databases or with non-default users. Create and Delete Tables Now that you know how to connect to the PostgreSQL database system, we can to go over how to complete some basic tasks. First, we can create a table to store some data. Let's create a table that describes playground equipment. The basic syntax for this command is something like this: CREATE TABLE table_name ( column_name1 col_type (field_length) column_constraints, column_name2 col_type (field_length), column_name3 col_type (field_length) ); As you can see, we give the table a name, and then define the columns that we want, as well as the column type and the max length of the field data. We can also optionally add table constraints for each column. You can learn more about how to create and manage tables in Postgres here. For our purposes, we're going to create a simple table like this: CREATE TABLE playground ( equip_id serial PRIMARY KEY, type varchar (50) NOT NULL, color varchar (25) NOT NULL, location varchar(25) check (location in ('north', 'south', 'west', 'east', 'northeast', 'southeast', 'southwest', 'northwest')), install_date date ); We have made a playground table that inventories the equipment that we have. This starts with an equipment ID, which is of the serial type. This data type is an auto-incrementing integer. We have given this column the constraint of primary key which means that the values must be unique and not null. For two of our columns (equip_id and install_date), we have not given a field length. This is because some column types don't require a set length because the length is implied by the type. We then give columns for the equipment type and color, each of which cannot be empty. We create a location column and create a constraint that requires the value to be one of eight possible values. The last column is a date column that records the date that we installed the equipment. We can see our new table by typing: \\d Output List of relations Schema | Name | Type | Owner --------+-------------------------+----------+------- public | playground | table | sammy public | playground_equip_id_seq | sequence | sammy (2 rows) Our playground table is here, but we also have something called playground_equip_id_seq that is of the type sequence. This is a representation of the serial type we gave our equip_id column. This keeps track of the next number in the sequence and is created automatically for columns of this type. If you want to see just the table without the sequence, you can type: \\dt Output List of relations Schema | Name | Type | Owner --------+------------+-------+------- public | playground | table | sammy (1 row) Add, Query, and Delete Data in a Table Now that we have a table, we can insert some data into it. Let's add a slide and a swing. We do this by calling the table we're wanting to add to, naming the columns and then providing data for each column. Our slide and swing could be added like this: INSERT INTO playground (type, color, location, install_date) VALUES ('slide', 'blue', 'south', '2014-04-28'); INSERT INTO playground (type, color, location, install_date) VALUES ('swing', 'yellow', 'northwest', '2010-08-16'); You should take care when entering the data to avoid a few common hangups. First, keep in mind that the column names should not be quoted, but the column values that you're entering do need quotes. Another thing to keep in mind is that we do not enter a value for the equip_id column. This is because this is auto-generated whenever a new row in the table is created. We can then get back the information we've added by typing: SELECT * FROM playground; Output equip_id | type | color | location | install_date ----------+-------+--------+-----------+-------------- 1 | slide | blue | south | 2014-04-28 2 | swing | yellow | northwest | 2010-08-16 (2 rows) Here, you can see that our equip_id has been filled in successfully and that all of our other data has been organized correctly. If the slide on the playground breaks and we have to remove it, we can also remove the row from our table by typing: DELETE FROM playground WHERE type = 'slide'; If we query our table again, we will see our slide is no longer a part of the table: SELECT * FROM playground; Output equip_id | type | color | location | install_date ----------+-------+--------+-----------+-------------- 2 | swing | yellow | northwest | 2010-08-16 (1 row) How To Add and Delete Columns from a Table If we want to modify a table after it has been created to add an additional column, we can do that easily. We can add a column to show the last maintenance visit for each piece of equipment by typing: ALTER TABLE playground ADD last_maint date; If you view your table information again, you will see the new column has been added (but no data has been entered): SELECT * FROM playground; Output equip_id | type | color | location | install_date | last_maint ----------+-------+--------+-----------+--------------+------------ 2 | swing | yellow | northwest | 2010-08-16 | (1 row) We can delete a column just as easily. If we find that our work crew uses a separate tool to keep track of maintenance history, we can get rid of the column here by typing: ALTER TABLE playground DROP last_maint; How To Update Data in a Table We know how to add records to a table and how to delete them, but we haven't covered how to modify existing entries yet. You can update the values of an existing entry by querying for the record you want and setting the column to the value you wish to use. We can query for the \"swing\" record (this will match every swing in our table) and change its color to \"red\". This could be useful if we gave the swing set a paint job: UPDATE playground SET color = 'red' WHERE type = 'swing'; We can verify that the operation was successful by querying our data again: SELECT * FROM playground; Output equip_id | type | color | location | install_date ----------+-------+-------+-----------+-------------- 2 | swing | red | northwest | 2010-08-16 (1 row) As you can see, our slide is now registered as being red. Source","title":"Create a New Database"},{"location":"cs-fundamentals/DS/","text":"Introduction Data Structure Vs Data Type Data Type Data Structure Abstract Data Type (ADT) Types Linear Data Structure Non Linear Data Structure Language Specific Array Linked List Doubly Linked List Circular Linked List Stack Queue Simple Queue Priority Queue Desc Properties Operations Implementation Hash Desc Terminologies Why Dictionary Hash Table Hash Map Tree Desc Terminologies Why Application Hand Shaking Lemma Binary Tree Desc Representation Properties Operations Depth First Traversal Breadth First Traversal (Level Order Traversal) Full Binary Tree Complete Binary Tree Perfect Binary Tree Degenerated / Pathological Tree Binary Search Tree (BST) Desc Operations Self Balancing Binary Tree B-Tree Desc Application Heap Min Heap Max Heap Trie Graph Undirected Graph Directed Graph Directed Acyclic Graph (DAG) Directed Cyclic Graph (DCG) Weighted Graph References Introduction # Data structure (is a way) or (are the special format/structures in computer memory) to store & organize the data. To suit a specific purpose. So, that we can perform some operations on them like search, add, delete, insert Data Structure Vs Data Type # Data Type # It is class of objects sharing certain properties. It is a premitive element of a particular language like C, C++, Java, Python, Go Have predefined characteristics according to the language Contains data/information without any semantic Can't be reduced anymore e.g. integer, float, character, string, boolean Data Structure # It is an abstract description of organization of data & operations on them It uses data types Can be decomposed to smaller DS are data type as well, but not a premitive type Abstract Data Type (ADT) # Its visualization, thought, logical description, or a picture of a new data type which we are going to create while DS is a real & concrete thing, we can directly use them DS is a super set and Data type is sub set or building block for DS Types # Linear Data Structure # Traverses the data elements sequentially. Only one data element can directly be reached. Array Linked List Singly Linked List Circular Linked List Doubly Linked List Stack Queue Simple Queue Circular Queue Priority Queue Dequeue / Double Ended Queue Hash Matrix Non Linear Data Structure # Every data item is attached to several other data items with a relationships. The data items are not arranged in a sequential structure. Tree Binary Tree Full Binary Tree Complete Binary Tree Binary Heap Max Heap Min Heap Perfect Binary Tree Degenerated / Pathological Tree Binary Search Tree - BST Self Balancing / Balanced / Height Balanced BST AVL Tree Red-Black Tree Splay Tree Treap K-ary Tree B Tree B+ tree Heap Max Heap Min Heap Binary Heap Bionomial Heap Fibbonacci Heap Trie Misc Indexing with Trees Segment Tree Fenwick Tree Binary Indexed Tree (BIT) Binomial Queues Fibonacci Heaps Leftist Heaps Skew Heaps Open Hash Tables (Closed Addressing) Closed Hash Tables (Open Addressing) Closed Hash Tables, using buckets Graph Undirected Directed Directed Acyclic Graph (DAG) Directed Cyclic Graph [having cycle(s)] (DCG) Weighted Weighted Undirected Graph Weighted Directed Graph (WITHOUT negative weights) Weighted DAG Weighted DCG Weighted Directed Graph (WITH negative weights) Weighted DAG Weighted DCG WITH Negative Weight Cycle WITHOUT Negative Weight Cycle Misc Finite Graph Infinite Graph Trivial Graph Simple Graph Multi Graph Null Graph Complete Graph Pseudo Graph Regular Graph Bipartite Graph Labelled Graph Connected & Disconnected Graph Cyclic Graph Vertex Labelled Graph Digraph Subgraph Misc Disjoint-set Data Structures Suffix Arrays Language Specific # Python list tuple set dict built-in dict collections.OrderedDict remember insertion order of keys collections.defaultdict return default values for missing keys collections.ChainMap search multiple dicts as a single mapping types.MappingProxyType A wrapper for making read-only dictionaries Java C# Go Array # Linked List # Doubly Linked List # Circular Linked List # Stack # LIFO Queue # FIFO Simple Queue # Priority Queue # Desc # Properties # Operations # Implementation # Array Binary Heap Fibbonacci Heap Hash # Desc # Linear data structure (ADT) to make lookup fast uses a hashing functions, a slot list and, a data list time complexity (lookup): best: O(1) worst: O(n) Terminologies # hash function folding method mid-squared method perfect hash functions slot/bucket load factor collision resolution techniques (rehashing) open addressing linear probing quadratic probing disadvantages clustered data chaining Why # to optimize the look-up speed after binary search and other varients Dictionary # a general concept/data structure that maps keys to values many ways to implement dictionary hashtable; O(1) - O(N) red-black tree; always O(longN) Hash Table # synchronized thread safe can be shared with many threads doesn't allows any null key or values Hash Map # non synchronized non-thread safe can't be shared between many threads without proper synchronization code allows one null key and multiple null values preferred over hash-table Tree # Desc # Are hierchical data structure made up of nodes or vertices and edges without having any cycle The tree with no nodes is called the null or empty tree Terminologies # Root: The top node in a tree. Child: A node directly connected to another node when moving away from the Root. Parent: The converse notion of a child. Siblings: A group of nodes with the same parent. Descendant: A node reachable by repeated proceeding from parent to child. Ancestor: A node reachable by repeated proceeding from child to parent. Leaf: (less commonly called External node) A node with no children. Branch: Internal node, A node with at least one child. Degree: The number of subtrees of a node. Edge: The connection between one node and another. Path: A sequence of nodes and edges connecting a node with a descendant. Level : The level of a node is defined by 1 + (the number of connections between the node and the root). Height of node : The height of a node is the number of edges on the longest path between that node and a leaf. Height of tree: The height of a tree is the height of its root node. Depth: The depth of a node is the number of edges from the tree's root node to the node. Forest: A forest is a set of n \u00e2\u0089\u00a5 0 disjoint trees. Why # need to store in hierchical way, e.g. computer filesystem provides quicker insertion/deletion than array but slower than unordered linked list No upper limit on number of nodes (like linkedlist & unlike array) Application # Easy to search (using traversal) Router Algorithm decision making Hand Shaking Lemma # In an undirected graph, Number of vertex of odd degree are alway even. Vertex of odd degree = Vertex connected to 3 edges. Binary Tree # Desc # tree whose each node have at most 2 children children typically known as left and right child. Representation # a node consist of data, pointer to left child, pointer to right child Properties # Level(Root) = 1, but height = 0 (don't get confuse) Maximum number of nodes at level $ i = 2^{i-1}$ Level of a Node = Height of the Node + 1 Minimum Possible Height of a tree having N nodes: h = \\lfloor \\log_2{(N+1)} \\rfloor h = \\lfloor \\log_2{(N+1)} \\rfloor A binary tree with L leaves is of at least height h = \\lceil \\log_2{L} \\rceil h = \\lceil \\log_2{L} \\rceil Number of leaves = Number of internal nodes having 2 children + 1 Operations # Depth First Traversal # Types: In Order: left, root, right Pre Order: root, left, right Post Order: left, right, root Ways: Standard (Recursive) Desc: Approach: Recursive DS Used: Using Stack (Iterative, Which is same as Recursive one) Desc: Apprach: Iterative DS Used: Stack Without Recursion, Without Stack: Morris Traversal: Based on Threaded Binary Tree Desc: Apprach: DS Used: Time Complexity: O(n) Auxilary Space: Avg: O(h) due to Recursive call stack; where h is max height of the tree Worst: When tree is skewed tree, i.e. h at last level = O(\\log_2{n}) O(\\log_2{n}) Dis-Advantage: Recursive solution Traversal starts from Leaf, unlike BFS. Breadth First Traversal (Level Order Traversal) # Way: Using Level By Level Looping: Desc: Find out total level of the tree : Traverse each sub-tree + Compare level of left & right Loop from first level to last For each level print all the nodes: If root is empty, return; If level reached 1, print the data Make Recursive call for each child by decreasing level by 1 Approach: Recursive DS Used: None Using Queue Desc: If given node is not none, visit & print given node, Then enqueue left & right child in the queue (if they are not none). Dequeue one node from the queue & make recursive call for that node. Approach: Recursive DS Used: Queue Time Complexity: \\theta{(n)} \\theta{(n)} Auxilary Space: Avg: O(w), where w is max width of the tree Worst: When tree is Perfect tree, i.e. w at last level = O(\\lceil {n/2} \\rceil) O(\\lceil {n/2} \\rceil) Advantage: Non recursive solution Traversal starts from root, unlike DFS. So, better if our finding is closer to root. Full Binary Tree # Every node has 0 or 2 children Complete Binary Tree # All level are completely filled, except possibly last level and last level has all keys as left as possible. Practical e.g.: Binary Heap 18 / \\ 15 30 / \\ / \\ 40 50 100 40 18 / \\ 15 30 / \\ / \\ 40 50 100 40 / \\ / 8 7 9 Perfect Binary Tree # All internal nodes have 2 children and all leaves are at same level. Degenerated / Pathological Tree # Every internal node has one child. Performance-wise same as linked list. Binary Search Tree (BST) # Desc # Operations # SEARCH, MINIMUM, MAXIMUM, PREDECESSOR, SUCCESSOR, INSERT, DELETE Self Balancing Binary Tree # B-Tree # Desc # Generalization of BST i.e. a node can have more than 2 children Application # Indexing in Databases Filesystem Heap # Min Heap # Max Heap # Trie # Graph # Undirected Graph # Directed Graph # Directed Acyclic Graph (DAG) # Directed Cyclic Graph (DCG) # Weighted Graph # References # https://gist.github.com/toransahu/bb1c9f1cd6490ff29c42fa229e827a2a","title":"DS"},{"location":"cs-fundamentals/DS/#introduction","text":"Data structure (is a way) or (are the special format/structures in computer memory) to store & organize the data. To suit a specific purpose. So, that we can perform some operations on them like search, add, delete, insert","title":"Introduction"},{"location":"cs-fundamentals/DS/#data-structure-vs-data-type","text":"","title":"Data Structure Vs Data Type"},{"location":"cs-fundamentals/DS/#data-type","text":"It is class of objects sharing certain properties. It is a premitive element of a particular language like C, C++, Java, Python, Go Have predefined characteristics according to the language Contains data/information without any semantic Can't be reduced anymore e.g. integer, float, character, string, boolean","title":"Data Type"},{"location":"cs-fundamentals/DS/#data-structure","text":"It is an abstract description of organization of data & operations on them It uses data types Can be decomposed to smaller DS are data type as well, but not a premitive type","title":"Data Structure"},{"location":"cs-fundamentals/DS/#abstract-data-type-adt","text":"Its visualization, thought, logical description, or a picture of a new data type which we are going to create while DS is a real & concrete thing, we can directly use them DS is a super set and Data type is sub set or building block for DS","title":"Abstract Data Type (ADT)"},{"location":"cs-fundamentals/DS/#types","text":"","title":"Types"},{"location":"cs-fundamentals/DS/#linear-data-structure","text":"Traverses the data elements sequentially. Only one data element can directly be reached. Array Linked List Singly Linked List Circular Linked List Doubly Linked List Stack Queue Simple Queue Circular Queue Priority Queue Dequeue / Double Ended Queue Hash Matrix","title":"Linear Data Structure"},{"location":"cs-fundamentals/DS/#non-linear-data-structure","text":"Every data item is attached to several other data items with a relationships. The data items are not arranged in a sequential structure. Tree Binary Tree Full Binary Tree Complete Binary Tree Binary Heap Max Heap Min Heap Perfect Binary Tree Degenerated / Pathological Tree Binary Search Tree - BST Self Balancing / Balanced / Height Balanced BST AVL Tree Red-Black Tree Splay Tree Treap K-ary Tree B Tree B+ tree Heap Max Heap Min Heap Binary Heap Bionomial Heap Fibbonacci Heap Trie Misc Indexing with Trees Segment Tree Fenwick Tree Binary Indexed Tree (BIT) Binomial Queues Fibonacci Heaps Leftist Heaps Skew Heaps Open Hash Tables (Closed Addressing) Closed Hash Tables (Open Addressing) Closed Hash Tables, using buckets Graph Undirected Directed Directed Acyclic Graph (DAG) Directed Cyclic Graph [having cycle(s)] (DCG) Weighted Weighted Undirected Graph Weighted Directed Graph (WITHOUT negative weights) Weighted DAG Weighted DCG Weighted Directed Graph (WITH negative weights) Weighted DAG Weighted DCG WITH Negative Weight Cycle WITHOUT Negative Weight Cycle Misc Finite Graph Infinite Graph Trivial Graph Simple Graph Multi Graph Null Graph Complete Graph Pseudo Graph Regular Graph Bipartite Graph Labelled Graph Connected & Disconnected Graph Cyclic Graph Vertex Labelled Graph Digraph Subgraph Misc Disjoint-set Data Structures Suffix Arrays","title":"Non Linear Data Structure"},{"location":"cs-fundamentals/DS/#language-specific","text":"Python list tuple set dict built-in dict collections.OrderedDict remember insertion order of keys collections.defaultdict return default values for missing keys collections.ChainMap search multiple dicts as a single mapping types.MappingProxyType A wrapper for making read-only dictionaries Java C# Go","title":"Language Specific"},{"location":"cs-fundamentals/DS/#array","text":"","title":"Array"},{"location":"cs-fundamentals/DS/#linked-list","text":"","title":"Linked List"},{"location":"cs-fundamentals/DS/#doubly-linked-list","text":"","title":"Doubly Linked List"},{"location":"cs-fundamentals/DS/#circular-linked-list","text":"","title":"Circular Linked List"},{"location":"cs-fundamentals/DS/#stack","text":"LIFO","title":"Stack"},{"location":"cs-fundamentals/DS/#queue","text":"FIFO","title":"Queue"},{"location":"cs-fundamentals/DS/#simple-queue","text":"","title":"Simple Queue"},{"location":"cs-fundamentals/DS/#priority-queue","text":"","title":"Priority Queue"},{"location":"cs-fundamentals/DS/#desc","text":"","title":"Desc"},{"location":"cs-fundamentals/DS/#properties","text":"","title":"Properties"},{"location":"cs-fundamentals/DS/#operations","text":"","title":"Operations"},{"location":"cs-fundamentals/DS/#implementation","text":"Array Binary Heap Fibbonacci Heap","title":"Implementation"},{"location":"cs-fundamentals/DS/#hash","text":"","title":"Hash"},{"location":"cs-fundamentals/DS/#desc_1","text":"Linear data structure (ADT) to make lookup fast uses a hashing functions, a slot list and, a data list time complexity (lookup): best: O(1) worst: O(n)","title":"Desc"},{"location":"cs-fundamentals/DS/#terminologies","text":"hash function folding method mid-squared method perfect hash functions slot/bucket load factor collision resolution techniques (rehashing) open addressing linear probing quadratic probing disadvantages clustered data chaining","title":"Terminologies"},{"location":"cs-fundamentals/DS/#why","text":"to optimize the look-up speed after binary search and other varients","title":"Why"},{"location":"cs-fundamentals/DS/#dictionary","text":"a general concept/data structure that maps keys to values many ways to implement dictionary hashtable; O(1) - O(N) red-black tree; always O(longN)","title":"Dictionary"},{"location":"cs-fundamentals/DS/#hash-table","text":"synchronized thread safe can be shared with many threads doesn't allows any null key or values","title":"Hash Table"},{"location":"cs-fundamentals/DS/#hash-map","text":"non synchronized non-thread safe can't be shared between many threads without proper synchronization code allows one null key and multiple null values preferred over hash-table","title":"Hash Map"},{"location":"cs-fundamentals/DS/#tree","text":"","title":"Tree"},{"location":"cs-fundamentals/DS/#desc_2","text":"Are hierchical data structure made up of nodes or vertices and edges without having any cycle The tree with no nodes is called the null or empty tree","title":"Desc"},{"location":"cs-fundamentals/DS/#terminologies_1","text":"Root: The top node in a tree. Child: A node directly connected to another node when moving away from the Root. Parent: The converse notion of a child. Siblings: A group of nodes with the same parent. Descendant: A node reachable by repeated proceeding from parent to child. Ancestor: A node reachable by repeated proceeding from child to parent. Leaf: (less commonly called External node) A node with no children. Branch: Internal node, A node with at least one child. Degree: The number of subtrees of a node. Edge: The connection between one node and another. Path: A sequence of nodes and edges connecting a node with a descendant. Level : The level of a node is defined by 1 + (the number of connections between the node and the root). Height of node : The height of a node is the number of edges on the longest path between that node and a leaf. Height of tree: The height of a tree is the height of its root node. Depth: The depth of a node is the number of edges from the tree's root node to the node. Forest: A forest is a set of n \u00e2\u0089\u00a5 0 disjoint trees.","title":"Terminologies"},{"location":"cs-fundamentals/DS/#why_1","text":"need to store in hierchical way, e.g. computer filesystem provides quicker insertion/deletion than array but slower than unordered linked list No upper limit on number of nodes (like linkedlist & unlike array)","title":"Why"},{"location":"cs-fundamentals/DS/#application","text":"Easy to search (using traversal) Router Algorithm decision making","title":"Application"},{"location":"cs-fundamentals/DS/#hand-shaking-lemma","text":"In an undirected graph, Number of vertex of odd degree are alway even. Vertex of odd degree = Vertex connected to 3 edges.","title":"Hand Shaking Lemma"},{"location":"cs-fundamentals/DS/#binary-tree","text":"","title":"Binary Tree"},{"location":"cs-fundamentals/DS/#desc_3","text":"tree whose each node have at most 2 children children typically known as left and right child.","title":"Desc"},{"location":"cs-fundamentals/DS/#representation","text":"a node consist of data, pointer to left child, pointer to right child","title":"Representation"},{"location":"cs-fundamentals/DS/#properties_1","text":"Level(Root) = 1, but height = 0 (don't get confuse) Maximum number of nodes at level $ i = 2^{i-1}$ Level of a Node = Height of the Node + 1 Minimum Possible Height of a tree having N nodes: h = \\lfloor \\log_2{(N+1)} \\rfloor h = \\lfloor \\log_2{(N+1)} \\rfloor A binary tree with L leaves is of at least height h = \\lceil \\log_2{L} \\rceil h = \\lceil \\log_2{L} \\rceil Number of leaves = Number of internal nodes having 2 children + 1","title":"Properties"},{"location":"cs-fundamentals/DS/#operations_1","text":"","title":"Operations"},{"location":"cs-fundamentals/DS/#depth-first-traversal","text":"Types: In Order: left, root, right Pre Order: root, left, right Post Order: left, right, root Ways: Standard (Recursive) Desc: Approach: Recursive DS Used: Using Stack (Iterative, Which is same as Recursive one) Desc: Apprach: Iterative DS Used: Stack Without Recursion, Without Stack: Morris Traversal: Based on Threaded Binary Tree Desc: Apprach: DS Used: Time Complexity: O(n) Auxilary Space: Avg: O(h) due to Recursive call stack; where h is max height of the tree Worst: When tree is skewed tree, i.e. h at last level = O(\\log_2{n}) O(\\log_2{n}) Dis-Advantage: Recursive solution Traversal starts from Leaf, unlike BFS.","title":"Depth First Traversal"},{"location":"cs-fundamentals/DS/#breadth-first-traversal-level-order-traversal","text":"Way: Using Level By Level Looping: Desc: Find out total level of the tree : Traverse each sub-tree + Compare level of left & right Loop from first level to last For each level print all the nodes: If root is empty, return; If level reached 1, print the data Make Recursive call for each child by decreasing level by 1 Approach: Recursive DS Used: None Using Queue Desc: If given node is not none, visit & print given node, Then enqueue left & right child in the queue (if they are not none). Dequeue one node from the queue & make recursive call for that node. Approach: Recursive DS Used: Queue Time Complexity: \\theta{(n)} \\theta{(n)} Auxilary Space: Avg: O(w), where w is max width of the tree Worst: When tree is Perfect tree, i.e. w at last level = O(\\lceil {n/2} \\rceil) O(\\lceil {n/2} \\rceil) Advantage: Non recursive solution Traversal starts from root, unlike DFS. So, better if our finding is closer to root.","title":"Breadth First Traversal (Level Order Traversal)"},{"location":"cs-fundamentals/DS/#full-binary-tree","text":"Every node has 0 or 2 children","title":"Full Binary Tree"},{"location":"cs-fundamentals/DS/#complete-binary-tree","text":"All level are completely filled, except possibly last level and last level has all keys as left as possible. Practical e.g.: Binary Heap 18 / \\ 15 30 / \\ / \\ 40 50 100 40 18 / \\ 15 30 / \\ / \\ 40 50 100 40 / \\ / 8 7 9","title":"Complete Binary Tree"},{"location":"cs-fundamentals/DS/#perfect-binary-tree","text":"All internal nodes have 2 children and all leaves are at same level.","title":"Perfect Binary Tree"},{"location":"cs-fundamentals/DS/#degenerated-pathological-tree","text":"Every internal node has one child. Performance-wise same as linked list.","title":"Degenerated / Pathological Tree"},{"location":"cs-fundamentals/DS/#binary-search-tree-bst","text":"","title":"Binary Search Tree (BST)"},{"location":"cs-fundamentals/DS/#desc_4","text":"","title":"Desc"},{"location":"cs-fundamentals/DS/#operations_2","text":"SEARCH, MINIMUM, MAXIMUM, PREDECESSOR, SUCCESSOR, INSERT, DELETE","title":"Operations"},{"location":"cs-fundamentals/DS/#self-balancing-binary-tree","text":"","title":"Self Balancing Binary Tree"},{"location":"cs-fundamentals/DS/#b-tree","text":"","title":"B-Tree"},{"location":"cs-fundamentals/DS/#desc_5","text":"Generalization of BST i.e. a node can have more than 2 children","title":"Desc"},{"location":"cs-fundamentals/DS/#application_1","text":"Indexing in Databases Filesystem","title":"Application"},{"location":"cs-fundamentals/DS/#heap","text":"","title":"Heap"},{"location":"cs-fundamentals/DS/#min-heap","text":"","title":"Min Heap"},{"location":"cs-fundamentals/DS/#max-heap","text":"","title":"Max Heap"},{"location":"cs-fundamentals/DS/#trie","text":"","title":"Trie"},{"location":"cs-fundamentals/DS/#graph","text":"","title":"Graph"},{"location":"cs-fundamentals/DS/#undirected-graph","text":"","title":"Undirected Graph"},{"location":"cs-fundamentals/DS/#directed-graph","text":"","title":"Directed Graph"},{"location":"cs-fundamentals/DS/#directed-acyclic-graph-dag","text":"","title":"Directed Acyclic Graph (DAG)"},{"location":"cs-fundamentals/DS/#directed-cyclic-graph-dcg","text":"","title":"Directed Cyclic Graph (DCG)"},{"location":"cs-fundamentals/DS/#weighted-graph","text":"","title":"Weighted Graph"},{"location":"cs-fundamentals/DS/#references","text":"https://gist.github.com/toransahu/bb1c9f1cd6490ff29c42fa229e827a2a","title":"References"},{"location":"cs-fundamentals/Network/","text":"Network Introduction Network Usages todos Basic Story Protocols Why TCP (Transmission Control Protocol) IP (Internet Protocol) UDP ICMP Why? What? How? HTTP, HTTPS TLS, SSL WebSocket SMTP ARP (Address Resolution Protocol) OSI Model Intro Application Layer Protocols Presentation Layer Protocols Session Layer Protocols Transport Layer Protocols Network Layer Protocols Data Link Layer Protocols Physical Layer Protocols TCP/IP Model Application Layer Protocols Transport Layer Protocols Internet Layer Protocols Network Interface/Access Layer (Link Layer) Protocols Ethernet TODOs Network # Introduction # 18th century: age of mechanical systems - indutries 19th century: age of steam engine 20th century: age of information + telephone networks + radios, tv, computer, satellite earlier - a centralized computer - a big computer ina room for an org nowadays - many distributed computers, in large quantity with rise - need more robust, sophisticated system to monitor each part/layer/unit of the network end to end. large number of separate computers able to exchange info i.e. interconnected == Computer Network focus : design & organization of this network internet/www != computer network internet == collection of computer networks www == distributed system running on top of internet distributed system == computer network ? Differences - distributed system - a collection of independent computers appears to its users as a single coherent system - has a single model, paradigm - responsible for implementing these models -> middleware - built on top of a network - softwares gives it a high degree of cohesiveness and transparency - e.g. - www: everything looks like a document, a **Web Page** computer network coherence, model, software are absent user are exposed to the actual machines The main differentiator is software or operating system. But no hardware. Middleware: software that acts as a bridge between an operating system or database and applications, especially on a network. Network Usages # resource sharing (more general) business applications client-server model communication / e-mail e-commerce home aaplications internet remote information p2p - phone, instant msg-ing entertainment e-com fin mobile / wireless todos # wap1.0 wap2.0 Basic Story # Connect WiFi in laptop to your modem 2 ARP will happen Will follow DORA process Discovery: client mac will Protocols # Why # Given the importance of protocols to the Internet, it\u2019s important that everyone agree on what each and every protocol does, so that people can create systems and products that interoperate. This is where standards come into play. Internet stan- dards are developed by the Internet Engineering Task Force (IETF)[IETF 2012]. The IETF standards documents are called requests for comments (RFCs). RFCs started out as general requests for comments (hence the name) to resolve network and protocol design problems that faced the precursor to the Internet RFCs tend to be quite technical and detailed TCP (Transmission Control Protocol) # IP (Internet Protocol) # UDP # https://www.smashingmagazine.com/2017/06/guide-switching-http-https/ ICMP # (Internet Control Message Protocol) - https://erg.abdn.ac.uk/users/gorry/eg3567/inet-pages/icmp.html - https://cse.sc.edu/~wyxu/515Fall08/slides/IPRoutingtrace.pdf Why? # Because IP wasn't designed to be absolutely reliable & it doesn't have an inbuilt mechanism for sending control(errors & query) messages. ICMP comes in picture: - to provide feedback to the source IP address by network devices like routers (and may be switch, hub..) - that a router/service/host can't be reached for packet (datagram) delivery - to answer queries raised by ping & traceroute tools What? # ICMP is a supporting protocol ICMP is not a transport protocol ICMP is typlically not used to exchange data between systems (except in case of diagnostic tools ^) ICMP sits in N/W layer of OSI along with IP and hence port doesn't come in picture here ports are only used for protocols which work at the transport layer and above ICMP send multiple types of messages: ping (echo) ping reply (echo reply) destination unreachable etc.. ICMP structure ICMP Header (8 bytes) ICMP type ICMP code (sub-type) Chechsum Extra content (of 4 bytes) based on type & code ICMP message (variable, min 28 bytes) entire IP Header from IP datagram that resulted in error (min 20 bytes, variable) atleast (first) 8 bytes of data from IP datagram that resulted in error ICMP Header Structure How? # ICMP messages are encapsulated in an IP datagrams and transmitted along with them to the transport layer protocol in IP datagrams are set to ICMP so that receiving end can interprete it using ICMP client source address is set to the IP address of the device that generated the datagram (& ICMP message) destination address is set to the source address mentioned in the packet (datagram) that resulted in error (i.e. of which delivery failed) Structure of IP datagram having ICMP encapsulated within it IP header (20 bytes) IP Protocol=ICMP IP data ICMP message ICMP header (1+1+2+4 bytes) ICMP data (min 28 bytes, variable) IP Datagram Structure HTTP, HTTPS # TLS, SSL # WebSocket # SMTP # ARP (Address Resolution Protocol) # OSI Model # (Open Systems Interconnection) https://www.webopedia.com/quick_ref/OSI_Layers.asp Intro # Open Systems Interconnection Model a conceptual model characterize & standarize the communication function of telecommunication/ compututing systems without any knowledge of its internal structure & technology partitioned in abstraction layers a layer serves the layer above it Application Layer # Protocols # HTTP, HTTPS, SMTP, FTP Presentation Layer # Protocols # JPEG, MPEG Session Layer # Protocols # NFS, SQL, RPC Transport Layer # Protocols # TCP, UDP Network Layer # Protocols # IP, ICMP, ARP, RARP, IGMP Data Link Layer # Protocols # HDLC, PPP Physical Layer # Protocols # no protocols at this layer TCP/IP Model # http://what-when-how.com/data-communications-and-networking/network-and-transport-layers-data-communications-and-networking/ https://www.hardwaresecrets.com/how-tcp-ip-protocol-works-part-1/6/ Application Layer # Protocols # HTTP, HTTPS, SMTP, FTP, JPEG, MPEG, NFS, SQL, RPC Transport Layer # Protocols # TCP, UDP Internet Layer # Protocols # TCP, UDP Network Interface/Access Layer (Link Layer) # Protocols # IP, ICMP, ARP, RARP, IGMP Ethernet # Note: TCP/IP is a set of protocols that deals with layers 3 to 7 from the OSI reference model, while Ethernet is a set of protocols that deals with layers 1 and 2 from the OSI reference model TODOs # Packets Packet Switch Internet API Internet Service Distributed App","title":"Network"},{"location":"cs-fundamentals/Network/#network","text":"","title":"Network"},{"location":"cs-fundamentals/Network/#introduction","text":"18th century: age of mechanical systems - indutries 19th century: age of steam engine 20th century: age of information + telephone networks + radios, tv, computer, satellite earlier - a centralized computer - a big computer ina room for an org nowadays - many distributed computers, in large quantity with rise - need more robust, sophisticated system to monitor each part/layer/unit of the network end to end. large number of separate computers able to exchange info i.e. interconnected == Computer Network focus : design & organization of this network internet/www != computer network internet == collection of computer networks www == distributed system running on top of internet distributed system == computer network ? Differences - distributed system - a collection of independent computers appears to its users as a single coherent system - has a single model, paradigm - responsible for implementing these models -> middleware - built on top of a network - softwares gives it a high degree of cohesiveness and transparency - e.g. - www: everything looks like a document, a **Web Page** computer network coherence, model, software are absent user are exposed to the actual machines The main differentiator is software or operating system. But no hardware. Middleware: software that acts as a bridge between an operating system or database and applications, especially on a network.","title":"Introduction"},{"location":"cs-fundamentals/Network/#network-usages","text":"resource sharing (more general) business applications client-server model communication / e-mail e-commerce home aaplications internet remote information p2p - phone, instant msg-ing entertainment e-com fin mobile / wireless","title":"Network Usages"},{"location":"cs-fundamentals/Network/#todos","text":"wap1.0 wap2.0","title":"todos"},{"location":"cs-fundamentals/Network/#basic-story","text":"Connect WiFi in laptop to your modem 2 ARP will happen Will follow DORA process Discovery: client mac will","title":"Basic Story"},{"location":"cs-fundamentals/Network/#protocols","text":"","title":"Protocols"},{"location":"cs-fundamentals/Network/#why","text":"Given the importance of protocols to the Internet, it\u2019s important that everyone agree on what each and every protocol does, so that people can create systems and products that interoperate. This is where standards come into play. Internet stan- dards are developed by the Internet Engineering Task Force (IETF)[IETF 2012]. The IETF standards documents are called requests for comments (RFCs). RFCs started out as general requests for comments (hence the name) to resolve network and protocol design problems that faced the precursor to the Internet RFCs tend to be quite technical and detailed","title":"Why"},{"location":"cs-fundamentals/Network/#tcp-transmission-control-protocol","text":"","title":"TCP (Transmission Control Protocol)"},{"location":"cs-fundamentals/Network/#ip-internet-protocol","text":"","title":"IP (Internet Protocol)"},{"location":"cs-fundamentals/Network/#udp","text":"https://www.smashingmagazine.com/2017/06/guide-switching-http-https/","title":"UDP"},{"location":"cs-fundamentals/Network/#icmp","text":"(Internet Control Message Protocol) - https://erg.abdn.ac.uk/users/gorry/eg3567/inet-pages/icmp.html - https://cse.sc.edu/~wyxu/515Fall08/slides/IPRoutingtrace.pdf","title":"ICMP"},{"location":"cs-fundamentals/Network/#why_1","text":"Because IP wasn't designed to be absolutely reliable & it doesn't have an inbuilt mechanism for sending control(errors & query) messages. ICMP comes in picture: - to provide feedback to the source IP address by network devices like routers (and may be switch, hub..) - that a router/service/host can't be reached for packet (datagram) delivery - to answer queries raised by ping & traceroute tools","title":"Why?"},{"location":"cs-fundamentals/Network/#what","text":"ICMP is a supporting protocol ICMP is not a transport protocol ICMP is typlically not used to exchange data between systems (except in case of diagnostic tools ^) ICMP sits in N/W layer of OSI along with IP and hence port doesn't come in picture here ports are only used for protocols which work at the transport layer and above ICMP send multiple types of messages: ping (echo) ping reply (echo reply) destination unreachable etc.. ICMP structure ICMP Header (8 bytes) ICMP type ICMP code (sub-type) Chechsum Extra content (of 4 bytes) based on type & code ICMP message (variable, min 28 bytes) entire IP Header from IP datagram that resulted in error (min 20 bytes, variable) atleast (first) 8 bytes of data from IP datagram that resulted in error ICMP Header Structure","title":"What?"},{"location":"cs-fundamentals/Network/#how","text":"ICMP messages are encapsulated in an IP datagrams and transmitted along with them to the transport layer protocol in IP datagrams are set to ICMP so that receiving end can interprete it using ICMP client source address is set to the IP address of the device that generated the datagram (& ICMP message) destination address is set to the source address mentioned in the packet (datagram) that resulted in error (i.e. of which delivery failed) Structure of IP datagram having ICMP encapsulated within it IP header (20 bytes) IP Protocol=ICMP IP data ICMP message ICMP header (1+1+2+4 bytes) ICMP data (min 28 bytes, variable) IP Datagram Structure","title":"How?"},{"location":"cs-fundamentals/Network/#http-https","text":"","title":"HTTP, HTTPS"},{"location":"cs-fundamentals/Network/#tls-ssl","text":"","title":"TLS, SSL"},{"location":"cs-fundamentals/Network/#websocket","text":"","title":"WebSocket"},{"location":"cs-fundamentals/Network/#smtp","text":"","title":"SMTP"},{"location":"cs-fundamentals/Network/#arp-address-resolution-protocol","text":"","title":"ARP (Address Resolution Protocol)"},{"location":"cs-fundamentals/Network/#osi-model","text":"(Open Systems Interconnection) https://www.webopedia.com/quick_ref/OSI_Layers.asp","title":"OSI Model"},{"location":"cs-fundamentals/Network/#intro","text":"Open Systems Interconnection Model a conceptual model characterize & standarize the communication function of telecommunication/ compututing systems without any knowledge of its internal structure & technology partitioned in abstraction layers a layer serves the layer above it","title":"Intro"},{"location":"cs-fundamentals/Network/#application-layer","text":"","title":"Application Layer"},{"location":"cs-fundamentals/Network/#protocols_1","text":"HTTP, HTTPS, SMTP, FTP","title":"Protocols"},{"location":"cs-fundamentals/Network/#presentation-layer","text":"","title":"Presentation Layer"},{"location":"cs-fundamentals/Network/#protocols_2","text":"JPEG, MPEG","title":"Protocols"},{"location":"cs-fundamentals/Network/#session-layer","text":"","title":"Session Layer"},{"location":"cs-fundamentals/Network/#protocols_3","text":"NFS, SQL, RPC","title":"Protocols"},{"location":"cs-fundamentals/Network/#transport-layer","text":"","title":"Transport Layer"},{"location":"cs-fundamentals/Network/#protocols_4","text":"TCP, UDP","title":"Protocols"},{"location":"cs-fundamentals/Network/#network-layer","text":"","title":"Network Layer"},{"location":"cs-fundamentals/Network/#protocols_5","text":"IP, ICMP, ARP, RARP, IGMP","title":"Protocols"},{"location":"cs-fundamentals/Network/#data-link-layer","text":"","title":"Data Link Layer"},{"location":"cs-fundamentals/Network/#protocols_6","text":"HDLC, PPP","title":"Protocols"},{"location":"cs-fundamentals/Network/#physical-layer","text":"","title":"Physical Layer"},{"location":"cs-fundamentals/Network/#protocols_7","text":"no protocols at this layer","title":"Protocols"},{"location":"cs-fundamentals/Network/#tcpip-model","text":"http://what-when-how.com/data-communications-and-networking/network-and-transport-layers-data-communications-and-networking/ https://www.hardwaresecrets.com/how-tcp-ip-protocol-works-part-1/6/","title":"TCP/IP Model"},{"location":"cs-fundamentals/Network/#application-layer_1","text":"","title":"Application Layer"},{"location":"cs-fundamentals/Network/#protocols_8","text":"HTTP, HTTPS, SMTP, FTP, JPEG, MPEG, NFS, SQL, RPC","title":"Protocols"},{"location":"cs-fundamentals/Network/#transport-layer_1","text":"","title":"Transport Layer"},{"location":"cs-fundamentals/Network/#protocols_9","text":"TCP, UDP","title":"Protocols"},{"location":"cs-fundamentals/Network/#internet-layer","text":"","title":"Internet Layer"},{"location":"cs-fundamentals/Network/#protocols_10","text":"TCP, UDP","title":"Protocols"},{"location":"cs-fundamentals/Network/#network-interfaceaccess-layer-link-layer","text":"","title":"Network Interface/Access Layer (Link Layer)"},{"location":"cs-fundamentals/Network/#protocols_11","text":"IP, ICMP, ARP, RARP, IGMP","title":"Protocols"},{"location":"cs-fundamentals/Network/#ethernet","text":"Note: TCP/IP is a set of protocols that deals with layers 3 to 7 from the OSI reference model, while Ethernet is a set of protocols that deals with layers 1 and 2 from the OSI reference model","title":"Ethernet"},{"location":"cs-fundamentals/Network/#todos_1","text":"Packets Packet Switch Internet API Internet Service Distributed App","title":"TODOs"},{"location":"cs-fundamentals/OS/","text":"Operating Systems Semaphore Vs Mutex Producer-Consumer Problem Critical Section Inter Process Communication Operating Systems # Semaphore Vs Mutex # Are kernel resources and provides synchronization service Also known as synchronization primitives both are semaphores Semaphore/Binary Semaphore (are generalized mutext) Mutual Exclusive (Mutex) Semaphore Recursive mutex But are different and work differently: Mutex: Locking Mechanism Ownership involved: The thread/process which have mutex and accessing data can only release mutex Semaphore: Signalling Mechanism: An Why 2 different synchronization premitives? Producer-Consumer Problem # Critical Section # In con-current programming * A group of instructions/statements or region of code * that region to be executed atomically (i.e. all or nothing) A simple solution to critical section acquireLock () executeCriticalSection () releaseLock () Inter Process Communication #","title":"OS"},{"location":"cs-fundamentals/OS/#operating-systems","text":"","title":"Operating Systems"},{"location":"cs-fundamentals/OS/#semaphore-vs-mutex","text":"Are kernel resources and provides synchronization service Also known as synchronization primitives both are semaphores Semaphore/Binary Semaphore (are generalized mutext) Mutual Exclusive (Mutex) Semaphore Recursive mutex But are different and work differently: Mutex: Locking Mechanism Ownership involved: The thread/process which have mutex and accessing data can only release mutex Semaphore: Signalling Mechanism: An Why 2 different synchronization premitives?","title":"Semaphore Vs Mutex"},{"location":"cs-fundamentals/OS/#producer-consumer-problem","text":"","title":"Producer-Consumer Problem"},{"location":"cs-fundamentals/OS/#critical-section","text":"In con-current programming * A group of instructions/statements or region of code * that region to be executed atomically (i.e. all or nothing) A simple solution to critical section acquireLock () executeCriticalSection () releaseLock ()","title":"Critical Section"},{"location":"cs-fundamentals/OS/#inter-process-communication","text":"","title":"Inter Process Communication"},{"location":"cs-fundamentals/SE/","text":"Programming Languages An Overview of Programs and Programming Languages Compiled, interpreted, or JIT-compiled High or Low Level Level Type System Paradigms Standardization Repository Structure History OS Open Source Guide Software Licensing Intro Apache-2.0 MIT BSD-2-Clause BSD-3-Clause GPL-2.0 GPL-3.0 AGPL-3.0 Software Security Obfuscation Obfuscation Tools Protect Code Protect .Net Code Decompile Tools DLLs Python PL/SQL Encryption Symmetric Key Encryption DES (Data Encryption Standard) AES (Advanced Encryption Standard) Asymmetric Encryption (Private/Public Key) Deffie-Hellman Key Exchange RSA (Rivest\u2013Shamir\u2013Adleman) Misc .Net DLL vs C++ DLL 32 bit vs 64 bit DLL Programming Languages # An Overview of Programs and Programming Languages # In order to better communicate to our computers what exactly it is we want them to do, we've developed a wide range of programming languages to make the communication process easier. Depending on the type of project, there are many factors that have to be considered when choosing a language. Here is a list of some of the more noteworthy ones: Compiled, interpreted, or JIT-compiled # Compiled languages are translated to the target machine's native language by a program called a compiler. This can result in very fast code, especially if the compiler is effective at optimizing, however the resulting code may not port well across operating systems and the compilation process may take a while. Interpreted languages are read by a program called an interpreter and are executed by that program. While they are as portable as their interpreter and have no long compile times, interpreted languages are usually much slower than an equivalent compiled program. Finally, just-in-time compiled (or JIT-compiled) languages are languages that are quickly compiled when programs written in them need to be run (usually with very little optimization), offering a balance between performance and portability. High or Low Level Level # In this case, refers to how much the nature of the language reflects the underlying system. In other words, a programming language's level refers to how similar the language is to a computer's native language. The higher the level, the less similar it is. A low-level language is generally quite similar to machine code, and thus is more suitable for programs like device drivers or very high performance programs that really need access to the hardware. Generally, the term is reserved for machine code itself and assembly languages, though many languages offer low-level elements. Since a low-level language is subject to all the nuances of the hardware it's accessing, however, a program written in a low-level language is generally difficult to port to other platforms. Low level languages are practically never interpreted, as this generally defeats the purpose. A high-level language focuses more on concepts that are easy to understand by the human mind, such as objects or mathematical functions. A high-level language usually is easier to understand than a low-level language, and it usually takes less time to develop a program in a high-level language than it does in a low-level language. As a trade-off one generally needs to sacrifice some degree of control over what the resulting program actually does. It is not, however, impossible to mix high-level and low-level functionality in a language. Type System # A type system refers to the rules that the different types of variables of a language have to follow. Some languages (including most assembly languages) do not have types and thus this section does not apply to them. However, as most languages (including C++) have types, this information is important. Type Strength: Strong or Weak A strong typing system puts restrictions on how different types of variables can be converted to each other without any converting statements. An ideal strong typing system would forbid implicit \"casts\" to types that do not make any sense, such as an integer to a Fruit object. A weak typing system would try to find some way to make the cast work. Type Expression: Manifest or Inferred This deals with how the compiler/interpreter for a language infers the types of variables. Many languages require variables' types to be explicitly defined, and thus rely on manifest typing. Some however, will infer the type of the variable based on the contexts in which it is used, and thus use inferred typing. Type Checking: Static or Dynamic If a language is statically typed, then the compiler/interpreter does the type checking once before the program runs/is compiled. If the language is dynamically type checked, then the types are checked at run-time. Type Safety: Safe or Unsafe These refer to the degree to which a language will prohibit operations on typed variables that might lead to undefined behavior or errors. A safe language will do more to ensure that such operations or conversions do not occur, while an unsafe language will give more responsibility to the user in this regard. These typing characteristics are not necessarily mutually exclusive, and some languages mix them. Paradigms # A programming paradigm is a methodology or way of programming that a programming language supports. Here is a summary of a few common paradigms: Declarative A declarative language will focus more on specifying what a language is supposed to accomplish rather than by what means it is supposed to accomplish it. Such a paradigm might be used to avoid undesired side-effects resulting from having to write one's own code. Functional Functional programming is a subset of declarative programming that tries to express problems in terms of mathematical equations and functions. It goes out of its way to avoid the concepts of states and mutable variables which are common in imperative languages. Generic Generic programming focuses on writing skeleton algorithms in terms of types that will be specified when the algorithm is actually used, thus allowing some leniency to programmers who wish to avoid strict strong typing rules. It can be a very powerful paradigm if well-implemented. Imperative Imperative languages allow programmers to give the computer ordered lists of instructions without necessarily having to explicitly state the task. It can be thought of being the opposite of declarative programming. Structured Structured programming languages aim to provide some form of noteworthy structure to a language, such as intuitive control over the order in which statements are executed (if X then do Y otherwise do Z, do X while Y is Z). Such languages generally deprecate \"jumps\", such as those provided by the goto statement in C and C++. Procedural Although it is sometimes used as a synonym for imperative programming, a procedural programming language can also refer to an imperative structured programming language which supports the concept of procedures and subroutines (also known as functions in C or C++). Object-Oriented Object-Oriented programming (sometimes abbreviated to OOP) is a subset of structured programming which expresses programs in the terms of \"objects\", which are meant to model objects in the real world. Such a paradigm allows code to be reused in remarkable ways and is meant to be easy to understand. Standardization # Does a language have a formal standard? This can be very important to ensure that programs written to work with one compiler/interpreter will work with another. Some languages are standardized by the American National Standards Institute (ANSI), some are standardized by the International Organization for Standardization (ISO), and some have an informal but de-facto standard not maintained by any standards organization. Repository Structure # Repo/ | | ------- README.md | | ------- LICENSE | | ------- CONTRIBUTING.md | | ------- CODE_OF_CONDUCT.md | | ------- NOTICE.md | | | ------- configs/ | | ----- anyfile.json | | | | ------- docs/ | | ----- Index | | ----- Overview | | ----- API | | ----- Code Structure | | ----- Installation | | ----- Configuration | | ----- References | | ----- Future | | | | ------- src/ | | -----project/ | | --__init__.py | | --settings.py | | --urls.py | \u2514--wsgi.py | | -----app1/ | | | | -----app2-RESTful/ | | | | -----manage.py | | | \u2514-----db.sqlite3 Django - Code of Conduct Other - Code of Conduct History # OS # https://en.wikipedia.org/wiki/Timeline_of_operating_systems Open Source Guide # Software Licensing # Intro # https://opensource.org/licenses/alphabetical http://www.gnu.org/licenses/ https://opensource.org/licenses Apache-2.0 # TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION - free, reproduce, sublicense, re-distribute in any form - Redistribution - provide copy of license - mention you changed this file/code - retain copy of source code - can be monitized - Summary MIT # Permission is hereby granted, free of charge , to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction , including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. Summary BSD-2-Clause # Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must `retain the above copyright notice`, this list of conditions and the following disclaimer. 2. Redistributions in binary form `must reproduce the above copyright notice`, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. also known as Simplified BSD or FreeBSD can be monitized Summary BSD-3-Clause # Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must `retain the above copyright notice`, this list of conditions and the following disclaimer. 2. Redistributions in binary form must `reproduce the above copyright notice`, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. Neither the `name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived` from this software without specific prior written permission. also known as Modified BSD or New BSD can be monitized Summary GPL-2.0 # everyone is permitted to copy and distribute verbatim copies of this LICENSE document, but changing it is not allowed can use, modify, redistribute original licensor can relicense to GPL-3.0 also used as GPL version 2 or any later version gives option to follow the terms and conditions of any later version so, any other licensors can follow the the term & conditions of GPL-3.0 can be monitized modified versions of code/software be marked as changed with the date of the change any patent must be licensed for everyone's free use or not licensed at all Summary GPL-3.0 # everyone is permitted to copy and distribute verbatim copies of this LICENSE document, but changing it is not allowed can use, modify, redistribute else, similar to GPL-2.0 but re-phrased Summary AGPL-3.0 # everyone is permitted to copy and distribute verbatim copies of this LICENSE document, but changing it is not allowed built for network software can distribute modified versions if you keep track of the changes and the date you made them source code must be distributed along with web service publication the AGPL is the GPL of the web http://www.gnu.org/licenses/agpl.html Summary Software Security # Obfuscation # The process of protecting the protable executable files (EXE, DLL) from getting decompiled into the original source code is called Obfuscation. Obfuscation Tools # ConfuserEx: https://yck1509.github.io/ConfuserEx/ (EXE, DLLs) ConfuserEx Decoder: https://github.com/cawk/ConfuserEx-Unpacker dotfuscators: https://www.preemptive.com/products/dotfuscator/overview https://translate.google.it/translate?hl=it?sl=it&tl=en&u=https%3A//gianmarcocastagna.blogspot.it/ Protect Code # https://stackoverflow.com/questions/805461/how-to-protect-dlls https://stackoverflow.com/questions/109997/how-do-you-protect-your-software-from-illegal-distribution https://stackoverflow.com/questions/506282/protect-net-code-from-reverse-engineering https://www.codeproject.com/Articles/1139773/Protect-Your-Source-Code-from-Decompiling-or-Rever https://stackoverflow.com/questions/7849620/what-is-the-best-way-to-protect-sensitive-data-in-the-code Protect .Net Code # https://stackoverflow.com/questions/7669684/encrypt-app-config-file-automatically-during-build-process Decompile Tools # https://stackoverflow.com/questions/130058/how-are-serial-generators-cracks-developed DLLs # dumpbin (c/c+) ILSpy dotPeek: https://www.jetbrains.com/decompiler/ ReSharper Python # uncompyle6 (.pyc/.pyo to .py) A native Python cross-version decompiler and fragment decompiler. The successor to decompyle, uncompyle, and uncompyle2. pyinstallerextractor (.exe to .py) PL/SQL # UnwrapIt Encryption # Symmetric Key Encryption # Intro use the same cryptographic keys for both encryption of plaintext and decryption of ciphertext The keys may be identical or there may be a simple transformation to go between the two keys Insecure DES (Data Encryption Standard) # Intro Insecure mainly due to the 56-bit key size being too small Once hacked in 22hrs AES (Advanced Encryption Standard) # Intro a subset of Rijndael superseded DES uses block cipher block cipher is a method of encrypting text (to produce ciphertext) a cryptographic key and algorithm are applied to a block of data (for example, 64 contiguous bits) at once as a group rather than to one bit at a time Design Principle substitution\u2013permutation network a combination of both substitution and permutation are applied to the plain text fixed block size of 128 bits, and a key size of 128, 192, or 256 bits Variaties MARS RC6 Rijndael Serpent Twofish Asymmetric Encryption (Private/Public Key) # Intro pair of keys made up of long random strings public key: known to every one private key: known to owner only Functions Authentication public key verifies that message received is sent by paired private key holder only Encryption only paired private key can decrypt the message encrypted by the public key Deffie-Hellman Key Exchange # http://www.omnisecu.com/security/public-key-infrastructure/asymmetric-encryption-algorithms.php Intro RSA (Rivest\u2013Shamir\u2013Adleman) # Misc # .Net DLL vs C++ DLL # https://stackoverflow.com/questions/10634743/net-dll-vs-c-dll 32 bit vs 64 bit DLL # https://stackoverflow.com/questions/495244/how-can-i-test-a-windows-dll-file-to-determine-if-it-is-32-bit-or-64-bit","title":"SE"},{"location":"cs-fundamentals/SE/#programming-languages","text":"","title":"Programming Languages"},{"location":"cs-fundamentals/SE/#an-overview-of-programs-and-programming-languages","text":"In order to better communicate to our computers what exactly it is we want them to do, we've developed a wide range of programming languages to make the communication process easier. Depending on the type of project, there are many factors that have to be considered when choosing a language. Here is a list of some of the more noteworthy ones:","title":"An Overview of Programs and Programming Languages"},{"location":"cs-fundamentals/SE/#compiled-interpreted-or-jit-compiled","text":"Compiled languages are translated to the target machine's native language by a program called a compiler. This can result in very fast code, especially if the compiler is effective at optimizing, however the resulting code may not port well across operating systems and the compilation process may take a while. Interpreted languages are read by a program called an interpreter and are executed by that program. While they are as portable as their interpreter and have no long compile times, interpreted languages are usually much slower than an equivalent compiled program. Finally, just-in-time compiled (or JIT-compiled) languages are languages that are quickly compiled when programs written in them need to be run (usually with very little optimization), offering a balance between performance and portability.","title":"Compiled, interpreted, or JIT-compiled"},{"location":"cs-fundamentals/SE/#high-or-low-level-level","text":"In this case, refers to how much the nature of the language reflects the underlying system. In other words, a programming language's level refers to how similar the language is to a computer's native language. The higher the level, the less similar it is. A low-level language is generally quite similar to machine code, and thus is more suitable for programs like device drivers or very high performance programs that really need access to the hardware. Generally, the term is reserved for machine code itself and assembly languages, though many languages offer low-level elements. Since a low-level language is subject to all the nuances of the hardware it's accessing, however, a program written in a low-level language is generally difficult to port to other platforms. Low level languages are practically never interpreted, as this generally defeats the purpose. A high-level language focuses more on concepts that are easy to understand by the human mind, such as objects or mathematical functions. A high-level language usually is easier to understand than a low-level language, and it usually takes less time to develop a program in a high-level language than it does in a low-level language. As a trade-off one generally needs to sacrifice some degree of control over what the resulting program actually does. It is not, however, impossible to mix high-level and low-level functionality in a language.","title":"High or Low Level Level"},{"location":"cs-fundamentals/SE/#type-system","text":"A type system refers to the rules that the different types of variables of a language have to follow. Some languages (including most assembly languages) do not have types and thus this section does not apply to them. However, as most languages (including C++) have types, this information is important. Type Strength: Strong or Weak A strong typing system puts restrictions on how different types of variables can be converted to each other without any converting statements. An ideal strong typing system would forbid implicit \"casts\" to types that do not make any sense, such as an integer to a Fruit object. A weak typing system would try to find some way to make the cast work. Type Expression: Manifest or Inferred This deals with how the compiler/interpreter for a language infers the types of variables. Many languages require variables' types to be explicitly defined, and thus rely on manifest typing. Some however, will infer the type of the variable based on the contexts in which it is used, and thus use inferred typing. Type Checking: Static or Dynamic If a language is statically typed, then the compiler/interpreter does the type checking once before the program runs/is compiled. If the language is dynamically type checked, then the types are checked at run-time. Type Safety: Safe or Unsafe These refer to the degree to which a language will prohibit operations on typed variables that might lead to undefined behavior or errors. A safe language will do more to ensure that such operations or conversions do not occur, while an unsafe language will give more responsibility to the user in this regard. These typing characteristics are not necessarily mutually exclusive, and some languages mix them.","title":"Type System"},{"location":"cs-fundamentals/SE/#paradigms","text":"A programming paradigm is a methodology or way of programming that a programming language supports. Here is a summary of a few common paradigms: Declarative A declarative language will focus more on specifying what a language is supposed to accomplish rather than by what means it is supposed to accomplish it. Such a paradigm might be used to avoid undesired side-effects resulting from having to write one's own code. Functional Functional programming is a subset of declarative programming that tries to express problems in terms of mathematical equations and functions. It goes out of its way to avoid the concepts of states and mutable variables which are common in imperative languages. Generic Generic programming focuses on writing skeleton algorithms in terms of types that will be specified when the algorithm is actually used, thus allowing some leniency to programmers who wish to avoid strict strong typing rules. It can be a very powerful paradigm if well-implemented. Imperative Imperative languages allow programmers to give the computer ordered lists of instructions without necessarily having to explicitly state the task. It can be thought of being the opposite of declarative programming. Structured Structured programming languages aim to provide some form of noteworthy structure to a language, such as intuitive control over the order in which statements are executed (if X then do Y otherwise do Z, do X while Y is Z). Such languages generally deprecate \"jumps\", such as those provided by the goto statement in C and C++. Procedural Although it is sometimes used as a synonym for imperative programming, a procedural programming language can also refer to an imperative structured programming language which supports the concept of procedures and subroutines (also known as functions in C or C++). Object-Oriented Object-Oriented programming (sometimes abbreviated to OOP) is a subset of structured programming which expresses programs in the terms of \"objects\", which are meant to model objects in the real world. Such a paradigm allows code to be reused in remarkable ways and is meant to be easy to understand.","title":"Paradigms"},{"location":"cs-fundamentals/SE/#standardization","text":"Does a language have a formal standard? This can be very important to ensure that programs written to work with one compiler/interpreter will work with another. Some languages are standardized by the American National Standards Institute (ANSI), some are standardized by the International Organization for Standardization (ISO), and some have an informal but de-facto standard not maintained by any standards organization.","title":"Standardization"},{"location":"cs-fundamentals/SE/#repository-structure","text":"Repo/ | | ------- README.md | | ------- LICENSE | | ------- CONTRIBUTING.md | | ------- CODE_OF_CONDUCT.md | | ------- NOTICE.md | | | ------- configs/ | | ----- anyfile.json | | | | ------- docs/ | | ----- Index | | ----- Overview | | ----- API | | ----- Code Structure | | ----- Installation | | ----- Configuration | | ----- References | | ----- Future | | | | ------- src/ | | -----project/ | | --__init__.py | | --settings.py | | --urls.py | \u2514--wsgi.py | | -----app1/ | | | | -----app2-RESTful/ | | | | -----manage.py | | | \u2514-----db.sqlite3 Django - Code of Conduct Other - Code of Conduct","title":"Repository Structure"},{"location":"cs-fundamentals/SE/#history","text":"","title":"History"},{"location":"cs-fundamentals/SE/#os","text":"https://en.wikipedia.org/wiki/Timeline_of_operating_systems","title":"OS"},{"location":"cs-fundamentals/SE/#open-source-guide","text":"","title":"Open Source Guide"},{"location":"cs-fundamentals/SE/#software-licensing","text":"","title":"Software Licensing"},{"location":"cs-fundamentals/SE/#intro","text":"https://opensource.org/licenses/alphabetical http://www.gnu.org/licenses/ https://opensource.org/licenses","title":"Intro"},{"location":"cs-fundamentals/SE/#apache-20","text":"TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION - free, reproduce, sublicense, re-distribute in any form - Redistribution - provide copy of license - mention you changed this file/code - retain copy of source code - can be monitized - Summary","title":"Apache-2.0"},{"location":"cs-fundamentals/SE/#mit","text":"Permission is hereby granted, free of charge , to any person obtaining a copy of this software and associated documentation files (the \"Software\"), to deal in the Software without restriction , including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so. Summary","title":"MIT"},{"location":"cs-fundamentals/SE/#bsd-2-clause","text":"Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must `retain the above copyright notice`, this list of conditions and the following disclaimer. 2. Redistributions in binary form `must reproduce the above copyright notice`, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. also known as Simplified BSD or FreeBSD can be monitized Summary","title":"BSD-2-Clause"},{"location":"cs-fundamentals/SE/#bsd-3-clause","text":"Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met: 1. Redistributions of source code must `retain the above copyright notice`, this list of conditions and the following disclaimer. 2. Redistributions in binary form must `reproduce the above copyright notice`, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. 3. Neither the `name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived` from this software without specific prior written permission. also known as Modified BSD or New BSD can be monitized Summary","title":"BSD-3-Clause"},{"location":"cs-fundamentals/SE/#gpl-20","text":"everyone is permitted to copy and distribute verbatim copies of this LICENSE document, but changing it is not allowed can use, modify, redistribute original licensor can relicense to GPL-3.0 also used as GPL version 2 or any later version gives option to follow the terms and conditions of any later version so, any other licensors can follow the the term & conditions of GPL-3.0 can be monitized modified versions of code/software be marked as changed with the date of the change any patent must be licensed for everyone's free use or not licensed at all Summary","title":"GPL-2.0"},{"location":"cs-fundamentals/SE/#gpl-30","text":"everyone is permitted to copy and distribute verbatim copies of this LICENSE document, but changing it is not allowed can use, modify, redistribute else, similar to GPL-2.0 but re-phrased Summary","title":"GPL-3.0"},{"location":"cs-fundamentals/SE/#agpl-30","text":"everyone is permitted to copy and distribute verbatim copies of this LICENSE document, but changing it is not allowed built for network software can distribute modified versions if you keep track of the changes and the date you made them source code must be distributed along with web service publication the AGPL is the GPL of the web http://www.gnu.org/licenses/agpl.html Summary","title":"AGPL-3.0"},{"location":"cs-fundamentals/SE/#software-security","text":"","title":"Software Security"},{"location":"cs-fundamentals/SE/#obfuscation","text":"The process of protecting the protable executable files (EXE, DLL) from getting decompiled into the original source code is called Obfuscation.","title":"Obfuscation"},{"location":"cs-fundamentals/SE/#obfuscation-tools","text":"ConfuserEx: https://yck1509.github.io/ConfuserEx/ (EXE, DLLs) ConfuserEx Decoder: https://github.com/cawk/ConfuserEx-Unpacker dotfuscators: https://www.preemptive.com/products/dotfuscator/overview https://translate.google.it/translate?hl=it?sl=it&tl=en&u=https%3A//gianmarcocastagna.blogspot.it/","title":"Obfuscation Tools"},{"location":"cs-fundamentals/SE/#protect-code","text":"https://stackoverflow.com/questions/805461/how-to-protect-dlls https://stackoverflow.com/questions/109997/how-do-you-protect-your-software-from-illegal-distribution https://stackoverflow.com/questions/506282/protect-net-code-from-reverse-engineering https://www.codeproject.com/Articles/1139773/Protect-Your-Source-Code-from-Decompiling-or-Rever https://stackoverflow.com/questions/7849620/what-is-the-best-way-to-protect-sensitive-data-in-the-code","title":"Protect Code"},{"location":"cs-fundamentals/SE/#protect-net-code","text":"https://stackoverflow.com/questions/7669684/encrypt-app-config-file-automatically-during-build-process","title":"Protect .Net Code"},{"location":"cs-fundamentals/SE/#decompile-tools","text":"https://stackoverflow.com/questions/130058/how-are-serial-generators-cracks-developed","title":"Decompile Tools"},{"location":"cs-fundamentals/SE/#dlls","text":"dumpbin (c/c+) ILSpy dotPeek: https://www.jetbrains.com/decompiler/ ReSharper","title":"DLLs"},{"location":"cs-fundamentals/SE/#python","text":"uncompyle6 (.pyc/.pyo to .py) A native Python cross-version decompiler and fragment decompiler. The successor to decompyle, uncompyle, and uncompyle2. pyinstallerextractor (.exe to .py)","title":"Python"},{"location":"cs-fundamentals/SE/#plsql","text":"UnwrapIt","title":"PL/SQL"},{"location":"cs-fundamentals/SE/#encryption","text":"","title":"Encryption"},{"location":"cs-fundamentals/SE/#symmetric-key-encryption","text":"Intro use the same cryptographic keys for both encryption of plaintext and decryption of ciphertext The keys may be identical or there may be a simple transformation to go between the two keys Insecure","title":"Symmetric Key Encryption"},{"location":"cs-fundamentals/SE/#des-data-encryption-standard","text":"Intro Insecure mainly due to the 56-bit key size being too small Once hacked in 22hrs","title":"DES (Data Encryption Standard)"},{"location":"cs-fundamentals/SE/#aes-advanced-encryption-standard","text":"Intro a subset of Rijndael superseded DES uses block cipher block cipher is a method of encrypting text (to produce ciphertext) a cryptographic key and algorithm are applied to a block of data (for example, 64 contiguous bits) at once as a group rather than to one bit at a time Design Principle substitution\u2013permutation network a combination of both substitution and permutation are applied to the plain text fixed block size of 128 bits, and a key size of 128, 192, or 256 bits Variaties MARS RC6 Rijndael Serpent Twofish","title":"AES (Advanced Encryption Standard)"},{"location":"cs-fundamentals/SE/#asymmetric-encryption-privatepublic-key","text":"Intro pair of keys made up of long random strings public key: known to every one private key: known to owner only Functions Authentication public key verifies that message received is sent by paired private key holder only Encryption only paired private key can decrypt the message encrypted by the public key","title":"Asymmetric Encryption (Private/Public Key)"},{"location":"cs-fundamentals/SE/#deffie-hellman-key-exchange","text":"http://www.omnisecu.com/security/public-key-infrastructure/asymmetric-encryption-algorithms.php Intro","title":"Deffie-Hellman Key Exchange"},{"location":"cs-fundamentals/SE/#rsa-rivestshamiradleman","text":"","title":"RSA (Rivest\u2013Shamir\u2013Adleman)"},{"location":"cs-fundamentals/SE/#misc","text":"","title":"Misc"},{"location":"cs-fundamentals/SE/#net-dll-vs-c-dll","text":"https://stackoverflow.com/questions/10634743/net-dll-vs-c-dll","title":".Net DLL vs C++ DLL"},{"location":"cs-fundamentals/SE/#32-bit-vs-64-bit-dll","text":"https://stackoverflow.com/questions/495244/how-can-i-test-a-windows-dll-file-to-determine-if-it-is-32-bit-or-64-bit","title":"32 bit vs 64 bit DLL"},{"location":"cs-fundamentals/ToC/","text":"Automata Deterministinc Finite Non-Detereministic Finite Decision Problems (H) P (Polynomial Time) NP (Non-Deterministic Polynomial Time) NP-Complete NP-Hard Automata # Deterministinc # Finite # Non-Detereministic Finite # Decision Problems (H) # P (Polynomial Time) # NP (Non-Deterministic Polynomial Time) # NP-Complete # NP-Hard #","title":"ToC"},{"location":"cs-fundamentals/ToC/#automata","text":"","title":"Automata"},{"location":"cs-fundamentals/ToC/#deterministinc","text":"","title":"Deterministinc"},{"location":"cs-fundamentals/ToC/#finite","text":"","title":"Finite"},{"location":"cs-fundamentals/ToC/#non-detereministic-finite","text":"","title":"Non-Detereministic Finite"},{"location":"cs-fundamentals/ToC/#decision-problems-h","text":"","title":"Decision Problems (H)"},{"location":"cs-fundamentals/ToC/#p-polynomial-time","text":"","title":"P (Polynomial Time)"},{"location":"cs-fundamentals/ToC/#np-non-deterministic-polynomial-time","text":"","title":"NP (Non-Deterministic Polynomial Time)"},{"location":"cs-fundamentals/ToC/#np-complete","text":"","title":"NP-Complete"},{"location":"cs-fundamentals/ToC/#np-hard","text":"","title":"NP-Hard"},{"location":"data-science/ML-Azure/","text":"Azure Machine Learning Sources Requirement Module 1: Intro to Data Science Introduction Data ---> What happened? --> Why did it happen? --> What will happen? ---> Decision Steps Types of Analytics Predictive vs Prescriptive Historical Notes Big Data Process CCC KDD Module 1 Chapter 4: Regression Intro Simple Linear Regression Ridge Regression Support Vector Machine Regression (SVM) Cross-Validation Nested Cross-Validation Chapter 5: Classification Intro Decision Boundary Classification Error Loss Functions Different ML Techniques & LFs Logistic Regression SVM Regression AdaBoost Regression Decision Tree Boosted Decision Tree Imbalanced Dataset Minority Class Data (Excess amount, Weight) ROC (Receiver Operating Characteristic) Curve FPR & TPR (False Positive Rate & True Positive Rate) Chapter 6: Clustering Intro Unsuperwised Learning K- Means Clustering Hierarchical Agglomerative Clustering Distance metrics are important Chapter 7: Recommender Systems & Matrix Factorization Intro Example: Options Matrix-Factorization Chapter 8: Intro to Data Science Technologies Why Azure ML? Supports? Cortana Analytics Suite Azure ML Studio Module 2: Working with Data Chapter 9 Chapter 10 Chapter 11: Data Sampling and Quantization Azure ML Table Data Types: Continuous Vs Catergorial Variables Quantization What? Sampling? Example Quantization of Continuous Variable Extra Chapter 12: Data Cleansing and Transformation Missing & Repeated Values Clean Missing & Repeated values Errors & Outliers Visualizing Outliers Clean Errors & Outliers Scaling Data Module 3: Visualizing Data & EXploring Models Chapter 13: Data Exploration & Visualization Exploratory Data Analysis View of data Types of plots Azure Machine Learning # Sources # https://github.com/MicrosoftLearning/Data-Science-and-ML-Essentials/tree/master/Labs Requirement # Anaconda OR Spyder (or IPython console) scikit-learn matplotlib numpy Module 1: Intro to Data Science # Introduction # Evolving subject, no single definition Requires a range of skills Exploration and quantitative analysis of all available structured or unstructured data to develop understanding, extract knowledge, and formulate actionable results. Data --> Decisions --> Actions Data ---> What happened? --> Why did it happen? --> What will happen? ---> Decision # Accidents like plane crashes etc Areas of interest: Automatic Trading, Bidding Steps # Finding data sources Acquiring data Cleaning and transforming data, Reshaping (99% work) Relationship finding Decision Types of Analytics # Retrospective Real-time Predictive (Most ML falls under) Prescriptive Intelligent Saas apps (Cortana, ..) Predictive vs Prescriptive # Predictive analysis calibrated on past data, tells us what to expect Prescriptive analysis tells what actions to take Historical Notes # Big Data by astronomers Cox & Ellsworth in 1997 By CCC in 2012 By KDD in 1996 Big Data Process # CCC # A KDD # A Module 1 # Chapter 4: Regression # Intro # Simple Linear Regression # Ridge Regression # Support Vector Machine Regression (SVM) # Cross-Validation # Nested Cross-Validation # Popular evalution technique in ML Divide data set into 10 folds, pich one for test, reserve 1 for validation, and rest 8 as test data. Chapter 5: Classification # Intro # Prediction of labels/predictable data - X (true/false or 1/-1) using independent variable/Feature/ - Y .. Decision Boundary # Classification Error # Loss Functions # Different ML Techniques & LFs # Logistic Regression # SVM Regression # AdaBoost Regression # Decision Tree # Boosted Decision Tree # Imbalanced Dataset # Minority Class Data (Excess amount, Weight) # ROC (Receiver Operating Characteristic) Curve # FPR & TPR (False Positive Rate & True Positive Rate) # Chapter 6: Clustering # Intro # Unsuperwised label prediction Unsuperwised Learning # Means training data has no ground truth labels to learn from K- Means Clustering # Input K = number of clusterss Randomly initialize centers Assign all the points to the closest centers Repeat till convergence Hierarchical Agglomerative Clustering # Start with each point in its own cluster Repeatedly merge the clusters of the closest two points Distance metrics are important # Large impact on the solution Some algos uses \"Adaptive\" distance measures Chapter 7: Recommender Systems & Matrix Factorization # Intro # \\left(\\begin{array}{cc} 5 & * & 1 & 1\\\\ 5 & * & 1 & 1 \\end{array}\\right) \\left(\\begin{array}{cc} 5 & * & 1 & 1\\\\ 5 & * & 1 & 1 \\end{array}\\right) Example: # Netflix contest Options # User-Based Collaborative Filtering Item-Based Collaborative Filtering Matrix-Factorization # Carmen_1 \\left (\\begin{array}{cc} 5 & 1 \\end{array}\\right) Carmen_1 \\left (\\begin{array}{cc} 5 & 1 \\end{array}\\right) Chapter 8: Intro to Data Science Technologies # Why Azure ML? # Easy to deploy services on production Supports? # Sql R Python Cortana Analytics Suite # https://www.microsoft.com/cortanaanalytics Preconfigures Solutions Dashboard & Visualization Machine Learning & Analytics Azure Bigdata (Hadoop Implementation) Information Management Azure ML Studio # https://account.azure.com Experiments contain workflow Experiments constructed of modules Modules: Transform Data Compute Models Score Models Evaluate Models Create custom modules with SQL, R & Python Module 2: Working with Data # Chapter 9 # Chapter 10 # Chapter 11: Data Sampling and Quantization # Azure ML Table Data Types: # Numeric: Integer, Floating points Boolean String Date time Time span Categorial Image Continuous Vs Catergorial Variables # Continuous: Countable, e.g. Time, Temperature, Counts* Categorial: Classifiable, e.g. Gender, Type, City * * descrete continuous Quantization # A range with sampled data. What? # Continuous variables must be sampled Sampling? # Digitizing the domain. * Time stamped * Precision Example # Temperature every minute Count over 1 hour Quantization of Continuous Variable # Convert continuous variables into categorial using binning/categorizing. Binning: Allocating each value into one category/bin. Example: * Small, Medium & Large Module to use: Quantize Module Extra # Metadata Editor Chapter 12: Data Cleansing and Transformation # (Data Munging) Deals with Missing & repeated values Outliers and errors Scaling Filtering with custom code Iterative process Example: Forest-Fire Data Missing & Repeated Values # are common many ML algos don't deal with missing values repeated values bias results, so search for them make estimation treat them Clean Missing & Repeated values # remove rows substitute a specific value Interpolate values - Linear/polynomial on the basis of growth/trend of the data forward/backword fill With Azure ML Module: Clean Missing Data, Remove Duplicate Rows With R Missing data: is.na() Repeated data: duplicated() With Python Missing data: pandas.isnull() Repeated data: DataFrame.drop_duplicates() Errors & Outliers # can bias model training, so search for them validate treat them Visualizing Outliers # Scatter plot matrix R - pairs plot Python - pandas.tools.plotting.scatter_matrix Bar chart or graph histogram Clean Errors & Outliers # Error treatment Censor: remove entire row Trim: trim the value inbetween a range Interpolate: Linear or polynomial on the basis of growth/trend of the data Substitute With Azure ML Module: Clip values (select column--> set lower/upper threshold) With R data.frame = data.fram[filter.expression,] With Python frame1 = frame1[(frame1[\"col1\"] > 40.0) & (frame1[\"col2\"] < 30.0) & (frame1[\"col3\"] < 23.0)] Scaling Data # (aka Normalization, Transformation) * Why: * to put all the numerical data into same range line -1 to 1 or 0 to 10 other than a:0-1, b:0-100, c:500:1000 * not doing so: * will make adverse effect on training model * will get biased training model What: looking at numerical features/columns numerical features/variable/columns needs similar scale Scaling methods: zero mean & unit variance min-max: all numeric values in range 0 to 1 logrithmic: does distributional changes (good for classification) LogNormal: Hyperbolic tangent scaling: distribution transformation ordered data like time-series may need to de-trend scale after treating outliers How: Azure ML Module: Normalize Data R: Python: Doubts: How to make such transformations? Module 3: Visualizing Data & EXploring Models # Chapter 13: Data Exploration & Visualization # Exploratory Data Analysis # What: Explore the data with visualization Understand the relationships in the data How: Create multiple views of data Data conditioning: Poweful plotting method to project multiple dimension on two dimension page/screen View of data # Relationships in data can be complex Data exploration requires multiple views Conditioned (aka faceted, trellis, lattice) plots are ideal project multiple dimension onto two plots of subsets (group by) Types of plots # Scatter and line plots Bar: like histogram but Used for categorical & factor data like disease, blood grp Types: ordered, un-ordered Histogram: used for continuos variable like time, temp density or count are plotted on vertical axis widely used Violin Q-Q Box: Shows 4 quartiles, i.e. a box divided in two half (by median), one upper vertical line, one lower and dot as outliers Line: connecting dot--> Polynomial regression--> curve","title":"ML Azure"},{"location":"data-science/ML-Azure/#azure-machine-learning","text":"","title":"Azure Machine Learning"},{"location":"data-science/ML-Azure/#sources","text":"https://github.com/MicrosoftLearning/Data-Science-and-ML-Essentials/tree/master/Labs","title":"Sources"},{"location":"data-science/ML-Azure/#requirement","text":"Anaconda OR Spyder (or IPython console) scikit-learn matplotlib numpy","title":"Requirement"},{"location":"data-science/ML-Azure/#module-1-intro-to-data-science","text":"","title":"Module 1: Intro to Data Science"},{"location":"data-science/ML-Azure/#introduction","text":"Evolving subject, no single definition Requires a range of skills Exploration and quantitative analysis of all available structured or unstructured data to develop understanding, extract knowledge, and formulate actionable results. Data --> Decisions --> Actions","title":"Introduction"},{"location":"data-science/ML-Azure/#data-what-happened-why-did-it-happen-what-will-happen-decision","text":"Accidents like plane crashes etc Areas of interest: Automatic Trading, Bidding","title":"Data ---&gt; What happened? --&gt;  Why did it happen? --&gt; What will happen? ---&gt; Decision"},{"location":"data-science/ML-Azure/#steps","text":"Finding data sources Acquiring data Cleaning and transforming data, Reshaping (99% work) Relationship finding Decision","title":"Steps"},{"location":"data-science/ML-Azure/#types-of-analytics","text":"Retrospective Real-time Predictive (Most ML falls under) Prescriptive Intelligent Saas apps (Cortana, ..)","title":"Types of Analytics"},{"location":"data-science/ML-Azure/#predictive-vs-prescriptive","text":"Predictive analysis calibrated on past data, tells us what to expect Prescriptive analysis tells what actions to take","title":"Predictive vs Prescriptive"},{"location":"data-science/ML-Azure/#historical-notes","text":"Big Data by astronomers Cox & Ellsworth in 1997 By CCC in 2012 By KDD in 1996","title":"Historical Notes"},{"location":"data-science/ML-Azure/#big-data-process","text":"","title":"Big Data Process"},{"location":"data-science/ML-Azure/#ccc","text":"A","title":"CCC"},{"location":"data-science/ML-Azure/#kdd","text":"A","title":"KDD"},{"location":"data-science/ML-Azure/#module-1","text":"","title":"Module 1"},{"location":"data-science/ML-Azure/#chapter-4-regression","text":"","title":"Chapter 4: Regression"},{"location":"data-science/ML-Azure/#intro","text":"","title":"Intro"},{"location":"data-science/ML-Azure/#simple-linear-regression","text":"","title":"Simple Linear Regression"},{"location":"data-science/ML-Azure/#ridge-regression","text":"","title":"Ridge Regression"},{"location":"data-science/ML-Azure/#support-vector-machine-regression-svm","text":"","title":"Support Vector Machine Regression (SVM)"},{"location":"data-science/ML-Azure/#cross-validation","text":"","title":"Cross-Validation"},{"location":"data-science/ML-Azure/#nested-cross-validation","text":"Popular evalution technique in ML Divide data set into 10 folds, pich one for test, reserve 1 for validation, and rest 8 as test data.","title":"Nested Cross-Validation"},{"location":"data-science/ML-Azure/#chapter-5-classification","text":"","title":"Chapter 5: Classification"},{"location":"data-science/ML-Azure/#intro_1","text":"Prediction of labels/predictable data - X (true/false or 1/-1) using independent variable/Feature/ - Y ..","title":"Intro"},{"location":"data-science/ML-Azure/#decision-boundary","text":"","title":"Decision Boundary"},{"location":"data-science/ML-Azure/#classification-error","text":"","title":"Classification Error"},{"location":"data-science/ML-Azure/#loss-functions","text":"","title":"Loss Functions"},{"location":"data-science/ML-Azure/#different-ml-techniques-lfs","text":"","title":"Different ML Techniques &amp; LFs"},{"location":"data-science/ML-Azure/#logistic-regression","text":"","title":"Logistic Regression"},{"location":"data-science/ML-Azure/#svm-regression","text":"","title":"SVM Regression"},{"location":"data-science/ML-Azure/#adaboost-regression","text":"","title":"AdaBoost Regression"},{"location":"data-science/ML-Azure/#decision-tree","text":"","title":"Decision Tree"},{"location":"data-science/ML-Azure/#boosted-decision-tree","text":"","title":"Boosted Decision Tree"},{"location":"data-science/ML-Azure/#imbalanced-dataset","text":"","title":"Imbalanced Dataset"},{"location":"data-science/ML-Azure/#minority-class-data-excess-amount-weight","text":"","title":"Minority Class Data (Excess amount, Weight)"},{"location":"data-science/ML-Azure/#roc-receiver-operating-characteristic-curve","text":"","title":"ROC (Receiver Operating Characteristic) Curve"},{"location":"data-science/ML-Azure/#fpr-tpr-false-positive-rate-true-positive-rate","text":"","title":"FPR &amp; TPR (False Positive Rate &amp; True Positive Rate)"},{"location":"data-science/ML-Azure/#chapter-6-clustering","text":"","title":"Chapter 6: Clustering"},{"location":"data-science/ML-Azure/#intro_2","text":"Unsuperwised label prediction","title":"Intro"},{"location":"data-science/ML-Azure/#unsuperwised-learning","text":"Means training data has no ground truth labels to learn from","title":"Unsuperwised Learning"},{"location":"data-science/ML-Azure/#k-means-clustering","text":"Input K = number of clusterss Randomly initialize centers Assign all the points to the closest centers Repeat till convergence","title":"K- Means Clustering"},{"location":"data-science/ML-Azure/#hierarchical-agglomerative-clustering","text":"Start with each point in its own cluster Repeatedly merge the clusters of the closest two points","title":"Hierarchical Agglomerative Clustering"},{"location":"data-science/ML-Azure/#distance-metrics-are-important","text":"Large impact on the solution Some algos uses \"Adaptive\" distance measures","title":"Distance metrics are important"},{"location":"data-science/ML-Azure/#chapter-7-recommender-systems-matrix-factorization","text":"","title":"Chapter 7: Recommender Systems &amp; Matrix Factorization"},{"location":"data-science/ML-Azure/#intro_3","text":"\\left(\\begin{array}{cc} 5 & * & 1 & 1\\\\ 5 & * & 1 & 1 \\end{array}\\right) \\left(\\begin{array}{cc} 5 & * & 1 & 1\\\\ 5 & * & 1 & 1 \\end{array}\\right)","title":"Intro"},{"location":"data-science/ML-Azure/#example","text":"Netflix contest","title":"Example:"},{"location":"data-science/ML-Azure/#options","text":"User-Based Collaborative Filtering Item-Based Collaborative Filtering","title":"Options"},{"location":"data-science/ML-Azure/#matrix-factorization","text":"Carmen_1 \\left (\\begin{array}{cc} 5 & 1 \\end{array}\\right) Carmen_1 \\left (\\begin{array}{cc} 5 & 1 \\end{array}\\right)","title":"Matrix-Factorization"},{"location":"data-science/ML-Azure/#chapter-8-intro-to-data-science-technologies","text":"","title":"Chapter 8: Intro to Data Science Technologies"},{"location":"data-science/ML-Azure/#why-azure-ml","text":"Easy to deploy services on production","title":"Why Azure ML?"},{"location":"data-science/ML-Azure/#supports","text":"Sql R Python","title":"Supports?"},{"location":"data-science/ML-Azure/#cortana-analytics-suite","text":"https://www.microsoft.com/cortanaanalytics Preconfigures Solutions Dashboard & Visualization Machine Learning & Analytics Azure Bigdata (Hadoop Implementation) Information Management","title":"Cortana Analytics Suite"},{"location":"data-science/ML-Azure/#azure-ml-studio","text":"https://account.azure.com Experiments contain workflow Experiments constructed of modules Modules: Transform Data Compute Models Score Models Evaluate Models Create custom modules with SQL, R & Python","title":"Azure ML Studio"},{"location":"data-science/ML-Azure/#module-2-working-with-data","text":"","title":"Module 2: Working with Data"},{"location":"data-science/ML-Azure/#chapter-9","text":"","title":"Chapter 9"},{"location":"data-science/ML-Azure/#chapter-10","text":"","title":"Chapter 10"},{"location":"data-science/ML-Azure/#chapter-11-data-sampling-and-quantization","text":"","title":"Chapter 11: Data Sampling and Quantization"},{"location":"data-science/ML-Azure/#azure-ml-table-data-types","text":"Numeric: Integer, Floating points Boolean String Date time Time span Categorial Image","title":"Azure ML Table Data Types:"},{"location":"data-science/ML-Azure/#continuous-vs-catergorial-variables","text":"Continuous: Countable, e.g. Time, Temperature, Counts* Categorial: Classifiable, e.g. Gender, Type, City * * descrete continuous","title":"Continuous Vs Catergorial Variables"},{"location":"data-science/ML-Azure/#quantization","text":"A range with sampled data.","title":"Quantization"},{"location":"data-science/ML-Azure/#what","text":"Continuous variables must be sampled","title":"What?"},{"location":"data-science/ML-Azure/#sampling","text":"Digitizing the domain. * Time stamped * Precision","title":"Sampling?"},{"location":"data-science/ML-Azure/#example_1","text":"Temperature every minute Count over 1 hour","title":"Example"},{"location":"data-science/ML-Azure/#quantization-of-continuous-variable","text":"Convert continuous variables into categorial using binning/categorizing. Binning: Allocating each value into one category/bin. Example: * Small, Medium & Large Module to use: Quantize Module","title":"Quantization of Continuous Variable"},{"location":"data-science/ML-Azure/#extra","text":"Metadata Editor","title":"Extra"},{"location":"data-science/ML-Azure/#chapter-12-data-cleansing-and-transformation","text":"(Data Munging) Deals with Missing & repeated values Outliers and errors Scaling Filtering with custom code Iterative process Example: Forest-Fire Data","title":"Chapter 12: Data Cleansing and Transformation"},{"location":"data-science/ML-Azure/#missing-repeated-values","text":"are common many ML algos don't deal with missing values repeated values bias results, so search for them make estimation treat them","title":"Missing &amp; Repeated Values"},{"location":"data-science/ML-Azure/#clean-missing-repeated-values","text":"remove rows substitute a specific value Interpolate values - Linear/polynomial on the basis of growth/trend of the data forward/backword fill With Azure ML Module: Clean Missing Data, Remove Duplicate Rows With R Missing data: is.na() Repeated data: duplicated() With Python Missing data: pandas.isnull() Repeated data: DataFrame.drop_duplicates()","title":"Clean Missing &amp; Repeated values"},{"location":"data-science/ML-Azure/#errors-outliers","text":"can bias model training, so search for them validate treat them","title":"Errors &amp; Outliers"},{"location":"data-science/ML-Azure/#visualizing-outliers","text":"Scatter plot matrix R - pairs plot Python - pandas.tools.plotting.scatter_matrix Bar chart or graph histogram","title":"Visualizing Outliers"},{"location":"data-science/ML-Azure/#clean-errors-outliers","text":"Error treatment Censor: remove entire row Trim: trim the value inbetween a range Interpolate: Linear or polynomial on the basis of growth/trend of the data Substitute With Azure ML Module: Clip values (select column--> set lower/upper threshold) With R data.frame = data.fram[filter.expression,] With Python frame1 = frame1[(frame1[\"col1\"] > 40.0) & (frame1[\"col2\"] < 30.0) & (frame1[\"col3\"] < 23.0)]","title":"Clean Errors &amp; Outliers"},{"location":"data-science/ML-Azure/#scaling-data","text":"(aka Normalization, Transformation) * Why: * to put all the numerical data into same range line -1 to 1 or 0 to 10 other than a:0-1, b:0-100, c:500:1000 * not doing so: * will make adverse effect on training model * will get biased training model What: looking at numerical features/columns numerical features/variable/columns needs similar scale Scaling methods: zero mean & unit variance min-max: all numeric values in range 0 to 1 logrithmic: does distributional changes (good for classification) LogNormal: Hyperbolic tangent scaling: distribution transformation ordered data like time-series may need to de-trend scale after treating outliers How: Azure ML Module: Normalize Data R: Python: Doubts: How to make such transformations?","title":"Scaling Data"},{"location":"data-science/ML-Azure/#module-3-visualizing-data-exploring-models","text":"","title":"Module 3: Visualizing Data &amp; EXploring Models"},{"location":"data-science/ML-Azure/#chapter-13-data-exploration-visualization","text":"","title":"Chapter 13: Data Exploration &amp; Visualization"},{"location":"data-science/ML-Azure/#exploratory-data-analysis","text":"What: Explore the data with visualization Understand the relationships in the data How: Create multiple views of data Data conditioning: Poweful plotting method to project multiple dimension on two dimension page/screen","title":"Exploratory Data Analysis"},{"location":"data-science/ML-Azure/#view-of-data","text":"Relationships in data can be complex Data exploration requires multiple views Conditioned (aka faceted, trellis, lattice) plots are ideal project multiple dimension onto two plots of subsets (group by)","title":"View of data"},{"location":"data-science/ML-Azure/#types-of-plots","text":"Scatter and line plots Bar: like histogram but Used for categorical & factor data like disease, blood grp Types: ordered, un-ordered Histogram: used for continuos variable like time, temp density or count are plotted on vertical axis widely used Violin Q-Q Box: Shows 4 quartiles, i.e. a box divided in two half (by median), one upper vertical line, one lower and dot as outliers Line: connecting dot--> Polynomial regression--> curve","title":"Types of plots"},{"location":"industrial/networking/mac/","text":"MAC # Media Access Control - The IEEE manages MAC addresses # How many combinations / Sufficient? # 12 digits (0-F i.e. 16 possible chars) 16^12=2.81E14 281 trillion 281, 474, 980, 000, 000 two hundred and eighty-one trillion, four hundred and seventy-four billion, nine hundred and eighty million 40k MAC per person on earth # Are MAC addresses really unique? # Or are there any (maybe cloned?) network interface cards that have the same MAC address as another NIC? What is the probability of having two identical MAC addresses within one network? The hardware identification addresses that the IEEE distributes are unique. That makes the probability of matching MAC addresses zero. On the other hand, some hardware MAC addresses are programmable, which makes them spoofable. This means that it is possible for two machines in the same network to have the same MAC address. List of MAC series vs Vendors # https://regauth.standards.ieee.org/standards-ra-web/pub/view.html#registries https://devtools360.com/en/macaddress/vendorMacs.xml https://gist.github.com/aallan/b4bb86db86079509e6159810ae9bd3e4 # - Read More # IEEE Standards IEEE MAC Addresss","title":"MAC"},{"location":"industrial/networking/mac/#mac","text":"Media Access Control","title":"MAC"},{"location":"industrial/networking/mac/#-the-ieee-manages-mac-addresses","text":"","title":"- The IEEE manages MAC addresses"},{"location":"industrial/networking/mac/#how-many-combinations-sufficient","text":"12 digits (0-F i.e. 16 possible chars) 16^12=2.81E14 281 trillion 281, 474, 980, 000, 000 two hundred and eighty-one trillion, four hundred and seventy-four billion, nine hundred and eighty million","title":"How many combinations / Sufficient?"},{"location":"industrial/networking/mac/#40k-mac-per-person-on-earth","text":"","title":"40k MAC per person on earth"},{"location":"industrial/networking/mac/#are-mac-addresses-really-unique","text":"Or are there any (maybe cloned?) network interface cards that have the same MAC address as another NIC? What is the probability of having two identical MAC addresses within one network? The hardware identification addresses that the IEEE distributes are unique. That makes the probability of matching MAC addresses zero. On the other hand, some hardware MAC addresses are programmable, which makes them spoofable. This means that it is possible for two machines in the same network to have the same MAC address.","title":"Are MAC addresses really unique?"},{"location":"industrial/networking/mac/#list-of-mac-series-vs-vendors","text":"https://regauth.standards.ieee.org/standards-ra-web/pub/view.html#registries https://devtools360.com/en/macaddress/vendorMacs.xml","title":"List of MAC series vs Vendors"},{"location":"industrial/networking/mac/#httpsgistgithubcomaallanb4bb86db86079509e6159810ae9bd3e4","text":"-","title":"https://gist.github.com/aallan/b4bb86db86079509e6159810ae9bd3e4"},{"location":"industrial/networking/mac/#read-more","text":"IEEE Standards IEEE MAC Addresss","title":"Read More"},{"location":"industrial/networking/openconfig/openconfig/","text":"Introduction # OpenConfig Access Point # joined-aps/ joined-ap/ provision-aps/ provision-aps/ access-points/ access-point/ Ref: http://ops.openconfig.net/branches/models/master/docs/openconfig-access-points.html","title":"Introduction"},{"location":"industrial/networking/openconfig/openconfig/#introduction","text":"","title":"Introduction"},{"location":"industrial/networking/openconfig/openconfig/#openconfig-access-point","text":"joined-aps/ joined-ap/ provision-aps/ provision-aps/ access-points/ access-point/ Ref: http://ops.openconfig.net/branches/models/master/docs/openconfig-access-points.html","title":"OpenConfig Access Point"},{"location":"industrial/networking/wireless/wifi_basics_1/","text":"IEEE & Wi-Fi Alliance IEEE Wi-Fi Alliance Wi-Fi Frequencies 2.4 GHz & 5 GHz 2.4 GHz Band 5 GHz Band Wi-Fi History Major 802.11 Amendments 2.4 GHz Band Channels Wi-Fi 2.4 Ghz and Interference Wi-Fi Adjacent Channel Interference Half Duplex Wi-Fi Co-channel interference 2.4 GHz Channel Re-Use Wi-Fi 5 Ghz Wi-Fi 5 Ghz Channels Wi-Fi DFS Wi-Fi Channel Bonding 5 GHz Channel Re-Use Wi-Fi Signal Strength BSSID, SSID and ESSIDs Other Wireless Technologies Bluetooth Low Energy (BLE) Wi-Fi NICs vs Ethernet SNR and Data Rates SNR Data Rate MCS Network Packets vs Frame Wi-Fi Frame Types and Timing Airtime Arbitration Process Wi-Fi Roaming Wi-Fi Security Roaming Wi-Fi Design Determine requirements Client channel support Further Define Metrics Wi-Fi Ekahau Design Sources: https://courses.mist.com/dashboard https://www.mist.com/documentation/wi-fi-basics-1/ IEEE & Wi-Fi Alliance # IEEE # Institute of Electrical & Electronics Engineers creates standard like: 802.15.1 (BlueTooth) 802.15.4 (Zigbee) IEEE 1394 (FireWire) 802.3 (Ethernet) 802.11 (Wi-Fi) Wi-Fi Alliance # Composed of major players in the wireless industry/space Apple Comcast Sony Motorola Intel Qualcomm T-Mobile Provides branding for Wi-Fi \"Wi-Fi\" WPA/WPA2/WPA3 802.11i WMM Wi-Fi 6 Ensures interoperability between diff vendors Wi-Fi Frequencies # 2.4 GHz & 5 GHz # unlicensed spectrum .-. .-. .-. .-. .-. .-. .-. .-. .-. '-' '-' '-' '-' '-' '-' '-' '-' '-' 2.4 GHz Band # low freq punch stuffs tend to attenuate longer wavelength 4.9 inch long more range 300 ft ? more crowded more non Wi-Fi interference 802.11b/g/n/ax 5 GHz Band # higher freq shorter wavelength 2.5 inch long less range 90 ft ? less crowded less non Wi-Fi interference 802.11a/n/ac/ax Q. Can a Wi-Fi adapter support multiple bands? Yes, depends on capabilities. Its called Dual-band. Wi-Fi History # Major 802.11 Amendments # Q. Band vs Channel? Within these (2.4/5) Wi-Fi frequency bands, we have smaller bands which are referred to as Wi-Fi channels. A Wi-Fi channel is the medium through which our wireless networks can send and receive data. For routers made in the U.S., the 2.4 GHz band has 11 channels and the 5 GHz band has 45 channels. Q. Why should I care what Wi-Fi channel I'm on? The reason that certain channels aren't the best choice to use is because they have interference. There are a couple different ways this interference is caused: Co-Channel interference results when there are numerous devices all competing for time to talk on the same channel. Adjacent-Channel interference occurs when devices from overlapping channels are trying to talk over each other. Channels that have interference from other devices are considered to be 'crowded'. The time it takes to transmit data is increased and you are left waiting for your Internet request to be made. The channels with the most interference are those that overlap with each other. To further explain channel overlapping, let's look at the 2.4 GHz band, where each channel is allotted 20 MHz and separated by 5 MHz. Considering the 2.4 GHz band is only 100 MHz wide, the 11 channels of 20 MHz overlap with one another. This is what causes the interference on your network and and a lag in your Wi-Fi's performance. Certain channels yield better Wi-Fi performance than others because they are non-overlapping. Yes, there are some channels in the 2.4 GHz spectrum that don't overlap with the other channels. These are the channels you ought to look for, especially if experiencing Wi-Fi problems: Channels 1, 6, and 11. Read more: 1. https://www.minim.com/blog/wifi-channels-explained 1. https://www.electronics-notes.com/articles/connectivity/wifi-ieee-802-11/channels-frequencies-bands-bandwidth.php Note: There are also 24 non-overlapping channels in the 5 GHz band spectrum. 2.4 GHz Band Channels # 20 MHz wide 11 channels Q. Different Country vs Channels? Possible? Yes. Europe has 12,13 as well. Japan has 14 as well. Wi-Fi 2.4 Ghz and Interference # Wi-Fi Adjacent Channel Interference # STAs on overlapping channels will corrupt each other's transmission. Half Duplex Wi-Fi # Only one device can transmit on a channel at a time. Ethernet cables are made up of multiple twisted pair of copper, they MUX. They can talk & listen at the same time. Co-channel interference # Slow devices on the channel consume more airtime. 2.4 GHz Channel Re-Use # But avoiding interference in 2.4GHz is hard due to high range. NOTE: Mist use channels 1,6,11 world-wide. (btw, they support all) Wi-Fi 5 Ghz # Wi-Fi 5 Ghz Channels # lot more channels thus lot more throughput Wi-Fi DFS # Dynamic frequency selection If detected radar, move to other channel. Announce to move other APs as well. Wi-Fi Channel Bonding # haha typo. haha typo again. 5 GHz Channel Re-Use # Channel reuse is much easier in 5 GHz band. Wi-Fi Signal Strength # Unit/repr: dB and dBm for absolute values. dB quantifies the ratio between two values, whereas dBm expresses the absolute power level. dBm is an absolute unit, whereas dB is a dimensionless unit. dBm is always relative to 1mW, while dB is expressed in watts and can be relative to other powers. the unit is logarithmic & not linear, so lets see 3 & 10 rule for simiplicty: Isn't there something in positive scale? Yes, mW . :D LOL! see the figures in mW. iwconfig # for streaming results watch -n1 iwconfig BSSID, SSID and ESSIDs # Other Wireless Technologies # Bluetooth Low Energy (BLE) # Wi-Fi NICs vs Ethernet # SNR and Data Rates # SNR # How much signal above the background noise. Unit: dB Data Rate # The same \"Maximum Signaling Rate\". Defined per standards 802.11xyz. Unit: Mbps Good the SNR, Can choose/set higher Data rates. Q. Signaling Rate vs Throughput? TBD MCS # Modulation and Coding scheme. Ref: http://mcsindex.com/ https://www.wlanpros.com/mcs-index-charts/ Network Packets vs Frame # TBD Wi-Fi Frame Types and Timing # STA (Station): In IEEE 802.11 (Wi-Fi) terminology, a station (abbreviated as STA) is a device that has the capability to use the 802.11 protocol. For example, a station may be a laptop, a desktop PC, PDA, access point or Wi-Fi phone. Airtime Arbitration Process # How wireless devices decides, who's going to talk next? Wi-Fi Roaming # Wi-Fi Security # Ethernet is a bounded medium, inheritently & physically secure. What about security of unbounded Wi-Fi? A Wi-Fi adapter in monitor mode can eavesdrop.. can capture all the packets nearby.. hmm.. What Mist supports today: WPA-2/PSK with passphrase WPA-2/EAP (802.1X) Open Access WPA-2/PSK with multiple passphrases WPA-PSK/TKIP WPA2-PSK/TKIP WEP Multi-mode/PSK with passphrase Multi-mode/EAP (802.1X) OWE Transition OWE Opportunistic Wireless Encryption MAC address authentication by RADIUS lookup Roaming # Every client device has its own green diamond. :D Some can roam, some are not designed to roam. Wi-Fi Design # How to design a wireless network? Probably for a customer.. :p Determine requirements # Client channel support # Some devices might not support some channels, so plan accordingly. Ref: https://clients.mikealbano.com/ (Mike - Our OpenConfig guy, from Wireless N/W Team, Google) ;) Further Define Metrics # Wi-Fi Ekahau Design # Software to design a Wireless network.","title":"Wifi basics 1"},{"location":"industrial/networking/wireless/wifi_basics_1/#ieee-wi-fi-alliance","text":"","title":"IEEE &amp; Wi-Fi Alliance"},{"location":"industrial/networking/wireless/wifi_basics_1/#ieee","text":"Institute of Electrical & Electronics Engineers creates standard like: 802.15.1 (BlueTooth) 802.15.4 (Zigbee) IEEE 1394 (FireWire) 802.3 (Ethernet) 802.11 (Wi-Fi)","title":"IEEE"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-alliance","text":"Composed of major players in the wireless industry/space Apple Comcast Sony Motorola Intel Qualcomm T-Mobile Provides branding for Wi-Fi \"Wi-Fi\" WPA/WPA2/WPA3 802.11i WMM Wi-Fi 6 Ensures interoperability between diff vendors","title":"Wi-Fi Alliance"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-frequencies","text":"","title":"Wi-Fi Frequencies"},{"location":"industrial/networking/wireless/wifi_basics_1/#24-ghz-5-ghz","text":"unlicensed spectrum .-. .-. .-. .-. .-. .-. .-. .-. .-. '-' '-' '-' '-' '-' '-' '-' '-' '-'","title":"2.4 GHz &amp; 5 GHz"},{"location":"industrial/networking/wireless/wifi_basics_1/#24-ghz-band","text":"low freq punch stuffs tend to attenuate longer wavelength 4.9 inch long more range 300 ft ? more crowded more non Wi-Fi interference 802.11b/g/n/ax","title":"2.4 GHz Band"},{"location":"industrial/networking/wireless/wifi_basics_1/#5-ghz-band","text":"higher freq shorter wavelength 2.5 inch long less range 90 ft ? less crowded less non Wi-Fi interference 802.11a/n/ac/ax Q. Can a Wi-Fi adapter support multiple bands? Yes, depends on capabilities. Its called Dual-band.","title":"5 GHz Band"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-history","text":"","title":"Wi-Fi History"},{"location":"industrial/networking/wireless/wifi_basics_1/#major-80211-amendments","text":"Q. Band vs Channel? Within these (2.4/5) Wi-Fi frequency bands, we have smaller bands which are referred to as Wi-Fi channels. A Wi-Fi channel is the medium through which our wireless networks can send and receive data. For routers made in the U.S., the 2.4 GHz band has 11 channels and the 5 GHz band has 45 channels. Q. Why should I care what Wi-Fi channel I'm on? The reason that certain channels aren't the best choice to use is because they have interference. There are a couple different ways this interference is caused: Co-Channel interference results when there are numerous devices all competing for time to talk on the same channel. Adjacent-Channel interference occurs when devices from overlapping channels are trying to talk over each other. Channels that have interference from other devices are considered to be 'crowded'. The time it takes to transmit data is increased and you are left waiting for your Internet request to be made. The channels with the most interference are those that overlap with each other. To further explain channel overlapping, let's look at the 2.4 GHz band, where each channel is allotted 20 MHz and separated by 5 MHz. Considering the 2.4 GHz band is only 100 MHz wide, the 11 channels of 20 MHz overlap with one another. This is what causes the interference on your network and and a lag in your Wi-Fi's performance. Certain channels yield better Wi-Fi performance than others because they are non-overlapping. Yes, there are some channels in the 2.4 GHz spectrum that don't overlap with the other channels. These are the channels you ought to look for, especially if experiencing Wi-Fi problems: Channels 1, 6, and 11. Read more: 1. https://www.minim.com/blog/wifi-channels-explained 1. https://www.electronics-notes.com/articles/connectivity/wifi-ieee-802-11/channels-frequencies-bands-bandwidth.php Note: There are also 24 non-overlapping channels in the 5 GHz band spectrum.","title":"Major 802.11 Amendments"},{"location":"industrial/networking/wireless/wifi_basics_1/#24-ghz-band-channels","text":"20 MHz wide 11 channels Q. Different Country vs Channels? Possible? Yes. Europe has 12,13 as well. Japan has 14 as well.","title":"2.4 GHz Band Channels"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-24-ghz-and-interference","text":"","title":"Wi-Fi 2.4 Ghz and Interference"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-adjacent-channel-interference","text":"STAs on overlapping channels will corrupt each other's transmission.","title":"Wi-Fi Adjacent Channel Interference"},{"location":"industrial/networking/wireless/wifi_basics_1/#half-duplex-wi-fi","text":"Only one device can transmit on a channel at a time. Ethernet cables are made up of multiple twisted pair of copper, they MUX. They can talk & listen at the same time.","title":"Half Duplex Wi-Fi"},{"location":"industrial/networking/wireless/wifi_basics_1/#co-channel-interference","text":"Slow devices on the channel consume more airtime.","title":"Co-channel interference"},{"location":"industrial/networking/wireless/wifi_basics_1/#24-ghz-channel-re-use","text":"But avoiding interference in 2.4GHz is hard due to high range. NOTE: Mist use channels 1,6,11 world-wide. (btw, they support all)","title":"2.4 GHz Channel Re-Use"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-5-ghz","text":"","title":"Wi-Fi 5 Ghz"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-5-ghz-channels","text":"lot more channels thus lot more throughput","title":"Wi-Fi 5 Ghz Channels"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-dfs","text":"Dynamic frequency selection If detected radar, move to other channel. Announce to move other APs as well.","title":"Wi-Fi DFS"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-channel-bonding","text":"haha typo. haha typo again.","title":"Wi-Fi Channel Bonding"},{"location":"industrial/networking/wireless/wifi_basics_1/#5-ghz-channel-re-use","text":"Channel reuse is much easier in 5 GHz band.","title":"5 GHz Channel Re-Use"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-signal-strength","text":"Unit/repr: dB and dBm for absolute values. dB quantifies the ratio between two values, whereas dBm expresses the absolute power level. dBm is an absolute unit, whereas dB is a dimensionless unit. dBm is always relative to 1mW, while dB is expressed in watts and can be relative to other powers. the unit is logarithmic & not linear, so lets see 3 & 10 rule for simiplicty: Isn't there something in positive scale? Yes, mW . :D LOL! see the figures in mW. iwconfig # for streaming results watch -n1 iwconfig","title":"Wi-Fi Signal Strength"},{"location":"industrial/networking/wireless/wifi_basics_1/#bssid-ssid-and-essids","text":"","title":"BSSID, SSID and ESSIDs"},{"location":"industrial/networking/wireless/wifi_basics_1/#other-wireless-technologies","text":"","title":"Other Wireless Technologies"},{"location":"industrial/networking/wireless/wifi_basics_1/#bluetooth-low-energy-ble","text":"","title":"Bluetooth Low Energy (BLE)"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-nics-vs-ethernet","text":"","title":"Wi-Fi NICs vs Ethernet"},{"location":"industrial/networking/wireless/wifi_basics_1/#snr-and-data-rates","text":"","title":"SNR and Data Rates"},{"location":"industrial/networking/wireless/wifi_basics_1/#snr","text":"How much signal above the background noise. Unit: dB","title":"SNR"},{"location":"industrial/networking/wireless/wifi_basics_1/#data-rate","text":"The same \"Maximum Signaling Rate\". Defined per standards 802.11xyz. Unit: Mbps Good the SNR, Can choose/set higher Data rates. Q. Signaling Rate vs Throughput? TBD","title":"Data Rate"},{"location":"industrial/networking/wireless/wifi_basics_1/#mcs","text":"Modulation and Coding scheme. Ref: http://mcsindex.com/ https://www.wlanpros.com/mcs-index-charts/","title":"MCS"},{"location":"industrial/networking/wireless/wifi_basics_1/#network-packets-vs-frame","text":"TBD","title":"Network Packets vs Frame"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-frame-types-and-timing","text":"STA (Station): In IEEE 802.11 (Wi-Fi) terminology, a station (abbreviated as STA) is a device that has the capability to use the 802.11 protocol. For example, a station may be a laptop, a desktop PC, PDA, access point or Wi-Fi phone.","title":"Wi-Fi Frame Types and Timing"},{"location":"industrial/networking/wireless/wifi_basics_1/#airtime-arbitration-process","text":"How wireless devices decides, who's going to talk next?","title":"Airtime Arbitration Process"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-roaming","text":"","title":"Wi-Fi Roaming"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-security","text":"Ethernet is a bounded medium, inheritently & physically secure. What about security of unbounded Wi-Fi? A Wi-Fi adapter in monitor mode can eavesdrop.. can capture all the packets nearby.. hmm.. What Mist supports today: WPA-2/PSK with passphrase WPA-2/EAP (802.1X) Open Access WPA-2/PSK with multiple passphrases WPA-PSK/TKIP WPA2-PSK/TKIP WEP Multi-mode/PSK with passphrase Multi-mode/EAP (802.1X) OWE Transition OWE Opportunistic Wireless Encryption MAC address authentication by RADIUS lookup","title":"Wi-Fi Security"},{"location":"industrial/networking/wireless/wifi_basics_1/#roaming","text":"Every client device has its own green diamond. :D Some can roam, some are not designed to roam.","title":"Roaming"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-design","text":"How to design a wireless network? Probably for a customer.. :p","title":"Wi-Fi Design"},{"location":"industrial/networking/wireless/wifi_basics_1/#determine-requirements","text":"","title":"Determine requirements"},{"location":"industrial/networking/wireless/wifi_basics_1/#client-channel-support","text":"Some devices might not support some channels, so plan accordingly. Ref: https://clients.mikealbano.com/ (Mike - Our OpenConfig guy, from Wireless N/W Team, Google) ;)","title":"Client channel support"},{"location":"industrial/networking/wireless/wifi_basics_1/#further-define-metrics","text":"","title":"Further Define Metrics"},{"location":"industrial/networking/wireless/wifi_basics_1/#wi-fi-ekahau-design","text":"Software to design a Wireless network.","title":"Wi-Fi Ekahau Design"},{"location":"industrial/networking/wireless/wifi_basics_2/","text":"Physical Carrier Sense Virtual Carrier Sense Duty Cycle and Spectrum Air-time Usage Multi Pre-shared Keys Interesting Site Survey SLEs Sources: https://courses.mist.com/dashboard https://www.mist.com/documentation/wi-fi-basics-1/ Physical Carrier Sense # Virtual Carrier Sense # Duty Cycle and Spectrum # Air-time Usage # Multi Pre-shared Keys # Interesting Site Survey # SLEs #","title":"Wifi basics 2"},{"location":"industrial/networking/wireless/wifi_basics_2/#physical-carrier-sense","text":"","title":"Physical Carrier Sense"},{"location":"industrial/networking/wireless/wifi_basics_2/#virtual-carrier-sense","text":"","title":"Virtual Carrier Sense"},{"location":"industrial/networking/wireless/wifi_basics_2/#duty-cycle-and-spectrum","text":"","title":"Duty Cycle and Spectrum"},{"location":"industrial/networking/wireless/wifi_basics_2/#air-time-usage","text":"","title":"Air-time Usage"},{"location":"industrial/networking/wireless/wifi_basics_2/#multi-pre-shared-keys","text":"","title":"Multi Pre-shared Keys"},{"location":"industrial/networking/wireless/wifi_basics_2/#interesting-site-survey","text":"","title":"Interesting Site Survey"},{"location":"industrial/networking/wireless/wifi_basics_2/#sles","text":"","title":"SLEs"},{"location":"industrial/networking/wireless/wifi_basics_3/","text":"Data Rates Modulation SNR OFDM Mimo Controllers Mist Config Templates Mist RRM Data Rates # Modulation # SNR # OFDM # Mimo # Controllers # Mist Config Templates # Mist RRM #","title":"Wifi basics 3"},{"location":"industrial/networking/wireless/wifi_basics_3/#data-rates","text":"","title":"Data Rates"},{"location":"industrial/networking/wireless/wifi_basics_3/#modulation","text":"","title":"Modulation"},{"location":"industrial/networking/wireless/wifi_basics_3/#snr","text":"","title":"SNR"},{"location":"industrial/networking/wireless/wifi_basics_3/#ofdm","text":"","title":"OFDM"},{"location":"industrial/networking/wireless/wifi_basics_3/#mimo","text":"","title":"Mimo"},{"location":"industrial/networking/wireless/wifi_basics_3/#controllers","text":"","title":"Controllers"},{"location":"industrial/networking/wireless/wifi_basics_3/#mist-config-templates","text":"","title":"Mist Config Templates"},{"location":"industrial/networking/wireless/wifi_basics_3/#mist-rrm","text":"","title":"Mist RRM"},{"location":"industrial/product-development/product_mindset/","text":"Intro # Key Features / competancy # Technical Expertise # Problem Solving # Scalable Architecture # Knowldege of New Technologies # DS/ML, Blockchain # Modular Monolith # Experience with Startups # Product Mindset # Startup Ecosystem # Agile Manifesto # Why # What # What NOT # How # scrum, retro, vemo Ref # https://agilemanifesto.org/ Product Mindset Principles # Must Should(level up) First Time Right Manage Scope Creep Commit & Deliver Improve Feature Adoption Solve Technical Problems Innovate Design w/ short term agility Ensure Architectural Longevity Manage Scope Screep # expansion of scope, rework vague requirements (b/c of that \ud83d\udc47) internal client detour weak project management gold platting Techniques # Context Map Uncover edge/complex/conflicting scenarios upfront TBD - Meaning - Techniques Misc # Hard Problem vs Technical challenges # Technical Challenge: Figuring out problem is tough, solution is straight-forward/simple Hard Problem: Figureing out problem is tough/easy, but solcing that is not simple as well","title":"Intro"},{"location":"industrial/product-development/product_mindset/#intro","text":"","title":"Intro"},{"location":"industrial/product-development/product_mindset/#key-features-competancy","text":"","title":"Key Features / competancy"},{"location":"industrial/product-development/product_mindset/#technical-expertise","text":"","title":"Technical Expertise"},{"location":"industrial/product-development/product_mindset/#problem-solving","text":"","title":"Problem Solving"},{"location":"industrial/product-development/product_mindset/#scalable-architecture","text":"","title":"Scalable Architecture"},{"location":"industrial/product-development/product_mindset/#knowldege-of-new-technologies","text":"","title":"Knowldege of New Technologies"},{"location":"industrial/product-development/product_mindset/#dsml-blockchain","text":"","title":"DS/ML, Blockchain"},{"location":"industrial/product-development/product_mindset/#modular-monolith","text":"","title":"Modular Monolith"},{"location":"industrial/product-development/product_mindset/#experience-with-startups","text":"","title":"Experience with Startups"},{"location":"industrial/product-development/product_mindset/#product-mindset","text":"","title":"Product Mindset"},{"location":"industrial/product-development/product_mindset/#startup-ecosystem","text":"","title":"Startup Ecosystem"},{"location":"industrial/product-development/product_mindset/#agile-manifesto","text":"","title":"Agile Manifesto"},{"location":"industrial/product-development/product_mindset/#why","text":"","title":"Why"},{"location":"industrial/product-development/product_mindset/#what","text":"","title":"What"},{"location":"industrial/product-development/product_mindset/#what-not","text":"","title":"What NOT"},{"location":"industrial/product-development/product_mindset/#how","text":"scrum, retro, vemo","title":"How"},{"location":"industrial/product-development/product_mindset/#ref","text":"https://agilemanifesto.org/","title":"Ref"},{"location":"industrial/product-development/product_mindset/#product-mindset-principles","text":"Must Should(level up) First Time Right Manage Scope Creep Commit & Deliver Improve Feature Adoption Solve Technical Problems Innovate Design w/ short term agility Ensure Architectural Longevity","title":"Product Mindset Principles"},{"location":"industrial/product-development/product_mindset/#manage-scope-screep","text":"expansion of scope, rework vague requirements (b/c of that \ud83d\udc47) internal client detour weak project management gold platting","title":"Manage Scope Screep"},{"location":"industrial/product-development/product_mindset/#techniques","text":"Context Map Uncover edge/complex/conflicting scenarios upfront TBD - Meaning - Techniques","title":"Techniques"},{"location":"industrial/product-development/product_mindset/#misc","text":"","title":"Misc"},{"location":"industrial/product-development/product_mindset/#hard-problem-vs-technical-challenges","text":"Technical Challenge: Figuring out problem is tough, solution is straight-forward/simple Hard Problem: Figureing out problem is tough/easy, but solcing that is not simple as well","title":"Hard Problem vs Technical challenges"},{"location":"infra/DevOps/","text":"Cloud Platforms AWS IAM - Identity and Access Management Computing AMI - Amazon Machine Image Instance Storage Bucket Database CI/CD AWS Elastic Beanstalk AWS CodeDeploy CI/CD Tools Kubernet Ansible Jenkins Chef Puppet Containers & VM Docker Vagrant Servers nginx gunicorn Apache ngrok CloudFlare Queues Celery RabbitMQ Redis Apache Kafka ELK Stack Elasticsearch Logstash Kibana Others Documentation Tool Sphinx ReadTheDoc MkDocs GitBook MoinMoin Ref Cloud Platforms # AWS # IAM - Identity and Access Management # Computing # AMI - Amazon Machine Image # Instance # Storage # Bucket # Database # CI/CD # AWS Elastic Beanstalk # Source: https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html AWS CodeDeploy # AWS CodeDeploy is a deployment service that automates application deployments to Amazon EC2 instances, on-premises instances, or serverless Lambda functions. Source: https://docs.aws.amazon.com/codedeploy/latest/userguide/welcome.html CI/CD Tools # Kubernet # Ansible # Jenkins # Chef # Puppet # Containers & VM # Docker # Vagrant # Servers # nginx # gunicorn # Apache # ngrok # CloudFlare # Queues # Celery # RabbitMQ # Redis # Source: https://logz.io/blog/kafka-vs-redis/ Apache Kafka # a distributed streaming platform/framework Source: https://logz.io/blog/kafka-vs-redis/ Use Case building realtime data pipelines and streaming applications messaging application ELK Stack # Elasticsearch # a no-sql db Logstash # a log pipeline tool Kibana # a vizualization tool Others # Documentation Tool # Sphinx # ReadTheDoc # MkDocs # GitBook # MoinMoin # Ref # https://www.znetlive.com/blog/compare-top-devops-tools-docker-kubernetes-puppet-chef-ansible/ ```","title":"DevOps"},{"location":"infra/DevOps/#cloud-platforms","text":"","title":"Cloud Platforms"},{"location":"infra/DevOps/#aws","text":"","title":"AWS"},{"location":"infra/DevOps/#iam-identity-and-access-management","text":"","title":"IAM - Identity and Access Management"},{"location":"infra/DevOps/#computing","text":"","title":"Computing"},{"location":"infra/DevOps/#ami-amazon-machine-image","text":"","title":"AMI - Amazon Machine Image"},{"location":"infra/DevOps/#instance","text":"","title":"Instance"},{"location":"infra/DevOps/#storage","text":"","title":"Storage"},{"location":"infra/DevOps/#bucket","text":"","title":"Bucket"},{"location":"infra/DevOps/#database","text":"","title":"Database"},{"location":"infra/DevOps/#cicd","text":"","title":"CI/CD"},{"location":"infra/DevOps/#aws-elastic-beanstalk","text":"Source: https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/Welcome.html","title":"AWS Elastic Beanstalk"},{"location":"infra/DevOps/#aws-codedeploy","text":"AWS CodeDeploy is a deployment service that automates application deployments to Amazon EC2 instances, on-premises instances, or serverless Lambda functions. Source: https://docs.aws.amazon.com/codedeploy/latest/userguide/welcome.html","title":"AWS CodeDeploy"},{"location":"infra/DevOps/#cicd-tools","text":"","title":"CI/CD Tools"},{"location":"infra/DevOps/#kubernet","text":"","title":"Kubernet"},{"location":"infra/DevOps/#ansible","text":"","title":"Ansible"},{"location":"infra/DevOps/#jenkins","text":"","title":"Jenkins"},{"location":"infra/DevOps/#chef","text":"","title":"Chef"},{"location":"infra/DevOps/#puppet","text":"","title":"Puppet"},{"location":"infra/DevOps/#containers-vm","text":"","title":"Containers &amp; VM"},{"location":"infra/DevOps/#docker","text":"","title":"Docker"},{"location":"infra/DevOps/#vagrant","text":"","title":"Vagrant"},{"location":"infra/DevOps/#servers","text":"","title":"Servers"},{"location":"infra/DevOps/#nginx","text":"","title":"nginx"},{"location":"infra/DevOps/#gunicorn","text":"","title":"gunicorn"},{"location":"infra/DevOps/#apache","text":"","title":"Apache"},{"location":"infra/DevOps/#ngrok","text":"","title":"ngrok"},{"location":"infra/DevOps/#cloudflare","text":"","title":"CloudFlare"},{"location":"infra/DevOps/#queues","text":"","title":"Queues"},{"location":"infra/DevOps/#celery","text":"","title":"Celery"},{"location":"infra/DevOps/#rabbitmq","text":"","title":"RabbitMQ"},{"location":"infra/DevOps/#redis","text":"Source: https://logz.io/blog/kafka-vs-redis/","title":"Redis"},{"location":"infra/DevOps/#apache-kafka","text":"a distributed streaming platform/framework Source: https://logz.io/blog/kafka-vs-redis/ Use Case building realtime data pipelines and streaming applications messaging application","title":"Apache Kafka"},{"location":"infra/DevOps/#elk-stack","text":"","title":"ELK Stack"},{"location":"infra/DevOps/#elasticsearch","text":"a no-sql db","title":"Elasticsearch"},{"location":"infra/DevOps/#logstash","text":"a log pipeline tool","title":"Logstash"},{"location":"infra/DevOps/#kibana","text":"a vizualization tool","title":"Kibana"},{"location":"infra/DevOps/#others","text":"","title":"Others"},{"location":"infra/DevOps/#documentation-tool","text":"","title":"Documentation Tool"},{"location":"infra/DevOps/#sphinx","text":"","title":"Sphinx"},{"location":"infra/DevOps/#readthedoc","text":"","title":"ReadTheDoc"},{"location":"infra/DevOps/#mkdocs","text":"","title":"MkDocs"},{"location":"infra/DevOps/#gitbook","text":"","title":"GitBook"},{"location":"infra/DevOps/#moinmoin","text":"","title":"MoinMoin"},{"location":"infra/DevOps/#ref","text":"https://www.znetlive.com/blog/compare-top-devops-tools-docker-kubernetes-puppet-chef-ansible/ ```","title":"Ref"},{"location":"lang/C-C%2B%2B/","text":"Introduction The Features of C++ as a Language Basic concepts Compiler Machine Code Assembly Code Linker Different kinds of files Source Code (.c/.cpp) Header Files (.h) Object Files (.o/.obj) Binary Executable Library Files (.a) Shared Library Files (.so) Preprocessor Preprocessor Directives define include if, #elif, #else, #ifdef, #ifndef, #endif GNU Compile Collection (GCC) Compile using gcc Background Flow gcc Misc is there any need to compile the .h files? How to organize things between .h files and .c/.cpp file? Should is include/import .c/.cpp file instead .h because it just works fine? C++ Keywords Expressions Operators Declaration Function definition Template declaration Explicit template instantiation Explicit template specialization Namespace definition Linkage specification Attribute declaration (attr ;) (since C++11) Empty declaration (;) (since C++11) A function declaration without a decl-specifier-seq: Specifiers Declaration Specifiers Type Specifiers Declarators Initialization Functions In-built Lambda Pass by Value Pass by Reference Statements Expression Statements Compound Statements Selection Statements Label Statements Iteration Statements Jump Statements Declaration Statements Try Blocks Atomic and Synchronized Blocks Classes Templates STL (Standard Template Library) Exceptions Misc namespace vs include REST API Microservice Based on REST Introduction # Source-0 Source-1 Source-2 Source-3 The Features of C++ as a Language # is an open ISO-standardized language. For a time, C++ had no official standard and was maintained by a de-facto standard, however since 1998, C++ is standardized by a committee of the ISO. Their page may be accessed here . is a compiled language. C++ compiles directly to a machine's native code, allowing it to be one of the fastest languages in the world, if optimized. is a strongly-typed unsafe language. C++ is a language that expects the programmer to know what he or she is doing, but allows for incredible amounts of control as a result. supports both manifest and inferred typing. As of the latest C++ standard, C++ supports both manifest and inferred typing, allowing flexibility and a means of avoiding verbosity where desired. supports both static and dynamic type checking. C++ allows type conversions to be checked either at compile-time or at run-time, again offering another degree of flexibility. Most C++ type checking is, however, static. offers many paradigm choices. C++ offers remarkable support for procedural, generic, and object-oriented programming paradigms, with many other paradigms being possible as well. is portable. As one of the most frequently used languages in the world and as an open language, C++ has a wide range of compilers that run on many different platforms that support it. Code that exclusively uses C++'s standard library will run on many platforms with few to no changes. is upwards compatible with C C++, being a language that directly builds off C, is compatible with almost all C code. C++ can use C libraries with few to no modifications of the libraries' code. has incredible library support. A search for \"library\" on the popular project-management website SourceForge will yield over 3000 results for C++ libraries. A link to the results of the search may be found here . Basic concepts # Source-GCC Source-Compile-Cycle Compiler # Compiler compiles/translates all the source code into machine readable (raw binary/machine) code. - creates a .o file (relocatable machine code for module func.c) from the output of the preprocessor - can see the assembly code in func.o using either objdump or gdb Machine Code # aka Raw binary code e.g. 8B 0E 34 12 Assembly Code # Assembly is one level higher that is semi readable without having to memorize a bunch of hex or binary codes allows you to use symbolic names for addresses and do some simple math in creating the code. e.g. MOV CX, 1234H Linker # Linker links together a number of object files to produce a binary file which can be directly executed. - creates an executable file (a.out file) from one or more .o files and .a or .so files (static or dynamic libraries) - can use objdump (or in gdb the disass command) to disassemble the code in the executable Different kinds of files # Source Code (.c/.cpp) # contain function definitions Header Files (.h) # contain function declarations (also known as function prototypes) and various preprocessor statements used to allow source code files to access externally-defined functions Object Files (.o/.obj) # (output of compiler & input to the linker) These files are produced as the output of the compiler consist of function definitions in binary form are not executable by themselves Object files end in \".o\" by convention can see the assembly code in func.o using either objdump or gdb Binary Executable # (output of linker & executable with resolved reference) produced as the output of a program called a \"linker\" linker links together a number of object files to produce a binary file which can be directly executed have no special suffix on Unix operating systems (or .out default suffix) have .exe suffix on Windows operating systems generates assembler output (a.out, default name) Library Files (.a) # files are archives are groups of objects or static libraries input to the linker similar to the .jar or .dll files Shared Library Files (.so) # Preprocessor # Before the C compiler starts compiling a source code file, the file is processed by a preprocessor automatically invoked by compiler before compilation expands the source code file by incorporating the pre-processor files (#include <.h/.c/.cpp>) included in the source code either it creates a real file or creates modified source code in memory for short time before being sent to the compiler Preprocessor Directives # Declarative define # mainly used to define constants #define BIGNUM 1000000 include # used to access function definitions defined outside of a source code file #include <stdio.h> #include \"somelocalcode.h\" or #include \"somelocalcode.c\" Conditional if, #elif, #else, #ifdef, #ifndef, #endif # GNU Compile Collection (GCC) # aka GNU C Compiler Compile using gcc # Background # Lets say func.h have a function declarations : hello() and we are defining it in func.c file (func.c does not have main() function) now want to use the hello() function in source.c, so we can include func.h file, or func.c file (BAD IDEA) Flow # func.c & source.c both need #include \"func.h\" , because func.c is defining the code which backs the hello() function source.c is using/calling the hello() function and invoking its behavior, so it has to know the behavior & memory size need to allocate for the same but it does not need the actual definition/implementation of hello() yet the compiler will generate .o (object file, compiled but not executable) file func.o from func.c, and source.o from source.c which includes main method and unresolved reference of hello() function gcc -c func.c gcc -c source.c here, func.o & source.o are not self executable because func.o doesn't have main() , and source.o have one un-resolved reference now, comes the linker linker will combine the two object files func.o & source.o into an executable file now it connects the dot between both the object files & resolves the un-resolved reference now, at run time, program can jump to the correct location gcc func.o source.o -o program gcc Misc # is there any need to compile the .h files? # No. How to organize things between .h files and .c/.cpp file? # Put as much as you can in the .c and as little as possible in the .h. The includes in the .c are only included when that one file is compiled, but the includes for the .h have to be included by every file that uses it. Should is include/import .c/.cpp file instead .h because it just works fine? # No. Lets say .c file has definition of class Foo & this .c/.cpp file are used/referenced by multiple source code files (compilation units), then those all source code files will have definition of class Foo multiple times and which may cause a problem because linker will get confused and throw error. C++ Keywords # Expressions # Operators # Arrow --> : Used to access classes, structure, or union member using pointer. e.g. Dot . : Used to access classes, structure, or union member. e.g. Scope Resolution :: : Qualifies the abstracted/hidden member/names e.g. int count = 0 ; int main ( void ) { int count = 0 ; :: count = 1 ; // set global count to 1 count = 2 ; // set local count to 2 return 0 ; } Declaration # Function definition # Template declaration # Explicit template instantiation # Explicit template specialization # Namespace definition # Linkage specification # extern \"C\" is a linkage-specification Attribute declaration (attr ;) (since C++11) # Empty declaration (;) (since C++11) # A function declaration without a decl-specifier-seq: # Specifiers # Declaration Specifiers # typedef: typedef is used to give data type a new name e.g. typedef unsigned char BYTE ; Type Specifiers # class ABC enum Abc char name Declarators # Initialization # Functions # In-built # strncpy(): char * strncpy ( char * destination, const char * source, size_t num ); copies characters from string Lambda # Pass by Value # Pass by Reference # Statements # Expression Statements # Compound Statements # Selection Statements # Label Statements # Iteration Statements # Jump Statements # Declaration Statements # Try Blocks # Atomic and Synchronized Blocks # Classes # Templates # STL (Standard Template Library) # The Standard Template Library (STL) is a set of C++ template classes to provide common programming data structures and functions such as lists, stacks, arrays, etc. It is a library of container classes, algorithms and iterators. Exceptions # Misc # namespace vs include # https://stackoverflow.com/questions/389922/c-namespace-and-include REST API # https://msdn.microsoft.com/en-us/magazine/dn342869.aspx Microservice Based on REST # https://medium.com/audelabs/modern-c-micro-service-implementation-rest-api-b499ffeaf898 https://martinfowler.com/articles/microservices.html https://dev.otto.de/2016/03/20/why-microservices/","title":"C C++"},{"location":"lang/C-C%2B%2B/#introduction","text":"Source-0 Source-1 Source-2 Source-3","title":"Introduction"},{"location":"lang/C-C%2B%2B/#the-features-of-c-as-a-language","text":"is an open ISO-standardized language. For a time, C++ had no official standard and was maintained by a de-facto standard, however since 1998, C++ is standardized by a committee of the ISO. Their page may be accessed here . is a compiled language. C++ compiles directly to a machine's native code, allowing it to be one of the fastest languages in the world, if optimized. is a strongly-typed unsafe language. C++ is a language that expects the programmer to know what he or she is doing, but allows for incredible amounts of control as a result. supports both manifest and inferred typing. As of the latest C++ standard, C++ supports both manifest and inferred typing, allowing flexibility and a means of avoiding verbosity where desired. supports both static and dynamic type checking. C++ allows type conversions to be checked either at compile-time or at run-time, again offering another degree of flexibility. Most C++ type checking is, however, static. offers many paradigm choices. C++ offers remarkable support for procedural, generic, and object-oriented programming paradigms, with many other paradigms being possible as well. is portable. As one of the most frequently used languages in the world and as an open language, C++ has a wide range of compilers that run on many different platforms that support it. Code that exclusively uses C++'s standard library will run on many platforms with few to no changes. is upwards compatible with C C++, being a language that directly builds off C, is compatible with almost all C code. C++ can use C libraries with few to no modifications of the libraries' code. has incredible library support. A search for \"library\" on the popular project-management website SourceForge will yield over 3000 results for C++ libraries. A link to the results of the search may be found here .","title":"The Features of C++ as a Language"},{"location":"lang/C-C%2B%2B/#basic-concepts","text":"Source-GCC Source-Compile-Cycle","title":"Basic concepts"},{"location":"lang/C-C%2B%2B/#compiler","text":"Compiler compiles/translates all the source code into machine readable (raw binary/machine) code. - creates a .o file (relocatable machine code for module func.c) from the output of the preprocessor - can see the assembly code in func.o using either objdump or gdb","title":"Compiler"},{"location":"lang/C-C%2B%2B/#machine-code","text":"aka Raw binary code e.g. 8B 0E 34 12","title":"Machine Code"},{"location":"lang/C-C%2B%2B/#assembly-code","text":"Assembly is one level higher that is semi readable without having to memorize a bunch of hex or binary codes allows you to use symbolic names for addresses and do some simple math in creating the code. e.g. MOV CX, 1234H","title":"Assembly Code"},{"location":"lang/C-C%2B%2B/#linker","text":"Linker links together a number of object files to produce a binary file which can be directly executed. - creates an executable file (a.out file) from one or more .o files and .a or .so files (static or dynamic libraries) - can use objdump (or in gdb the disass command) to disassemble the code in the executable","title":"Linker"},{"location":"lang/C-C%2B%2B/#different-kinds-of-files","text":"","title":"Different kinds of files"},{"location":"lang/C-C%2B%2B/#source-code-ccpp","text":"contain function definitions","title":"Source Code (.c/.cpp)"},{"location":"lang/C-C%2B%2B/#header-files-h","text":"contain function declarations (also known as function prototypes) and various preprocessor statements used to allow source code files to access externally-defined functions","title":"Header Files (.h)"},{"location":"lang/C-C%2B%2B/#object-files-oobj","text":"(output of compiler & input to the linker) These files are produced as the output of the compiler consist of function definitions in binary form are not executable by themselves Object files end in \".o\" by convention can see the assembly code in func.o using either objdump or gdb","title":"Object Files (.o/.obj)"},{"location":"lang/C-C%2B%2B/#binary-executable","text":"(output of linker & executable with resolved reference) produced as the output of a program called a \"linker\" linker links together a number of object files to produce a binary file which can be directly executed have no special suffix on Unix operating systems (or .out default suffix) have .exe suffix on Windows operating systems generates assembler output (a.out, default name)","title":"Binary Executable"},{"location":"lang/C-C%2B%2B/#library-files-a","text":"files are archives are groups of objects or static libraries input to the linker similar to the .jar or .dll files","title":"Library Files (.a)"},{"location":"lang/C-C%2B%2B/#shared-library-files-so","text":"","title":"Shared Library Files (.so)"},{"location":"lang/C-C%2B%2B/#preprocessor","text":"Before the C compiler starts compiling a source code file, the file is processed by a preprocessor automatically invoked by compiler before compilation expands the source code file by incorporating the pre-processor files (#include <.h/.c/.cpp>) included in the source code either it creates a real file or creates modified source code in memory for short time before being sent to the compiler","title":"Preprocessor"},{"location":"lang/C-C%2B%2B/#preprocessor-directives","text":"Declarative","title":"Preprocessor Directives"},{"location":"lang/C-C%2B%2B/#define","text":"mainly used to define constants #define BIGNUM 1000000","title":"define"},{"location":"lang/C-C%2B%2B/#include","text":"used to access function definitions defined outside of a source code file #include <stdio.h> #include \"somelocalcode.h\" or #include \"somelocalcode.c\" Conditional","title":"include"},{"location":"lang/C-C%2B%2B/#if-elif-else-ifdef-ifndef-endif","text":"","title":"if, #elif, #else, #ifdef, #ifndef, #endif"},{"location":"lang/C-C%2B%2B/#gnu-compile-collection-gcc","text":"aka GNU C Compiler","title":"GNU Compile Collection (GCC)"},{"location":"lang/C-C%2B%2B/#compile-using-gcc","text":"","title":"Compile using gcc"},{"location":"lang/C-C%2B%2B/#background","text":"Lets say func.h have a function declarations : hello() and we are defining it in func.c file (func.c does not have main() function) now want to use the hello() function in source.c, so we can include func.h file, or func.c file (BAD IDEA)","title":"Background"},{"location":"lang/C-C%2B%2B/#flow","text":"func.c & source.c both need #include \"func.h\" , because func.c is defining the code which backs the hello() function source.c is using/calling the hello() function and invoking its behavior, so it has to know the behavior & memory size need to allocate for the same but it does not need the actual definition/implementation of hello() yet the compiler will generate .o (object file, compiled but not executable) file func.o from func.c, and source.o from source.c which includes main method and unresolved reference of hello() function gcc -c func.c gcc -c source.c here, func.o & source.o are not self executable because func.o doesn't have main() , and source.o have one un-resolved reference now, comes the linker linker will combine the two object files func.o & source.o into an executable file now it connects the dot between both the object files & resolves the un-resolved reference now, at run time, program can jump to the correct location gcc func.o source.o -o program","title":"Flow"},{"location":"lang/C-C%2B%2B/#gcc-misc","text":"","title":"gcc Misc"},{"location":"lang/C-C%2B%2B/#is-there-any-need-to-compile-the-h-files","text":"No.","title":"is there any need to compile the .h files?"},{"location":"lang/C-C%2B%2B/#how-to-organize-things-between-h-files-and-ccpp-file","text":"Put as much as you can in the .c and as little as possible in the .h. The includes in the .c are only included when that one file is compiled, but the includes for the .h have to be included by every file that uses it.","title":"How to organize things between .h files and .c/.cpp file?"},{"location":"lang/C-C%2B%2B/#should-is-includeimport-ccpp-file-instead-h-because-it-just-works-fine","text":"No. Lets say .c file has definition of class Foo & this .c/.cpp file are used/referenced by multiple source code files (compilation units), then those all source code files will have definition of class Foo multiple times and which may cause a problem because linker will get confused and throw error.","title":"Should is include/import .c/.cpp file instead .h because it just works fine?"},{"location":"lang/C-C%2B%2B/#c-keywords","text":"","title":"C++ Keywords"},{"location":"lang/C-C%2B%2B/#expressions","text":"","title":"Expressions"},{"location":"lang/C-C%2B%2B/#operators","text":"Arrow --> : Used to access classes, structure, or union member using pointer. e.g. Dot . : Used to access classes, structure, or union member. e.g. Scope Resolution :: : Qualifies the abstracted/hidden member/names e.g. int count = 0 ; int main ( void ) { int count = 0 ; :: count = 1 ; // set global count to 1 count = 2 ; // set local count to 2 return 0 ; }","title":"Operators"},{"location":"lang/C-C%2B%2B/#declaration","text":"","title":"Declaration"},{"location":"lang/C-C%2B%2B/#function-definition","text":"","title":"Function definition"},{"location":"lang/C-C%2B%2B/#template-declaration","text":"","title":"Template declaration"},{"location":"lang/C-C%2B%2B/#explicit-template-instantiation","text":"","title":"Explicit template instantiation"},{"location":"lang/C-C%2B%2B/#explicit-template-specialization","text":"","title":"Explicit template specialization"},{"location":"lang/C-C%2B%2B/#namespace-definition","text":"","title":"Namespace definition"},{"location":"lang/C-C%2B%2B/#linkage-specification","text":"extern \"C\" is a linkage-specification","title":"Linkage specification"},{"location":"lang/C-C%2B%2B/#attribute-declaration-attr-since-c11","text":"","title":"Attribute declaration (attr ;) (since C++11)"},{"location":"lang/C-C%2B%2B/#empty-declaration-since-c11","text":"","title":"Empty declaration (;) (since C++11)"},{"location":"lang/C-C%2B%2B/#a-function-declaration-without-a-decl-specifier-seq","text":"","title":"A function declaration without a decl-specifier-seq:"},{"location":"lang/C-C%2B%2B/#specifiers","text":"","title":"Specifiers"},{"location":"lang/C-C%2B%2B/#declaration-specifiers","text":"typedef: typedef is used to give data type a new name e.g. typedef unsigned char BYTE ;","title":"Declaration Specifiers"},{"location":"lang/C-C%2B%2B/#type-specifiers","text":"class ABC enum Abc char name","title":"Type Specifiers"},{"location":"lang/C-C%2B%2B/#declarators","text":"","title":"Declarators"},{"location":"lang/C-C%2B%2B/#initialization","text":"","title":"Initialization"},{"location":"lang/C-C%2B%2B/#functions","text":"","title":"Functions"},{"location":"lang/C-C%2B%2B/#in-built","text":"strncpy(): char * strncpy ( char * destination, const char * source, size_t num ); copies characters from string","title":"In-built"},{"location":"lang/C-C%2B%2B/#lambda","text":"","title":"Lambda"},{"location":"lang/C-C%2B%2B/#pass-by-value","text":"","title":"Pass by Value"},{"location":"lang/C-C%2B%2B/#pass-by-reference","text":"","title":"Pass by Reference"},{"location":"lang/C-C%2B%2B/#statements","text":"","title":"Statements"},{"location":"lang/C-C%2B%2B/#expression-statements","text":"","title":"Expression Statements"},{"location":"lang/C-C%2B%2B/#compound-statements","text":"","title":"Compound Statements"},{"location":"lang/C-C%2B%2B/#selection-statements","text":"","title":"Selection Statements"},{"location":"lang/C-C%2B%2B/#label-statements","text":"","title":"Label Statements"},{"location":"lang/C-C%2B%2B/#iteration-statements","text":"","title":"Iteration Statements"},{"location":"lang/C-C%2B%2B/#jump-statements","text":"","title":"Jump Statements"},{"location":"lang/C-C%2B%2B/#declaration-statements","text":"","title":"Declaration Statements"},{"location":"lang/C-C%2B%2B/#try-blocks","text":"","title":"Try Blocks"},{"location":"lang/C-C%2B%2B/#atomic-and-synchronized-blocks","text":"","title":"Atomic and Synchronized Blocks"},{"location":"lang/C-C%2B%2B/#classes","text":"","title":"Classes"},{"location":"lang/C-C%2B%2B/#templates","text":"","title":"Templates"},{"location":"lang/C-C%2B%2B/#stl-standard-template-library","text":"The Standard Template Library (STL) is a set of C++ template classes to provide common programming data structures and functions such as lists, stacks, arrays, etc. It is a library of container classes, algorithms and iterators.","title":"STL (Standard Template Library)"},{"location":"lang/C-C%2B%2B/#exceptions","text":"","title":"Exceptions"},{"location":"lang/C-C%2B%2B/#misc","text":"","title":"Misc"},{"location":"lang/C-C%2B%2B/#namespace-vs-include","text":"https://stackoverflow.com/questions/389922/c-namespace-and-include","title":"namespace vs include"},{"location":"lang/C-C%2B%2B/#rest-api","text":"https://msdn.microsoft.com/en-us/magazine/dn342869.aspx","title":"REST API"},{"location":"lang/C-C%2B%2B/#microservice-based-on-rest","text":"https://medium.com/audelabs/modern-c-micro-service-implementation-rest-api-b499ffeaf898 https://martinfowler.com/articles/microservices.html https://dev.otto.de/2016/03/20/why-microservices/","title":"Microservice Based on REST"},{"location":"lang/markdown/","text":"Math Inline Block Source: https://ia.net/writer/support/general/markdown-guide Escape Dollar sign issue in Jupyter notebook ### use of `$` <!--`$`--> (End of String Anchors) Math # $ $ Inline # uses single $ syntax: $\\theta$ output: \\theta \\theta Syntax $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$, \\(p(x|y) = \\frac{p(y|x)p(x)}{p(y)}\\). Output p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} , p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} . Block # Double Dollar Syntax $$ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} $$ Output \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}}","title":"Markdown"},{"location":"lang/markdown/#math","text":"$ $","title":"Math"},{"location":"lang/markdown/#inline","text":"uses single $ syntax: $\\theta$ output: \\theta \\theta Syntax $p(x|y) = \\frac{p(y|x)p(x)}{p(y)}$, \\(p(x|y) = \\frac{p(y|x)p(x)}{p(y)}\\). Output p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} , p(x|y) = \\frac{p(y|x)p(x)}{p(y)} p(x|y) = \\frac{p(y|x)p(x)}{p(y)} .","title":"Inline"},{"location":"lang/markdown/#block","text":"Double Dollar Syntax $$ \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} $$ Output \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}} \\operatorname{ker} f=\\{g\\in G:f(g)=e_{H}\\}{\\mbox{.}}","title":"Block"},{"location":"lang/golang/go/","text":"Introduction How Go is different than other languages Install Setup Run Keywords package import type const var func struct Declaration Data Type int string UTF-8 and string literals bool byte Code points, characters, and runes Data Structure Array Slice Map Types & interfaces interface{} The representation of an interface Reflection The first law of reflection - Reflection goes from interface value to reflection object The second law of reflection - Reflection goes from reflection object to interface value The third law of reflection - To modify a reflection object, the value must be settable Statements Control Flows if, else for switch goto range Functions First Class User-defined Higher-order Closures Multiple Return Values Variadic Anonymous/Lambda Access Modifier Struct Methods Interface Constructor goroutine go defer panic recover Channels Channel Buffering Channel Synchromization Channel Directions select Timeouts Non-blocking Channel operations Closing Channels range over channels Modules go mod Semantic Import Versioning (SEMVER) Package main package Vs directory Built-in Packages timer & ticker Import Inbuilt Package Intra Package Inter Package Remote Package Cyclic json Encoding Decoding Generic JSON with interface{} Creating arbitrary data Encoding arbitrary data Decoding arbitrary data Json & Reference Type (pointers, slices, maps) Streaming Encoders and Decoders Misc regexp Errors Error Handling Testing Testcase Benchmarks Examples Skipping Subtests and Sub-benchmarks Main Run Coverage Debug gdb Delve Profiling pprof CPU Profiling - stack sampling (vs instrumentation) Heap Profiling - allocation profiling Block Trace Deploy CircleCI Run Test Misc generate Advance Testing assert Extra Best Practices Naming Convetions Code Organization Documentation Godoc Best Practices Concepts Compilation Static Typing Pointer Garbage Collection References Surprises Introduction # intially developed at Google - 2007 by Robert Griesemer, Rob Pike, and Ken Thompson is a statically-typed language with syntax similar to that of C provides garbage collection type safety dynamic-typing capability many advanced built-in types such as variable length arrays key-value maps heap a rich standard library is expressive, concise, clean, and efficient its concurrency mechanisms make it easy to write programs that get the most out of multi core and networked machines compiles quickly to machine code yet has the convenience of garbage collection and the power of run-time reflection runtime reflection in go garbage collection in go How Go is different than other languages # native concurrency support - i.e. at language-level different GC design single executable - copy/paste & deploy no dynamic/linked libraries keep lang. simple & expressive directly compiles to machine code - no virtual runtime or interpreter concept interior pointer concept Install # Setup # Run # Keywords # package # import # type # const # var # func # struct # Declaration # Data Type # int # string # https://blog.golang.org/strings In Go, a string is in effect a read-only slice of bytes string holds arbitrary bytes It is not required to hold Unicode text, UTF-8 text, or any other predefined format string literal that uses \\xNN notation to define a string constant holding some peculiar byte values Of course, bytes range from hexadecimal values 00 through FF, inclusive const sample = \"\\xbd\\xb2\\x3d\\xbc\\x20\\xe2\\x8c\\x98\" fmt . Println ( sample ) // out: \ufffd\ufffd=\ufffd \u2318 // in our sample string are not valid ASCII, not even valid UTF-8, printing the string directly will produce ugly output NOTE : indexing/iterating over string gives bytes and not characters in Go UTF-8 and string literals # placeOfInterest = \u2318 Unicode character value U+2318 const placeOfInterest = `\u2318` fmt . Printf ( \"%s\" , placeOfInterest ) // plain string: \u2318 fmt . Printf ( \"%+q\" , placeOfInterest ) // quoted string: \"\\u2318\" for i := 0 ; i < len ( placeOfInterest ); i ++ { fmt . Printf ( \"%x \" , placeOfInterest [ i ]) // hex bytes: e2 8c 98 } NOTE : Source code in Go is defined to be UTF-8 text; no other representation is allowed bool # byte # Code points, characters, and runes # https://blog.golang.org/strings Given lower case Latin letter 'A': a A: unicode code point: U+0061 lower case grave-accented letter 'A', \u00e0 B: unicode code point: U+00E0 grave accent code point (that sign above a): C: unicode code point: U+0300 Then \u00e0 == A + C or \u00e0 == B code point == rune code point is a bit of mouthful, hence go introduces shorter term rune rune meaning: any of the characters of any of several alphabets character when we store a character value in a string, we store its byte-at-a-time representation In general, a character may be represented by a number of different sequences of code points, and therefore different sequences of UTF-8 bytes The concept of character in computing is therefore ambiguous, or at least confusing, so we use it with care NOTE : Go team have been very careful so far in how we use the words \"byte\" and \"character\" That's partly because strings hold bytes, and partly because the idea of \"character\" is a little hard/ambiguous to define Data Structure # Array # var a [ 5 ] int fmt . Println ( \"emp:\" , a ) a [ 4 ] = 100 fmt . Println ( \"set:\" , a ) fmt . Println ( \"get:\" , a [ 4 ]) Slice # s := make ([] string , 3 ) fmt . Println ( \"emp:\" , s ) s [ 0 ] = \"a\" s [ 1 ] = \"b\" s [ 2 ] = \"c\" fmt . Println ( \"set:\" , s ) fmt . Println ( \"get:\" , s [ 2 ]) fmt . Println ( \"len:\" , len ( s )) s = append ( s , \"d\" ) s = append ( s , \"e\" , \"f\" ) c := make ([] string , len ( s )) copy ( c , s ) l := s [ 2 : 5 ] t := [] string { \"g\" , \"h\" , \"i\" } // TODO: len vs size?? Map # m := make ( map [ string ] int ) m [ \"k1\" ] = 7 v1 := m [ \"k1\" ] fmt . Println ( \"len:\" , len ( m )) delete ( m , \"k2\" ) // no error isThere , value := m [ \"k2\" ] // out: false, 0 isThere , value := m [ \"k1\" ] // out: true, 7 n := map [ string ] int { \"foo\" : 1 , \"bar\" : 2 } n := map [ string ] interface {}{ \"foo\" : 1 , \"bar\" : \"some string\" } Types & interfaces # Go is statically typed Every variable has a static type, that is, exactly one type known and fixed at compile time: int, float32, *MyType, []byte, and so on interface is one important category of type - which represent fixed/minimal sets of methods If we declare type MyInt int var i int var j MyInt then i has type int and j has type MyInt variables i and j have distinct static types and, although they have the same underlying type, they cannot be assigned to one another without a conversion An interface variable can store any concrete (non-interface) value as long as that value implements the interface's methods. var r io . Reader r = os . Stdin r = bufio . NewReader ( r ) r = new ( bytes . Buffer ) // and so on Here r can exhibit lot more methods than Read() of io.Reader . Its not limited to methods provided by interface io.Reader . An extremely important example of an interface type is the empty interface: interface{} interface{} # A.K.A. Empty Interface It represents the empty set of methods and is satisfied by any value at all, since any value has zero or more methods. interface{} (empty interface) type describes an interface with zero methods Every Go type implements at least zero methods therefore satisfies the empty interface so we can receive any go data type in an empty interface (similar to object/var in other langs.) var i interface{} i = \"a string\" i = 2011 i = 2.777 fmt.Println() https://github.com/toransahu/go-misc/blob/master/interfac/main.go A variable of interface type always has the same static type, and even though at run time the value stored in the interface variable may change type, that value will always satisfy the interface. The representation of an interface # A variable of type interface type stores a pair: a concrete value assigned to the variable, and that concrete values's type/type-descriptor. e.g. var r io . Reader tty , err := os . OpenFile ( \"/dev/tty\" , os . O_RDWR , 0 ) if err != nil { return nil , err } r = tty here r contains pair (value, concrete type) == (tty, *os.File). As a interface variable also stores the type details, we can do things like this: var w io . Writer w = r .( io . Writer ) // The expression in this assignment is a type assertion // it asserts is that the item inside r also implements io.Writer, and so we can assign it to w // or var s interface {} s = \"hello\" ss := s .( string ) // The expression in this assignment is a type assertion // or ss , ok := s .( string ) this is called type assertion . Reflection # Reflection in computing is the ability of a program to examine its own structure, particularly through types; it's a form of metaprogramming. It's also a great source of confusion. reflection builds on the type system The first law of reflection - Reflection goes from interface value to reflection object # At the basic level, reflection is just a mechanism to examine the type and value pair stored inside an interface variable there are two types we need to know about in package reflect: Type and Value Those two types give access to the contents of an interface variable, and two simple functions, called reflect.TypeOf() and reflect.ValueOf() tbd The second law of reflection - Reflection goes from reflection object to interface value # tbd The third law of reflection - To modify a reflection object, the value must be settable # tbd Statements # Control Flows # if , else # if num := 9 ; num < 0 { fmt . Println ( num , \"is negative\" ) } else if num < 10 { fmt . Println ( num , \"has 1 digit\" ) } else { fmt . Println ( num , \"has multiple digits\" ) } NOTE : there is no ternary ? if else condition for # for is the only looping construct in Go for have 3-4 pattern // like while loop i := 1 for i <= 3 { fmt . Println ( i ) i = i + 1 } // regular for loop for j := 7 ; j <= 9 ; j ++ { fmt . Println ( j ) } for n := 0 ; n <= 5 ; n ++ { if n % 2 == 0 { continue } fmt . Println ( n ) } // infinite loop (or with break for { fmt . Println ( \"loop\" ) break } switch # // regular switch case i := 2 fmt . Print ( \"Write \" , i , \" as \" ) switch i { case 1 : fmt . Println ( \"one\" ) case 2 : fmt . Println ( \"two\" ) case 3 : fmt . Println ( \"three\" ) } // TODO: switch time . Now (). Weekday () { case time . Saturday , time . Sunday : fmt . Println ( \"It's the weekend\" ) default : fmt . Println ( \"It's a weekday\" ) } // regular if else t := time . Now () switch { case t . Hour () < 12 : fmt . Println ( \"It's before noon\" ) default : fmt . Println ( \"It's after noon\" ) } // interface type assertion whatAmI := func ( i interface {}) { switch t := i .( type ) { case bool : fmt . Println ( \"I'm a bool\" ) case int : fmt . Println ( \"I'm an int\" ) default : fmt . Printf ( \"Don't know type %T\\n\" , t ) } } whatAmI ( true ) whatAmI ( 1 ) whatAmI ( \"hey\" ) goto # why its still valid in a new-gen prog. lang. ?? range # nums := [] int { 2 , 3 , 4 } sum := 0 // range on arrays and slices provides both the index and value for each entry for _ , num := range nums { sum += num } for i , num := range nums { if num == 3 { fmt . Println ( \"index:\" , i ) } } // range on map iterates over key/value pairs kvs := map [ string ] string { \"a\" : \"apple\" , \"b\" : \"banana\" } for k , v := range kvs { fmt . Printf ( \"%s -> %s\\n\" , k , v ) } // range can also iterate over just the keys of a map for k := range kvs { fmt . Println ( \"key:\" , k ) } // range on strings iterates over Unicode code points // The first value is the starting byte index of the rune and the second the rune itself. for i , c := range \"go\" { fmt . Println ( i , c ) } // out: 0 103 1 111 Functions # src: https://golang.org/doc/codewalk/functions/ First Class # User-defined # Higher-order # a function which accepts another function as a arg Closures # a concept of having access of outer scope in an Anonynous function, function literals are closures: they inherit the scope of the function in which they are declared same as python, javascript Multiple Return Values # similar to pl/sql procedures func () string , int { return \"Yes\" , 1 } Variadic # variable/arbitrary numbers of arguments similar to *args variable [space] ... concateanted to type vardiac arg is always a slice builtin e.g. fmt.Println func sum ( nums ... int ) int { total := 0 for _ , number := range nums { total += number } return total } func main () { sum ( 1 , 2 ) sum ( 1 , 2 , 3 ) } can directly pass a slice like num_slice := [] int { 1 , 2 , 3 } sum ( num_slice ... ) Anonymous/Lambda # func ( msg string ) { fmt . Println ( msg ) }( \"Some message\" ) Access Modifier # depends on CASE of the func if starts with Capital case --> Public should have comment/doc string else private Struct # regular struct in go, struct are alternative to classes type Vehicle struct { Make string `json:make` // additional json tag for de/serialization Fuel string Engine Engine owner string // not an exportable/exposed/public key/object } type Engine struct { Stroke string HorsePower string } Methods # func ( v * Vehicle ) Start () ( string , error ) { return \"Vrooom\" , nil } engine := Engine { \"Four\" , \"1000\" } car := Vehicle { \"Tesla\" , \"Li\" , engine , \"Toran\" } res , err := car . Start () Interface # Interfaces are named collections of method signatures https://gobyexample.com/interfaces Constructor # goroutine # A goroutine is a lightweight thread of execution go # func f ( from string ) { for i := 0 ; i < 3 ; i ++ { fmt . Println ( from , \":\" , i ) } } func main () { f ( \"direct\" ) // direct call go f ( \"goroutine\" ) // goroutine call go func ( msg string ){ fmt . Println ( msg ) }( \"goroutine from anonymous func\" ) fmt . Scanln () // input from stdio fmt . Println ( \"done\" ) } // out: direct : 0 direct : 1 direct : 2 goroutine : 0 goroutine from anonymous func goroutine : 1 goroutine : 2 < enter > done by going through above mentioned example: if we want to invoke the function f as a goroutine we call it using go statement func f will execute concurrently with the calling/main one we can also start a goroutine for an anonymous func our two function calls are running asynchronously in separate goroutines now we see output of blocking/synchronous call first then the interleaved output of two goroutines (output order may vary system to system) defer # tbd https://blog.golang.org/defer-panic-and-recover panic # recover # Channels # https://gobyexample.com/channels Channels are the pipes that connect concurrent goroutines You can send values into channels from one goroutine and receive those values into another goroutine messages := make ( chan string ) // create a channel named message go func () { messages <- \"ping\" }() // from go routine `send` a string value/msg \"ping\" to the channel msg := <- messages // `receive` value/msg from the channel fmt . Println ( msg ) fmt . Println ( msg .( string ) // assert type NOTE : By default sends and receives block until both the sender and receiver are ready. This property allowed us to wait at the end of our program for the \"ping\" message without having to use any other synchronization. meaning that, whenever there will be receiver (and is ready to receive the value) then only sender can send the value/msg to the channel see: https://github.com/toransahu/go-misc/blob/master/goroutines/channels/channels.go#L30 hence we can say, by default go channels are unbufferred Channel Buffering # we checked above NOTE about readiness of senders & receivers channel buffering is to alter that nature & keep the value/msg in the buffer Buffered channels accept a limited number of values without a corresponding receiver for those values message := make ( chan string , 2 ) // here 2 is capacity of the buffer message <- \"value 1\" message <- \"value 2\" fmt . Println ( <- message ) fmt . Println ( <- message ) https://github.com/toransahu/go-misc/blob/master/goroutines/channels/buffered/buffered_channels.go Channel Synchromization # tbd https://gobyexample.com/channel-synchronization Channel Directions # tbd https://gobyexample.com/channel-directions select # tbd https://gobyexample.com/select Timeouts # tbd https://gobyexample.com/timeouts Non-blocking Channel operations # tbd https://gobyexample.com/non-blocking-channel-operations Closing Channels # tbd https://gobyexample.com/closing-channels range over channels # tbd https://gobyexample.com/range-over-channels Modules # A module is a collection of related Go packages that are versioned together as a single unit. Ref: https://github.com/golang/go/wiki/Modules#modules https://github.com/golang/go/wiki/Modules go mod # to manage [versioned] dependencies was out with go 1.11 with preliminary/provisionary support & target to finalizing the feature for 1.14 (considering all feedbacks since 1.11-1.13) don't need to live the code in GOPATH creates/uses go.mod file the initial prototype vgo was announced in February 2018 other alternatives were: dep, gom etc. management of interdependencies: vgo's controversial algo uses the oldest common version to support stability this may while discard the acceptance of any security bug fixed in newer version e.g. package A uses B and B uses D's atleast 1.0 version package A also uses C and C uses D's either 1.0 or 1.1 version then, as per vgo vgo versioned go manages all the algorithm of versioning the go projects/packages/modules cmd vgo build is capable of generating go.mod creates/manages versioned cache packages inside GOPATH/src/v there are support for more than one module in repository, but general idea is one As of Go 1.11, the go command enables the use of modules when the current directory or any parent directory has a go.mod, provided the directory is outside GOPATH/src. (Inside GOPATH/src, for compatibility, the go command still runs in the old GOPATH mode, even if a go.mod is found. See the go command documentation for details.) Starting in Go 1.13, module mode will be the default for all development. In addition to go.mod, the go command maintains a file named go.sum containing the expected cryptographic hashes of the content of specific module versions to maintain the intigrity of the go.mod Semantic Import Versioning (SEMVER) # way to handle major dependency changes like: v1 to v2, v3,... API/interface changes how /github.com/mistsys/log (contains all v1.x.x) & /github.com/mistsys/log/v2 (contains all v2.x.x) Ref: https://research.swtch.com/vgo-import Package # main # package Vs directory # Built-in Packages # timer & ticker # tbd https://gobyexample.com/timers https://gobyexample.com/tickers continue exploring other packages from here Import # Inbuilt Package # Intra Package # Inter Package # Remote Package # Cyclic # json # Encoding # func Marshal(v interface{}) ([]byte, error) Only data structures that can be represented as valid JSON will be encoded: JSON objects only support strings as keys; to encode a Go map type it must be of the form map[string]T (where T is any Go type supported by the json package). TODO: Channel, complex, and function types cannot be encoded. TODO: Cyclic data structures are not supported; they will cause Marshal to go into an infinite loop. Pointers will be encoded as the values they point to (or 'null' if the pointer is nil) The json package only accesses the exported fields of struct types (those that begin with an uppercase letter). Therefore only the the exported fields of a struct will be present in the JSON output. TODO: what if alias is also provided? we can also provide json:\"alias\" for each field in the struct so that those fields will be encoded as per aliases shortcut to generate those: vim-go: visual select -> <leader> GoAddTags GoLand: // data structure, Message type Message struct { Name string `json:\"name\"` Body string `json:\"body\"` Time int64 `json:\"time\"` } // an instance of Message m := Message { \"Alice\" , \"Hello\" , 1294706395881547000 } // encoding m b , err := json . Marshal ( m ) // If all is well, err will be nil and b will be a []byte containing this JSON data b == [] byte ( `{\"Name\":\"Alice\",\"Body\":\"Hello\",\"Time\":1294706395881547000}` ) https://github.com/toransahu/go-misc/blob/master/json/encoding.go Decoding # https://github.com/toransahu/go-misc/blob/master/json/decoding.go Generic JSON with interface{} # The json package uses map[string]interface{} and []interface{} values to store arbitrary JSON objects and arrays it will happily unmarshal any valid JSON blob into a plain interface{} value default concrete Go types are: bool for JSON booleans float64 for JSON numbers string for JSON strings nil for JSON null Creating arbitrary data # i := map [ string ] interface {}{ \"id\" : 1111 , \"name\" : \"Toran\" } fmt . Println ( i ) } Encoding arbitrary data # bytes := json . Marshal ( i ) Decoding arbitrary data # https://github.com/toransahu/go-misc/blob/master/json/json_test.go#L33 var i interface {} json . Unmarshal ( bytes , & i ) Json & Reference Type (pointers, slices, maps) # https://blog.golang.org/json-and-go https://github.com/toransahu/go-misc/blob/master/jsons/reference_type.go#L53 Streaming Encoders and Decoders # https://blog.golang.org/json-and-go Misc # https://vsupalov.com/go-json-omitempty/ regexp # Ref: https://golang.org/pkg/regexp/ https://github.com/google/re2/wiki/Syntax https://shapeshed.com/golang-regexp/ Errors # https://gobyexample.com/errors Error Handling # https://blog.golang.org/error-handling-and-go Testing # test module should named as *_test.go under packages FIXME: better to organize test modules in a separate package - similar to Java?? Testcase # Benchmarks # Examples # Skipping # Subtests and Sub-benchmarks # Main # Run # a test file ~/go/src/github.com/toransahu/go-misc/json on \ue0a0 master! \u231a 14:18:45 $ go test json_test.go config.go encoding.go ok command-line-arguments 0.003s all test files under a package ~/go/src/github.com/toransahu/go-misc/json on \ue0a0 master! \u231a 14:18:56 $ go test PASS ok github.com/toransahu/go-misc/json 0.002s all test files in all packages tbd specific test function of a test file tbd specific test function/file with pattern/regex tbd Coverage # https://blog.alexellis.io/golang-writing-unit-tests/ src: https://golang.org/pkg/testing/#hdr-Subtests_and_Sub_benchmarks https://stackoverflow.com/questions/16935965/how-to-run-test-cases-in-a-specified-file Debug # gdb # https://golang.org/doc/gdb Delve # Profiling # pprof # https://blog.golang.org/pprof CPU Profiling - stack sampling (vs instrumentation) # Heap Profiling - allocation profiling # Block # Trace # Deploy # CircleCI # Run Test # Misc # generate # automatically generate golang code for a particular purpose like print name of memebers in a struct stringr https://blog.golang.org/generate can set header/preprocessor (with commands) in the go file to do the job on each build Advance Testing # assert # 3rd party packages for assert.* https://github.com/stretchr/testify Extra # https://talks.golang.org/2012/10things.slide#3 Best Practices # Naming Convetions # https://golang.org/doc/effective_go.html#names https://blog.golang.org/package-names Code Organization # Package main test https://blog.golang.org/organizing-go-code inside a directory all modules with only single package name can only execute/run main package module hence main package func main should be declared to run the main package module Documentation # to document a type, variable, constant, function, or even a package, write a regular comment directly preceding its declaration, with no intervening blank line a complete sentence begins with the name of the element similar to python 's Docstring & java 's Javadoc but simpler than them src: https://blog.golang.org/godoc-documenting-go-code // Package sort provides primitives for sorting slices and user-defined // collections. package sort ... // Fprint formats using the default formats for its operands and writes to w. // Spaces are added between operands when neither is a string. // It returns the number of bytes written and any write error encountered. func Fprint ( w io . Writer , a ... interface {}) ( n int , err error ) { extra: do something like this to achieve this notable keywords: Deprecated: BUG(<contact person>) Godoc # Best Practices # Concepts # Compilation # Static Typing # Pointer # Garbage Collection # Go language features, goals, and use cases have forced to rethink the entire garbage collection stack and have led to a surprising place Go programs have hundreds of thousands of stacks They are managed by the Go scheduler and are always preempted at GC safepoints The Go scheduler multiplexes Go routines onto OS threads which hopefully run with one OS thread per HW thread We manage the stacks and their size by copying them and updating pointers in the stack. It's a local operation so it scales fairly well. Ref: https://blog.golang.org/ismmkeynote https://www.ardanlabs.com/blog/2018/12/garbage-collection-in-go-part1-semantics.html References # https://golang.org/doc/code.html https://github.com/golang/go/wiki/Learn Surprises # https://medium.com/@karel_3d/things-that-surprised-me-in-go-47bccce94558 https://utcc.utoronto.ca/~cks/space/blog/programming/GoInteriorPointerGC https://dave.cheney.net/2017/04/29/there-is-no-pass-by-reference-in-go","title":"Go"},{"location":"lang/golang/go/#introduction","text":"intially developed at Google - 2007 by Robert Griesemer, Rob Pike, and Ken Thompson is a statically-typed language with syntax similar to that of C provides garbage collection type safety dynamic-typing capability many advanced built-in types such as variable length arrays key-value maps heap a rich standard library is expressive, concise, clean, and efficient its concurrency mechanisms make it easy to write programs that get the most out of multi core and networked machines compiles quickly to machine code yet has the convenience of garbage collection and the power of run-time reflection runtime reflection in go garbage collection in go","title":"Introduction"},{"location":"lang/golang/go/#how-go-is-different-than-other-languages","text":"native concurrency support - i.e. at language-level different GC design single executable - copy/paste & deploy no dynamic/linked libraries keep lang. simple & expressive directly compiles to machine code - no virtual runtime or interpreter concept interior pointer concept","title":"How Go is different than other languages"},{"location":"lang/golang/go/#install","text":"","title":"Install"},{"location":"lang/golang/go/#setup","text":"","title":"Setup"},{"location":"lang/golang/go/#run","text":"","title":"Run"},{"location":"lang/golang/go/#keywords","text":"","title":"Keywords"},{"location":"lang/golang/go/#package","text":"","title":"package"},{"location":"lang/golang/go/#import","text":"","title":"import"},{"location":"lang/golang/go/#type","text":"","title":"type"},{"location":"lang/golang/go/#const","text":"","title":"const"},{"location":"lang/golang/go/#var","text":"","title":"var"},{"location":"lang/golang/go/#func","text":"","title":"func"},{"location":"lang/golang/go/#struct","text":"","title":"struct"},{"location":"lang/golang/go/#declaration","text":"","title":"Declaration"},{"location":"lang/golang/go/#data-type","text":"","title":"Data Type"},{"location":"lang/golang/go/#int","text":"","title":"int"},{"location":"lang/golang/go/#string","text":"https://blog.golang.org/strings In Go, a string is in effect a read-only slice of bytes string holds arbitrary bytes It is not required to hold Unicode text, UTF-8 text, or any other predefined format string literal that uses \\xNN notation to define a string constant holding some peculiar byte values Of course, bytes range from hexadecimal values 00 through FF, inclusive const sample = \"\\xbd\\xb2\\x3d\\xbc\\x20\\xe2\\x8c\\x98\" fmt . Println ( sample ) // out: \ufffd\ufffd=\ufffd \u2318 // in our sample string are not valid ASCII, not even valid UTF-8, printing the string directly will produce ugly output NOTE : indexing/iterating over string gives bytes and not characters in Go","title":"string"},{"location":"lang/golang/go/#utf-8-and-string-literals","text":"placeOfInterest = \u2318 Unicode character value U+2318 const placeOfInterest = `\u2318` fmt . Printf ( \"%s\" , placeOfInterest ) // plain string: \u2318 fmt . Printf ( \"%+q\" , placeOfInterest ) // quoted string: \"\\u2318\" for i := 0 ; i < len ( placeOfInterest ); i ++ { fmt . Printf ( \"%x \" , placeOfInterest [ i ]) // hex bytes: e2 8c 98 } NOTE : Source code in Go is defined to be UTF-8 text; no other representation is allowed","title":"UTF-8 and string literals"},{"location":"lang/golang/go/#bool","text":"","title":"bool"},{"location":"lang/golang/go/#byte","text":"","title":"byte"},{"location":"lang/golang/go/#code-points-characters-and-runes","text":"https://blog.golang.org/strings Given lower case Latin letter 'A': a A: unicode code point: U+0061 lower case grave-accented letter 'A', \u00e0 B: unicode code point: U+00E0 grave accent code point (that sign above a): C: unicode code point: U+0300 Then \u00e0 == A + C or \u00e0 == B code point == rune code point is a bit of mouthful, hence go introduces shorter term rune rune meaning: any of the characters of any of several alphabets character when we store a character value in a string, we store its byte-at-a-time representation In general, a character may be represented by a number of different sequences of code points, and therefore different sequences of UTF-8 bytes The concept of character in computing is therefore ambiguous, or at least confusing, so we use it with care NOTE : Go team have been very careful so far in how we use the words \"byte\" and \"character\" That's partly because strings hold bytes, and partly because the idea of \"character\" is a little hard/ambiguous to define","title":"Code points, characters, and runes"},{"location":"lang/golang/go/#data-structure","text":"","title":"Data Structure"},{"location":"lang/golang/go/#array","text":"var a [ 5 ] int fmt . Println ( \"emp:\" , a ) a [ 4 ] = 100 fmt . Println ( \"set:\" , a ) fmt . Println ( \"get:\" , a [ 4 ])","title":"Array"},{"location":"lang/golang/go/#slice","text":"s := make ([] string , 3 ) fmt . Println ( \"emp:\" , s ) s [ 0 ] = \"a\" s [ 1 ] = \"b\" s [ 2 ] = \"c\" fmt . Println ( \"set:\" , s ) fmt . Println ( \"get:\" , s [ 2 ]) fmt . Println ( \"len:\" , len ( s )) s = append ( s , \"d\" ) s = append ( s , \"e\" , \"f\" ) c := make ([] string , len ( s )) copy ( c , s ) l := s [ 2 : 5 ] t := [] string { \"g\" , \"h\" , \"i\" } // TODO: len vs size??","title":"Slice"},{"location":"lang/golang/go/#map","text":"m := make ( map [ string ] int ) m [ \"k1\" ] = 7 v1 := m [ \"k1\" ] fmt . Println ( \"len:\" , len ( m )) delete ( m , \"k2\" ) // no error isThere , value := m [ \"k2\" ] // out: false, 0 isThere , value := m [ \"k1\" ] // out: true, 7 n := map [ string ] int { \"foo\" : 1 , \"bar\" : 2 } n := map [ string ] interface {}{ \"foo\" : 1 , \"bar\" : \"some string\" }","title":"Map"},{"location":"lang/golang/go/#types-interfaces","text":"Go is statically typed Every variable has a static type, that is, exactly one type known and fixed at compile time: int, float32, *MyType, []byte, and so on interface is one important category of type - which represent fixed/minimal sets of methods If we declare type MyInt int var i int var j MyInt then i has type int and j has type MyInt variables i and j have distinct static types and, although they have the same underlying type, they cannot be assigned to one another without a conversion An interface variable can store any concrete (non-interface) value as long as that value implements the interface's methods. var r io . Reader r = os . Stdin r = bufio . NewReader ( r ) r = new ( bytes . Buffer ) // and so on Here r can exhibit lot more methods than Read() of io.Reader . Its not limited to methods provided by interface io.Reader . An extremely important example of an interface type is the empty interface: interface{}","title":"Types &amp; interfaces"},{"location":"lang/golang/go/#interface","text":"A.K.A. Empty Interface It represents the empty set of methods and is satisfied by any value at all, since any value has zero or more methods. interface{} (empty interface) type describes an interface with zero methods Every Go type implements at least zero methods therefore satisfies the empty interface so we can receive any go data type in an empty interface (similar to object/var in other langs.) var i interface{} i = \"a string\" i = 2011 i = 2.777 fmt.Println() https://github.com/toransahu/go-misc/blob/master/interfac/main.go A variable of interface type always has the same static type, and even though at run time the value stored in the interface variable may change type, that value will always satisfy the interface.","title":"interface{}"},{"location":"lang/golang/go/#the-representation-of-an-interface","text":"A variable of type interface type stores a pair: a concrete value assigned to the variable, and that concrete values's type/type-descriptor. e.g. var r io . Reader tty , err := os . OpenFile ( \"/dev/tty\" , os . O_RDWR , 0 ) if err != nil { return nil , err } r = tty here r contains pair (value, concrete type) == (tty, *os.File). As a interface variable also stores the type details, we can do things like this: var w io . Writer w = r .( io . Writer ) // The expression in this assignment is a type assertion // it asserts is that the item inside r also implements io.Writer, and so we can assign it to w // or var s interface {} s = \"hello\" ss := s .( string ) // The expression in this assignment is a type assertion // or ss , ok := s .( string ) this is called type assertion .","title":"The representation of an interface"},{"location":"lang/golang/go/#reflection","text":"Reflection in computing is the ability of a program to examine its own structure, particularly through types; it's a form of metaprogramming. It's also a great source of confusion. reflection builds on the type system","title":"Reflection"},{"location":"lang/golang/go/#the-first-law-of-reflection-reflection-goes-from-interface-value-to-reflection-object","text":"At the basic level, reflection is just a mechanism to examine the type and value pair stored inside an interface variable there are two types we need to know about in package reflect: Type and Value Those two types give access to the contents of an interface variable, and two simple functions, called reflect.TypeOf() and reflect.ValueOf() tbd","title":"The first law of reflection - Reflection goes from interface value to reflection object"},{"location":"lang/golang/go/#the-second-law-of-reflection-reflection-goes-from-reflection-object-to-interface-value","text":"tbd","title":"The second law of reflection - Reflection goes from reflection object to interface value"},{"location":"lang/golang/go/#the-third-law-of-reflection-to-modify-a-reflection-object-the-value-must-be-settable","text":"tbd","title":"The third law of reflection - To modify a reflection object, the value must be settable"},{"location":"lang/golang/go/#statements","text":"","title":"Statements"},{"location":"lang/golang/go/#control-flows","text":"","title":"Control Flows"},{"location":"lang/golang/go/#if-else","text":"if num := 9 ; num < 0 { fmt . Println ( num , \"is negative\" ) } else if num < 10 { fmt . Println ( num , \"has 1 digit\" ) } else { fmt . Println ( num , \"has multiple digits\" ) } NOTE : there is no ternary ? if else condition","title":"if, else"},{"location":"lang/golang/go/#for","text":"for is the only looping construct in Go for have 3-4 pattern // like while loop i := 1 for i <= 3 { fmt . Println ( i ) i = i + 1 } // regular for loop for j := 7 ; j <= 9 ; j ++ { fmt . Println ( j ) } for n := 0 ; n <= 5 ; n ++ { if n % 2 == 0 { continue } fmt . Println ( n ) } // infinite loop (or with break for { fmt . Println ( \"loop\" ) break }","title":"for"},{"location":"lang/golang/go/#switch","text":"// regular switch case i := 2 fmt . Print ( \"Write \" , i , \" as \" ) switch i { case 1 : fmt . Println ( \"one\" ) case 2 : fmt . Println ( \"two\" ) case 3 : fmt . Println ( \"three\" ) } // TODO: switch time . Now (). Weekday () { case time . Saturday , time . Sunday : fmt . Println ( \"It's the weekend\" ) default : fmt . Println ( \"It's a weekday\" ) } // regular if else t := time . Now () switch { case t . Hour () < 12 : fmt . Println ( \"It's before noon\" ) default : fmt . Println ( \"It's after noon\" ) } // interface type assertion whatAmI := func ( i interface {}) { switch t := i .( type ) { case bool : fmt . Println ( \"I'm a bool\" ) case int : fmt . Println ( \"I'm an int\" ) default : fmt . Printf ( \"Don't know type %T\\n\" , t ) } } whatAmI ( true ) whatAmI ( 1 ) whatAmI ( \"hey\" )","title":"switch"},{"location":"lang/golang/go/#goto","text":"why its still valid in a new-gen prog. lang. ??","title":"goto"},{"location":"lang/golang/go/#range","text":"nums := [] int { 2 , 3 , 4 } sum := 0 // range on arrays and slices provides both the index and value for each entry for _ , num := range nums { sum += num } for i , num := range nums { if num == 3 { fmt . Println ( \"index:\" , i ) } } // range on map iterates over key/value pairs kvs := map [ string ] string { \"a\" : \"apple\" , \"b\" : \"banana\" } for k , v := range kvs { fmt . Printf ( \"%s -> %s\\n\" , k , v ) } // range can also iterate over just the keys of a map for k := range kvs { fmt . Println ( \"key:\" , k ) } // range on strings iterates over Unicode code points // The first value is the starting byte index of the rune and the second the rune itself. for i , c := range \"go\" { fmt . Println ( i , c ) } // out: 0 103 1 111","title":"range"},{"location":"lang/golang/go/#functions","text":"src: https://golang.org/doc/codewalk/functions/","title":"Functions"},{"location":"lang/golang/go/#first-class","text":"","title":"First Class"},{"location":"lang/golang/go/#user-defined","text":"","title":"User-defined"},{"location":"lang/golang/go/#higher-order","text":"a function which accepts another function as a arg","title":"Higher-order"},{"location":"lang/golang/go/#closures","text":"a concept of having access of outer scope in an Anonynous function, function literals are closures: they inherit the scope of the function in which they are declared same as python, javascript","title":"Closures"},{"location":"lang/golang/go/#multiple-return-values","text":"similar to pl/sql procedures func () string , int { return \"Yes\" , 1 }","title":"Multiple Return Values"},{"location":"lang/golang/go/#variadic","text":"variable/arbitrary numbers of arguments similar to *args variable [space] ... concateanted to type vardiac arg is always a slice builtin e.g. fmt.Println func sum ( nums ... int ) int { total := 0 for _ , number := range nums { total += number } return total } func main () { sum ( 1 , 2 ) sum ( 1 , 2 , 3 ) } can directly pass a slice like num_slice := [] int { 1 , 2 , 3 } sum ( num_slice ... )","title":"Variadic"},{"location":"lang/golang/go/#anonymouslambda","text":"func ( msg string ) { fmt . Println ( msg ) }( \"Some message\" )","title":"Anonymous/Lambda"},{"location":"lang/golang/go/#access-modifier","text":"depends on CASE of the func if starts with Capital case --> Public should have comment/doc string else private","title":"Access Modifier"},{"location":"lang/golang/go/#struct_1","text":"regular struct in go, struct are alternative to classes type Vehicle struct { Make string `json:make` // additional json tag for de/serialization Fuel string Engine Engine owner string // not an exportable/exposed/public key/object } type Engine struct { Stroke string HorsePower string }","title":"Struct"},{"location":"lang/golang/go/#methods","text":"func ( v * Vehicle ) Start () ( string , error ) { return \"Vrooom\" , nil } engine := Engine { \"Four\" , \"1000\" } car := Vehicle { \"Tesla\" , \"Li\" , engine , \"Toran\" } res , err := car . Start ()","title":"Methods"},{"location":"lang/golang/go/#interface_1","text":"Interfaces are named collections of method signatures https://gobyexample.com/interfaces","title":"Interface"},{"location":"lang/golang/go/#constructor","text":"","title":"Constructor"},{"location":"lang/golang/go/#goroutine","text":"A goroutine is a lightweight thread of execution","title":"goroutine"},{"location":"lang/golang/go/#go","text":"func f ( from string ) { for i := 0 ; i < 3 ; i ++ { fmt . Println ( from , \":\" , i ) } } func main () { f ( \"direct\" ) // direct call go f ( \"goroutine\" ) // goroutine call go func ( msg string ){ fmt . Println ( msg ) }( \"goroutine from anonymous func\" ) fmt . Scanln () // input from stdio fmt . Println ( \"done\" ) } // out: direct : 0 direct : 1 direct : 2 goroutine : 0 goroutine from anonymous func goroutine : 1 goroutine : 2 < enter > done by going through above mentioned example: if we want to invoke the function f as a goroutine we call it using go statement func f will execute concurrently with the calling/main one we can also start a goroutine for an anonymous func our two function calls are running asynchronously in separate goroutines now we see output of blocking/synchronous call first then the interleaved output of two goroutines (output order may vary system to system)","title":"go"},{"location":"lang/golang/go/#defer","text":"tbd https://blog.golang.org/defer-panic-and-recover","title":"defer"},{"location":"lang/golang/go/#panic","text":"","title":"panic"},{"location":"lang/golang/go/#recover","text":"","title":"recover"},{"location":"lang/golang/go/#channels","text":"https://gobyexample.com/channels Channels are the pipes that connect concurrent goroutines You can send values into channels from one goroutine and receive those values into another goroutine messages := make ( chan string ) // create a channel named message go func () { messages <- \"ping\" }() // from go routine `send` a string value/msg \"ping\" to the channel msg := <- messages // `receive` value/msg from the channel fmt . Println ( msg ) fmt . Println ( msg .( string ) // assert type NOTE : By default sends and receives block until both the sender and receiver are ready. This property allowed us to wait at the end of our program for the \"ping\" message without having to use any other synchronization. meaning that, whenever there will be receiver (and is ready to receive the value) then only sender can send the value/msg to the channel see: https://github.com/toransahu/go-misc/blob/master/goroutines/channels/channels.go#L30 hence we can say, by default go channels are unbufferred","title":"Channels"},{"location":"lang/golang/go/#channel-buffering","text":"we checked above NOTE about readiness of senders & receivers channel buffering is to alter that nature & keep the value/msg in the buffer Buffered channels accept a limited number of values without a corresponding receiver for those values message := make ( chan string , 2 ) // here 2 is capacity of the buffer message <- \"value 1\" message <- \"value 2\" fmt . Println ( <- message ) fmt . Println ( <- message ) https://github.com/toransahu/go-misc/blob/master/goroutines/channels/buffered/buffered_channels.go","title":"Channel Buffering"},{"location":"lang/golang/go/#channel-synchromization","text":"tbd https://gobyexample.com/channel-synchronization","title":"Channel Synchromization"},{"location":"lang/golang/go/#channel-directions","text":"tbd https://gobyexample.com/channel-directions","title":"Channel Directions"},{"location":"lang/golang/go/#select","text":"tbd https://gobyexample.com/select","title":"select"},{"location":"lang/golang/go/#timeouts","text":"tbd https://gobyexample.com/timeouts","title":"Timeouts"},{"location":"lang/golang/go/#non-blocking-channel-operations","text":"tbd https://gobyexample.com/non-blocking-channel-operations","title":"Non-blocking Channel operations"},{"location":"lang/golang/go/#closing-channels","text":"tbd https://gobyexample.com/closing-channels","title":"Closing Channels"},{"location":"lang/golang/go/#range-over-channels","text":"tbd https://gobyexample.com/range-over-channels","title":"range over channels"},{"location":"lang/golang/go/#modules","text":"A module is a collection of related Go packages that are versioned together as a single unit. Ref: https://github.com/golang/go/wiki/Modules#modules https://github.com/golang/go/wiki/Modules","title":"Modules"},{"location":"lang/golang/go/#go-mod","text":"to manage [versioned] dependencies was out with go 1.11 with preliminary/provisionary support & target to finalizing the feature for 1.14 (considering all feedbacks since 1.11-1.13) don't need to live the code in GOPATH creates/uses go.mod file the initial prototype vgo was announced in February 2018 other alternatives were: dep, gom etc. management of interdependencies: vgo's controversial algo uses the oldest common version to support stability this may while discard the acceptance of any security bug fixed in newer version e.g. package A uses B and B uses D's atleast 1.0 version package A also uses C and C uses D's either 1.0 or 1.1 version then, as per vgo vgo versioned go manages all the algorithm of versioning the go projects/packages/modules cmd vgo build is capable of generating go.mod creates/manages versioned cache packages inside GOPATH/src/v there are support for more than one module in repository, but general idea is one As of Go 1.11, the go command enables the use of modules when the current directory or any parent directory has a go.mod, provided the directory is outside GOPATH/src. (Inside GOPATH/src, for compatibility, the go command still runs in the old GOPATH mode, even if a go.mod is found. See the go command documentation for details.) Starting in Go 1.13, module mode will be the default for all development. In addition to go.mod, the go command maintains a file named go.sum containing the expected cryptographic hashes of the content of specific module versions to maintain the intigrity of the go.mod","title":"go mod"},{"location":"lang/golang/go/#semantic-import-versioning-semver","text":"way to handle major dependency changes like: v1 to v2, v3,... API/interface changes how /github.com/mistsys/log (contains all v1.x.x) & /github.com/mistsys/log/v2 (contains all v2.x.x) Ref: https://research.swtch.com/vgo-import","title":"Semantic Import Versioning (SEMVER)"},{"location":"lang/golang/go/#package_1","text":"","title":"Package"},{"location":"lang/golang/go/#main","text":"","title":"main"},{"location":"lang/golang/go/#package-vs-directory","text":"","title":"package Vs directory"},{"location":"lang/golang/go/#built-in-packages","text":"","title":"Built-in Packages"},{"location":"lang/golang/go/#timer-ticker","text":"tbd https://gobyexample.com/timers https://gobyexample.com/tickers continue exploring other packages from here","title":"timer &amp; ticker"},{"location":"lang/golang/go/#import_1","text":"","title":"Import"},{"location":"lang/golang/go/#inbuilt-package","text":"","title":"Inbuilt Package"},{"location":"lang/golang/go/#intra-package","text":"","title":"Intra Package"},{"location":"lang/golang/go/#inter-package","text":"","title":"Inter Package"},{"location":"lang/golang/go/#remote-package","text":"","title":"Remote Package"},{"location":"lang/golang/go/#cyclic","text":"","title":"Cyclic"},{"location":"lang/golang/go/#json","text":"","title":"json"},{"location":"lang/golang/go/#encoding","text":"func Marshal(v interface{}) ([]byte, error) Only data structures that can be represented as valid JSON will be encoded: JSON objects only support strings as keys; to encode a Go map type it must be of the form map[string]T (where T is any Go type supported by the json package). TODO: Channel, complex, and function types cannot be encoded. TODO: Cyclic data structures are not supported; they will cause Marshal to go into an infinite loop. Pointers will be encoded as the values they point to (or 'null' if the pointer is nil) The json package only accesses the exported fields of struct types (those that begin with an uppercase letter). Therefore only the the exported fields of a struct will be present in the JSON output. TODO: what if alias is also provided? we can also provide json:\"alias\" for each field in the struct so that those fields will be encoded as per aliases shortcut to generate those: vim-go: visual select -> <leader> GoAddTags GoLand: // data structure, Message type Message struct { Name string `json:\"name\"` Body string `json:\"body\"` Time int64 `json:\"time\"` } // an instance of Message m := Message { \"Alice\" , \"Hello\" , 1294706395881547000 } // encoding m b , err := json . Marshal ( m ) // If all is well, err will be nil and b will be a []byte containing this JSON data b == [] byte ( `{\"Name\":\"Alice\",\"Body\":\"Hello\",\"Time\":1294706395881547000}` ) https://github.com/toransahu/go-misc/blob/master/json/encoding.go","title":"Encoding"},{"location":"lang/golang/go/#decoding","text":"https://github.com/toransahu/go-misc/blob/master/json/decoding.go","title":"Decoding"},{"location":"lang/golang/go/#generic-json-with-interface","text":"The json package uses map[string]interface{} and []interface{} values to store arbitrary JSON objects and arrays it will happily unmarshal any valid JSON blob into a plain interface{} value default concrete Go types are: bool for JSON booleans float64 for JSON numbers string for JSON strings nil for JSON null","title":"Generic JSON with interface{}"},{"location":"lang/golang/go/#creating-arbitrary-data","text":"i := map [ string ] interface {}{ \"id\" : 1111 , \"name\" : \"Toran\" } fmt . Println ( i ) }","title":"Creating arbitrary data"},{"location":"lang/golang/go/#encoding-arbitrary-data","text":"bytes := json . Marshal ( i )","title":"Encoding arbitrary data"},{"location":"lang/golang/go/#decoding-arbitrary-data","text":"https://github.com/toransahu/go-misc/blob/master/json/json_test.go#L33 var i interface {} json . Unmarshal ( bytes , & i )","title":"Decoding arbitrary data"},{"location":"lang/golang/go/#json-reference-type-pointers-slices-maps","text":"https://blog.golang.org/json-and-go https://github.com/toransahu/go-misc/blob/master/jsons/reference_type.go#L53","title":"Json &amp; Reference Type (pointers, slices, maps)"},{"location":"lang/golang/go/#streaming-encoders-and-decoders","text":"https://blog.golang.org/json-and-go","title":"Streaming Encoders and Decoders"},{"location":"lang/golang/go/#misc","text":"https://vsupalov.com/go-json-omitempty/","title":"Misc"},{"location":"lang/golang/go/#regexp","text":"Ref: https://golang.org/pkg/regexp/ https://github.com/google/re2/wiki/Syntax https://shapeshed.com/golang-regexp/","title":"regexp"},{"location":"lang/golang/go/#errors","text":"https://gobyexample.com/errors","title":"Errors"},{"location":"lang/golang/go/#error-handling","text":"https://blog.golang.org/error-handling-and-go","title":"Error Handling"},{"location":"lang/golang/go/#testing","text":"test module should named as *_test.go under packages FIXME: better to organize test modules in a separate package - similar to Java??","title":"Testing"},{"location":"lang/golang/go/#testcase","text":"","title":"Testcase"},{"location":"lang/golang/go/#benchmarks","text":"","title":"Benchmarks"},{"location":"lang/golang/go/#examples","text":"","title":"Examples"},{"location":"lang/golang/go/#skipping","text":"","title":"Skipping"},{"location":"lang/golang/go/#subtests-and-sub-benchmarks","text":"","title":"Subtests and Sub-benchmarks"},{"location":"lang/golang/go/#main_1","text":"","title":"Main"},{"location":"lang/golang/go/#run_1","text":"a test file ~/go/src/github.com/toransahu/go-misc/json on \ue0a0 master! \u231a 14:18:45 $ go test json_test.go config.go encoding.go ok command-line-arguments 0.003s all test files under a package ~/go/src/github.com/toransahu/go-misc/json on \ue0a0 master! \u231a 14:18:56 $ go test PASS ok github.com/toransahu/go-misc/json 0.002s all test files in all packages tbd specific test function of a test file tbd specific test function/file with pattern/regex tbd","title":"Run"},{"location":"lang/golang/go/#coverage","text":"https://blog.alexellis.io/golang-writing-unit-tests/ src: https://golang.org/pkg/testing/#hdr-Subtests_and_Sub_benchmarks https://stackoverflow.com/questions/16935965/how-to-run-test-cases-in-a-specified-file","title":"Coverage"},{"location":"lang/golang/go/#debug","text":"","title":"Debug"},{"location":"lang/golang/go/#gdb","text":"https://golang.org/doc/gdb","title":"gdb"},{"location":"lang/golang/go/#delve","text":"","title":"Delve"},{"location":"lang/golang/go/#profiling","text":"","title":"Profiling"},{"location":"lang/golang/go/#pprof","text":"https://blog.golang.org/pprof","title":"pprof"},{"location":"lang/golang/go/#cpu-profiling-stack-sampling-vs-instrumentation","text":"","title":"CPU Profiling - stack sampling (vs instrumentation)"},{"location":"lang/golang/go/#heap-profiling-allocation-profiling","text":"","title":"Heap Profiling - allocation profiling"},{"location":"lang/golang/go/#block","text":"","title":"Block"},{"location":"lang/golang/go/#trace","text":"","title":"Trace"},{"location":"lang/golang/go/#deploy","text":"","title":"Deploy"},{"location":"lang/golang/go/#circleci","text":"","title":"CircleCI"},{"location":"lang/golang/go/#run-test","text":"","title":"Run Test"},{"location":"lang/golang/go/#misc_1","text":"","title":"Misc"},{"location":"lang/golang/go/#generate","text":"automatically generate golang code for a particular purpose like print name of memebers in a struct stringr https://blog.golang.org/generate can set header/preprocessor (with commands) in the go file to do the job on each build","title":"generate"},{"location":"lang/golang/go/#advance-testing","text":"","title":"Advance Testing"},{"location":"lang/golang/go/#assert","text":"3rd party packages for assert.* https://github.com/stretchr/testify","title":"assert"},{"location":"lang/golang/go/#extra","text":"https://talks.golang.org/2012/10things.slide#3","title":"Extra"},{"location":"lang/golang/go/#best-practices","text":"","title":"Best Practices"},{"location":"lang/golang/go/#naming-convetions","text":"https://golang.org/doc/effective_go.html#names https://blog.golang.org/package-names","title":"Naming Convetions"},{"location":"lang/golang/go/#code-organization","text":"Package main test https://blog.golang.org/organizing-go-code inside a directory all modules with only single package name can only execute/run main package module hence main package func main should be declared to run the main package module","title":"Code Organization"},{"location":"lang/golang/go/#documentation","text":"to document a type, variable, constant, function, or even a package, write a regular comment directly preceding its declaration, with no intervening blank line a complete sentence begins with the name of the element similar to python 's Docstring & java 's Javadoc but simpler than them src: https://blog.golang.org/godoc-documenting-go-code // Package sort provides primitives for sorting slices and user-defined // collections. package sort ... // Fprint formats using the default formats for its operands and writes to w. // Spaces are added between operands when neither is a string. // It returns the number of bytes written and any write error encountered. func Fprint ( w io . Writer , a ... interface {}) ( n int , err error ) { extra: do something like this to achieve this notable keywords: Deprecated: BUG(<contact person>)","title":"Documentation"},{"location":"lang/golang/go/#godoc","text":"","title":"Godoc"},{"location":"lang/golang/go/#best-practices_1","text":"","title":"Best Practices"},{"location":"lang/golang/go/#concepts","text":"","title":"Concepts"},{"location":"lang/golang/go/#compilation","text":"","title":"Compilation"},{"location":"lang/golang/go/#static-typing","text":"","title":"Static Typing"},{"location":"lang/golang/go/#pointer","text":"","title":"Pointer"},{"location":"lang/golang/go/#garbage-collection","text":"Go language features, goals, and use cases have forced to rethink the entire garbage collection stack and have led to a surprising place Go programs have hundreds of thousands of stacks They are managed by the Go scheduler and are always preempted at GC safepoints The Go scheduler multiplexes Go routines onto OS threads which hopefully run with one OS thread per HW thread We manage the stacks and their size by copying them and updating pointers in the stack. It's a local operation so it scales fairly well. Ref: https://blog.golang.org/ismmkeynote https://www.ardanlabs.com/blog/2018/12/garbage-collection-in-go-part1-semantics.html","title":"Garbage Collection"},{"location":"lang/golang/go/#references","text":"https://golang.org/doc/code.html https://github.com/golang/go/wiki/Learn","title":"References"},{"location":"lang/golang/go/#surprises","text":"https://medium.com/@karel_3d/things-that-surprised-me-in-go-47bccce94558 https://utcc.utoronto.ca/~cks/space/blog/programming/GoInteriorPointerGC https://dave.cheney.net/2017/04/29/there-is-no-pass-by-reference-in-go","title":"Surprises"},{"location":"lang/python/Python-Advanced/","text":"Regular Expressions Basic Patterns use of . use of * use of + use of ? use of \\ use of \\t, \\r, \\n use of \\b (start and end of word anchors) use of \\B use of \\s use of \\d use of \\D use of \\w use of \\W use of [] use of () use of ^ (Start of String Anchors) use of $ $--> (End of String Anchors) use of | use of syntax (? ...) Builtin Functions: re.search re.group re.findall re.sub re.compile extra options to above functions Examples: Multithreading & Multiprocessing GIL - Global Interpreter Lock Some terminologies Concurrency Parallelism process thread Multi-threading Note: Use of thread Facts Multi-processing pipe What is .join()? daemon Files File Handling Using try, except, finally Using with JSON Operations import json flask: jsonify() Shipping Python Solution .pyc .pyo .exe PyInstaller py2exe Python Version Management Setting default Python Version By creating softlink to /usr/bin/python file By aliasing python By setting PATH env variable Anaconda Linux Windows virtualenv pipenv Installation Usage create venv create venv with specific python version install/uninstall dependencies lock dependencies for production install dependencies only for development install dependencies with other options run command within venv remove venv see venv details/path enter venv shell clean venv update venv security check Python Package Distribution (PyPi) Project Structure Pre-requisites Build Test Distribution Final Distribution Rebuild Test (Test) Package (Final) Package Advanced - Run Package in Command Line FAQ Python Linter & PEP-8 Python Templates PyCharm Live & File Templates Vim Template Regular Expressions # Basic Patterns # use of . # - matches any character use of * # - matches 0 or more repetition of a char/set use of + # - matches 1 or more repetition of a char/set use of ? # - matches 0 or 1 repetition of a char/set - also works as a Non-greedy pattern (with repeaters) - means in string '<b>Hello</b>' pattern r'<.*>' will match the whole string instead of '<b>' - but if pattern is used as r'<.*?>' then will match '<b>' only - AKA pcre (Perl Compatible Regular Expression) use of \\ # - sign of speciality - used before any special chars, to match that char use of \\t , \\r , \\n # - \\t matches a tab - \\r matches a carriage return (line break) in Mac, \\n\\r in Windows - \\n matches a line break ( carriage return) in Linux & Windows - note: On \"old\" printers, \\r sent the print head back to the start of the line, and \\n advanced the paper by one line. Both were therefore necessary to start printing on the next line. use of \\b (start and end of word anchors) # - matches the boundary between word and non-word chars - matches the position called word boundaries - match has zero length - usually before (including start of the line) and after a word -e.g. <here>apple<here> use of \\B # - opposite of \\b - matches every position where \\b does not use of \\s # use of \\d # use of \\D # use of \\w # use of \\W # use of [] # - dash - inside [] - dot . inside [] use of () # use of ^ (Start of String Anchors) # - with square bracket (set of chars) use of $ (End of String Anchors) # use of | # use of syntax ( ? ... ) # - Lookarounds - +ve Lookahead - -ve Lookahead - +ve Lookbehind - -ve Lookbehind - Non-Capturing Group Builtin Functions: # re.search # re.group # re.findall # - with files - with groups re.sub # re.compile # extra options to above functions # Examples: # Repetitions Leftmost and largest Square Brackets (Set of chars) Email example Group Extraction Greedy vs Non-Greedy Substitution import re str = \"This#is#$ % a &%name%$ #\" r = re . sub ( r '(?<=[\\w])([\\W]+)(?=[\\w])' , ' ' , str ) print ( r ) r = re . sub ( r '(?<=[A-Za-z0-9])([^A-Za-z0-9]+)(?=[A-Za-z0-9])' , ' ' , str ) print ( r ) r = re . sub ( r 'q(?=u)' , ' ' , 'quit' ) print ( r ) remove white spaces from starting of the line but line break regex = r '^[^\\S\\n]+' #or if regex supports PCRE regex = r '^[\\h]+' Credits: https://www.rexegg.com/regex-disambiguation.html#lookarounds www.regular-expressions.info Multithreading & Multiprocessing # GIL - Global Interpreter Lock # Is a mutex (mutual exclusion attribute) in python protects python objects from multiple threads i.e. prevents multiple threads to execute python (byte)codes at once inorder to protect access to python objects i.e. provides lock to protect shared mutable state The lock is necessary because CPython's Interpreter or memory management is not thread safe for example, when two threads simultaneously increment the reference count of the same object, the reference count could end up being incremented only once instead of twice. hence, GIL is here to make python thread-safe, wherever needed GIL is controversial because due to it python's multithreading lack few features like python's multithreaded codes cannot utilize multiprocessor system the longer operations like I/O, image processing happens outside the GIL it is only bottleneck for codes which enter GIL for longer time GIL can causes scheduling IO-bound threads ahead of a CPU-bound threads inshort, GIL is only bad for multi-core CPU - bound thread operations each forked process have separate GIL Jython, IronPython does not have GIL writing a C extension needs GIL in Cython the GIL exists, but can be released temporarily using a \"with\" statement - read more extra: https://stackoverflow.com/questions/1294382/what-is-a-global-interpreter-lock-gil Note : cython & CPython are different Some terminologies # Concurrency # When two or more task can start, run & complete in overlapping time periods. It doesn't necessarily mean they'll ever be running at the same instant. e.g. Multi-tasking on a single core Parallelism # When two are more tasks are executed simultaneously. process # is an instance of a program running in a computer can contain one or more threads has its independent memory space are spawned by creating a Process() object and then calling its start() method thread # is a sequence of instructions within a process as a light-weight process all threads shares the same memory space of the process Multi-threading # can be implemented to speedup the program using module : threading thread-based parallelism concurrency CPython implementation uses a python construct GIL (global interpreter lock). GIL makes sure that at a time only single thread can execute. a thread acquires GIL --> executes just for a while --> passes GIL to next thread happens very quickly that human cannot detect, and creates illusion of multiple thread running simultaneously. in reality all threads works turn by turn into the same core of CPU parallel CPU computation not possible due to GIL but parallel IO operations are possible (it releases GIL on IO) GIL passing is an overhead here. Note: # can turn off GIL - dirty practice this will result in messed memory management need to be very careful while writting semaphores & mutex properly Use of thread # in GUI apps to keep UI threads responsive IO tasks (network IO or filesystem IO) Facts # using multiple-threads for CPU bound tasks will result in worse performance than a single thread Multi-processing # used to speedup CPU bound tasks using module: multiprocessing process-based parallelism module results in full CPU utilization Inter-process communication can be achieved using queues and pipes * pipe # is a duplex(two way) communication channel from multiprocessing import Process def f ( name ): print ( 'hello' , name ) if __name__ == '__main__' : p = Process ( target = f , args = ( 'bob' ,)) p . start () p . join () Out: hello bob from multiprocessing import Process import os def info ( title ): print ( title ) print ( 'module name:' , __name__ ) print ( 'parent process:' , os . getppid ()) print ( 'process id:' , os . getpid ()) def f ( name ): info ( 'function f' ) print ( 'hello' , name ) if __name__ == '__main__' : info ( 'main line' ) p = Process ( target = f , args = ( 'bob' ,)) p . start () p . join () Out: main line module name: __main__ parent process: 65 process id: 66 function f module name: __main__ parent process: 66 process id: 80 hello bob What is .join()? # The join() method, when used with threading or multiprocessing, is not related to str.join() it's not actually concatenating anything together It just means \"wait for this [thread/process] to complete\" The name join is used because the multiprocessing module's API is meant to look as similar to the threading module's API The reason why is called join is that is joining the processes into a single one. Note: * By default, when the main process is ready to exit, it will implicitly call join() on all running multiprocessing Process instances * This isn't as clearly stated in the multiprocessing docs as it should be, but it is mentioned in the Programming Guidelines section. * non-daemonic processes will be automatically be joined. * can override this behavior by setting the daemon flag on the Process to True prior to starting the process: from multiprocessing import Process import os def say_hello (): print ( \"Hello\" ) p = Process ( target = say_hello ) p . daemon = True p . start () # Both parent and child will exit here, since the main process has completed. # the child process will be terminated as soon as the main process completes: Out: Hello daemon # In Linux: A daemon is a long-running background process that answers requests for services. There are also some other processes like orphan & zombie The process has daemon flag a Boolean value This must be set before start() is called The initial value is inherited from the creating process When a process exits, it attempts to terminate all of its daemonic child processes Files # File Handling # How Using try , except , finally Using with (pythonic way) Why to manage resources effeciently file descriptors (fd) are limited at OS level, so we can save fd by closing after use Using try , except , finally # the step finally is important here for us to use finally we need to write whole try , except , finally block in each languages finally is important because we need f.close() here to close the file descriptor with 100% guarantee file descriptors (fd) are limited at OS level, so we can save fd by closing after use code: try : f = open ( 'csv.txt' , 'r' , encoding = 'utf-8' ) f . write ( 'abc' ) except : pass finally : f . close () Using with # Read here code: with open ( 'csv.txt' , 'r' , encoding = 'utf-8' ) as f : f . readline () JSON Operations # import json # flask: jsonify() # Shipping Python Solution # never ship .py files find /path/to/your/files -type f -name \"*.py\" -delete can ship .pyc or .pyo files .pyc # compiled size(.py) < size(.pyc) .pyo # compiled + optimized removed doc strings does not contain \"set the current line to ...\" bytecode instructions for faster performance renaming .pyo to .pyc works fine find \"ETHEREAL_DIR\"/Ray/src/ -type f -name \"*.pyo\" -exec bash -c 'mv $0 ${0/.pyo/.pyc}' {} \\; size(.pyo) < size(.pyc) python -O -m compileall /path/to/your/files Note - After this, you may get some import issues .exe # Source http://docs.python-guide.org/en/latest/shipping/freezing/ https://pyinstaller.readthedocs.io/en/v3.3.1/ Note: Freezing Python code on Linux into a Windows executable was only once supported in PyInstaller and later dropped All solutions need MS Visual C++ dll to be installed on target machine, except py2app. Only Pyinstaller makes self-executable exe that bundles the dll when passing --onefile to Configure.py. PyInstaller # Uses the OS support to load the dynamic libraries, thus ensures full compatibility available for windows, linux, macOS etc. pyinstaller -i <icon.ico> --windowed --onefile <python_file.py> py2exe # Python Version Management # Setting default Python Version # By creating softlink to /usr/bin/python file # not recommanded will affect other applications using another version of python can be done like: ln -l /usr/bin/python /usr/bin/python3.6 ln -l /usr/bin/python /home/toran/anaconda/bin/python3.6 By aliasing python # not recommanded will conflict when python will encounter in other commands like which python python manage.py runserver can be done like: alias python = ' /home/toran/anaconda/bin/python3.6 ` By setting PATH env variable # recommanded with anaconda works on particular shell only for persistency; include the command in .bashrc or .zshrc file can be done like: export PATH = \"/home/toran/anaconda3/bin:<dollar>PATH\" Anaconda # install it from official site you can also choose miniconda over regular anaconda can be used in production env/ deployments etc. Linux # set anaconda python as default export PATH = \"/home/toran/anaconda3/bin:<dollar>PATH\" Windows # set anaconda python as default C: \\P rogramData \\M iniconda3 \\S cripts \\a ctivate #if using git bash . /c/ProgramData/Miniconda3/Scripts/activate virtualenv # pipenv # officially recommended dependency management system automagically installs dependencies in venv keep record in Pipfile packages section dev-packages section keeps record of dependencies with specific version in Pipfile.lock file if requirements.txt already exists, installs dep from there installs & uninstalls deps Installation # pip install pipenv Usage # create venv # pipenv install create venv with specific python version # pipenv --two install pipenv --three install will initialize the venv with that python version install/uninstall dependencies # pipenv install nose2 pipenv uninstall nose2 lock dependencies for production # pipenv lock - will keep record of all the deps in Pipfile.lock file with their specific versions install dependencies only for development # pipenv install --dev nose2 will keep this record in [dev-packages] section and will do not install it by default to install dev packages; need to do: pipenv install --dev install dependencies with other options # --dev : Install both develop and default packages from Pipfile.lock. --system : Use the system pip command rather than the one from your virtualenv. --ignore-pipfile : Ignore the Pipfile and install from the Pipfile.lock. --skip-lock : Ignore the Pipfile.lock and install from the Pipfile. In addition, do not write out a Pipfile.lock reflecting changes to the Pipfile. run command within venv # pipenv run which python remove venv # pipenv --rm see venv details/path # pipenv --venv enter venv shell # pipenv shell clean venv # uninstall all the packages not recorded in Pipfile pipenv clean update venv # locks & then update all the packages pipenv update security check # checks for compliance with PEP 508 Dependency specification for Python Software Packages as well as package safety pipenv check Python Package Distribution (PyPi) # Project Structure # /example_pkg /pkg1 __init__.py /pkg2 /pkg2_1 setup.py LICENSE README.md where - __init__.py should contain a variable name='example_pkg' - setup.py should look like this gist - where classifiers can be like this or gist - README.md should be present, which will define the long_description about the package - LICENSE should be accurate with the list - packages - if want to includes all the packages/subpackages - use defaultone packages=setuptools.find_packages(), - else define manually like - packages=['pkg1', 'pkg2', 'pkg2.pkg2_1'] Note: After installing the package, you able to import packages with names listed in packages var. Pre-requisites # #setuptools & wheel - to create build in .whl as well as .tar.gz. format python3 -m pip install --user --upgrade setuptools wheel #twine - to upload build in pypi server python3 -m pip install --user --upgrade twine Build # change directory where setup.py is & run python3 setup.py sdist bdist_wheel output will be like dist/ example_pkg-0.0.1-py3-none-any.whl example_pkg-0.0.1.tar.gz Test Distribution # twine upload --repository-url https://test.pypi.org/legacy/ dist/* Final Distribution # twine upload --repository-url https://upload.test.pypi.org/legacy/ dist/* #OR twine upload dist/* Rebuild # delete build , dist , & *.egg-info files then build again Test # (Test) Package # python3 -m pip install --index-url https://test.pypi.org/simple/ example_pkg (Final) Package # python3 -m pip install example_pkg Advanced - Run Package in Command Line # Source: http://python-packaging.readthedocs.io/en/latest/command-line-scripts.html FAQ # You're not allowed File already exists File already exists, change version particular line is not know/right Python Linter & PEP-8 # I found flake8, autopep8 & yapf similar but I found black best among them quotes: double no extra line change only draw back is bad list slice formating create issue: https://github.com/python/black/issues Python Templates # PyCharm Live & File Templates # https://gist.github.com/toransahu/6080cbf2cc1a8808f19bd0eccafc5ef0 Vim Template # https://github.com/toransahu/vim-template/blob/master/templates/%3Dtemplate%3D.py","title":"Python Advanced"},{"location":"lang/python/Python-Advanced/#regular-expressions","text":"","title":"Regular Expressions"},{"location":"lang/python/Python-Advanced/#basic-patterns","text":"","title":"Basic Patterns"},{"location":"lang/python/Python-Advanced/#use-of","text":"- matches any character","title":"use of ."},{"location":"lang/python/Python-Advanced/#use-of_1","text":"- matches 0 or more repetition of a char/set","title":"use of *"},{"location":"lang/python/Python-Advanced/#use-of_2","text":"- matches 1 or more repetition of a char/set","title":"use of +"},{"location":"lang/python/Python-Advanced/#use-of_3","text":"- matches 0 or 1 repetition of a char/set - also works as a Non-greedy pattern (with repeaters) - means in string '<b>Hello</b>' pattern r'<.*>' will match the whole string instead of '<b>' - but if pattern is used as r'<.*?>' then will match '<b>' only - AKA pcre (Perl Compatible Regular Expression)","title":"use of ?"},{"location":"lang/python/Python-Advanced/#use-of_4","text":"- sign of speciality - used before any special chars, to match that char","title":"use of \\"},{"location":"lang/python/Python-Advanced/#use-of-t-r-n","text":"- \\t matches a tab - \\r matches a carriage return (line break) in Mac, \\n\\r in Windows - \\n matches a line break ( carriage return) in Linux & Windows - note: On \"old\" printers, \\r sent the print head back to the start of the line, and \\n advanced the paper by one line. Both were therefore necessary to start printing on the next line.","title":"use of \\t, \\r, \\n"},{"location":"lang/python/Python-Advanced/#use-of-b-start-and-end-of-word-anchors","text":"- matches the boundary between word and non-word chars - matches the position called word boundaries - match has zero length - usually before (including start of the line) and after a word -e.g. <here>apple<here>","title":"use of \\b (start and end of word anchors)"},{"location":"lang/python/Python-Advanced/#use-of-b","text":"- opposite of \\b - matches every position where \\b does not","title":"use of \\B"},{"location":"lang/python/Python-Advanced/#use-of-s","text":"","title":"use of \\s"},{"location":"lang/python/Python-Advanced/#use-of-d","text":"","title":"use of \\d"},{"location":"lang/python/Python-Advanced/#use-of-d_1","text":"","title":"use of \\D"},{"location":"lang/python/Python-Advanced/#use-of-w","text":"","title":"use of \\w"},{"location":"lang/python/Python-Advanced/#use-of-w_1","text":"","title":"use of \\W"},{"location":"lang/python/Python-Advanced/#use-of_5","text":"- dash - inside [] - dot . inside []","title":"use of []"},{"location":"lang/python/Python-Advanced/#use-of_6","text":"","title":"use of ()"},{"location":"lang/python/Python-Advanced/#use-of-start-of-string-anchors","text":"- with square bracket (set of chars)","title":"use of ^ (Start of String Anchors)"},{"location":"lang/python/Python-Advanced/#use-of-end-of-string-anchors","text":"","title":"use of $ $-->  (End of String Anchors)"},{"location":"lang/python/Python-Advanced/#use-of_7","text":"","title":"use of |"},{"location":"lang/python/Python-Advanced/#use-of-syntax","text":"- Lookarounds - +ve Lookahead - -ve Lookahead - +ve Lookbehind - -ve Lookbehind - Non-Capturing Group","title":"use of syntax (? ...)"},{"location":"lang/python/Python-Advanced/#builtin-functions","text":"","title":"Builtin Functions:"},{"location":"lang/python/Python-Advanced/#research","text":"","title":"re.search"},{"location":"lang/python/Python-Advanced/#regroup","text":"","title":"re.group"},{"location":"lang/python/Python-Advanced/#refindall","text":"- with files - with groups","title":"re.findall"},{"location":"lang/python/Python-Advanced/#resub","text":"","title":"re.sub"},{"location":"lang/python/Python-Advanced/#recompile","text":"","title":"re.compile"},{"location":"lang/python/Python-Advanced/#extra-options-to-above-functions","text":"","title":"extra options to above functions"},{"location":"lang/python/Python-Advanced/#examples","text":"Repetitions Leftmost and largest Square Brackets (Set of chars) Email example Group Extraction Greedy vs Non-Greedy Substitution import re str = \"This#is#$ % a &%name%$ #\" r = re . sub ( r '(?<=[\\w])([\\W]+)(?=[\\w])' , ' ' , str ) print ( r ) r = re . sub ( r '(?<=[A-Za-z0-9])([^A-Za-z0-9]+)(?=[A-Za-z0-9])' , ' ' , str ) print ( r ) r = re . sub ( r 'q(?=u)' , ' ' , 'quit' ) print ( r ) remove white spaces from starting of the line but line break regex = r '^[^\\S\\n]+' #or if regex supports PCRE regex = r '^[\\h]+' Credits: https://www.rexegg.com/regex-disambiguation.html#lookarounds www.regular-expressions.info","title":"Examples:"},{"location":"lang/python/Python-Advanced/#multithreading-multiprocessing","text":"","title":"Multithreading &amp; Multiprocessing"},{"location":"lang/python/Python-Advanced/#gil-global-interpreter-lock","text":"Is a mutex (mutual exclusion attribute) in python protects python objects from multiple threads i.e. prevents multiple threads to execute python (byte)codes at once inorder to protect access to python objects i.e. provides lock to protect shared mutable state The lock is necessary because CPython's Interpreter or memory management is not thread safe for example, when two threads simultaneously increment the reference count of the same object, the reference count could end up being incremented only once instead of twice. hence, GIL is here to make python thread-safe, wherever needed GIL is controversial because due to it python's multithreading lack few features like python's multithreaded codes cannot utilize multiprocessor system the longer operations like I/O, image processing happens outside the GIL it is only bottleneck for codes which enter GIL for longer time GIL can causes scheduling IO-bound threads ahead of a CPU-bound threads inshort, GIL is only bad for multi-core CPU - bound thread operations each forked process have separate GIL Jython, IronPython does not have GIL writing a C extension needs GIL in Cython the GIL exists, but can be released temporarily using a \"with\" statement - read more extra: https://stackoverflow.com/questions/1294382/what-is-a-global-interpreter-lock-gil Note : cython & CPython are different","title":"GIL - Global Interpreter Lock"},{"location":"lang/python/Python-Advanced/#some-terminologies","text":"","title":"Some terminologies"},{"location":"lang/python/Python-Advanced/#concurrency","text":"When two or more task can start, run & complete in overlapping time periods. It doesn't necessarily mean they'll ever be running at the same instant. e.g. Multi-tasking on a single core","title":"Concurrency"},{"location":"lang/python/Python-Advanced/#parallelism","text":"When two are more tasks are executed simultaneously.","title":"Parallelism"},{"location":"lang/python/Python-Advanced/#process","text":"is an instance of a program running in a computer can contain one or more threads has its independent memory space are spawned by creating a Process() object and then calling its start() method","title":"process"},{"location":"lang/python/Python-Advanced/#thread","text":"is a sequence of instructions within a process as a light-weight process all threads shares the same memory space of the process","title":"thread"},{"location":"lang/python/Python-Advanced/#multi-threading","text":"can be implemented to speedup the program using module : threading thread-based parallelism concurrency CPython implementation uses a python construct GIL (global interpreter lock). GIL makes sure that at a time only single thread can execute. a thread acquires GIL --> executes just for a while --> passes GIL to next thread happens very quickly that human cannot detect, and creates illusion of multiple thread running simultaneously. in reality all threads works turn by turn into the same core of CPU parallel CPU computation not possible due to GIL but parallel IO operations are possible (it releases GIL on IO) GIL passing is an overhead here.","title":"Multi-threading"},{"location":"lang/python/Python-Advanced/#note","text":"can turn off GIL - dirty practice this will result in messed memory management need to be very careful while writting semaphores & mutex properly","title":"Note:"},{"location":"lang/python/Python-Advanced/#use-of-thread","text":"in GUI apps to keep UI threads responsive IO tasks (network IO or filesystem IO)","title":"Use of thread"},{"location":"lang/python/Python-Advanced/#facts","text":"using multiple-threads for CPU bound tasks will result in worse performance than a single thread","title":"Facts"},{"location":"lang/python/Python-Advanced/#multi-processing","text":"used to speedup CPU bound tasks using module: multiprocessing process-based parallelism module results in full CPU utilization Inter-process communication can be achieved using queues and pipes *","title":"Multi-processing"},{"location":"lang/python/Python-Advanced/#pipe","text":"is a duplex(two way) communication channel from multiprocessing import Process def f ( name ): print ( 'hello' , name ) if __name__ == '__main__' : p = Process ( target = f , args = ( 'bob' ,)) p . start () p . join () Out: hello bob from multiprocessing import Process import os def info ( title ): print ( title ) print ( 'module name:' , __name__ ) print ( 'parent process:' , os . getppid ()) print ( 'process id:' , os . getpid ()) def f ( name ): info ( 'function f' ) print ( 'hello' , name ) if __name__ == '__main__' : info ( 'main line' ) p = Process ( target = f , args = ( 'bob' ,)) p . start () p . join () Out: main line module name: __main__ parent process: 65 process id: 66 function f module name: __main__ parent process: 66 process id: 80 hello bob","title":"pipe"},{"location":"lang/python/Python-Advanced/#what-is-join","text":"The join() method, when used with threading or multiprocessing, is not related to str.join() it's not actually concatenating anything together It just means \"wait for this [thread/process] to complete\" The name join is used because the multiprocessing module's API is meant to look as similar to the threading module's API The reason why is called join is that is joining the processes into a single one. Note: * By default, when the main process is ready to exit, it will implicitly call join() on all running multiprocessing Process instances * This isn't as clearly stated in the multiprocessing docs as it should be, but it is mentioned in the Programming Guidelines section. * non-daemonic processes will be automatically be joined. * can override this behavior by setting the daemon flag on the Process to True prior to starting the process: from multiprocessing import Process import os def say_hello (): print ( \"Hello\" ) p = Process ( target = say_hello ) p . daemon = True p . start () # Both parent and child will exit here, since the main process has completed. # the child process will be terminated as soon as the main process completes: Out: Hello","title":"What is .join()?"},{"location":"lang/python/Python-Advanced/#daemon","text":"In Linux: A daemon is a long-running background process that answers requests for services. There are also some other processes like orphan & zombie The process has daemon flag a Boolean value This must be set before start() is called The initial value is inherited from the creating process When a process exits, it attempts to terminate all of its daemonic child processes","title":"daemon"},{"location":"lang/python/Python-Advanced/#files","text":"","title":"Files"},{"location":"lang/python/Python-Advanced/#file-handling","text":"How Using try , except , finally Using with (pythonic way) Why to manage resources effeciently file descriptors (fd) are limited at OS level, so we can save fd by closing after use","title":"File Handling"},{"location":"lang/python/Python-Advanced/#using-try-except-finally","text":"the step finally is important here for us to use finally we need to write whole try , except , finally block in each languages finally is important because we need f.close() here to close the file descriptor with 100% guarantee file descriptors (fd) are limited at OS level, so we can save fd by closing after use code: try : f = open ( 'csv.txt' , 'r' , encoding = 'utf-8' ) f . write ( 'abc' ) except : pass finally : f . close ()","title":"Using try, except, finally"},{"location":"lang/python/Python-Advanced/#using-with","text":"Read here code: with open ( 'csv.txt' , 'r' , encoding = 'utf-8' ) as f : f . readline ()","title":"Using with"},{"location":"lang/python/Python-Advanced/#json-operations","text":"","title":"JSON Operations"},{"location":"lang/python/Python-Advanced/#import-json","text":"","title":"import json"},{"location":"lang/python/Python-Advanced/#flask-jsonify","text":"","title":"flask: jsonify()"},{"location":"lang/python/Python-Advanced/#shipping-python-solution","text":"never ship .py files find /path/to/your/files -type f -name \"*.py\" -delete can ship .pyc or .pyo files","title":"Shipping Python Solution"},{"location":"lang/python/Python-Advanced/#pyc","text":"compiled size(.py) < size(.pyc)","title":".pyc"},{"location":"lang/python/Python-Advanced/#pyo","text":"compiled + optimized removed doc strings does not contain \"set the current line to ...\" bytecode instructions for faster performance renaming .pyo to .pyc works fine find \"ETHEREAL_DIR\"/Ray/src/ -type f -name \"*.pyo\" -exec bash -c 'mv $0 ${0/.pyo/.pyc}' {} \\; size(.pyo) < size(.pyc) python -O -m compileall /path/to/your/files Note - After this, you may get some import issues","title":".pyo"},{"location":"lang/python/Python-Advanced/#exe","text":"Source http://docs.python-guide.org/en/latest/shipping/freezing/ https://pyinstaller.readthedocs.io/en/v3.3.1/ Note: Freezing Python code on Linux into a Windows executable was only once supported in PyInstaller and later dropped All solutions need MS Visual C++ dll to be installed on target machine, except py2app. Only Pyinstaller makes self-executable exe that bundles the dll when passing --onefile to Configure.py.","title":".exe"},{"location":"lang/python/Python-Advanced/#pyinstaller","text":"Uses the OS support to load the dynamic libraries, thus ensures full compatibility available for windows, linux, macOS etc. pyinstaller -i <icon.ico> --windowed --onefile <python_file.py>","title":"PyInstaller"},{"location":"lang/python/Python-Advanced/#py2exe","text":"","title":"py2exe"},{"location":"lang/python/Python-Advanced/#python-version-management","text":"","title":"Python Version Management"},{"location":"lang/python/Python-Advanced/#setting-default-python-version","text":"","title":"Setting default Python Version"},{"location":"lang/python/Python-Advanced/#by-creating-softlink-to-usrbinpython-file","text":"not recommanded will affect other applications using another version of python can be done like: ln -l /usr/bin/python /usr/bin/python3.6 ln -l /usr/bin/python /home/toran/anaconda/bin/python3.6","title":"By creating softlink to /usr/bin/python file"},{"location":"lang/python/Python-Advanced/#by-aliasing-python","text":"not recommanded will conflict when python will encounter in other commands like which python python manage.py runserver can be done like: alias python = ' /home/toran/anaconda/bin/python3.6 `","title":"By aliasing python"},{"location":"lang/python/Python-Advanced/#by-setting-path-env-variable","text":"recommanded with anaconda works on particular shell only for persistency; include the command in .bashrc or .zshrc file can be done like: export PATH = \"/home/toran/anaconda3/bin:<dollar>PATH\"","title":"By setting PATH env variable"},{"location":"lang/python/Python-Advanced/#anaconda","text":"install it from official site you can also choose miniconda over regular anaconda can be used in production env/ deployments etc.","title":"Anaconda"},{"location":"lang/python/Python-Advanced/#linux","text":"set anaconda python as default export PATH = \"/home/toran/anaconda3/bin:<dollar>PATH\"","title":"Linux"},{"location":"lang/python/Python-Advanced/#windows","text":"set anaconda python as default C: \\P rogramData \\M iniconda3 \\S cripts \\a ctivate #if using git bash . /c/ProgramData/Miniconda3/Scripts/activate","title":"Windows"},{"location":"lang/python/Python-Advanced/#virtualenv","text":"","title":"virtualenv"},{"location":"lang/python/Python-Advanced/#pipenv","text":"officially recommended dependency management system automagically installs dependencies in venv keep record in Pipfile packages section dev-packages section keeps record of dependencies with specific version in Pipfile.lock file if requirements.txt already exists, installs dep from there installs & uninstalls deps","title":"pipenv"},{"location":"lang/python/Python-Advanced/#installation","text":"pip install pipenv","title":"Installation"},{"location":"lang/python/Python-Advanced/#usage","text":"","title":"Usage"},{"location":"lang/python/Python-Advanced/#create-venv","text":"pipenv install","title":"create venv"},{"location":"lang/python/Python-Advanced/#create-venv-with-specific-python-version","text":"pipenv --two install pipenv --three install will initialize the venv with that python version","title":"create venv with specific python version"},{"location":"lang/python/Python-Advanced/#installuninstall-dependencies","text":"pipenv install nose2 pipenv uninstall nose2","title":"install/uninstall dependencies"},{"location":"lang/python/Python-Advanced/#lock-dependencies-for-production","text":"pipenv lock - will keep record of all the deps in Pipfile.lock file with their specific versions","title":"lock dependencies for production"},{"location":"lang/python/Python-Advanced/#install-dependencies-only-for-development","text":"pipenv install --dev nose2 will keep this record in [dev-packages] section and will do not install it by default to install dev packages; need to do: pipenv install --dev","title":"install dependencies only for development"},{"location":"lang/python/Python-Advanced/#install-dependencies-with-other-options","text":"--dev : Install both develop and default packages from Pipfile.lock. --system : Use the system pip command rather than the one from your virtualenv. --ignore-pipfile : Ignore the Pipfile and install from the Pipfile.lock. --skip-lock : Ignore the Pipfile.lock and install from the Pipfile. In addition, do not write out a Pipfile.lock reflecting changes to the Pipfile.","title":"install dependencies with other options"},{"location":"lang/python/Python-Advanced/#run-command-within-venv","text":"pipenv run which python","title":"run command within venv"},{"location":"lang/python/Python-Advanced/#remove-venv","text":"pipenv --rm","title":"remove venv"},{"location":"lang/python/Python-Advanced/#see-venv-detailspath","text":"pipenv --venv","title":"see venv details/path"},{"location":"lang/python/Python-Advanced/#enter-venv-shell","text":"pipenv shell","title":"enter venv shell"},{"location":"lang/python/Python-Advanced/#clean-venv","text":"uninstall all the packages not recorded in Pipfile pipenv clean","title":"clean venv"},{"location":"lang/python/Python-Advanced/#update-venv","text":"locks & then update all the packages pipenv update","title":"update venv"},{"location":"lang/python/Python-Advanced/#security-check","text":"checks for compliance with PEP 508 Dependency specification for Python Software Packages as well as package safety pipenv check","title":"security check"},{"location":"lang/python/Python-Advanced/#python-package-distribution-pypi","text":"","title":"Python Package Distribution (PyPi)"},{"location":"lang/python/Python-Advanced/#project-structure","text":"/example_pkg /pkg1 __init__.py /pkg2 /pkg2_1 setup.py LICENSE README.md where - __init__.py should contain a variable name='example_pkg' - setup.py should look like this gist - where classifiers can be like this or gist - README.md should be present, which will define the long_description about the package - LICENSE should be accurate with the list - packages - if want to includes all the packages/subpackages - use defaultone packages=setuptools.find_packages(), - else define manually like - packages=['pkg1', 'pkg2', 'pkg2.pkg2_1'] Note: After installing the package, you able to import packages with names listed in packages var.","title":"Project Structure"},{"location":"lang/python/Python-Advanced/#pre-requisites","text":"#setuptools & wheel - to create build in .whl as well as .tar.gz. format python3 -m pip install --user --upgrade setuptools wheel #twine - to upload build in pypi server python3 -m pip install --user --upgrade twine","title":"Pre-requisites"},{"location":"lang/python/Python-Advanced/#build","text":"change directory where setup.py is & run python3 setup.py sdist bdist_wheel output will be like dist/ example_pkg-0.0.1-py3-none-any.whl example_pkg-0.0.1.tar.gz","title":"Build"},{"location":"lang/python/Python-Advanced/#test-distribution","text":"twine upload --repository-url https://test.pypi.org/legacy/ dist/*","title":"Test Distribution"},{"location":"lang/python/Python-Advanced/#final-distribution","text":"twine upload --repository-url https://upload.test.pypi.org/legacy/ dist/* #OR twine upload dist/*","title":"Final Distribution"},{"location":"lang/python/Python-Advanced/#rebuild","text":"delete build , dist , & *.egg-info files then build again","title":"Rebuild"},{"location":"lang/python/Python-Advanced/#test","text":"","title":"Test"},{"location":"lang/python/Python-Advanced/#test-package","text":"python3 -m pip install --index-url https://test.pypi.org/simple/ example_pkg","title":"(Test) Package"},{"location":"lang/python/Python-Advanced/#final-package","text":"python3 -m pip install example_pkg","title":"(Final)  Package"},{"location":"lang/python/Python-Advanced/#advanced-run-package-in-command-line","text":"Source: http://python-packaging.readthedocs.io/en/latest/command-line-scripts.html","title":"Advanced - Run Package in Command Line"},{"location":"lang/python/Python-Advanced/#faq","text":"You're not allowed File already exists File already exists, change version particular line is not know/right","title":"FAQ"},{"location":"lang/python/Python-Advanced/#python-linter-pep-8","text":"I found flake8, autopep8 & yapf similar but I found black best among them quotes: double no extra line change only draw back is bad list slice formating create issue: https://github.com/python/black/issues","title":"Python Linter &amp; PEP-8"},{"location":"lang/python/Python-Advanced/#python-templates","text":"","title":"Python Templates"},{"location":"lang/python/Python-Advanced/#pycharm-live-file-templates","text":"https://gist.github.com/toransahu/6080cbf2cc1a8808f19bd0eccafc5ef0","title":"PyCharm Live &amp; File Templates"},{"location":"lang/python/Python-Advanced/#vim-template","text":"https://github.com/toransahu/vim-template/blob/master/templates/%3Dtemplate%3D.py","title":"Vim Template"},{"location":"lang/python/Python-Basics/","text":"Introduction The Zen of Python (PEP 20) Easter Egg Implementations Internal PEP 8 - Style Guide for Python Code Features of Python are: Compilers Interpreters Compiler characteristics: Interpreter characteristics: Python interpreted/compiled? Compiled Language Interpreted Language How python works? Note What is .pyc file? What is .pyo file? Memory Management Data types in python? Data structure in python? 4 Built in Collection & heapq modules Abstract data type we can create are Data Types Strings String formatting What is doc string? byte string vs unicode string Intro 3 things unicode List Intro Why? When? Features List Generator List comprehension List Flattening Randomize items of list in place How to insert an element in between a list? Diif between append and extend method in list? enumerate() Tuple Why? When? Properties Expanding Tuple Dictionary When to use dict & set? dict vs list lookup performance? dict comprehension dict with order Variables Global vs Local vs Non-Local Variable Global Variable Global Variables in Nested Functions Local Variable Non-Local Variable Operators in and or xor is not Generators xrange vs range? Statements assert yield return Compound Statements with Example #1 : file handling Example #2: Expressions lambda Operators Ternary Operator [Operator Overloading Using Magic Methods] Functions eval() partial() lambda map() filter() reduce() zip() Inverse a Matrix (list/tuple) Decorators Nested function Closures As per JavaScript Function Factory Parameter passing in python Passed As Default Parameters Variable Number of Parameters Exception Handling Inbuilt Exceptions AssertionError AttributeError EOFError ImportError IndentationError IndexError KeyError NameError NotImplementedError OSError RecursionError SyntaxError TypeError UnicodeError ValueError ZeroDivisionError User-defined Exception Performance Misc is vs == operator Pickling Unpickling Pickling Unpickling Comparision with JSON Monkey Patching Uses Duck Typing Copy Regular Reference (Hard Copy) Shallow copy Deep copy Introduction # The Zen of Python (PEP 20) # Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than right now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those! Easter Egg # In computer software and media, an Easter egg is an intentional inside joke, hidden message or image, or secret feature of a work The Zen of python can be listed by importing this >>> import this Implementations # CPython (Default) Jython IronPython RPython (PyPy) Internal # Runs on a single process by forking Each process have seperate GIL Python can run only one thread at once Context Manager PEP 8 - Style Guide for Python Code # Package: lowercase, '_' is discouraged, use hyphen '-' instead Module: lowercase + '_' Class: Initial Capital, Camal Case Function: lowercase, Valid word, '_' Method: self, lowercase, Valid word, '_' Variable: Same as functions Local: Global: Static: Constant: Generally Module Level, All CAPS + '_' Private Attribute: To avoid name clashes with subclasses, Leading dunder Protected Attribute: For non-public methods and instance variables, Leading underscore '_' Exception Name: Same as class NOTE: Never use the characters 'l' (lowercase letter el), 'O' (uppercase letter oh), or 'I' (uppercase letter eye) as single character variable names. Features of Python are: # Unique Interpreted Language Dynamic type system but strongly typed (changing data type need explicit conversion) emphasizes on code readability - lesser line of code/syntax Supports multiple programming paradigms, including object-oriented, imperative, functional and procedural Has community based developement model Dynamic name resolution/ late binding: unlike compiled languages, the name of method, variable is lookedup by name at runtime Data types are strongly and dynamically typed. Mixing incompatible types (e.g. attempting to add a string and a number) causes an exception to be raised, so errors are caught sooner. Python contains advanced programming features such as generators and list comprehensions. Lambda functions Multiple inheritance Common A variety of basic data types are available: numbers (floating point, complex, and unlimited-length long integers), strings (both ASCII and Unicode), lists, and dictionaries. Python supports object-oriented programming with classes and multiple inheritance. Code can be grouped into modules and packages. The language supports raising and catching exceptions, resulting in cleaner error handling. Python's automatic memory management frees you from having to manually allocate and free memory in your code. Compilers # A type of translator. Compiler analyze the whole source code at once and translate it to another language. i.e. machine code Interpreters # An interpreter is also a program that translates a high-level language into a low-level one (but not directly into machine code), and it does it at the moment the program is run. It takes the program, one line at a time, and translates each line before running it: It translates the first line and runs it, then translates the second line and runs it etc. Compiler characteristics: # spends a lot of time analyzing and processing the program the resulting executable is some form of machine- specific binary code the computer hardware interprets (executes) the resulting code program execution is fast Interpreter characteristics: # relatively little time is spent analyzing and processing the program the resulting code is some sort of intermediate code the resulting code is interpreted by another program program execution is relatively slow Python interpreted/compiled? # Compiled Language # A compiled language turn human-readable code into machine code (a string of binary numbers), which are directly executed by OS & CPU. Interpreted Language # A language which is in non-machine code form just before its execution. In general an interpreted prog. language turn human-readable code into non-machine code (byte-code), which are then line by line executed by virtual machine. Interpreted/Compiled is not property of language, its property of implementation. Its byte-code INTERPRETED, because .py is first COMPILED/translated to .pyc (a byte-code language, a non-machine language, executed by python virtual machine, not by OS / CPU). How python works? # run module i.e. .py file .py loaded into memory parsing in order .py compiled to bytecode .pyc file (which is not binary machinecode) compilation is translation step .pyc (.i.e. bytecode) is low-level platform -independent version of source-code require more work than CPU instructions if .pyc of source code is present, compilation step will be skipped by checking time-stamp of .py & .pyc if python cannot create .pyc, then bytecode will be created in-memory then routed/shipped to python virtual machine PVM for execution pre-installed / inbuilt it is runtime engine of python .pyc is also way of shipping python code without source-code Note # no initial/explicit compilation phase compiles at runtime only and then executes in single step able to produce executable, frozen binaries using py2exe PyInstaller freeze What is .pyc file? # Low-level Platform-independent Bytecode What is .pyo file? # in addition to .pyc, .pyo removes all the comments & docs(i guess) Memory Management # Basics: Python's memory allocation and deallocation method is automatic. involves a private heap the heap contains all the objects & data structures managed by python \"memory manager MM\" interpreter manages this all no user control heap space allocation for objects & buffers are performed on-demand by MM c memory management libs works in-behind: malloc(), calloc(), realloc(), free() at low level, raw memory allocator allocates enough memory for all the data on top of low-level, object-specific allocators allocates memory as per object's policies e.g. for integer: speed tradeoff Memory De-allocation Strategies: Reference Counting Was only option Prior Python 2.0 When an object gets created and referenced, it counts the number of times the object is referenced by some other objects When reference is removed, the reference count for the object is decremented When the reference count becomes zero, the object is deallocated. Extremely efficient but Have limitations like: Cannot handle reference cycle Reference Cycle: When there is no way to reach an object but its reference count is still greater than zero e.g. list1 = [] list1 . append ( list1 ) Examples, where the reference count increases: assignment operator argument passing appending an object to a list (object's reference count will be increased). foo = [] # 2 references, 1 from the foo var and 1 from getrefcount print ( sys . getrefcount ( foo )) def bar ( a ): # 4 references # from the foo var, function argument, getrefcount and Python's function stack print ( sys . getrefcount ( a )) bar ( foo ) # 2 references, the function scope is destroyed print ( sys . getrefcount ( foo )) Garbage Collection Introduced after Python 2.0 it contains reference counting as well as garbage collector Automatic / Scheduled: The \"Reference Counting\" mechanism was not able to deallocate objects in few cases like: Reference Cycle How reference counting is solved by garbage collection it is a scheduled task based on a threshold threshold = allocations - de-allocations The GC classifies container objects into three generations. Every new object starts in the first generation. If an object survives a garbage collection round, it moves to the older (higher) generation. Lower generations are collected more often than higher. Because most of the newly created objects die young, it improves GC performance and reduces the GC pause time. Source : read Pro Python for better understanding https://rushter.com/blog/python-garbage-collector/ whenever threshold is reached, garbage collector starts identifying memory spaces which are garbage garbage? the memory spaces which are un-reachable to python objects e.g. import gc gc . disable () obj1 = { \"val\" : 1 } obj2 = { \"val\" : 2 } obj1 [ \"obj2\" ] = obj2 obj2 [ \"obj1\" ] = obj1 del obj1 , obj2 - it is most important to identify a memory space whether it is a garbage or not - otherwise it will lead to memory leak - memory leak means, automatically data loss Note: Automatic garbage collection will not run if your Python device is running out of memory Manual / Explicitly import gc # get_count() returns a tuple of (threshold, no. of objects allocated, no. of objects de-allocated) print ( gc . get_count ()) # With no arguments, run a full collection gc . collect () https://docs.python.org/3/c-api/memory.html pass by value pass by reference change reference change value behaviour of mutable and immutable Data types in python? # data type: set of data with predefined values. primitive: integers floating char string user-defined Data structure in python? # Data Structure: are special format/structures to store & organize data. 4 Built in # Sequence data types: Ordered Sequence: List Tuple Set Dictionary We consider string more as a data type. Collection & heapq modules # provides additional data structure collections: dequeue ordereddict heapq: priority queue heap Abstract data type we can create are # linear: linked list stack queue hash table non-linear: tree graph Data Types # Strings # String formatting # i = 1 v = 'a' print ( \"Value at index {0} is {1} \" . format ( i , v )) print ( \"Value at index {} is {} \" . format ( i , v )) print ( \"Value at index %d is %s \" % ( i , v )) # my favorite way before Python 3.6.4 emp = { 'name' : 'toran' , 'age' : 26 , 'mobile' : '8602431733' } print ( \"My name is {name} and I'm {age} years old. You can contact me at {mobile} \" . format ( ** emp )) # in Python 3.6.4 print ( f 'The value of i is { i } and value of v is { v } ' ) What is doc string? # way of associating document with modules, functions, class, methods describes what it does instead how first line should heading (start with capital, end with dot), then gap of one-line, then desc byte string vs unicode string # Intro # there are a lot of encodings available world-wide e.g. ASCII, CP-1252 (windows), Mac-greek.. etc computer only understands bit, bytes e.g. in ASCII: 65 is -a, 97 is A HOW TO REPRESENT ALL LANGUAGEs IN SAME FILE? 3 things # str python object byte string, computer native array of bytes unicode, some encoded text unicode # one encoding, all chars represent a char as 4-byte number: 4*8 = 32; UTF-32 a lot memory freak similarly, 2*8 = 16; UTF-16 UTF-8 a variable-length encoding system for Unicode till 128, ASCII & UTF-8 is same, uses 1 byte uses 2 bytes for latin read more at 1 , 2 List # Intro # A data structure/type to store objects/data/items Ordered collection: stores in ordered way i.e. using index from 0 Variable length: dynamic sized Mutable: can change any existing element in run-time Preferred for homogenious collection, but can store heterogenious data types inside. many attribute/member methods: Why? When? # when dynamic data structure is benificial like: appending, removing, altering use when implementing buffer, stack, queues Features # List Generator # generates iterable items on demand build up in memory xrange in Python 2.x i.e. range() in Python 3.x is example of generator Advantages: No need to wait until all the elements have been generated before we use them in python 2.x, range returns a list while xrange returns a generator e.g. def first_n ( n ): num = 0 while ( num < n ): yield num num += 1 for i in first_n ( 5 ): print ( i ) List comprehension # l = [ i for i in range ( 0 , 10 )] print ( l ) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9] List Flattening # l = [[ 1 , 2 , 3 ], [ 4 , 5 , 6 ], [ 7 , 8 , 9 ] ] flat_list = [ item for sublist in l for item in sublist ] which is equivalent to flat_list = [] for sublist in l : for item in sublist : flat_list . append ( item ) Randomize items of list in place # Code: from random import shuffle l = [ 1 , 2 , 3 , 4 ] shuffle ( l ) print ( l ) shuffle ( l ) print ( l ) Out: [3, 2, 1, 4] [4, 1, 2, 3] How to insert an element in between a list? # Code: l = [ 1 , 2 , 3 , 5 , 6 , 7 ] l . insert ( 3 , 4 ) l Out: [1, 2, 3, 4, 5, 6, 7] Diif between append and extend method in list? # append - appends object at the end extend - extends list by appending elements from iterables Code: l = [ 1 , 2 , 3 ] a = [ 4 , 5 ] e = [ 6 , 7 , 8 ] l . append ( a ) l . extend ( e ) print ( l ) Out: [1, 2, 3, [4, 5], 6, 7, 8] enumerate() # for i , v in enumerate ([ 'f' , 's' , 't' ]): print ( \"Value at index %d is %s \" % ( i , v )) print ( \"Value at index {0} is {1} \" % ( i , v )) print ( \"Value at index {} is {} \" . format ( i , v )) Tuple # A fixed data structure/type to store objects/data/items Ordered collection: stores in ordered way i.e. using index from 0 Fixed length: cannot change length of a tuple, cannot append, pop an element Immutable: cannot change any existing element in run-time Preferred for heterogenious collection, but can store homoge data types inside. Why? When? # when a collection of values will not change i.e. in case of functions args. use when fixed structure is benificial like: heavy memory intensive work, api, server can be used as key in dictionary due to its fixed structure use when need to store a db table data and want to maintain column structure Properties # l = [ 1 , 2 , ( 3 , 'a' ), 'b' , [ 4 , 5 ]] t = ( 1 , 2 ,[ 3 , 'a' ], 'b' , ( 4 , 5 ) ) #Lets try to make changes in l & t # l[2][0] = 1 #does not work # l[2] = 3 #works # t[2] = 3 #does not work # t[2][0] = 1 #works Expanding Tuple # used to pass tuple elements as function parameter t = ( 1 , 2 , 3 , 4 , 5 ) # simple def bar ( a , b , c , d , e ): print ( a , b , c , d , e ) bar ( * t ) # in general def foo ( * args ): for arg in args : print ( arg ) foo ( * t ) Dictionary # Is map type of data structure which holds a key value pair. Unordered collection: does not maintain order When to use dict & set? # When data is labelled Use a dictionary when you have a set of unique keys that map to values. Use a set to store an unordered unique set of items. dict vs list lookup performance? # dict - O(1) due to hashing list - O(n) dict comprehension # Code: d = { i : i * i for i in range ( 0 , 10 )} print ( d ) Out: {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81} dict with order # maintains the order of elements in which they were inserted from collections import OrderedDict d = OrderedDict ({ 2 : 'second' , 1 : 'first' }) d . items () Variables # Global vs Local vs Non-Local Variable # src: https://www.python-course.eu/python3_global_vs_local_variables.php not same as other languages (by default global) by default all are local (if you need, declare global) def f (): s = \"I'm local\" print ( s ) s = \"I'm global\" f () print ( s ) Out: I'm local I'm global Global Variable # How to access global variable inside a function: def f (): # print(s) #error : cannot access a global variable directly global s # keyword global will give access to outer s s = \"I'm local\" # value of global s has been changed print ( s ) s = \"I'm global\" f () print ( s ) Out: I'm local I'm local Global Variables in Nested Functions # keyword global inside inner function will not access the upper function level variable instead, it will create a variable in main scope to make it possible there is one more keyword : nonlocal def f (): x = 42 def g (): global x x = 43 print ( \"Before calling g: \" + str ( x )) print ( \"Calling g now:\" ) g () print ( \"After calling g: \" + str ( x )) f () print ( \"x in main: \" + str ( x )) Out: Before calling g: 42 Calling g now: After calling g: 42 x in main: 43 Local Variable # variable defined inside a function are local to that function Non-Local Variable # introduced in Python 3 different than global can only be used inside of nested functions has to be defined in the enclosing/upper function scope def f (): y = 42 def g (): nonlocal y y = 43 print ( \"Before calling g: \" + str ( y )) print ( \"Calling g now:\" ) g () print ( \"After calling g: \" + str ( y )) f () print ( \"y in main: \" + str ( y )) # this will create error Out: Before calling g: 42 Calling g now: After calling g: 43 NameError: name 'y' is not defined Operators # in # Searching Time Complexity: (Depends on type of operand) List Avg: O(n) Dict/Set Avg: O(1) Worst: O(n) magic/member method: __contains__(<element>) and # or # xor # is # not # Generators # xrange vs range? # python3: * xrange is renamed to range. python2: * same result but xrange is more memory efficient * range creates iterable list (in python2) * while xrange creates xrange object and generate list of demand Statements # assert # A statement Used to check an expectation Works on logical condition If true, return nothing, if false raise AssertionError exception yield # A statement Does not end a function Returns value to its caller suspends the function and then return value to its caller then resume the function Continues with next line of statement uses: in generators like range return # A statement Ends function Returns value to caller Compound Statements # Compound statements contain (groups of) other statements they affect or control the execution of those other statements in some way contains multi line code block e.g. if , while , for , def , class , with with # The with statement is used to wrap the execution of a block with methods defined by a context manager with statement allows the execution of initialization and finalization code around a block of code i.e. try / finally + context manager having methods __enter__() & __exit__() read more Example #1 : file handling # # automatically acquring `csv.txt` file and does not allows others to acquire it with open ( 'csv.txt' , 'r' , encoding = 'utf-8' ) as f : # do some operations on f # do some operations more on f # if any exception occur, closes the file before exception is caught and shown by interpreter # automatically closed/released `csv.txt` file for others with statement opens a file or acquires a resource then do some block of codes then closes the file or releases the resource if any exception occur, during operations closes the file before exception is caught and shown by interpreter thats how we are better than try, except, finally I/O operation : GIL free Example #2: # with A () as a , B () as b : suite is equivalent to with A () as a : with B () as b : suite - thats how, it does not need help of GIL Expressions # lambda # Operators # Ternary Operator # [on-true] if [expression] else [on-flase] Code: x , y = 23 , 50 big = x if x > y else y print ( big ) Out: 50 [Operator Overloading Using Magic Methods] # Read in Python-OOPs notebook Functions # Source https://docs.python.org/3/library/functions.html eval() # Source: https://www.programiz.com/python-programming/methods/built-in/eval a built-in function to evaluate the python expression writter in string form str = \"lambda x: x**2\" square = eval ( str ) square ( 2 ) # returns 4 str_list = \"[1,2,3]\" eval ( str_list ) # returns a list str_dict = \"{'a':1, 'b':[2,3]}\" eval ( str_dict ) # returns a dict - eval takes 3 parameters - expression: string - globals: dict (used for namespace) - locals: any mapping object partial() # a closure or a nested function used to fulfill the cases when we need to provide some/few fixed parameters to any functions need to import from functools import partial partial always takes functions as first parameter e.g. from functools import partial def foo ( a , b , c = 10 ): print ( f \"I'm foo with { a } , { b } , and { c } \" ) foo_partial = partial ( foo , 1 , 2 ) foo_partial () lambda # format: lambda arg1, arg2, ...argN : expression using arguments anonymous function single-line statement expression in-place function definition can be stored in a variable syntax: lambda x : return x * x Scopes: to make Jump Tables nested lambda loop in lambda using map() map() # signature: map(aFunction, aSequence) applies a passed-in function to each item in an iterable object python2 :returns a list containing all the function call results python3 :returns an iterator of type map object Syntax sqrs = list ( map ( lambda x : x * x , range ( 0 , 10 ))) print ( sqrs ) Out: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] filter() # signature: filter(aFunction, aSequence) applies a passed-in function to each item in an iterable object python2 :returns a list of items for whose function call returns True python3 :returns an iterator of type map object for the items whose function call returns True Syntax evens = list ( filter ( lambda x : x % 2 == 0 , range ( 0 , 10 ))) print ( evens ) Out: [0, 2, 4, 6, 8] reduce() # (Dropped out in Python 3.x) * signature: filter(aFunction, aSequence) * applies a passed-in function to each item in an iterable object * python2 :returns a single value * python3 : dropped out zip() # list1 = [ 'A' , 'B' , 'C' ] and list2 = [ 10 , 20 , 30 ] . zip ( list1 , list2 ) # results in a list of tuples say [('A',10),('B',20),('C',30)] Inverse a Matrix (list/tuple) # m = [[ 1 , 2 , 3 , 4 ], [ 5 , 6 , 7 , 8 ], [ 9 , 10 , 11 , 12 ] ] m_inverse = list ( zip ( * m )) # here *m is expanding of list/tuple, mostly used in passing tuple as func parameters Decorators # are a thin wrapper arround any function or any class there are also decorators for classes (read in Python-OOPs) benifits: do not need to decorate each method manually when we apply a decorator to any function a few lines code in before start (if any) of the fuction call will get executed and/or a few lines code in after end (if any) of the fuction call will get executed types of function decorator made out of a nested functions made out of a class decorator with param decorator over decorator order of decorators Using wraps from functools The way we have defined decorators so far hasn't taken into account that the attributes __name__ ( name of the function ), __doc__ ( the docstring ) and __module__ ( The module in which the function is defined ) of the original functions will be lost after the decoration. simplest form of e.g. to create a custom decorator is: def exec_time ( some_func ): print ( 'this is start time' ) some_func () print ( 'this is end time' ) @exec_time def foo (): print ( 'running foo' ) - gist: https://gist.github.com/toransahu/7ac4c7f139e78d15b74ca0ce6e17cf85 Nested function # def outer_func (): x = 5 def inner_func ( y = 3 ): return ( x + y ) return inner_func a = outer_func () print ( a ()) # 8 Closures # is a concept - not a function a few may refer it as a nested function The local function is able to reference the outer scope through closures. Closures maintain references to objects from the earlier scope. As per JavaScript # A closure is the combination of a function bundled together (enclosed) with references to its surrounding state (the lexical environment). In other words, a closure gives you access to an outer function\u2019s scope from an inner function. In JavaScript, closures are created every time a function is created, at function creation time. Function Factory # these are functions that return other functions the returned functions are specialized Function Factory takes in argument(s), creates local function that creates its own argument(s) and also uses the argument(s) passed to the function factory this is possible with closures def multiply_by ( num ): def multiply_by_num ( k ): return num * k return multiply_by_num five = multiply_by ( 5 ) print ( five ( 2 )) # 10 print ( five ( 4 )) # 20 decimal = multiply_by ( 10 ) print ( decimal ( 20 )) # 200 print ( decimal ( 3 )) # 30 Parameter passing in python # Passed As # by default, all the parameters (arguments) are passed \u00e2\u0080\u009cby reference\u00e2\u0080\u009d to the functions numbers, strings, tuples (i.e. immutables) are passed by value Default Parameters # Non-default parameters comes before default parameters following will give SyntaxError def add ( a , b = 3 , c ): return a + b + c SyntaxError: non-default argument follows default argument Variable Number of Parameters # *args **kwarg Exception Handling # Syntax: try : # do something except IOError as e : # handle except ValueError : # handle except : # handle finally : # do final work can also put an else block after all the except block (will be executed if no exception occurs) Inbuilt Exceptions # All the buil-in exceptions are subclass of BaseException AssertionError # raised when assert statement fails AttributeError # EOFError # raised when the input() function hits an end-of-file condition without reading any data ImportError # raised when there is some trouble loading mudules IndentationError # wrong indentation IndexError # raised when a sequence is out of range KeyError # when key not found in Dict NameError # when a local or global name is not found NotImplementedError # when a abstract/interface method lacks real implementation in sub-class OSError # when there is some OS level failure like, file not found , disk full RecursionError # when intrepreter detects maximum recursion depth SyntaxError # when parser encounters some syntax error print 1 SyntaxError: Missing parentheses in call to 'print' TypeError # when an operation or function is applied to an inappropriate object e.g. when index is not an int addition of int + str a = 1 + 'abc' TypeError: unsupported operand type(s) for +: 'int' and 'str' UnicodeError # when a unicode related encoding/decoding error occurs ValueError # when a built-in operations or function receives an argument that has the right type but an inappropriate value. int ( 'abc' ) ValueError: invalid literal for int() with base 10: 'abc' ZeroDivisionError # when 2nd arg in division or modulo operation is zero User-defined Exception # make a class inherit the Exception class syntax: # define Python user-defined exceptions class Error ( Exception ): \"\"\"Base class for other exceptions\"\"\" pass class ValueTooSmallError ( Error ): \"\"\"Raised when the input value is too small\"\"\" pass class ValueTooLargeError ( Error ): \"\"\"Raised when the input value is too large\"\"\" pass Performance # https://wiki.python.org/moin/TimeComplexity Misc # is vs == operator # == compares for values i.e. checks that 2 arguments have the same value l1 = [ 1 , 2 , 3 ] l2 = l1 l3 = [ 1 , 2 , 3 ] l1 == l2 # returns True l1 == l3 # returns True l3 == l2 # returns True is checks if operand1 is exact copy of operand2 i.e. checks that 2 arguments refer to the same object l1 = [ 1 , 2 , 3 ] l2 = l1 l3 = [ 1 , 2 , 3 ] l1 is l2 # returns True l1 is l3 # returns False l3 is l2 # returns False Pickling Unpickling # Pickling # python object hierarchy is converted into byte stream aka serialization, marshal, flattening can say 'binary serialization format' module: pickle Unpickling # byte-like objects or binary files are converted back into objects hierarchy opposite of pickling Comparision with JSON # JSON is a text serialization format it outputs unicode text, and most of the time it is then encoded to 'utf-8' JSON text is human readable which pickle is not widely used outside the python, while pickle is python-specific Monkey Patching # an evil hack ;) It's simply the dynamic replacement of attributes of a class/module at runtime. its possible because classes are mutable & methods are just attributes Also, we can replace classes and functions in a module Uses # for testing purpose, replace a function which calls a heavy API with a dummy one Code: class MyClass : def f ( self ): print ( \"f()\" ) def monkey_f ( self ): print ( \"monkey_f()\" ) MyClass . f = monkey_f obj = MyClass () obj . f () # here, definition of f has been replace with def of monkey_f #obj.monkey_f() Out: monkey_f() Duck Typing # EAFP: Easier to Ask Forgiveness than Permission Tag line definition: If an object can quack & fly, then its a duck. Do not worry about, if this object has this attribute or not, just try it inside try: block. If work then great, else handle the error. Opposite is LBYL: Look Before You Leap. (Check if it is possible or not, then try) e.g. https://gist.github.com/toransahu/337c287f8ead0d663c13b96d4b8fb7d2 Copy # Regular Reference (Hard Copy) # Copies reference of original only not value. Changes in copy will also reflect in original. i.e. id of both would be same The difference between shallow and deep copying is only relevant for compound objects (objects that contain other objects, like lists or class instances) Shallow copy # A shallow copy constructs a new compound object and then (to the extent possible) inserts references into it to the objects found in the original. Copies top level data & references other level objects into new Changes in top level not reflect in orignal Changes in other level objects reflect in orignal Means ids of nested/child objects will remain same in both the copies doesn't slow downs programs refer example Deep copy # A deep copy constructs a new compound object and then, recursively, inserts copies into it of the objects found in the deforiginal. slow downs programs print ( \"Regular reference Example \\n \" ) print ( \"Ops on mutable\" ) l1 = [ 1 , 2 , 3 ] l2 = l1 # l2 have reference of l1 # changes in regular reference affects original data l2 . append ( 4 ) print ( \"l1 =\" , l1 ) print ( \"l2 =\" , l2 ) print ( \"id(l1) =\" , id ( l1 )) print ( \"id(l2) =\" , id ( l2 )) print ( \"Ops on Immutable\" ) s1 = \"abcd\" s2 = s1 print ( id ( s1 )) print ( id ( s2 )) print ( s1 ) print ( s2 ) s1 = \"efgh\" print ( id ( s1 )) print ( id ( s2 )) print ( s1 , s2 ) Out: Regular reference Example Ops on mutable l1 = [1, 2, 3, 4] l2 = [1, 2, 3, 4] id(l1) = 140486838971464 id(l2) = 140486838971464 Ops on Immutable 140486838172392 140486838172392 abcd abcd 140486838172784 140486838172392 efgh abcd print ( \" \\n Shallow Copy Example - Manual \\n \" ) l0 = [ 1 , 2 , 3 ] l3 = [ 1 , l0 ] l4 = list ( l3 ) print ( \"l3 = \" , l3 ) print ( \"l4 = \" , l4 ) print ( \"id(l3) =\" , id ( l3 )) print ( \"id(l4) = \" , id ( l4 )) print ( \"l3 == l4\" , l3 == l4 ) #checks value-wise print ( \"l3 is l4\" , l3 is l4 ) #checks object identity-wise print ( \"id(l3[1]) =\" , id ( l3 [ 1 ])) print ( \"id(l4[1]) = \" , id ( l4 [ 1 ])) print ( \"l3[1] == l4[1]\" , l3 [ 1 ] == l4 [ 1 ]) print ( \"l3[1] is l4[1]\" , l3 [ 1 ] is l4 [ 1 ]) print ( \"Size of l3 = \" , sys . getsizeof ( l3 )) print ( \"Size of l4 = \" , sys . getsizeof ( l4 )) print ( \"Size of l3[1] = \" , sys . getsizeof ( l3 [ 1 ])) print ( \"Size of l4[1] = \" , sys . getsizeof ( l4 [ 1 ])) Out: Shallow Copy Example - Manual l3 = [1, [1, 2, 3]] l4 = [1, [1, 2, 3]] id(l3) = 140486838605384 id(l4) = 140486838202312 l3 == l4 True l3 is l4 False id(l3[1]) = 140486839016584 id(l4[1]) = 140486839016584 l3[1] == l4[1] True l3[1] is l4[1] True --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-14-607e640db462> in <module>() 19 print(\"l3[1] is l4[1]\", l3[1] is l4[1]) 20 ---> 21 print(\"Size of l3 = \",sys.getsizeof(l3)) 22 print(\"Size of l4 = \",sys.getsizeof(l4)) 23 NameError: name 'sys' is not defined Here, * values of l3 and l4 are same * but ids of l3 and l4 are different * nested/child object of l3 is not directly copied to l4 instead the reference of that child is provided. * the id of l3[1] & l4[1] are same, means changes in l4[0] will affect l3[0]. * sizes of l3 & l4 are different * sizes of l3[1] & l4[1] are different print ( \" \\n Shallow Copy Example - copy.copy()\" ) import copy import sys l3 = [ 1 , l0 ] l4 = copy . copy ( l3 ) # some value of l3 are copied to l4 and reference of some are passed to l4 print ( \"l3 = \" , l3 ) print ( \"l4 = \" , l4 ) print ( \"id(l3) =\" , id ( l3 )) print ( \"id(l4) = \" , id ( l4 )) print ( \"l3 == l4\" , l3 == l4 ) #checks value-wise print ( \"l3 is l4\" , l3 is l4 ) #checks object identity-wise print ( \"id(l3[1]) =\" , id ( l3 [ 1 ])) print ( \"id(l4[1]) = \" , id ( l4 [ 1 ])) print ( \"l3[1] == l4[1]\" , l3 [ 1 ] == l4 [ 1 ]) print ( \"l3[1] is l4[1]\" , l3 [ 1 ] is l4 [ 1 ]) print ( \"Size of l3 = \" , sys . getsizeof ( l3 )) print ( \"Size of l4 = \" , sys . getsizeof ( l4 )) print ( \"Size of l3[1] = \" , sys . getsizeof ( l3 [ 1 ])) print ( \"Size of l4[1] = \" , sys . getsizeof ( l4 [ 1 ])) Out: Shallow Copy Example - copy.copy() l3 = [1, [1, 2, 3]] l4 = [1, [1, 2, 3]] id(l3) = 140486838153032 id(l4) = 140486838151368 l3 == l4 True l3 is l4 False id(l3[1]) = 140486839016584 id(l4[1]) = 140486839016584 l3[1] == l4[1] True l3[1] is l4[1] True Size of l3 = 80 Size of l4 = 104 Size of l3[1] = 88 Size of l4[1] = 88 Here, * Results are same as Manual shallow copy. Except, * sizes of l3 & l4 are different * sizes of l3[1] & l4[1] are same print ( \" \\n Deep Copy Example - Manual\" ) import copy import sys l5 = [ 1 , l0 ] l6 = [ 1 , list ( l0 )] # all value of l5 are copied to l6 print ( \"l5 = \" , l5 ) print ( \"l6 = \" , l6 ) print ( \"id(l5) =\" , id ( l5 )) print ( \"id(l6) = \" , id ( l6 )) print ( \"l5 == l6\" , l5 == l6 ) #checks value-wise print ( \"l5 is l6\" , l5 is l6 ) #checks object identity-wise print ( \"id(l5[1]) =\" , id ( l5 [ 1 ])) print ( \"id(l6[1]) = \" , id ( l6 [ 1 ])) print ( \"l5[1] == l6[1]\" , l5 [ 1 ] == l6 [ 1 ]) print ( \"l5[1] is l6[1]\" , l5 [ 1 ] is l6 [ 1 ]) print ( \"Size of l5 = \" , sys . getsizeof ( l5 )) print ( \"Size of l6 = \" , sys . getsizeof ( l6 )) print ( \"Size of l5[1] = \" , sys . getsizeof ( l5 [ 1 ])) print ( \"Size of l6[1] = \" , sys . getsizeof ( l6 [ 1 ])) Out: Deep Copy Example - Manual l5 = [1, [1, 2, 3]] l6 = [1, [1, 2, 3]] id(l5) = 140486838605384 id(l6) = 140486838226760 l5 == l6 True l5 is l6 False id(l5[1]) = 140486839016584 id(l6[1]) = 140486838253000 l5[1] == l6[1] True l5[1] is l6[1] False Size of l5 = 80 Size of l6 = 80 Size of l5[1] = 88 Size of l6[1] = 112 Here, * values of l5 and l6 are same * but ids of l5 and l6 are different * nested/child object of l5 is directly copied to l6 instead of passing the reference * the id of l5[1] & l6[1] are different, means changes in l6[0] will not affect l5[0] * sizes of l5 & l6 are same * sizes of l5[1] & l6[1] are different print ( \" \\n Deep Copy Example - copy.deepcopy()\" ) import copy import sys l5 = [ 1 , l0 ] l6 = copy . deepcopy ( l5 ) # all value of l5 are copied to l6 print ( \"l5 = \" , l5 ) print ( \"l6 = \" , l6 ) print ( \"id(l5) =\" , id ( l5 )) print ( \"id(l6) = \" , id ( l6 )) print ( \"l5 == l6\" , l5 == l6 ) #checks value-wise print ( \"l5 is l6\" , l5 is l6 ) #checks object identity-wise print ( \"id(l5[1]) =\" , id ( l5 [ 1 ])) print ( \"id(l6[1]) = \" , id ( l6 [ 1 ])) print ( \"l5[1] == l6[1]\" , l5 [ 1 ] == l6 [ 1 ]) print ( \"l5[1] is l6[1]\" , l5 [ 1 ] is l6 [ 1 ]) print ( \"Size of l5 = \" , sys . getsizeof ( l5 )) print ( \"Size of l6 = \" , sys . getsizeof ( l6 )) print ( \"Size of l5[1] = \" , sys . getsizeof ( l5 [ 1 ])) print ( \"Size of l6[1] = \" , sys . getsizeof ( l6 [ 1 ])) Out: Deep Copy Example - copy.deepcopy() l5 = [1, [1, 2, 3]] l6 = [1, [1, 2, 3]] id(l5) = 140486838138056 id(l6) = 140486838211656 l5 == l6 True l5 is l6 False id(l5[1]) = 140486839016584 id(l6[1]) = 140486838168328 l5[1] == l6[1] True l5[1] is l6[1] False Size of l5 = 80 Size of l6 = 96 Size of l5[1] = 88 Size of l6[1] = 96 Here, * Results are same as Manual Deep copy. Except, * sizes of l5 & l6 are different * sizes of l5[1] & l6[1] are different Two problems often exist with deep copy operations that don\u2019t exist with shallow copy operations: Recursive objects (compound objects that, directly or indirectly, contain a reference to themselves) may cause a recursive loop. Because deep copy copies everything it may copy too much, such as data which is intended to be shared between copies.","title":"Python Basics"},{"location":"lang/python/Python-Basics/#introduction","text":"","title":"Introduction"},{"location":"lang/python/Python-Basics/#the-zen-of-python-pep-20","text":"Beautiful is better than ugly. Explicit is better than implicit. Simple is better than complex. Complex is better than complicated. Flat is better than nested. Sparse is better than dense. Readability counts. Special cases aren't special enough to break the rules. Although practicality beats purity. Errors should never pass silently. Unless explicitly silenced. In the face of ambiguity, refuse the temptation to guess. There should be one-- and preferably only one --obvious way to do it. Although that way may not be obvious at first unless you're Dutch. Now is better than never. Although never is often better than right now. If the implementation is hard to explain, it's a bad idea. If the implementation is easy to explain, it may be a good idea. Namespaces are one honking great idea -- let's do more of those!","title":"The Zen of Python (PEP 20)"},{"location":"lang/python/Python-Basics/#easter-egg","text":"In computer software and media, an Easter egg is an intentional inside joke, hidden message or image, or secret feature of a work The Zen of python can be listed by importing this >>> import this","title":"Easter Egg"},{"location":"lang/python/Python-Basics/#implementations","text":"CPython (Default) Jython IronPython RPython (PyPy)","title":"Implementations"},{"location":"lang/python/Python-Basics/#internal","text":"Runs on a single process by forking Each process have seperate GIL Python can run only one thread at once Context Manager","title":"Internal"},{"location":"lang/python/Python-Basics/#pep-8-style-guide-for-python-code","text":"Package: lowercase, '_' is discouraged, use hyphen '-' instead Module: lowercase + '_' Class: Initial Capital, Camal Case Function: lowercase, Valid word, '_' Method: self, lowercase, Valid word, '_' Variable: Same as functions Local: Global: Static: Constant: Generally Module Level, All CAPS + '_' Private Attribute: To avoid name clashes with subclasses, Leading dunder Protected Attribute: For non-public methods and instance variables, Leading underscore '_' Exception Name: Same as class NOTE: Never use the characters 'l' (lowercase letter el), 'O' (uppercase letter oh), or 'I' (uppercase letter eye) as single character variable names.","title":"PEP 8 - Style Guide for Python Code"},{"location":"lang/python/Python-Basics/#features-of-python-are","text":"Unique Interpreted Language Dynamic type system but strongly typed (changing data type need explicit conversion) emphasizes on code readability - lesser line of code/syntax Supports multiple programming paradigms, including object-oriented, imperative, functional and procedural Has community based developement model Dynamic name resolution/ late binding: unlike compiled languages, the name of method, variable is lookedup by name at runtime Data types are strongly and dynamically typed. Mixing incompatible types (e.g. attempting to add a string and a number) causes an exception to be raised, so errors are caught sooner. Python contains advanced programming features such as generators and list comprehensions. Lambda functions Multiple inheritance Common A variety of basic data types are available: numbers (floating point, complex, and unlimited-length long integers), strings (both ASCII and Unicode), lists, and dictionaries. Python supports object-oriented programming with classes and multiple inheritance. Code can be grouped into modules and packages. The language supports raising and catching exceptions, resulting in cleaner error handling. Python's automatic memory management frees you from having to manually allocate and free memory in your code.","title":"Features of Python are:"},{"location":"lang/python/Python-Basics/#compilers","text":"A type of translator. Compiler analyze the whole source code at once and translate it to another language. i.e. machine code","title":"Compilers"},{"location":"lang/python/Python-Basics/#interpreters","text":"An interpreter is also a program that translates a high-level language into a low-level one (but not directly into machine code), and it does it at the moment the program is run. It takes the program, one line at a time, and translates each line before running it: It translates the first line and runs it, then translates the second line and runs it etc.","title":"Interpreters"},{"location":"lang/python/Python-Basics/#compiler-characteristics","text":"spends a lot of time analyzing and processing the program the resulting executable is some form of machine- specific binary code the computer hardware interprets (executes) the resulting code program execution is fast","title":"Compiler characteristics:"},{"location":"lang/python/Python-Basics/#interpreter-characteristics","text":"relatively little time is spent analyzing and processing the program the resulting code is some sort of intermediate code the resulting code is interpreted by another program program execution is relatively slow","title":"Interpreter characteristics:"},{"location":"lang/python/Python-Basics/#python-interpretedcompiled","text":"","title":"Python interpreted/compiled?"},{"location":"lang/python/Python-Basics/#compiled-language","text":"A compiled language turn human-readable code into machine code (a string of binary numbers), which are directly executed by OS & CPU.","title":"Compiled Language"},{"location":"lang/python/Python-Basics/#interpreted-language","text":"A language which is in non-machine code form just before its execution. In general an interpreted prog. language turn human-readable code into non-machine code (byte-code), which are then line by line executed by virtual machine. Interpreted/Compiled is not property of language, its property of implementation. Its byte-code INTERPRETED, because .py is first COMPILED/translated to .pyc (a byte-code language, a non-machine language, executed by python virtual machine, not by OS / CPU).","title":"Interpreted Language"},{"location":"lang/python/Python-Basics/#how-python-works","text":"run module i.e. .py file .py loaded into memory parsing in order .py compiled to bytecode .pyc file (which is not binary machinecode) compilation is translation step .pyc (.i.e. bytecode) is low-level platform -independent version of source-code require more work than CPU instructions if .pyc of source code is present, compilation step will be skipped by checking time-stamp of .py & .pyc if python cannot create .pyc, then bytecode will be created in-memory then routed/shipped to python virtual machine PVM for execution pre-installed / inbuilt it is runtime engine of python .pyc is also way of shipping python code without source-code","title":"How python works?"},{"location":"lang/python/Python-Basics/#note","text":"no initial/explicit compilation phase compiles at runtime only and then executes in single step able to produce executable, frozen binaries using py2exe PyInstaller freeze","title":"Note"},{"location":"lang/python/Python-Basics/#what-is-pyc-file","text":"Low-level Platform-independent Bytecode","title":"What is .pyc file?"},{"location":"lang/python/Python-Basics/#what-is-pyo-file","text":"in addition to .pyc, .pyo removes all the comments & docs(i guess)","title":"What is .pyo file?"},{"location":"lang/python/Python-Basics/#memory-management","text":"Basics: Python's memory allocation and deallocation method is automatic. involves a private heap the heap contains all the objects & data structures managed by python \"memory manager MM\" interpreter manages this all no user control heap space allocation for objects & buffers are performed on-demand by MM c memory management libs works in-behind: malloc(), calloc(), realloc(), free() at low level, raw memory allocator allocates enough memory for all the data on top of low-level, object-specific allocators allocates memory as per object's policies e.g. for integer: speed tradeoff Memory De-allocation Strategies: Reference Counting Was only option Prior Python 2.0 When an object gets created and referenced, it counts the number of times the object is referenced by some other objects When reference is removed, the reference count for the object is decremented When the reference count becomes zero, the object is deallocated. Extremely efficient but Have limitations like: Cannot handle reference cycle Reference Cycle: When there is no way to reach an object but its reference count is still greater than zero e.g. list1 = [] list1 . append ( list1 ) Examples, where the reference count increases: assignment operator argument passing appending an object to a list (object's reference count will be increased). foo = [] # 2 references, 1 from the foo var and 1 from getrefcount print ( sys . getrefcount ( foo )) def bar ( a ): # 4 references # from the foo var, function argument, getrefcount and Python's function stack print ( sys . getrefcount ( a )) bar ( foo ) # 2 references, the function scope is destroyed print ( sys . getrefcount ( foo )) Garbage Collection Introduced after Python 2.0 it contains reference counting as well as garbage collector Automatic / Scheduled: The \"Reference Counting\" mechanism was not able to deallocate objects in few cases like: Reference Cycle How reference counting is solved by garbage collection it is a scheduled task based on a threshold threshold = allocations - de-allocations The GC classifies container objects into three generations. Every new object starts in the first generation. If an object survives a garbage collection round, it moves to the older (higher) generation. Lower generations are collected more often than higher. Because most of the newly created objects die young, it improves GC performance and reduces the GC pause time. Source : read Pro Python for better understanding https://rushter.com/blog/python-garbage-collector/ whenever threshold is reached, garbage collector starts identifying memory spaces which are garbage garbage? the memory spaces which are un-reachable to python objects e.g. import gc gc . disable () obj1 = { \"val\" : 1 } obj2 = { \"val\" : 2 } obj1 [ \"obj2\" ] = obj2 obj2 [ \"obj1\" ] = obj1 del obj1 , obj2 - it is most important to identify a memory space whether it is a garbage or not - otherwise it will lead to memory leak - memory leak means, automatically data loss Note: Automatic garbage collection will not run if your Python device is running out of memory Manual / Explicitly import gc # get_count() returns a tuple of (threshold, no. of objects allocated, no. of objects de-allocated) print ( gc . get_count ()) # With no arguments, run a full collection gc . collect () https://docs.python.org/3/c-api/memory.html pass by value pass by reference change reference change value behaviour of mutable and immutable","title":"Memory Management"},{"location":"lang/python/Python-Basics/#data-types-in-python","text":"data type: set of data with predefined values. primitive: integers floating char string user-defined","title":"Data types in python?"},{"location":"lang/python/Python-Basics/#data-structure-in-python","text":"Data Structure: are special format/structures to store & organize data.","title":"Data structure in python?"},{"location":"lang/python/Python-Basics/#4-built-in","text":"Sequence data types: Ordered Sequence: List Tuple Set Dictionary We consider string more as a data type.","title":"4 Built in"},{"location":"lang/python/Python-Basics/#collection-heapq-modules","text":"provides additional data structure collections: dequeue ordereddict heapq: priority queue heap","title":"Collection &amp; heapq modules"},{"location":"lang/python/Python-Basics/#abstract-data-type-we-can-create-are","text":"linear: linked list stack queue hash table non-linear: tree graph","title":"Abstract data type we can create are"},{"location":"lang/python/Python-Basics/#data-types","text":"","title":"Data Types"},{"location":"lang/python/Python-Basics/#strings","text":"","title":"Strings"},{"location":"lang/python/Python-Basics/#string-formatting","text":"i = 1 v = 'a' print ( \"Value at index {0} is {1} \" . format ( i , v )) print ( \"Value at index {} is {} \" . format ( i , v )) print ( \"Value at index %d is %s \" % ( i , v )) # my favorite way before Python 3.6.4 emp = { 'name' : 'toran' , 'age' : 26 , 'mobile' : '8602431733' } print ( \"My name is {name} and I'm {age} years old. You can contact me at {mobile} \" . format ( ** emp )) # in Python 3.6.4 print ( f 'The value of i is { i } and value of v is { v } ' )","title":"String formatting"},{"location":"lang/python/Python-Basics/#what-is-doc-string","text":"way of associating document with modules, functions, class, methods describes what it does instead how first line should heading (start with capital, end with dot), then gap of one-line, then desc","title":"What is doc string?"},{"location":"lang/python/Python-Basics/#byte-string-vs-unicode-string","text":"","title":"byte string vs unicode string"},{"location":"lang/python/Python-Basics/#intro","text":"there are a lot of encodings available world-wide e.g. ASCII, CP-1252 (windows), Mac-greek.. etc computer only understands bit, bytes e.g. in ASCII: 65 is -a, 97 is A HOW TO REPRESENT ALL LANGUAGEs IN SAME FILE?","title":"Intro"},{"location":"lang/python/Python-Basics/#3-things","text":"str python object byte string, computer native array of bytes unicode, some encoded text","title":"3 things"},{"location":"lang/python/Python-Basics/#unicode","text":"one encoding, all chars represent a char as 4-byte number: 4*8 = 32; UTF-32 a lot memory freak similarly, 2*8 = 16; UTF-16 UTF-8 a variable-length encoding system for Unicode till 128, ASCII & UTF-8 is same, uses 1 byte uses 2 bytes for latin read more at 1 , 2","title":"unicode"},{"location":"lang/python/Python-Basics/#list","text":"","title":"List"},{"location":"lang/python/Python-Basics/#intro_1","text":"A data structure/type to store objects/data/items Ordered collection: stores in ordered way i.e. using index from 0 Variable length: dynamic sized Mutable: can change any existing element in run-time Preferred for homogenious collection, but can store heterogenious data types inside. many attribute/member methods:","title":"Intro"},{"location":"lang/python/Python-Basics/#why-when","text":"when dynamic data structure is benificial like: appending, removing, altering use when implementing buffer, stack, queues","title":"Why? When?"},{"location":"lang/python/Python-Basics/#features","text":"","title":"Features"},{"location":"lang/python/Python-Basics/#list-generator","text":"generates iterable items on demand build up in memory xrange in Python 2.x i.e. range() in Python 3.x is example of generator Advantages: No need to wait until all the elements have been generated before we use them in python 2.x, range returns a list while xrange returns a generator e.g. def first_n ( n ): num = 0 while ( num < n ): yield num num += 1 for i in first_n ( 5 ): print ( i )","title":"List Generator"},{"location":"lang/python/Python-Basics/#list-comprehension","text":"l = [ i for i in range ( 0 , 10 )] print ( l ) [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]","title":"List comprehension"},{"location":"lang/python/Python-Basics/#list-flattening","text":"l = [[ 1 , 2 , 3 ], [ 4 , 5 , 6 ], [ 7 , 8 , 9 ] ] flat_list = [ item for sublist in l for item in sublist ] which is equivalent to flat_list = [] for sublist in l : for item in sublist : flat_list . append ( item )","title":"List Flattening"},{"location":"lang/python/Python-Basics/#randomize-items-of-list-in-place","text":"Code: from random import shuffle l = [ 1 , 2 , 3 , 4 ] shuffle ( l ) print ( l ) shuffle ( l ) print ( l ) Out: [3, 2, 1, 4] [4, 1, 2, 3]","title":"Randomize items of list in place"},{"location":"lang/python/Python-Basics/#how-to-insert-an-element-in-between-a-list","text":"Code: l = [ 1 , 2 , 3 , 5 , 6 , 7 ] l . insert ( 3 , 4 ) l Out: [1, 2, 3, 4, 5, 6, 7]","title":"How to insert an element in between a list?"},{"location":"lang/python/Python-Basics/#diif-between-append-and-extend-method-in-list","text":"append - appends object at the end extend - extends list by appending elements from iterables Code: l = [ 1 , 2 , 3 ] a = [ 4 , 5 ] e = [ 6 , 7 , 8 ] l . append ( a ) l . extend ( e ) print ( l ) Out: [1, 2, 3, [4, 5], 6, 7, 8]","title":"Diif  between append and extend method in list?"},{"location":"lang/python/Python-Basics/#enumerate","text":"for i , v in enumerate ([ 'f' , 's' , 't' ]): print ( \"Value at index %d is %s \" % ( i , v )) print ( \"Value at index {0} is {1} \" % ( i , v )) print ( \"Value at index {} is {} \" . format ( i , v ))","title":"enumerate()"},{"location":"lang/python/Python-Basics/#tuple","text":"A fixed data structure/type to store objects/data/items Ordered collection: stores in ordered way i.e. using index from 0 Fixed length: cannot change length of a tuple, cannot append, pop an element Immutable: cannot change any existing element in run-time Preferred for heterogenious collection, but can store homoge data types inside.","title":"Tuple"},{"location":"lang/python/Python-Basics/#why-when_1","text":"when a collection of values will not change i.e. in case of functions args. use when fixed structure is benificial like: heavy memory intensive work, api, server can be used as key in dictionary due to its fixed structure use when need to store a db table data and want to maintain column structure","title":"Why? When?"},{"location":"lang/python/Python-Basics/#properties","text":"l = [ 1 , 2 , ( 3 , 'a' ), 'b' , [ 4 , 5 ]] t = ( 1 , 2 ,[ 3 , 'a' ], 'b' , ( 4 , 5 ) ) #Lets try to make changes in l & t # l[2][0] = 1 #does not work # l[2] = 3 #works # t[2] = 3 #does not work # t[2][0] = 1 #works","title":"Properties"},{"location":"lang/python/Python-Basics/#expanding-tuple","text":"used to pass tuple elements as function parameter t = ( 1 , 2 , 3 , 4 , 5 ) # simple def bar ( a , b , c , d , e ): print ( a , b , c , d , e ) bar ( * t ) # in general def foo ( * args ): for arg in args : print ( arg ) foo ( * t )","title":"Expanding Tuple"},{"location":"lang/python/Python-Basics/#dictionary","text":"Is map type of data structure which holds a key value pair. Unordered collection: does not maintain order","title":"Dictionary"},{"location":"lang/python/Python-Basics/#when-to-use-dict-set","text":"When data is labelled Use a dictionary when you have a set of unique keys that map to values. Use a set to store an unordered unique set of items.","title":"When to use dict &amp; set?"},{"location":"lang/python/Python-Basics/#dict-vs-list-lookup-performance","text":"dict - O(1) due to hashing list - O(n)","title":"dict vs list lookup performance?"},{"location":"lang/python/Python-Basics/#dict-comprehension","text":"Code: d = { i : i * i for i in range ( 0 , 10 )} print ( d ) Out: {0: 0, 1: 1, 2: 4, 3: 9, 4: 16, 5: 25, 6: 36, 7: 49, 8: 64, 9: 81}","title":"dict comprehension"},{"location":"lang/python/Python-Basics/#dict-with-order","text":"maintains the order of elements in which they were inserted from collections import OrderedDict d = OrderedDict ({ 2 : 'second' , 1 : 'first' }) d . items ()","title":"dict with order"},{"location":"lang/python/Python-Basics/#variables","text":"","title":"Variables"},{"location":"lang/python/Python-Basics/#global-vs-local-vs-non-local-variable","text":"src: https://www.python-course.eu/python3_global_vs_local_variables.php not same as other languages (by default global) by default all are local (if you need, declare global) def f (): s = \"I'm local\" print ( s ) s = \"I'm global\" f () print ( s ) Out: I'm local I'm global","title":"Global vs Local vs Non-Local Variable"},{"location":"lang/python/Python-Basics/#global-variable","text":"How to access global variable inside a function: def f (): # print(s) #error : cannot access a global variable directly global s # keyword global will give access to outer s s = \"I'm local\" # value of global s has been changed print ( s ) s = \"I'm global\" f () print ( s ) Out: I'm local I'm local","title":"Global Variable"},{"location":"lang/python/Python-Basics/#global-variables-in-nested-functions","text":"keyword global inside inner function will not access the upper function level variable instead, it will create a variable in main scope to make it possible there is one more keyword : nonlocal def f (): x = 42 def g (): global x x = 43 print ( \"Before calling g: \" + str ( x )) print ( \"Calling g now:\" ) g () print ( \"After calling g: \" + str ( x )) f () print ( \"x in main: \" + str ( x )) Out: Before calling g: 42 Calling g now: After calling g: 42 x in main: 43","title":"Global Variables in Nested Functions"},{"location":"lang/python/Python-Basics/#local-variable","text":"variable defined inside a function are local to that function","title":"Local Variable"},{"location":"lang/python/Python-Basics/#non-local-variable","text":"introduced in Python 3 different than global can only be used inside of nested functions has to be defined in the enclosing/upper function scope def f (): y = 42 def g (): nonlocal y y = 43 print ( \"Before calling g: \" + str ( y )) print ( \"Calling g now:\" ) g () print ( \"After calling g: \" + str ( y )) f () print ( \"y in main: \" + str ( y )) # this will create error Out: Before calling g: 42 Calling g now: After calling g: 43 NameError: name 'y' is not defined","title":"Non-Local Variable"},{"location":"lang/python/Python-Basics/#operators","text":"","title":"Operators"},{"location":"lang/python/Python-Basics/#in","text":"Searching Time Complexity: (Depends on type of operand) List Avg: O(n) Dict/Set Avg: O(1) Worst: O(n) magic/member method: __contains__(<element>)","title":"in"},{"location":"lang/python/Python-Basics/#and","text":"","title":"and"},{"location":"lang/python/Python-Basics/#or","text":"","title":"or"},{"location":"lang/python/Python-Basics/#xor","text":"","title":"xor"},{"location":"lang/python/Python-Basics/#is","text":"","title":"is"},{"location":"lang/python/Python-Basics/#not","text":"","title":"not"},{"location":"lang/python/Python-Basics/#generators","text":"","title":"Generators"},{"location":"lang/python/Python-Basics/#xrange-vs-range","text":"python3: * xrange is renamed to range. python2: * same result but xrange is more memory efficient * range creates iterable list (in python2) * while xrange creates xrange object and generate list of demand","title":"xrange vs range?"},{"location":"lang/python/Python-Basics/#statements","text":"","title":"Statements"},{"location":"lang/python/Python-Basics/#assert","text":"A statement Used to check an expectation Works on logical condition If true, return nothing, if false raise AssertionError exception","title":"assert"},{"location":"lang/python/Python-Basics/#yield","text":"A statement Does not end a function Returns value to its caller suspends the function and then return value to its caller then resume the function Continues with next line of statement uses: in generators like range","title":"yield"},{"location":"lang/python/Python-Basics/#return","text":"A statement Ends function Returns value to caller","title":"return"},{"location":"lang/python/Python-Basics/#compound-statements","text":"Compound statements contain (groups of) other statements they affect or control the execution of those other statements in some way contains multi line code block e.g. if , while , for , def , class , with","title":"Compound Statements"},{"location":"lang/python/Python-Basics/#with","text":"The with statement is used to wrap the execution of a block with methods defined by a context manager with statement allows the execution of initialization and finalization code around a block of code i.e. try / finally + context manager having methods __enter__() & __exit__() read more","title":"with"},{"location":"lang/python/Python-Basics/#example-1-file-handling","text":"# automatically acquring `csv.txt` file and does not allows others to acquire it with open ( 'csv.txt' , 'r' , encoding = 'utf-8' ) as f : # do some operations on f # do some operations more on f # if any exception occur, closes the file before exception is caught and shown by interpreter # automatically closed/released `csv.txt` file for others with statement opens a file or acquires a resource then do some block of codes then closes the file or releases the resource if any exception occur, during operations closes the file before exception is caught and shown by interpreter thats how we are better than try, except, finally I/O operation : GIL free","title":"Example #1 : file handling"},{"location":"lang/python/Python-Basics/#example-2","text":"with A () as a , B () as b : suite is equivalent to with A () as a : with B () as b : suite - thats how, it does not need help of GIL","title":"Example #2:"},{"location":"lang/python/Python-Basics/#expressions","text":"","title":"Expressions"},{"location":"lang/python/Python-Basics/#lambda","text":"","title":"lambda"},{"location":"lang/python/Python-Basics/#operators_1","text":"","title":"Operators"},{"location":"lang/python/Python-Basics/#ternary-operator","text":"[on-true] if [expression] else [on-flase] Code: x , y = 23 , 50 big = x if x > y else y print ( big ) Out: 50","title":"Ternary Operator"},{"location":"lang/python/Python-Basics/#operator-overloading-using-magic-methods","text":"Read in Python-OOPs notebook","title":"[Operator Overloading Using Magic Methods]"},{"location":"lang/python/Python-Basics/#functions","text":"Source https://docs.python.org/3/library/functions.html","title":"Functions"},{"location":"lang/python/Python-Basics/#eval","text":"Source: https://www.programiz.com/python-programming/methods/built-in/eval a built-in function to evaluate the python expression writter in string form str = \"lambda x: x**2\" square = eval ( str ) square ( 2 ) # returns 4 str_list = \"[1,2,3]\" eval ( str_list ) # returns a list str_dict = \"{'a':1, 'b':[2,3]}\" eval ( str_dict ) # returns a dict - eval takes 3 parameters - expression: string - globals: dict (used for namespace) - locals: any mapping object","title":"eval()"},{"location":"lang/python/Python-Basics/#partial","text":"a closure or a nested function used to fulfill the cases when we need to provide some/few fixed parameters to any functions need to import from functools import partial partial always takes functions as first parameter e.g. from functools import partial def foo ( a , b , c = 10 ): print ( f \"I'm foo with { a } , { b } , and { c } \" ) foo_partial = partial ( foo , 1 , 2 ) foo_partial ()","title":"partial()"},{"location":"lang/python/Python-Basics/#lambda_1","text":"format: lambda arg1, arg2, ...argN : expression using arguments anonymous function single-line statement expression in-place function definition can be stored in a variable syntax: lambda x : return x * x Scopes: to make Jump Tables nested lambda loop in lambda using map()","title":"lambda"},{"location":"lang/python/Python-Basics/#map","text":"signature: map(aFunction, aSequence) applies a passed-in function to each item in an iterable object python2 :returns a list containing all the function call results python3 :returns an iterator of type map object Syntax sqrs = list ( map ( lambda x : x * x , range ( 0 , 10 ))) print ( sqrs ) Out: [0, 1, 4, 9, 16, 25, 36, 49, 64, 81]","title":"map()"},{"location":"lang/python/Python-Basics/#filter","text":"signature: filter(aFunction, aSequence) applies a passed-in function to each item in an iterable object python2 :returns a list of items for whose function call returns True python3 :returns an iterator of type map object for the items whose function call returns True Syntax evens = list ( filter ( lambda x : x % 2 == 0 , range ( 0 , 10 ))) print ( evens ) Out: [0, 2, 4, 6, 8]","title":"filter()"},{"location":"lang/python/Python-Basics/#reduce","text":"(Dropped out in Python 3.x) * signature: filter(aFunction, aSequence) * applies a passed-in function to each item in an iterable object * python2 :returns a single value * python3 : dropped out","title":"reduce()"},{"location":"lang/python/Python-Basics/#zip","text":"list1 = [ 'A' , 'B' , 'C' ] and list2 = [ 10 , 20 , 30 ] . zip ( list1 , list2 ) # results in a list of tuples say [('A',10),('B',20),('C',30)]","title":"zip()"},{"location":"lang/python/Python-Basics/#inverse-a-matrix-listtuple","text":"m = [[ 1 , 2 , 3 , 4 ], [ 5 , 6 , 7 , 8 ], [ 9 , 10 , 11 , 12 ] ] m_inverse = list ( zip ( * m )) # here *m is expanding of list/tuple, mostly used in passing tuple as func parameters","title":"Inverse a Matrix (list/tuple)"},{"location":"lang/python/Python-Basics/#decorators","text":"are a thin wrapper arround any function or any class there are also decorators for classes (read in Python-OOPs) benifits: do not need to decorate each method manually when we apply a decorator to any function a few lines code in before start (if any) of the fuction call will get executed and/or a few lines code in after end (if any) of the fuction call will get executed types of function decorator made out of a nested functions made out of a class decorator with param decorator over decorator order of decorators Using wraps from functools The way we have defined decorators so far hasn't taken into account that the attributes __name__ ( name of the function ), __doc__ ( the docstring ) and __module__ ( The module in which the function is defined ) of the original functions will be lost after the decoration. simplest form of e.g. to create a custom decorator is: def exec_time ( some_func ): print ( 'this is start time' ) some_func () print ( 'this is end time' ) @exec_time def foo (): print ( 'running foo' ) - gist: https://gist.github.com/toransahu/7ac4c7f139e78d15b74ca0ce6e17cf85","title":"Decorators"},{"location":"lang/python/Python-Basics/#nested-function","text":"def outer_func (): x = 5 def inner_func ( y = 3 ): return ( x + y ) return inner_func a = outer_func () print ( a ()) # 8","title":"Nested function"},{"location":"lang/python/Python-Basics/#closures","text":"is a concept - not a function a few may refer it as a nested function The local function is able to reference the outer scope through closures. Closures maintain references to objects from the earlier scope.","title":"Closures"},{"location":"lang/python/Python-Basics/#as-per-javascript","text":"A closure is the combination of a function bundled together (enclosed) with references to its surrounding state (the lexical environment). In other words, a closure gives you access to an outer function\u2019s scope from an inner function. In JavaScript, closures are created every time a function is created, at function creation time.","title":"As per JavaScript"},{"location":"lang/python/Python-Basics/#function-factory","text":"these are functions that return other functions the returned functions are specialized Function Factory takes in argument(s), creates local function that creates its own argument(s) and also uses the argument(s) passed to the function factory this is possible with closures def multiply_by ( num ): def multiply_by_num ( k ): return num * k return multiply_by_num five = multiply_by ( 5 ) print ( five ( 2 )) # 10 print ( five ( 4 )) # 20 decimal = multiply_by ( 10 ) print ( decimal ( 20 )) # 200 print ( decimal ( 3 )) # 30","title":"Function Factory"},{"location":"lang/python/Python-Basics/#parameter-passing-in-python","text":"","title":"Parameter passing in python"},{"location":"lang/python/Python-Basics/#passed-as","text":"by default, all the parameters (arguments) are passed \u00e2\u0080\u009cby reference\u00e2\u0080\u009d to the functions numbers, strings, tuples (i.e. immutables) are passed by value","title":"Passed As"},{"location":"lang/python/Python-Basics/#default-parameters","text":"Non-default parameters comes before default parameters following will give SyntaxError def add ( a , b = 3 , c ): return a + b + c SyntaxError: non-default argument follows default argument","title":"Default Parameters"},{"location":"lang/python/Python-Basics/#variable-number-of-parameters","text":"*args **kwarg","title":"Variable Number of Parameters"},{"location":"lang/python/Python-Basics/#exception-handling","text":"Syntax: try : # do something except IOError as e : # handle except ValueError : # handle except : # handle finally : # do final work can also put an else block after all the except block (will be executed if no exception occurs)","title":"Exception Handling"},{"location":"lang/python/Python-Basics/#inbuilt-exceptions","text":"All the buil-in exceptions are subclass of BaseException","title":"Inbuilt Exceptions"},{"location":"lang/python/Python-Basics/#assertionerror","text":"raised when assert statement fails","title":"AssertionError"},{"location":"lang/python/Python-Basics/#attributeerror","text":"","title":"AttributeError"},{"location":"lang/python/Python-Basics/#eoferror","text":"raised when the input() function hits an end-of-file condition without reading any data","title":"EOFError"},{"location":"lang/python/Python-Basics/#importerror","text":"raised when there is some trouble loading mudules","title":"ImportError"},{"location":"lang/python/Python-Basics/#indentationerror","text":"wrong indentation","title":"IndentationError"},{"location":"lang/python/Python-Basics/#indexerror","text":"raised when a sequence is out of range","title":"IndexError"},{"location":"lang/python/Python-Basics/#keyerror","text":"when key not found in Dict","title":"KeyError"},{"location":"lang/python/Python-Basics/#nameerror","text":"when a local or global name is not found","title":"NameError"},{"location":"lang/python/Python-Basics/#notimplementederror","text":"when a abstract/interface method lacks real implementation in sub-class","title":"NotImplementedError"},{"location":"lang/python/Python-Basics/#oserror","text":"when there is some OS level failure like, file not found , disk full","title":"OSError"},{"location":"lang/python/Python-Basics/#recursionerror","text":"when intrepreter detects maximum recursion depth","title":"RecursionError"},{"location":"lang/python/Python-Basics/#syntaxerror","text":"when parser encounters some syntax error print 1 SyntaxError: Missing parentheses in call to 'print'","title":"SyntaxError"},{"location":"lang/python/Python-Basics/#typeerror","text":"when an operation or function is applied to an inappropriate object e.g. when index is not an int addition of int + str a = 1 + 'abc' TypeError: unsupported operand type(s) for +: 'int' and 'str'","title":"TypeError"},{"location":"lang/python/Python-Basics/#unicodeerror","text":"when a unicode related encoding/decoding error occurs","title":"UnicodeError"},{"location":"lang/python/Python-Basics/#valueerror","text":"when a built-in operations or function receives an argument that has the right type but an inappropriate value. int ( 'abc' ) ValueError: invalid literal for int() with base 10: 'abc'","title":"ValueError"},{"location":"lang/python/Python-Basics/#zerodivisionerror","text":"when 2nd arg in division or modulo operation is zero","title":"ZeroDivisionError"},{"location":"lang/python/Python-Basics/#user-defined-exception","text":"make a class inherit the Exception class syntax: # define Python user-defined exceptions class Error ( Exception ): \"\"\"Base class for other exceptions\"\"\" pass class ValueTooSmallError ( Error ): \"\"\"Raised when the input value is too small\"\"\" pass class ValueTooLargeError ( Error ): \"\"\"Raised when the input value is too large\"\"\" pass","title":"User-defined Exception"},{"location":"lang/python/Python-Basics/#performance","text":"https://wiki.python.org/moin/TimeComplexity","title":"Performance"},{"location":"lang/python/Python-Basics/#misc","text":"","title":"Misc"},{"location":"lang/python/Python-Basics/#is-vs-operator","text":"== compares for values i.e. checks that 2 arguments have the same value l1 = [ 1 , 2 , 3 ] l2 = l1 l3 = [ 1 , 2 , 3 ] l1 == l2 # returns True l1 == l3 # returns True l3 == l2 # returns True is checks if operand1 is exact copy of operand2 i.e. checks that 2 arguments refer to the same object l1 = [ 1 , 2 , 3 ] l2 = l1 l3 = [ 1 , 2 , 3 ] l1 is l2 # returns True l1 is l3 # returns False l3 is l2 # returns False","title":"is vs == operator"},{"location":"lang/python/Python-Basics/#pickling-unpickling","text":"","title":"Pickling Unpickling"},{"location":"lang/python/Python-Basics/#pickling","text":"python object hierarchy is converted into byte stream aka serialization, marshal, flattening can say 'binary serialization format' module: pickle","title":"Pickling"},{"location":"lang/python/Python-Basics/#unpickling","text":"byte-like objects or binary files are converted back into objects hierarchy opposite of pickling","title":"Unpickling"},{"location":"lang/python/Python-Basics/#comparision-with-json","text":"JSON is a text serialization format it outputs unicode text, and most of the time it is then encoded to 'utf-8' JSON text is human readable which pickle is not widely used outside the python, while pickle is python-specific","title":"Comparision with JSON"},{"location":"lang/python/Python-Basics/#monkey-patching","text":"an evil hack ;) It's simply the dynamic replacement of attributes of a class/module at runtime. its possible because classes are mutable & methods are just attributes Also, we can replace classes and functions in a module","title":"Monkey Patching"},{"location":"lang/python/Python-Basics/#uses","text":"for testing purpose, replace a function which calls a heavy API with a dummy one Code: class MyClass : def f ( self ): print ( \"f()\" ) def monkey_f ( self ): print ( \"monkey_f()\" ) MyClass . f = monkey_f obj = MyClass () obj . f () # here, definition of f has been replace with def of monkey_f #obj.monkey_f() Out: monkey_f()","title":"Uses"},{"location":"lang/python/Python-Basics/#duck-typing","text":"EAFP: Easier to Ask Forgiveness than Permission Tag line definition: If an object can quack & fly, then its a duck. Do not worry about, if this object has this attribute or not, just try it inside try: block. If work then great, else handle the error. Opposite is LBYL: Look Before You Leap. (Check if it is possible or not, then try) e.g. https://gist.github.com/toransahu/337c287f8ead0d663c13b96d4b8fb7d2","title":"Duck Typing"},{"location":"lang/python/Python-Basics/#copy","text":"","title":"Copy"},{"location":"lang/python/Python-Basics/#regular-reference-hard-copy","text":"Copies reference of original only not value. Changes in copy will also reflect in original. i.e. id of both would be same The difference between shallow and deep copying is only relevant for compound objects (objects that contain other objects, like lists or class instances)","title":"Regular Reference (Hard Copy)"},{"location":"lang/python/Python-Basics/#shallow-copy","text":"A shallow copy constructs a new compound object and then (to the extent possible) inserts references into it to the objects found in the original. Copies top level data & references other level objects into new Changes in top level not reflect in orignal Changes in other level objects reflect in orignal Means ids of nested/child objects will remain same in both the copies doesn't slow downs programs refer example","title":"Shallow copy"},{"location":"lang/python/Python-Basics/#deep-copy","text":"A deep copy constructs a new compound object and then, recursively, inserts copies into it of the objects found in the deforiginal. slow downs programs print ( \"Regular reference Example \\n \" ) print ( \"Ops on mutable\" ) l1 = [ 1 , 2 , 3 ] l2 = l1 # l2 have reference of l1 # changes in regular reference affects original data l2 . append ( 4 ) print ( \"l1 =\" , l1 ) print ( \"l2 =\" , l2 ) print ( \"id(l1) =\" , id ( l1 )) print ( \"id(l2) =\" , id ( l2 )) print ( \"Ops on Immutable\" ) s1 = \"abcd\" s2 = s1 print ( id ( s1 )) print ( id ( s2 )) print ( s1 ) print ( s2 ) s1 = \"efgh\" print ( id ( s1 )) print ( id ( s2 )) print ( s1 , s2 ) Out: Regular reference Example Ops on mutable l1 = [1, 2, 3, 4] l2 = [1, 2, 3, 4] id(l1) = 140486838971464 id(l2) = 140486838971464 Ops on Immutable 140486838172392 140486838172392 abcd abcd 140486838172784 140486838172392 efgh abcd print ( \" \\n Shallow Copy Example - Manual \\n \" ) l0 = [ 1 , 2 , 3 ] l3 = [ 1 , l0 ] l4 = list ( l3 ) print ( \"l3 = \" , l3 ) print ( \"l4 = \" , l4 ) print ( \"id(l3) =\" , id ( l3 )) print ( \"id(l4) = \" , id ( l4 )) print ( \"l3 == l4\" , l3 == l4 ) #checks value-wise print ( \"l3 is l4\" , l3 is l4 ) #checks object identity-wise print ( \"id(l3[1]) =\" , id ( l3 [ 1 ])) print ( \"id(l4[1]) = \" , id ( l4 [ 1 ])) print ( \"l3[1] == l4[1]\" , l3 [ 1 ] == l4 [ 1 ]) print ( \"l3[1] is l4[1]\" , l3 [ 1 ] is l4 [ 1 ]) print ( \"Size of l3 = \" , sys . getsizeof ( l3 )) print ( \"Size of l4 = \" , sys . getsizeof ( l4 )) print ( \"Size of l3[1] = \" , sys . getsizeof ( l3 [ 1 ])) print ( \"Size of l4[1] = \" , sys . getsizeof ( l4 [ 1 ])) Out: Shallow Copy Example - Manual l3 = [1, [1, 2, 3]] l4 = [1, [1, 2, 3]] id(l3) = 140486838605384 id(l4) = 140486838202312 l3 == l4 True l3 is l4 False id(l3[1]) = 140486839016584 id(l4[1]) = 140486839016584 l3[1] == l4[1] True l3[1] is l4[1] True --------------------------------------------------------------------------- NameError Traceback (most recent call last) <ipython-input-14-607e640db462> in <module>() 19 print(\"l3[1] is l4[1]\", l3[1] is l4[1]) 20 ---> 21 print(\"Size of l3 = \",sys.getsizeof(l3)) 22 print(\"Size of l4 = \",sys.getsizeof(l4)) 23 NameError: name 'sys' is not defined Here, * values of l3 and l4 are same * but ids of l3 and l4 are different * nested/child object of l3 is not directly copied to l4 instead the reference of that child is provided. * the id of l3[1] & l4[1] are same, means changes in l4[0] will affect l3[0]. * sizes of l3 & l4 are different * sizes of l3[1] & l4[1] are different print ( \" \\n Shallow Copy Example - copy.copy()\" ) import copy import sys l3 = [ 1 , l0 ] l4 = copy . copy ( l3 ) # some value of l3 are copied to l4 and reference of some are passed to l4 print ( \"l3 = \" , l3 ) print ( \"l4 = \" , l4 ) print ( \"id(l3) =\" , id ( l3 )) print ( \"id(l4) = \" , id ( l4 )) print ( \"l3 == l4\" , l3 == l4 ) #checks value-wise print ( \"l3 is l4\" , l3 is l4 ) #checks object identity-wise print ( \"id(l3[1]) =\" , id ( l3 [ 1 ])) print ( \"id(l4[1]) = \" , id ( l4 [ 1 ])) print ( \"l3[1] == l4[1]\" , l3 [ 1 ] == l4 [ 1 ]) print ( \"l3[1] is l4[1]\" , l3 [ 1 ] is l4 [ 1 ]) print ( \"Size of l3 = \" , sys . getsizeof ( l3 )) print ( \"Size of l4 = \" , sys . getsizeof ( l4 )) print ( \"Size of l3[1] = \" , sys . getsizeof ( l3 [ 1 ])) print ( \"Size of l4[1] = \" , sys . getsizeof ( l4 [ 1 ])) Out: Shallow Copy Example - copy.copy() l3 = [1, [1, 2, 3]] l4 = [1, [1, 2, 3]] id(l3) = 140486838153032 id(l4) = 140486838151368 l3 == l4 True l3 is l4 False id(l3[1]) = 140486839016584 id(l4[1]) = 140486839016584 l3[1] == l4[1] True l3[1] is l4[1] True Size of l3 = 80 Size of l4 = 104 Size of l3[1] = 88 Size of l4[1] = 88 Here, * Results are same as Manual shallow copy. Except, * sizes of l3 & l4 are different * sizes of l3[1] & l4[1] are same print ( \" \\n Deep Copy Example - Manual\" ) import copy import sys l5 = [ 1 , l0 ] l6 = [ 1 , list ( l0 )] # all value of l5 are copied to l6 print ( \"l5 = \" , l5 ) print ( \"l6 = \" , l6 ) print ( \"id(l5) =\" , id ( l5 )) print ( \"id(l6) = \" , id ( l6 )) print ( \"l5 == l6\" , l5 == l6 ) #checks value-wise print ( \"l5 is l6\" , l5 is l6 ) #checks object identity-wise print ( \"id(l5[1]) =\" , id ( l5 [ 1 ])) print ( \"id(l6[1]) = \" , id ( l6 [ 1 ])) print ( \"l5[1] == l6[1]\" , l5 [ 1 ] == l6 [ 1 ]) print ( \"l5[1] is l6[1]\" , l5 [ 1 ] is l6 [ 1 ]) print ( \"Size of l5 = \" , sys . getsizeof ( l5 )) print ( \"Size of l6 = \" , sys . getsizeof ( l6 )) print ( \"Size of l5[1] = \" , sys . getsizeof ( l5 [ 1 ])) print ( \"Size of l6[1] = \" , sys . getsizeof ( l6 [ 1 ])) Out: Deep Copy Example - Manual l5 = [1, [1, 2, 3]] l6 = [1, [1, 2, 3]] id(l5) = 140486838605384 id(l6) = 140486838226760 l5 == l6 True l5 is l6 False id(l5[1]) = 140486839016584 id(l6[1]) = 140486838253000 l5[1] == l6[1] True l5[1] is l6[1] False Size of l5 = 80 Size of l6 = 80 Size of l5[1] = 88 Size of l6[1] = 112 Here, * values of l5 and l6 are same * but ids of l5 and l6 are different * nested/child object of l5 is directly copied to l6 instead of passing the reference * the id of l5[1] & l6[1] are different, means changes in l6[0] will not affect l5[0] * sizes of l5 & l6 are same * sizes of l5[1] & l6[1] are different print ( \" \\n Deep Copy Example - copy.deepcopy()\" ) import copy import sys l5 = [ 1 , l0 ] l6 = copy . deepcopy ( l5 ) # all value of l5 are copied to l6 print ( \"l5 = \" , l5 ) print ( \"l6 = \" , l6 ) print ( \"id(l5) =\" , id ( l5 )) print ( \"id(l6) = \" , id ( l6 )) print ( \"l5 == l6\" , l5 == l6 ) #checks value-wise print ( \"l5 is l6\" , l5 is l6 ) #checks object identity-wise print ( \"id(l5[1]) =\" , id ( l5 [ 1 ])) print ( \"id(l6[1]) = \" , id ( l6 [ 1 ])) print ( \"l5[1] == l6[1]\" , l5 [ 1 ] == l6 [ 1 ]) print ( \"l5[1] is l6[1]\" , l5 [ 1 ] is l6 [ 1 ]) print ( \"Size of l5 = \" , sys . getsizeof ( l5 )) print ( \"Size of l6 = \" , sys . getsizeof ( l6 )) print ( \"Size of l5[1] = \" , sys . getsizeof ( l5 [ 1 ])) print ( \"Size of l6[1] = \" , sys . getsizeof ( l6 [ 1 ])) Out: Deep Copy Example - copy.deepcopy() l5 = [1, [1, 2, 3]] l6 = [1, [1, 2, 3]] id(l5) = 140486838138056 id(l6) = 140486838211656 l5 == l6 True l5 is l6 False id(l5[1]) = 140486839016584 id(l6[1]) = 140486838168328 l5[1] == l6[1] True l5[1] is l6[1] False Size of l5 = 80 Size of l6 = 96 Size of l5[1] = 88 Size of l6[1] = 96 Here, * Results are same as Manual Deep copy. Except, * sizes of l5 & l6 are different * sizes of l5[1] & l6[1] are different Two problems often exist with deep copy operations that don\u2019t exist with shallow copy operations: Recursive objects (compound objects that, directly or indirectly, contain a reference to themselves) may cause a recursive loop. Because deep copy copies everything it may copy too much, such as data which is intended to be shared between copies.","title":"Deep copy"},{"location":"lang/python/Python-Django/","text":"Intro Why should we use Django MVC Architecture Models Fields Field Options Views Templates Project Structure WSGI: Web Server Gateway Interface Rename Django Project Workflow django-admin.py Vs manage.py Uses Clean Database Load initial data / fixtures dump data / save DB data Check production readyness Run Dev server makemigrations into files migrate changes into db makemigrations into files Clean Migration Files Features Database Set CharSet MySQL Prerequisites Do Django models support multiple-column primary keys? Does Django support NoSQL databases? Using Multiple Databases in Django Migrations in Django ORM - Object Relational Mapper QuerySet Features: Iteration Slicing len() list() bool() QuerySet Operations: Field Lookups Custom Lookups & Transforms queries which do not return QuerySet all() distinct() filter() select_for_update() raw() F() order_by() exclude() annotate() reverse() values() values_list() extra() only() defer() dates() datetimes() none() union() intersection() difference() select_related() prefetch_related() using() 1 + N Problems Models Query Manager Manager names Custom Manager Inheritance style in django? Abstract base class Multi-table Inheritance Proxy models Extend User Model (Custom User Model) Using a Proxy Model Using One-To-One Link with a User Model (Profile) Creating a Custom User Model Extending AbstractBaseUser Creating a Custom User Model Extending AbstractUser Conclusion class Meta Options Views Function Based Generic View Class Based View URLs using view function using class based view including app urls django 2.0: using path django <=1.9: using url Static files In Production In Developement Templates Middlewares Custom Middleware Function Based Custom Middleware Class Based Custom Middleware Settings Place in settings.py Separated into production & development environments like STRICT SEPERATION FROM CODE Python Decouple Signals Built-in Signals Request/Response Signals Way of connecting/registering signals using <signal>.connect using receiver() decorator Asynchronous Signals Using Celery Installation Task Queue System - Celery Message Broker System - RabbitMQ Setup Code Enable Celery Write Task Celery vs RabiitMQ State Management Theory Stateless Session Anonymous Session Enabling the session Configuring The Session Engine Using Database-Backed Sessions Using Cached Sessions Using File-Based Sessions Using Cookie-Based Sessions Cookies What Why How Uses: Cache Why Architecture - Django Production Servers Web Server nginx (Pronounced as: Engine X) Application Server gunicorn (Pronounced as: gee-unicorn) DB Asynchronous Task Queue Celery Cron jobs Message Broker Solutions RabbitMQ Redis Amazon SQS Caching Solution Memcached Monitoring Graphite Statsd Sentry - logging New Relic Supervisor Stack Flow Working Deployment - Production Environment How to deploy django application in Production checklist critical settings Environment Related Settings HTTPS Performance Optimizations Error Reporting Testing Run Test Cases Security CSRF - Cross Site Request Forgery Why CSRF? Is it required in REST Django REST Framewok Some reasons you might want to use REST framework: REST API HTTP Request Methods (HTTP verbs) HTTP Response Codes Serializers Implementations Relations Writable Nested Serializers class Meta Options Misc Views Custom/Disable Request Methods in ViewSet mapping for views from ViewSet using as_view() adding custom routes/action to the existing ViewSet URLs Routers actions using base_name: how to use namespace (provided in url patterns) adding custom routes/action urls to the existing Router or urlpatterns API Versioning Configurations Uses Allow CORS (Cross Origin Resource Sharing) in DRF Using Custom Middleware class Using package django-cors-headers Creating Schema from API Setting Media URL & ROOT Site Wide App Based Permission request methods level permissions (in ViewSet) objects level permission Exception/Http response Authentication Basic Auth Session Auth Token Auth JWT (JSON Web Token) django-rest-auth (Register, Login, Logout, Reset, Change..) djoser django-templated-mail Testing Testing ViewSet using: Security Vulnerabilities CSRF (Cross Site Request Forgery) XSS (Cross Site Script) Vulnerables Web Client Local/ Session Storage Cookies (JWT/Auth) Misc Running Multiple Host (website) from Single Django Project Get request URL string Get slugs from url Microservice Based on REST To Do: * Project Structure * REST App * App * Working: Re-phrase * Django Form * UUID Source: * https://docs.djangoproject.com/en/1.11/contents/ * https://docs.djangoproject.com/en/1.11/topics/ * https://www.ibm.com/developerworks/library/os-django/index.html * https://www.edureka.co/blog/django-tutorial/ Intro # Django is an open source Web development framework for the Python Designed to be loosely coupled and tightly cohesive, meaning that different parts of the framework, while connected to one another, are not dependent on one another DRY principle Why should we use Django # modular ease the administration by auto-generated web admin pre-packaged APIs template system to avoid code duplication enables to define URL for gives function seperates business logic from HTML everything is in python MVC Architecture # MTV - Model, Template, View Similar to MVC Models # Describes database schema & data structure Fields # BinaryField BigAutoField BigIntegerField CharField DateField DateTimeField DecimalField DurationFields EmailField IntegerField BooleanField TextField ImageField FileField FilePathField FloatField GenericIPAddressField AutoField ForeignKey ManytoOne solution ManyToMany OneToOne SlugField TimeField URLField UUIDField Field Options # blank null primary_key max_length choices validators db_columns db_index db_tablespace default editable help_text error_messages auto_now auto_now_add unique unique_for_date unique_for_month unique_for_year verbose_name Views # Same as Controller in MVC Controls what a user sees it retrieves data from appropriate model, executes any calculation on data and pass it to template 5 Module Name: HttpResponse, template.render(templatename),from django.shortcuts import render(req,temp_name,context), get_object_or_404, Templates # Same as View in MVC describes how user sees data & info describes how tha data recieved from views should be changed/formatted for display on the page Note: According to Django the framework + URL config feature itself is known as Controller. Project Structure # Project (just a container)/ | |-----project/ | |--__init__.py | |--settings.py | |--urls.py | \u2514--wsgi.py | |-----app1/ | | | |-----app2-RESTful/ | | | |-----manage.py | | | \u2514-----db.sqlite3 Project: main project package settings.py: python module (module level) represents django settings urls.py: represents site-wide urls configuration (includes apps also) wsgi.py: Web-server-gateway-interface: djangos's primary deployement platform wsgi.py gets created on \"startproject\" contains \"application\" callable & \"DJANGO_SETTINGS_MODULE\" django setting eviroment variable DJANGO_SETTINGS_MODULE: locates setting file, default: project_name.settings.py application: used by server to communicate with code, default: get_wsgi_application() App1 App2- REST-ful WSGI: Web Server Gateway Interface # an interface between web server & application contains some statements, set of rules its not a software/library/framework WSGI compliant server will able to communicate with a WSGI compliant web app in WSGI, WSGI application has to be callable & it needs to be given to web server, so web server can call web application whenever it receives a request Rename Django Project # Your django project structure ProjectName/ manage.py ProjectName/ __init__.py settings.py urls.py wsgi.py changes required at 4 places settings.py ROOT_URLCONF = 'NewProjectName.urls' WSGI_APPLICATION = 'NewProjectName.wsgi.application' wsgi.py os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"NewProjectName.settings\") manage.py os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"NewProjectName.settings\") Workflow # runserver --> web-server gateway interface WSGI--> DJANGO_SETTING_MODULE env var -->by default project.Setting.py (site folder) --> ROOT_URLCONF --> url.py (site url file location) --> Browser --> URL --> DNS + PortNo from application (protocol based)--> IP + port --> http request--> Server -->web-server gateway interface WSGI--> DJANGO_SETTING_MODULE env var -->by default project.Setting.py (site folder) --> ROOT_URLCONF --> url.py (site url file location) --> urlpattern --> url scanning --> matched view --> model + http response + template --> web page django-admin.py Vs manage.py # Django-admin.py: It is a Django's command line utility for administrative tasks. Manage.py: It is an automatically created file in each Django project. It is a thin wrapper around the Django-admin.py. Uses # Clean Database # python manage.py flush Load initial data / fixtures # src: https://coderwall.com/p/mvsoyg/django-dumpdata-and-loaddata #prerequisites- <app_dir>/<fixtures>/<fixture_file.json> #else provide fixture files path python manage.py loaddata <fixture_file_name> dump data / save DB data # src: https://coderwall.com/p/mvsoyg/django-dumpdata-and-loaddata #whole db python manage.py dumpdata > [ db.json ] #app wise python manage.py dumpdata [ app_name ] > [ app.json ] #table/model wise python manage.py dumpdata [ app.model ( in small )] > [ app_model.json ] #exclude some table python manage.py dumpdata --exclude [ app.model ( in small )] > [ db.json ] #specify indentation python manage.py dumpdata --indent 4 > [ db.json ] #specify output format python manage.py dumpdata --format [ json/xml/yaml ] > [ db.json ] #backup whole db fresh (without any Integrity Issue) python manage.py dumpdata --exclude auth.permission --exclude contenttypes > db.json Check production readyness # python manage.py check --deploy Run Dev server # python manage.py runserver 0 .0.0.0:8000 makemigrations into files # python manage.py makemifrations <app_name> migrate changes into db # python manage.py migrate makemigrations into files # python manage.py makemifrations <app_name> Clean Migration Files # Features # Admin Interface (CRUD: Create, Retrieve, Update, Delete) Templating Form Handling Internationalization Session, User management, role-based permissions ORM (Object-Relational Mapping) Testing Framework Best Documentation Database # site folder setting.py DATABASES fill dict entries ENGINE: type of db django.db.backends.sqlite3 django.db.backends.mysql django.db.backends.postgresql_psycopg2 django.db.backends.oracle NAME: name of database USERNAME(optional) PASSWORD(optional) HOST(optional) DATABASES = { 'sqlite3' : { 'ENGINE' : 'django.db.backends.sqlite3' , 'NAME' : os . path . join ( BASE_DIR , 'db.sqlite3' ), }, 'default' : { 'ENGINE' : 'django.db.backends.mysql' , 'NAME' : 'employees' , 'USER' : 'test' , 'HOST' : 'localhost' , 'PORT' : '' , } } (optional) are required in case of DB other than sqlite. Set CharSet # By deafult django uses latin1 , its better to use unicode utf8 to support all types of language characters. So, Put this in settings.py: DATABASE_OPTIONS = dict ( charset = \"utf8\" ) MySQL # Prerequisites # sudo apt install python-dev libmysqlclient-dev pipenv install mysqlclient login to root sudo mysql -u root -p create another user & grant all access use ` <db_name> ` CREATE USER 'dev' @ 'localhost' IDENTIFIED BY 'password' ; GRANT ALL PRIVILEGES ON *.* TO 'dev' @ 'localhost' WITH GRANT OPTION ; use dev user in django install workbench (optional) sudo apt install mysql-workbench Do Django models support multiple-column primary keys? # Ans No. Only single-column primary keys are supported. But using the unique_together model option we can achieve it. Does Django support NoSQL databases? # Ans No. Not officially. But can using 3rd party forks like Django non-rel. Using Multiple Databases in Django # Different ways of using multiple databases: * QuerySet's \"using\" Method # This will run on the 'default' database. Author . objects . all () # So will this. Author . objects . using ( 'default' ) . all () # This will run on the 'other' database. Author . objects . using ( 'other' ) . all () Model.save()'s \"using\" Parameter choice_one = Choice . objects . get ( pk = 1 ) choice_one . text = \"New Text\" choice_one . save ( using = \"Polls_DB\" ) Database Routing Migrations in Django # applies changes in models to database tables like deleteing/adding models/fields commands makemigrations creates migration files as per changes in models inside app-->migrations-->0001_initial.py, contains Migration class with all the operations/changes does not applies changes in DB python manage . py makemigrations migrate applies migration files to DB python manage . py migrate sqlmigrate generates sql from migration files python manage . py sqlmigrate polls_app 0001 _initial ORM - Object Relational Mapper # defines your data model entirely in python provides rich & dynamic database-access API QuerySet Features: # Iteration # for e in Entry . objects . all (): print ( e . headline ) Slicing # len() # record_count = len ( Entry . objects . all ()) # will return length of result list list() # entry_list = list ( Entry . objects . all ()) # convert to list bool() # bool ( Entry . objects . filter ( age = 21 )) # same as EXISTS, will return True if there are results QuerySet Operations: # Field Lookups # Parameter passed using \",\" comma == AND For OR, use exclude() field__gt: greater than field__gte: greater than equal to field__lt: less than field__lte: less than equal to list slicing [:5] == for starting 5 records list slicing some_queryset.reverse()[:5] == for last 5 records field__exact field__iexact: non-casesensitive match field__contains : Entry.objects.get(headline__contains='Lennon'), same as LIKE %Lennon% field__icontains : Entry.objects.get(headline__icontains='LeNnon'), same as ILIKE %LenNon% field__in : Entry.objects.filter(id__in=[1, 3, 4]), same as SELECT ... WHERE id IN (1, 3, 4); field__startswith: Entry.objects.filter(headline__startswith='Lennon') field__istartswith: Entry.objects.filter(headline__istartswith='LeNnon') field__endswith: Entry.objects.filter(headline__endswith='Lennon') field__iendswith: Entry.objects.filter(headline__iendswith='Lennon') field__range : Entry.objects.filter(pub_date__range=(start_date, end_date)), same as SELECT ... WHERE pub_date BETWEEN '2005-01-01' and '2005-03-31'; field__date: Entry.objects.filter(pub_date__date=datetime.date(2005, 1, 1)) Entry.objects.filter(pub_date__date__gt=datetime.date(2005, 1, 1)) year month day week week_day quarter time : Entry.objects.filter(pub_date__time=datetime.time(14, 30)) hour minute second isnull : Entry.objects.filter(pub_date__isnull=True), same as SELECT ... WHERE pub_date IS NULL; regex : Entry.objects.get(title__regex=r'^(An?|The) +') iregex : Entry.objects.get(title__iregex=r'^(An?|The) +') Custom Lookups & Transforms # e.g. : title__slug='first-blog' TODO queries which do not return QuerySet # get() returns object MultipleObjectsError get_or_create() update_or_create() bulk_create() count() return count in_bulk() iterator() latest() earliest() first() last() aggreagte() returns dict exists() return True/False delete() returns the number of objects deleted and a dictionary with the number of deletions per object type. update() returns the number of objects updated all() # same as SELECT * distinct() # same as SELECT DISTINCT Author . objects . distinct () Entry . objects . order_by ( 'blog' ) . distinct ( 'blog' ) # write parameters in same order in both Entry . objects . order_by ( 'blog' ) . distinct ( 'blog' ) # if 'blog' is foreign Model, then by deafult order_by will take it as 'blog__name', so explicity define it as 'blog__id' or 'blog__pk', else will not produce any result filter() # select_for_update() # will lock the row(s) till end of transaction raw() # raw(raw_query, params=None, translations=None) F() # for updating (increment/decrement) column value without fetching the current value in python memory from django.db.models import F User . object . filter ( pk = 1 ) . update ( salary = F ( 'salary' ) + 1000 ) # here F is usefull order_by() # User . objects . filter ( age = 21 ) . order_by ( '-salary' , 'name' ) # negative salary means in descending order User . objects . filter ( age = 21 ) . order_by ( '?' ) # random order (expensive) User . objects . order_by ( 'id' ) exclude() # Entry . objects . exclude ( pub_date__gt = datetime . date ( 2005 , 1 , 3 )) # __gt: greater than annotate() # from django.db.models import Count u = User . objects . annotate ( Count ( ' reverse() # to reverse the order values() # returns dictionary object instead list query result Blog . objects . values () Blog . objects . values ( 'id' , 'name' ) values_list() # same as values() but returns tuple extra() # extra(select=None, where=None, params=None, tables=None, order_by=None, select_params=None) Sometimes, the Django query syntax by itself can\u2019t easily express a complex WHERE clause. For these edge cases, Django provides the extra() QuerySet modifier \u2014 a hook for injecting specific clauses into the SQL generated by a QuerySet. only() # opposite to defer name those, which should not get deferred except rest defer() # to defer some fields from a large data base passing field to it will not load those columns in queryset from DB, but we can access to field if we need by calling we can never defer pk dates() # datetimes() # none() # returns null queryset instance of EmptyQuerySet union() # same as SELECT * FROM TABLE1 UNION SELECT * FROM TABLE2 queryset1.union(queryset2) intersection() # difference() # select_related() # returns Foreign key related objects without hitting database #Hits the database. e = Entry . objects . get ( id = 5 ) #Hits the database again to get the related Blog object. b = e . blog #Hits the database. e = Entry . objects . select_related ( 'blog' ) . get ( id = 5 ) #Doesn't hit the database, because e.blog has been prepopulated #in the previous query. b = e . blog prefetch_related() # To solve the 1 + N problem in all types of ORM after Django 1.4 using() # for choosing databse for the queryset 1 + N Problems # TODO Models # Query Manager # A class An interface through which database query operations are performed to Django models by default Manager for each Model is objects e.g. Questions. object .all() Manager names # if you want to rename objects e.g. from django.db import models class Person ( models . Model ): #... people = models . Manager () #Uses Person . objects . all () #AttributeError Person . people . all () Custom Manager # if you want to define some more query methods Extend models.Manager class Code: https://gist.github.com/toransahu/62cd045891656b90f7e18a492e9b81db Inheritance style in django? # Abstract base class # you define a base class model as a abstract class cannot instantiate cannot use as a regular model cannot create a table in db you want to reuse the code for attributes (fields/methods) of the base class into other models each child model will have their own table in db e.g. class CommonInfo ( models . Model ): name = models . CharField ( max_length = 100 ) age = models . PositiveIntegerField () class Meta : abstract = True class Student ( CommonInfo ): home_group = models . CharField ( max_length = 5 ) Multi-table Inheritance # This style is used when subclassing an existing model & need each model to have its own database table e.g. from django.db import models class Place ( models . Model ): name = models . CharField ( max_length = 50 ) address = models . CharField ( max_length = 80 ) class Restaurant ( Place ): serves_hot_dogs = models . BooleanField ( default = False ) serves_pizza = models . BooleanField ( default = False ) All of the fields of Place will also be available in Restaurant, although the data will reside in a different database table. So these are both possible: Place.objects.filter ( name = \"Bob's Cafe\" ) Restaurant.objects.filter ( name = \"Bob's Cafe\" ) Note: The inheritance relationship introduces links between the child model and each of its parents (via an automatically-created OneToOneField) Proxy models # You can use this model, If you only want to modify the Python level behavior of the model (means any methods/functions), without changing the models fields unlike multi-table inheritance, if we only want to add some methods change the default manager change the default ordering and at the same time we don't want to create different tables for each model we can inherit the base model & can define child models as proxy e.g. from django.db import models class Person ( models . Model ): first_name = models . CharField ( max_length = 30 ) last_name = models . CharField ( max_length = 30 ) class MyPerson ( Person ): class Meta : proxy = True def do_something ( self ): #... pass Extend User Model (Custom User Model) # Some modifications on top of Django's default User Model just to fit our web appplication. Source: https://simpleisbetterthancomplex.com/tutorial/2016/07/22/how-to-extend-django-user-model.html 4 Ways to extend existing User Model: Using a Proxy Model # Proxy Model: Model inheritance without creating a new table in database. Used to change the deafult behaviour of an existing model (e.g. methods, ordering by) without affecting exisitng database table When used: When you don't need to save extra information in the databse, but want to add extra methods or change query Manager Code: https://gist.github.com/toransahu/676d4a8c29b5cbd7737ff1c0a0b4dfc4 Using One-To-One Link with a User Model (Profile) # One-To-One Link: one to one relationship between two Django Models Both Models are normal django model implemented using models.OneToOneField(SomeModelHere) When Should Use when you need to store some extra information about the exisitng User Model that's not related to authentication process called as User Profile How to Use Create User model & Profile model Create OneToOneField in Profile model of User model Define signals so our Profile model will be automatically created/updated when we create/update User instances We'll use post_save signals for this purpose follow e.g. https://gist.github.com/toransahu/f0bd7313c24605ce92d38a7b09caf4b4 Creating a Custom User Model Extending AbstractBaseUser # Custom User Model Extending AbstractBaseUser a new User model inheriting AbtractBaseUser class require extra care & AUTH_USER_MODEL reference in settings.py ideally it should be done in starting of the project When Should Use when specific requirement in authentication process e.g. change identification token from username to emailId or mobile_number Code: https://gist.github.com/toransahu/4a6314f40676a75b0288953f5c0e8b1c Creating a Custom User Model Extending AbstractUser # Custom User Model Extending AbstractUser a new User model inheriting AbtractUser class require extra care & AUTH_USER_MODEL reference in settings.py ideally it should be done in starting of the project When Should Use when we are perfectly happy with how Django handles the authentication process and we don't want to change anything on it yet we want to add some extra information directly in the User model without having to create extra class like Profile Code: https://gist.github.com/toransahu/0ce910494dedb8b9f2774b751f45b559 Whenever we define custom User Model like this from django.db import models from django.contrib.auth.models import AbstractUser class User ( AbstractUser ): name = models . CharField ( max_length = 100 , blank = True , null = True ) we need to specify custom user model in settings.py like AUTH_USER_MODEL = \u2018 your_app . User ' and we can refer this User model in our code either as User = get_user_model () or User = settings . AUTH_USER_MODEL # use when define a foreign relationship, to make it resuable app Conclusion # Proxy Model: You are happy with everything Django User provide and don\u2019t need to store extra information. User Profile: You are happy with the way Django handles the auth and need to add some non-auth related attributes to the User. Custom User Model from AbstractBaseUser: The way Django handles auth doesn\u2019t fit your project. Custom User Model from AbstractUser: The way Django handles auth is a perfect fit for your project but still you want to add extra attributes without having to create a separate Model. class Meta Options # TODO: Views # Function Based Generic View # with template (by rendering) from django.shortcuts import render def home ( request ): return render ( request , 'home.html' ) without template : using HttpResponse from django.http import HttpResponse def home ( request ): return HttpResponse ( \"Hello World\" ) Need to write conditional branch for different HTTP request type like POST, GET, PUT Need to provide view method name in URL Disadvantage: Cannot extend Class Based View # Module: from django.views import View Inherit View class Need to define get(), post() like HTTP methods Need to provide ClassName.as_view() in URL Advantage: Can be extended by sub classes from django.http import HttpResponse from django.views import View class MyView ( View ): def get ( self , request ): # <view logic> return HttpResponse ( 'result' ) ``` ## Class Based Generic View * Module : from django.views.generic import ListView * Can inherit ListView , TemplateView ... class * No need to define request handler methods * set model attribute to Model Class * Need to provide ClassName . as_view () in URL ``` python from django.views.generic import ListView from books.models import Publisher class PublisherList ( ListView ): model = Publisher URLs # using view function # urlpatterns = [ path ( '/' , views . home (), name = 'home' ),] using class based view # urlpatterns = [ path ( '/' , views . IndexView . as_view (), name = 'index' ),] including app urls # from django.urls import path , include urlpatterns = [ path ( '' , include ( 'home.urls' )),] django 2.0: using path # from django.urls import path , include django <=1.9: using url # from django.conf.urls import url Static files # In Production # set STATIC_ROOT in settings.py run manage.py collectstatic In Developement # STATICFILES_FINDERS = ( 'django.contrib.staticfiles.finders.FileSystemFinder' , 'django.contrib.staticfiles.finders.AppDirectoriesFinder' ) STATICFILES_DIRS = [ os . path . join ( BASE_DIR , 'static' ), '/var/www/static/' , ] STATIC_URL = '/static/' Templates # Contains Markups JS, CSS, HTML, XML django tags Variables/Logic blocks {% extends 'home/base.html' %} {% load static %} Comments {# CSS files#} Middlewares # Middleware is framework of hooks to Django's request/response processing its light and low-level plugin system for making global changes in Django's input/output each middleware component in responsible for performing some specific task Some usage of middlewares in Django is: Session management User authentication Cross-site request forgery protection Content Gzipping, etc. Custom Middleware # a middleware factory (i.e. outer function or a class) is a callable it takes an argument called get_response get_response might be an actual Django view if the middleware is last listed else, get_response might be a next middleware and it returns a middleware (or ultimately a response ) a middleware is also a callable which takes an arg called request and it returns a response Function Based Custom Middleware # def simple_middleware ( get_response ): # One-time configuration and initialization. def middleware ( request ): # Code to be executed for each request before # the view (and later middleware) are called. response = get_response ( request ) # Code to be executed for each request/response after # the view is called. return response return middleware Class Based Custom Middleware # class SimpleMiddleware : def __init__ ( self , get_response ): self . get_response = get_response # One-time configuration and initialization. def __call__ ( self , request ): # Code to be executed for each request before # the view (and later middleware) are called. response = self . get_response ( request ) # Code to be executed for each request/response after # the view is called. return response Settings # Place in settings.py # Separated into production & development environments like # - base_settings.py - dev_settings.py - prod_settings.py - settings.py STRICT SEPERATION FROM CODE # Python Decouple # Source: https://pypi.org/project/python-decouple/ Usage Where the settings data are stored? Ini file Env file How it works? Understanding the CAST argument Signals # Signals are a strategy to allow decoupled applications to get notified when some event occurs. Source: https://simpleisbetterthancomplex.com/tutorial/2016/07/28/how-to-create-django-signals.html where to create <signals_module>.py ? anywhere recommended: inside apps Built-in Signals # django.db.models.signals.pre_init: receiver_function(sender, *args, **kwargs) django.db.models.signals.post_init: receiver_function(sender, instance) django.db.models.signals.pre_save: receiver_function(sender, instance, raw, using, update_fields) django.db.models.signals.post_save: receiver_function(sender, instance, created, raw, using, update_fields) django.db.models.signals.pre_delete: receiver_function(sender, instance, using) django.db.models.signals.post_delete: receiver_function(sender, instance, using) django.db.models.signals.m2m_changed: receiver_function(sender, instance, action, reverse, model, pk_set, using) Request/Response Signals # django.core.signals.request_started: receiver_function(sender, environ) django.core.signals.request_finished: receiver_function(sender, environ) django.core.signals.got_request_exception: receiver_function(sender, request) Way of connecting/registering signals # using <signal>.connect # Need to register signals inside ready() in AppConfig class in <app>.apps.py Need to define default_app_config = '<app>.apps.<App>Config' in <app>.__init__.py ignore if '<app>.apps.<App>Config' is inside INSTALLED_APPS insettings.py Issues: In django 2.0+, not working fine. Throwing error: AppRegistryNotReady: Apps aren't loaded yet. e.g.: https://gist.github.com/toransahu/c3870b4ad58bde5a9b9563f7e0883729 using receiver() decorator # Only need to import signals inside ready() in AppConfig class in <app>.apps.py Need to define default_app_config = '<app>.apps.<App>Config' in <app>.__init__.py ignore if '<app>.apps.<App>Config' is inside INSTALLED_APPS insettings.py No issues till yet e.g.: https://gist.github.com/toransahu/c3870b4ad58bde5a9b9563f7e0883729 Asynchronous Signals Using Celery # src https://simpleisbetterthancomplex.com/tutorial/2017/08/20/how-to-use-celery-with-django.html http://docs.celeryproject.org/en/latest/django/first-steps-with-django.html Installation # Task Queue System - Celery # pip install celery Message Broker System - RabbitMQ # src: http://docs.celeryproject.org/en/latest/getting-started/brokers/rabbitmq.html#broker-rabbitmq sudo apt install rabbitmq-server Setup # no need to define any setup, but can set credentials for rabbitmq-server Code # Enable Celery # Define celery instance in project level inside celery.py Load celery when django starts import the celery instance app to init .py in project package Write Task # code: https://gist.github.com/toransahu/d01c7374c5317a908b99ac03cf24cc11 create tasks.py inside django app celery searches for tasks inside tasks.py modules either import celery app instance & use from backend.celery import app @app . task def foo (): pass or use shared_task from celery import shared_task @shared_task def foo (): pass set broker_url inside settings.py every celery config variables start with CELERY_ CELERY_BROKER_URL = 'amqp://localhost' start rabbitmq starts automatically on boot sudo systemctl enable rabbitmq-server sudo systemctl start rabbitmq-server start celery worker need to run inside src folder need to be in virtual env celery -A project_name worker -l info or create script to start celery cd ethereal-machines-backend/src (where manage.py is) vim start_celery.sh make sure to write #! /bin/bash in first line chmod a+x start_celery.sh start_celery.sh should look like this: https://gist.github.com/toransahu/31874def1bd661db676d0dfe02e1c651 Celery vs RabiitMQ # Celery is a queue Wrapper/Framework which takes away the complexity of having to manage the underlying AMQP mechanisms/architecture that come with operating RabbitMQ directly Celery is just a very high level of abstraction to implement the producer / consumer of events. It takes out several painful things you need to do to work for example with rabbitmq. Celery itself is not the queue. The events queues are stored in the system of your choice, celery helps you to work with such events without having to write the producer / consumer from scratch. State Management # Session: Anonymous Session Cookies Theory # Stateless # Meaning navigating from one web page to another will not retain infos of first one. There is no persistence between one request and the next, and there is no way the server can tell whether successive requests come from the same person e.g. HTTP, REST This lack of state is managed using sessions. Session # are a semi-permanent, two-way communication between your browser and the web server. The session framework lets you store and retrieve arbitrary data on a per-site-visitor basis It stores data on the server side and abstracts the sending and receiving of cookies can be implemented through middleware In client side cookies contain a session ID \u0093 not the data itself (unless youre using the cookie based backend) INSTALLED_APPS = [ 'django.contrib.sessions' , ] MIDDLEWARE = [ 'django.contrib.sessions.middleware.SessionMiddleware' , ] Anonymous Session # to keep track of data relevant to your visit the web server can only record what you did, not who you are Enabling the session # Using middleware MIDDLEWARE_CLASSES in setting.py should contain 'django.contrib.sessions.middleware.SessionMiddleware' by deafult enabled Configuring The Session Engine # by default stored in database using the model django.contrib.sessions.models.Session can be configured to store session data on file system or in cache Using Database-Backed Sessions # need to add 'django.contrib.sessions' to your INSTALLED_APPS setting Using Cached Sessions # for better performance, for making web pages more responsive local memory cache backend doesnt retain data long enough to be a good choice use third-party like Memcached cache backend, else use file system or DB based session two different implementation: Only cache Set SESSION_ENGINE to \"django.contrib.sessions.backends.cache\" Cache + DB (Persistent) set SESSION_ENGINE to \"django.contrib.sessions.backends.cached_db\" every write to the cache will also be written to the database use the database if the data is not already in the cache Using File-Based Sessions # have to set the SESSION_ENGINE settings to \u009cdjango.contrib.sessions.backends.file\u009d Using Cookie-Based Sessions # Cookies # What # An HTTP cookie (web cookie, browser cookie) is a small piece of data that a server sends to the user's web browser. The browser may store it and send it back with the next request to the same server. module: http.cookies Why # Typically, it's used to tell if two requests came from the same browser \u2014 keeping a user logged-in, for example. How # It remembers stateful information for the stateless HTTP protocol. Uses: # Session management Logins, shopping carts, game scores, or anything else the server should remember Personalization User preferences, themes, and other settings Tracking Recording and analyzing user behavior Cache # Why # The performance of web sites and applications can be significantly improved by reusing previously fetched resources. Web caches reduce latency and network traffic and thus lessen the time needed to display a representation of a resource. By making use of HTTP caching, Web sites become more responsive. Architecture - Django Production Servers # Source : https://www.sayonetech.com/blog/how-host-your-django-project-production-server/#.WgSKV3VL9Xo Web Server # the outermost tier of the Backend(3-tiers) Apache, nginx, lighttpd, cherokee used as proxy, reverse proxy, load balancer, static data (css, html, images) dispatcher and cache it can't talk directly to Django applications nginx (Pronounced as: Engine X) # Application Server # the middle tier of the Backend(3-tiers) Gunicorn, mod_python, mod_wsgi, mod_uwsgi, FastCGI is used to handle all dynamic requests, basically based on URL pattern (view call) the Interface between the web server and the python app so that the app(or any python framework) understands the incoming requests create a Unix socket, and serve responses to nginx via the wsgi protocol - the socket passes data in both directions gunicorn (Pronounced as: gee-unicorn) # inspired from Ruby's Unicorn DB # the third tier of the Backend(3-tiers) MySQL/ Postgres/ Other databases Asynchronous Task Queue # Celery # Celery is an asynchronous task/job queue based on distributed message passing requires an external solution to send and receive messages i.e. Message Brokers like RabbitMQ, Redis focused on real-time operation, but supports scheduling as well Cron jobs # Message Broker Solutions # RabbitMQ # Redis # Amazon SQS # Caching Solution # Memcached # Monitoring # When our project is hosted, we need to monitor it using some tools to check its performance, its error logs and user interactions.We have some tools available for this. Graphite # Graphite provides real-time visualization and storage of numeric time-series data on an enterprise level. Statsd # A network daemon that runs on the Node.js platform and listens for statistics, like counters and timers, sent over UDP or TCP and sends aggregates to one or more pluggable backend services (e.g.,Graphite). Sentry - logging # Sentry is a modern error logging and aggregation platform. New Relic # A software analytics tool suite used by developers, ops, and software companies to understand how your applications are performing in development and production. Supervisor # a process control system a client/server system which allows its users to monitor and control a number of process in UNIX-like OS similar to launchd , daemontools , and runit monitors projects starts on boot Supervisord starts processes as its subprocesses, and can be configured to automatically restart them on a crash accurately shows the up/down times of the processes can asign priorities to the processes can group the processes Stack Flow # User requests from browser. Request reaches Nginx. If (request is staic) Nginx serves the request. Else if (request is dynamic) Nginx forwards the request to Application server (Gunicorn). Gunicorn receives the request, executes corresponding python (Flask) code. Gunicorn returns the response to Nginx. Nginx serves the response to the user. Working # You need both Nginx and Gunicorn (or something similar) for a proper Django deployment The complete answer is both Nginx and Gunicorn handle the request. Basically, Nginx will receive the request and if it's a dynamic request (generally based on URL patterns) then it will give that request to Gunicorn, which will process it, and then return a response to Nginx which then forwards the response back to the original client. Deployment - Production Environment # How to deploy django application in Production # https://devcenter.heroku.com/articles/getting-started-with-python#introduction https://developer.mozilla.org/en-US/docs/Learn/Server-side/Django/Deployment DEBUG = False change default SECRET_KEY (used for CRSF protection) and hide it somewhere else Run manage.py check --deploy (to check the default list of changes mentioned by django) checklist https://docs.djangoproject.com/en/1.10/howto/deployment/checklist/ checklist # in settings must be set properly for Django to provide the expected level of security; are expected to be different in each environment; enable optional security features; enable performance optimizations; provide error reporting. or Run manage.py check --deploy to list all the factors listed below take care of these things if releasing source code critical settings # SECRET_KEY Instead of hardcoding the secret key in your settings module, consider loading it from an environment variable or file import os SECRET_KEY = os . environ [ 'SECRET_KEY' ] with open ( '/etc/secret_key.txt' ) as f : SECRET_KEY = f . read () . strip () avoid committing it to source control DEBUG : set to False Environment Related Settings # ALLOWED_HOSTS When DEBUG = False, Django doesn\u2019t work at all without a suitable value for ALLOWED_HOSTS. This setting is required to protect your site against some CSRF attacks CACHE change it for production performance otimization default for developement is 'local-memory caching' instead use cache servers like Memcached using 'cached sessions' Cache servers often have weak authentication. Make sure they only accept connections from your application servers. DATABASE Database passwords are very sensitive. Keep them in environment variable or in file same as SECRET_KEY For maximum security, make sure database servers only accept connections from your application servers. If you haven\u2019t set up backups for your database, do it right now! EMAIL_BACKEND and related settings If your site sends emails, these values need to be set correctly. modify the DEFAULT_FROM_EMAIL and SERVER_EMAIL settings By default, Django sends email from webmaster@localhost and root@localhost. STATIC_ROOT and STATIC_URL Static files are automatically served by the development server. In production, you must define a STATIC_ROOT directory where collectstatic will copy them. MEDIA_ROOT and MEDIA_URL Media files are uploaded by your users. They\u2019re untrusted! Make sure your web server never attempts to interpret them. For instance, if a user uploads a .php file, the web server shouldn\u2019t execute it. HTTPS # Any website which allows users to log in should enforce site-wide HTTPS to avoid transmitting access tokens in clear. In Django, access tokens include the login/password, the session cookie, and password reset tokens. Note: You can\u2019t do much to protect password reset tokens if you\u2019re sending them by email web server must redirect all HTTP traffic to HTTPS, and only transmit HTTPS requests to Django. because: the same session cookie is used for HTTP and HTTPS. Once you\u2019ve set up HTTPS, enable the following settings. CSRF_COOKIE_SECURE Set this to True to avoid transmitting the CSRF cookie over HTTP accidentally. SESSION_COOKIE_SECURE Set this to True to avoid transmitting the session cookie over HTTP accidentally. Performance Optimizations # DEBUG = False CONN_MAX_AGE TEMPLATES Enabling the cached template loader often improves performance drastically, as it avoids compiling each template every time it needs to be rendered. Error Reporting # LOGGING Review your logging configuration before putting your website in production, and check that it works as expected as soon as you have received some traffic Customize the default error views Django includes default views and templates for several HTTP error codes. You may want to override the default templates by creating the following templates in your root template directory: 404.html, 500.html, 403.html, and 400.html. Testing # Class level testing for each app from django.test import TestCase class QuestionModelTests ( TestCase ): def test_was_published_recently_with_future_question ( self ): #do something self . assertIs ( future_question . was_published_recently (), False ) Run Test Cases # python manage.py test appname Security # CSRF - Cross Site Request Forgery # Why CSRF? # CSRF attack happens in presence of state It really boils down to the browsers ability to automatically present login credentials for any request by sending along cookies. If a session id is stored in a cookie the browser will automatically send it along with all requests that go back to the original website. This means that an attacker doesn't actually have to know authentication details to take an action as the victim user. Rather, the attacker just has to trick the victims browser into making a request, and the credentials to authenticate the request will ride along for free. Is it required in REST # No, it will be useless piece of code because REST is stateless at client-side a cookie-less REST endpoint is completely immune from CSRF attacks if there is cookie used for authentication, then we need CSRF protection HTTP/BasicAuthentication will also need CSRF protection also, if any app uses any tech to store state of app at clientside, then its not a RESTful app src: https://security.stackexchange.com/questions/166724/should-i-use-csrf-protection-on-rest-api-endpoints Django REST Framewok # Django REST framework \"djangorestframework\" is powerful & flexibal toolkit for creating web APIs. - https://stackoverflow.com/questions/671118/what-exactly-is-restful-programming Some reasons you might want to use REST framework: # The Web browsable API is a huge usability win for your developers. Authentication policies including packages for OAuth1a and OAuth2. Serialization that supports both ORM and non-ORM data sources. Customizable all the way down - just use regular function-based views if you don't need the more powerful features. Extensive documentation, and great community support. REST API # Representation State Transfer An architectural pattern for creating an API that uses HTTP as its communication method for designing network based application Resource: If we have endpoint/URI(URL or URN), lets say https://127.0.0.1/coders then we have resource. Here coders is a resource. Its nothing new, we already used to make URLs that way Representation: When a client makes a GET request to coders/toran/ client gets following JSON response { \"nickname\" : \"toran\" , \"powerLevel\" : 5 } so, this is representation in the form of JSON having metadata representation also could be XML, HTML the same applies when a client sends a request which contains a 'coder' data, its sends representation Representational State: like browsing the web a HTML page is a representation of a resource at current state (or current data) of that resource. When we submit a form, we just send a representation back to the server Representational State Transfer a client and server exchange representations of a resource, which reflects its current state or desired state. So, REST is a way for two machines to transfer the state of a resource via representations. HTTP Request Methods (HTTP verbs) # HTTP defines a set of request methods to indicate the desired action to be performed for a given resource GET The GET method requests a representation of a specified resource. GET request should only used for data retrieval. (But can also be used for submit/posting/sending data) a resource is mentioned in URL. POST Used to modify/update an existing entity of a specified resource. Do mention the object/entity of the resource in the URL to update we should use PUT and PATCH for update PUT would create a new unwanted resource when the resouce doesn't exists while updating that particular resource PATCH is perfect for partial updation But there is no restrictions using POST for updates POST /questions/<existing_question> HTTP / 1.1 Host : www.example.com/ - Used to submit a new entity/data to a specified resource. - Do not mention the object/entity of the resource in the URL while creating it. Otherwise it will give \"Resource Not Found\" error. POST /questions/ HTTP / 1.1 Host : www.example.com/ - Causes change in state of the resource - Use this if you want server to let the name, the URL object while creating a new one - Two simultaneous POST requests works fine (lets say, 1st request is updating some part & 2nd request is updating other part of an object) - The UPDATE performed by the POST method might not result in a resource that can be identified by a URI. PUT Used to create a new resource entity or overrite (Completely replaces) the existing one. For a new resource entity: PUT /questions/<new_question> HTTP / 1.1 Host : www.example.com/ To overrite an existing one PUT /questions/<existing_question> HTTP / 1.1 Host : www.example.com/ Usefull when you know the name of the entity/object Use this if you want to name the URL object while creating a new one PUT is idempotent, so if you PUT the same object twice, it has no effect (will overrite) Can create or update an object with the same URL DELETE Deletes/destroyes a specified resource object/entity/record. PATCH Used to make partial modification to an existing resource object/entity. Works differently than POST & PUT for update Need to have URL object known PATCH /users/1 HTTP / 1.1 Host : www.example.com Content-Type : application/example If-Match : \"c0b42b66e\" Content-Length : 120 [changes] where [changes] could be JSON/XML like {email:'toran.sahu@yahoo.com'} HEAD Ask for the response same as GET but without response/message body. OPTIONS Used to describe the communication option for the target resource CONNECT Establishes a tunnel to the server identified by the target resource TRACE Performs message loop-back test along the path to the target resource Note: There is a very common confusion in terminology. \"Resource\" - In URI \"app/questions/1\" here \"1\" is also know as resource and at the same time \"questions\" is also know as resource. - Some people around the globe also use \"1\" as record/entity & \"questions\" as resource. - We could generalize \"1\" as \"resource object\" and \"questions\" as \"resource class\" HTTP Response Codes # 200 (Ok) 201 (Created) 204 (No Content) 304 404 501 (Not Implemented) Serializers # Module: from rest_framework import serializers Provides a way to serialize & deserialize Model instances into representations like JSON. Serialization is mechanism of converting the state of an object into byte-stream, which can be displayed, stored. Deserialization is reverse mechanism of serialization. Note: In django its very similar to Django Form class and includes similar validation flags on the various fields, such as required, max_length and default. Implementations # Inherit classes serializers.Serializer need to write all the fields mentioned in Model (only those, which we want to use here) need to define create() & update() method to create/update new Model instance from validated data (representaion/JSON) serializers.ModelSerializer Inside Meta class mention model inside Meta class; model = Snippet i.e. Class fields = ('id', ....,'title') i.e. tuple Automatically implements default create() and update() methods Note : If we want to include url in fields, then the base_name (in case of routers) in urls.py should same as the name of Model in lower case, alternatively don't mention base_name serializers.HyperlinkedModelSerializer The only difference is, as in citation you included, that primary and foreign keys are represented by URLs that point to those resources, instead of just actual key values. The benefit is that you will not have to construct resource URLs in your frontend when you want to retrieve related objects. Relations # src: http://www.django-rest-framework.org/api-guide/relations/#serializer-relations Writable Nested Serializers # scr: http://www.django-rest-framework.org/api-guide/relations/#writable-nested-serializers code: https://gist.github.com/toransahu/221371c981c20f0b9c645019a53b90c7 by default django does not provides write access in case of nested model objects & their model serializers strategy create 2 models assign M2M/Foreign key field in one model write serializers for both the models keep foreign model serializers normal/default for other model serializer write custom code override create() method handle foreign field data explicitly create post instance from data iterate over list value of foreign field create instance of image append image instance to post instance's foreign field override update() method write normal viewset for only one : i.e. posts (both is optional) Issues faced: if nested fields are char if posting as application/json from django form : works fine if posting as multipart/form-data from django form: validation fails for required fields means data received is empty works fine with python code only iff data & files both are provided if nested fields are image cannot post using django form able to post using custom form: https://github.com/toransahu/multiple-file-upload able to post using python code class Meta Options # TODO: Misc # Note: after serializer.is_valid() we can't save serializer if we have already accessed serializer.data; to avoid this, access serializer.validated_data custom create & update in serializer - writable nested serializers datefield attribute: auto_now vs auto_now_add auto_now: Automatically set the field to now every time the object is saved Useful for \"last-modified\" timestamps cannot be overriden auto_now_add Automatically set the field to now when the object is first created Useful for creation of timestamps cannot be overriden Postman: nested: https://medium.com/@darilldrems/how-to-send-arrays-with-get-or-post-request-in-postman-f87ca70b154e Try: https://github.com/beda-software/drf-writable-nested https://github.com/alanjds/drf-nested-routers Base64 ImageField Views # Function Based View Using normal functions like in Django (without using any rest_framework feature) Modules: from django.views.decorators.csrf import csrf_exempt from django.http import HttpResponse , JsonResponse from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser Approach: write function with conditional branching for different http request methods write a _list function for listing all records (GET) & submiting a record (POST) write a _detail function for fetching, modifying or destroying a specific record by pk, ID or Name use JSON response & parser use @csrf_exempt decorator for safety code: https://gist.github.com/toransahu/1bad12b87dcd160c0de0d29d218d9bf6 Using @api_view() decorator Modules: from rest_framework import status from rest_framework.decorators import api_view from rest_framework.response import Response Approach: write function with conditional branching for different http request methods write a _list function for listing all records (GET) & submiting a record (POST) write a _detail function for fetching, modifying or destroying a specific record by pk, ID or Name decorate with @api_view() with parameters like ['GET'], ['GET', 'POST'], ['GET', 'PUT', 'DELETE'] etc By default @api_view() takes GET method if nothing is mentioned code: https://gist.github.com/toransahu/5c99704ec721e461b5f8fa67776a6d74 Class Based View By Inheriting APIView class Modules: from rest_framework.views import APIView from rest_framework.response import Response from rest_framework import status from django.http import Http404 Approach: write classes and define request handler methods in name of http request method for each http request method write a List class for listing all records (GET) & submiting a record (POST) write a Detail class for fetching, modifying or destroying a specific record by pk, ID or Name similar to Django's \"View\" class Note request handler methods receives REST's Request instance instead django's HttpRequest instance request handler methods may return REST's Response instance instead django's HttpResponse instance set few attributes like authentication_classes = (authentication.TokenAuthentication,) permission_classes = (permissions.IsAdminUser,) code: https://gist.github.com/toransahu/bcdb1a6beb5da0475c8c056837da940f Using mixins Modules: from rest_framework import mixins from rest_framework import generics Approach: write classes and inherit generics.GenericAPIView & mixins as per use write a List class and inherit mixins.ListModelMixin, mixins.CreateModelMixin, generics.GenericAPIView write a Detail class and inherit mixins.RetrieveModelMixin, mixins.UpdateModelMixin, mixins.DestroyModelMixin, generics.GenericAPIView base class providescore functionality & mixin classes provides actions like .list(), .create(), .retrieve(), .update() and .destroy() Code: https://gist.github.com/toransahu/dfc2666307c1628042b99edaba630c07 Using generic class-based views Modules: from rest_framework import generics Approach: write List class and inherit generics.ListCreateAPIView write Detail class and generics.RetrieveUpdateDestroyAPIView Code: https://gist.github.com/toransahu/ab21d8bf46f45616ccb9285dbd0b201a Using ViewSet Modules: from rest_framework import viewsets Approach: Only need to write a single class, named ModelNameViewSet and inhert viewsets.ModelViewSet facilitates router for URL writing Advantage: provides create, retrieve, update, and destroy in a single Class def DRY View code DRY URL code can also add custom endpoints as per our need, apart from regular create, retrieve, update, and destroy endpoint provided by ViewSet Code: https://gist.github.com/toransahu/c7d43776065aa6fda05d7389133c68f9 Custom/Disable Request Methods in ViewSet # By default ViewSets provides All the requests methods this technique will give power to override,disable those methods to do this use mixins with viewset.GenericViewSet , or override methods of ViewSet class url: https://gist.github.com/toransahu/e02fc30cd0e55e968971c46e59862acb mapping for views from ViewSet using as_view() # syntax {<method>:<action>} patterns {'get': 'list'} {'get': 'retrieve'} {'post': 'create'} {'put': 'update'} {'patch': 'partial_update'} {'delete': 'destroy'} adding custom routes/action to the existing ViewSet # https://gist.github.com/toransahu/95781bc23f39192276d011d0aa990470 http://www.django-rest-framework.org/api-guide/routers/#customizing-dynamic-routes URLs # if using include( ) dont provide namespace if providing namespace inside include define app_name = in app/urls.py Routers # REST framework adds support for automatic URL routing to Django, and provides you with a simple, quick and consistent way of wiring your view logic to a set of URLs. from django.urls import path from .views import BlogViewSet from rest_framework.routers import DefaultRouter router = DefaultRouter () router . register ( '' , BlogViewSet , base_name = 'blogs' ) urlpatterns = router . urls Note: Try to keep base_name same as Model name, because view_name like blog-detail, blog-list comes from Model & not from app's name when we create custom actions (similar to -list, -detail) in any View using @detail_route(), we access that action using base_name in serializers. alternatively remove base_name actions using base_name: # <base_name>-list <base_name>-detail <base_name>-<any_custom> how to use namespace (provided in url patterns) # using from django.urls import reverse reverse(<namespace>:<base_name>-<action> or reverse(<namespace>:<model_name>-<action> adding custom routes/action urls to the existing Router or urlpatterns # https://gist.github.com/toransahu/95781bc23f39192276d011d0aa990470 API Versioning # Source e.g. Its always a good idea to version your API so that you can make changes in your API without disturbing your current clients. e.g. http://127.0.0.1:8000/api/v1/blogs/ Configurations # settings.py REST_FRAMEWORK = { 'DEFAULT_VERSIONING_CLASS' : 'rest_framework.versioning.NamespaceVersioning' } urls.py urlpatterns = [ path ( 'admin/' , admin . site . urls ), path ( 'api/v1/blogs/' , include ( 'blogs.urls' , namespace = 'v1' )), ] blogs/urls.py app_name = 'blogs' router = DefaultRouter () router . register ( '' , BlogViewSet , base_name = 'blogs' ) urlpatterns = router . urls Uses # Once you have set versioning, django will be able to provide value of request.version else it will be None so, apply conditions ( if/else ) in View or serializers if there are changes in fields, then use versioning in serializers else, if there are only changes in some functionalities, (which current client cannot consume), then use versioning in veiws only, like: def get_serializer_class ( self ): if self . request . version == 'v1' : return AccountSerializerVersion1 return AccountSerializer Allow CORS (Cross Origin Resource Sharing) in DRF # Source1 Source2 Using Custom Middleware class # need to define for each app python manage.py startapp app create app/cors.py and write class CorsMiddleware ( object ): def process_response ( self , req , resp ): response [ \"Access-Control-Allow-Origin\" ] = \"*\" return response - MIDDLEWARE_CLASSES = ['app.CorsMiddleware'] Using package django-cors-headers # works site-wide pipenv install django-cors-headers in settings.py INSTALLED_APPS = ['corsheaders'] MIDDLEWARE_CLASSES = ['corsheaders.middleware.CorsMiddleware',] , keep in top as possible as Allow using any one CORS_ORIGIN_ALLOW_ALL = True OR CORS_ORIGIN_ALLOW_ALL = False CORS_ORIGIN_WHITELIST = ['http//:localhost:8000',] also set ALLOWED_HOSTS = ['192.168.1.121'] and run server like python manage.py runserver 192.168.1.121:8000 Creating Schema from API # provides all the details about api endpoint present in site-wide urls will show all the endpoints actions fields if any authentication is needed it will show schema accordingly; if not authenticated, it will show that much api endpoints only need to configure in site-wide urls.py source: http://www.django-rest-framework.org/api-guide/schemas/ pipenv install coreapi from rest_framework.schemas import get_schema_view schema_view = get_schema_view ( title = \"Server Monitoring API\" ) urlpatterns = [ url ( '^<dollor_sign>' , schema_view ), ... ] Setting Media URL & ROOT # Site Wide # App Based # define MEDIA_URL & MEDIA_ROOT in settings.py # Media files # https://timmyomahony.com/blog/static-vs-media-and-root-vs-path-in-django/ # the relative browser URL to be used when accessing our media files in the browser MEDIA_URL = 'media/' # the absolute path to the folder that will hold our user uploads # to get absolute path without hardcoding ENV_PATH = os . path . abspath ( os . path . dirname ( __file__ )) + os . sep + os . pardir MEDIA_ROOT = os . path . join ( ENV_PATH , 'media/' ) - add following code in app/urls.py # adding media url from django.conf import settings # from backend.settings import DEBUG from django.conf.urls.static import static # If developement env if settings . DEBUG is True : urlpatterns += static ( settings . MEDIA_URL , document_root = settings . MEDIA_ROOT ) want to set upload_to directory dynamically: code: https://gist.github.com/toransahu/8f9407250cee7a729473335bdd7a3f3b here comes, signal things, pre_save, post_save Permission # request methods level permissions (in ViewSet) # this needs when \"a user must post only or admin must post only\" type of requirements comes url-view: https://gist.github.com/toransahu/e02fc30cd0e55e968971c46e59862acb url-permission: https://gist.github.com/toransahu/c40b625165a395fabf772700f3ab2e04 objects level permission # TODO Exception/Http response # When the permissions checks fail either a \"403 Forbidden\" or a \"401 Unauthorized\" response will be returned, according to the following rules: The request was successfully authenticated, but permission was denied. \u2014 An HTTP 403 Forbidden response will be returned. The request was not successfully authenticated, and the highest priority authentication class does not use WWW-Authenticate headers. \u2014 An HTTP 403 Forbidden response will be returned. The request was not successfully authenticated, and the highest priority authentication class does use WWW-Authenticate headers. \u2014 An HTTP 401 Unauthorized response, with an appropriate WWW-Authenticate header will be returned. Authentication # Source: http://www.django-rest-framework.org/api-guide/authentication/ Basic Auth # module: from rest_framework.authentication import BasicAuthentication By default used in DRF, whether you mention it in settings.py or views.py or not is only suitable for testing purpose, don't use in production if using in production you need to stick to Django Admin Login form page, can't use JSON need to be HTTPS Session Auth # module from rest_framework.authentication import SessionAuthentication TODO Token Auth # Source: https://stackoverflow.com/questions/14838128/django-rest-framework-token-authentication module `from rest_framework.authentication import TokenAuthentication Prerequisites add 'rest_framework.authtoken' to INSTALLED_APPS in settings.py mention TokenAuthentication class in views or function based @authentication_classes ([ TokenAuthentication , ]) def abcd - detail (): pass class based class Abcd (): authentication_classes = [ TokenAuthentication , ] settings.py REST_FRAMEWORK = { 'DEFAULT_VERSIONING_CLASS' : 'rest_framework.versioning.NamespaceVersioning' , 'DEFAULT_AUTHENTICATION_CLASSES' : ( # 'rest_framework.authentication.BasicAuthentication', # 'rest_framework.authentication.SessionAuthentication', 'rest_framework.authentication.TokenAuthentication' , ), } Obtain Token DRF provides a view which returns a token on correct username & password. include following in urls.py from rest_framework.authtoken.views import obtain_auth_token urlpatterns = [ path ( 'api-auth-token/' , obtain_auth_token ),] - call the view as: http POST 127.0.0.1:8000/api-token-auth/ username='admin' password='whatever' will get token like: { \"token\" : \"blah_blah_blah\" } Use the Token in API call put the following in Header key: Authorization value: Token token_value Please mind the space between Token & token_value http GET 127.0.0.1:8000/whatever 'Authorization: Token your_token_value' JWT (JSON Web Token) # src: http://getblimp.github.io/django-rest-framework-jwt/ quick replacement of Default Token Auth Basic Changes Needed: pip install djangorestframework-jwt add in REST_FRAMEWORK setting 'DEFAULT_AUTHENTICATION_CLASSES': ( 'rest_framework_jwt.authentication.JSONWebTokenAuthentication', ) add view in url from rest_framework_jwt.views import obtain_jwt_token #... urlpatterns = [ '' , # ... url ( r '^api-token-auth/' , obtain_jwt_token ), ] jwt setting variables JWT_AUTH = { 'JWT_ENCODE_HANDLER' : 'rest_framework_jwt.utils.jwt_encode_handler' , 'JWT_DECODE_HANDLER' : 'rest_framework_jwt.utils.jwt_decode_handler' , 'JWT_PAYLOAD_HANDLER' : 'rest_framework_jwt.utils.jwt_payload_handler' , 'JWT_PAYLOAD_GET_USER_ID_HANDLER' : 'rest_framework_jwt.utils.jwt_get_user_id_from_payload_handler' , 'JWT_RESPONSE_PAYLOAD_HANDLER' : 'rest_framework_jwt.utils.jwt_response_payload_handler' , #'JWT_SECRET_KEY': settings.SECRET_KEY, #will take from settings.py by default 'JWT_GET_USER_SECRET_KEY' : None , 'JWT_PUBLIC_KEY' : None , 'JWT_PRIVATE_KEY' : None , 'JWT_ALGORITHM' : 'HS256' , 'JWT_VERIFY' : True , 'JWT_VERIFY_EXPIRATION' : True , 'JWT_LEEWAY' : 0 , 'JWT_EXPIRATION_DELTA' : datetime . timedelta ( seconds = 300 ), 'JWT_AUDIENCE' : None , 'JWT_ISSUER' : None , 'JWT_ALLOW_REFRESH' : True , #allowing it to refresh 'JWT_REFRESH_EXPIRATION_DELTA' : datetime . timedelta ( days = 7 ), 'JWT_AUTH_HEADER_PREFIX' : 'Token' , 'JWT_AUTH_COOKIE' : None , } django-rest-auth (Register, Login, Logout, Reset, Change..) # src http://django-rest-auth.readthedocs.io/en/latest/api_endpoints.html https://michaelwashburnjr.com/django-user-authentication/ not recommanded, is not completely RESTful have issues with password/reset & password/reset/confirm/ depends on django-allauth for email things djoser # src: http://djoser.readthedocs.io/en/stable/sample_usage.html djoser uses following settings for email configuration (which is also used by django's default mail module from django.core.mail import send_mail CONFIG_PATH = os . path . join ( ENV_PATH , '../configs/' ) EMAIL_USE_TLS = True #EMAIL_USE_SSL = True #Use any one from TLS, SSL EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend' #default one, production #EMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend' #for development EMAIL_HOST = 'smtp.gmail.com' with open ( os . path . join ( CONFIG_PATH , 'email_pwd' )) as f : EMAIL_HOST_PASSWORD = f . readline () EMAIL_HOST_USER = 'noreply.etherealmachines@gmail.com' EMAIL_PORT = 587 DEFAULT_FROM_EMAIL = EMAIL_HOST_USER EMAIL_ADMIN = ( 'toran.ethereal@gmail.com' , ) - djoser setting variables DJOSER = { 'PASSWORD_RESET_CONFIRM_URL' : 'auth/password/reset/confirm/ {uid} / {token} ' , 'ACTIVATION_URL' : 'auth/password/reset/confirm/ {uid} / {token} ' , 'EMAIL' : { 'activation' : 'djoser.email.ActivationEmail' , 'confirmation' : 'djoser.email.ConfirmationEmail' , 'password_reset' : 'djoser.email.PasswordResetEmail' , }, # DEFAULT; no need to define here 'SERIALIZERS' : { 'activation' : 'djoser.serializers.ActivationSerializer' , 'password_reset' : 'djoser.serializers.PasswordResetSerializer' , 'password_reset_confirm' : 'djoser.serializers.PasswordResetConfirmSerializer' , 'password_reset_confirm_retype' : 'djoser.serializers.PasswordResetConfirmRetypeSerializer' , 'set_password' : 'djoser.serializers.SetPasswordSerializer' , 'set_password_retype' : 'djoser.serializers.SetPasswordRetypeSerializer' , 'set_username' : 'djoser.serializers.SetUsernameSerializer' , 'set_username_retype' : 'djoser.serializers.SetUsernameRetypeSerializer' , 'user_create' : 'djoser.serializers.UserCreateSerializer' , 'user_delete' : 'djoser.serializers.UserDeleteSerializer' , 'user' : 'djoser.serializers.UserSerializer' , 'token' : 'djoser.serializers.TokenSerializer' , 'token_create' : 'djoser.serializers.TokenCreateSerializer' , }, } django-templated-mail # djoser uses it to create mail template & send mails few setting variables: DOMAIN SITE_NAME Testing # Testing ViewSet using: # APITestCase Token Authentication APIRequestFactory Source: https://gist.github.com/toransahu/706bd1de705e21f3be000e1517f7cae8 Security # https://stormpath.com/blog/where-to-store-your-jwts-cookies-vs-html5-web-storage http://kylebebak.github.io/post/django-rest-framework-auth-csrf django-jwt (JWT_AUTH_COOKIE ) is not safe https://github.com/GetBlimp/django-rest-framework-jwt/issues/338 if SessionAuthentication is enabled, then CSRF will be used (if ON) https://stackoverflow.com/questions/30871033/django-rest-framework-remove-csrf if JWTAuthentications is enabled, then CSRF is automatically disabled Vulnerabilities # CSRF (Cross Site Request Forgery) # XSS (Cross Site Script) # Vulnerables # Web Client Local/ Session Storage # XSS Cookies (JWT/Auth) # CSRF ajax call : https://gist.github.com/bengolder/aa9033efc8959dc38e5d Misc # Running Multiple Host (website) from Single Django Project # source: http://effbot.org/zone/django-multihost.htm Get request URL string # from django.contrib.sites.shortcuts import get_current_site print ( 'query_params are:' , request . build_absolute_uri ()) #returns url with domain print ( request . get_full_path ()) #returns url without domain print ( get_current_site ( request ) . domain , request . get_host ()) #both returns host or domain Get slugs from url # if you have any - url like: http://127.0.0.1:8000/auth/password/reset/confirm/Mw/4vw-d9cdc8954482ecf8e253/ - url pattern like: path('password/reset/confirm/ / /', password_reset_confirm, name='password_reset_confirm_custom_get') then code to fetch uid & token will be: https://gist.github.com/toransahu/68663e302f87a9c32a1dcd0654408577 Microservice Based on REST # https://www.fullstackpython.com/microservices.html https://martinfowler.com/articles/microservices.html https://dev.otto.de/2016/03/20/why-microservices/ with flask: https://medium.com/@ssola/building-microservices-with-python-part-i-5240a8dcc2fb django to flask based microservice - https://medium.com/greedygame-media/how-we-broke-up-our-monolithic-django-service-into-microservices-8ad6ff4db9d4 https://blog.rapid7.com/2016/09/15/microservices-please-dont/","title":"Python Django"},{"location":"lang/python/Python-Django/#intro","text":"Django is an open source Web development framework for the Python Designed to be loosely coupled and tightly cohesive, meaning that different parts of the framework, while connected to one another, are not dependent on one another DRY principle","title":"Intro"},{"location":"lang/python/Python-Django/#why-should-we-use-django","text":"modular ease the administration by auto-generated web admin pre-packaged APIs template system to avoid code duplication enables to define URL for gives function seperates business logic from HTML everything is in python","title":"Why should we use Django"},{"location":"lang/python/Python-Django/#mvc-architecture","text":"MTV - Model, Template, View Similar to MVC","title":"MVC Architecture"},{"location":"lang/python/Python-Django/#models","text":"Describes database schema & data structure","title":"Models"},{"location":"lang/python/Python-Django/#fields","text":"BinaryField BigAutoField BigIntegerField CharField DateField DateTimeField DecimalField DurationFields EmailField IntegerField BooleanField TextField ImageField FileField FilePathField FloatField GenericIPAddressField AutoField ForeignKey ManytoOne solution ManyToMany OneToOne SlugField TimeField URLField UUIDField","title":"Fields"},{"location":"lang/python/Python-Django/#field-options","text":"blank null primary_key max_length choices validators db_columns db_index db_tablespace default editable help_text error_messages auto_now auto_now_add unique unique_for_date unique_for_month unique_for_year verbose_name","title":"Field Options"},{"location":"lang/python/Python-Django/#views","text":"Same as Controller in MVC Controls what a user sees it retrieves data from appropriate model, executes any calculation on data and pass it to template 5 Module Name: HttpResponse, template.render(templatename),from django.shortcuts import render(req,temp_name,context), get_object_or_404,","title":"Views"},{"location":"lang/python/Python-Django/#templates","text":"Same as View in MVC describes how user sees data & info describes how tha data recieved from views should be changed/formatted for display on the page Note: According to Django the framework + URL config feature itself is known as Controller.","title":"Templates"},{"location":"lang/python/Python-Django/#project-structure","text":"Project (just a container)/ | |-----project/ | |--__init__.py | |--settings.py | |--urls.py | \u2514--wsgi.py | |-----app1/ | | | |-----app2-RESTful/ | | | |-----manage.py | | | \u2514-----db.sqlite3 Project: main project package settings.py: python module (module level) represents django settings urls.py: represents site-wide urls configuration (includes apps also) wsgi.py: Web-server-gateway-interface: djangos's primary deployement platform wsgi.py gets created on \"startproject\" contains \"application\" callable & \"DJANGO_SETTINGS_MODULE\" django setting eviroment variable DJANGO_SETTINGS_MODULE: locates setting file, default: project_name.settings.py application: used by server to communicate with code, default: get_wsgi_application() App1 App2- REST-ful","title":"Project Structure"},{"location":"lang/python/Python-Django/#wsgi-web-server-gateway-interface","text":"an interface between web server & application contains some statements, set of rules its not a software/library/framework WSGI compliant server will able to communicate with a WSGI compliant web app in WSGI, WSGI application has to be callable & it needs to be given to web server, so web server can call web application whenever it receives a request","title":"WSGI: Web Server Gateway Interface"},{"location":"lang/python/Python-Django/#rename-django-project","text":"Your django project structure ProjectName/ manage.py ProjectName/ __init__.py settings.py urls.py wsgi.py changes required at 4 places settings.py ROOT_URLCONF = 'NewProjectName.urls' WSGI_APPLICATION = 'NewProjectName.wsgi.application' wsgi.py os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"NewProjectName.settings\") manage.py os.environ.setdefault(\"DJANGO_SETTINGS_MODULE\", \"NewProjectName.settings\")","title":"Rename Django Project"},{"location":"lang/python/Python-Django/#workflow","text":"runserver --> web-server gateway interface WSGI--> DJANGO_SETTING_MODULE env var -->by default project.Setting.py (site folder) --> ROOT_URLCONF --> url.py (site url file location) --> Browser --> URL --> DNS + PortNo from application (protocol based)--> IP + port --> http request--> Server -->web-server gateway interface WSGI--> DJANGO_SETTING_MODULE env var -->by default project.Setting.py (site folder) --> ROOT_URLCONF --> url.py (site url file location) --> urlpattern --> url scanning --> matched view --> model + http response + template --> web page","title":"Workflow"},{"location":"lang/python/Python-Django/#django-adminpy-vs-managepy","text":"Django-admin.py: It is a Django's command line utility for administrative tasks. Manage.py: It is an automatically created file in each Django project. It is a thin wrapper around the Django-admin.py.","title":"django-admin.py Vs manage.py"},{"location":"lang/python/Python-Django/#uses","text":"","title":"Uses"},{"location":"lang/python/Python-Django/#clean-database","text":"python manage.py flush","title":"Clean Database"},{"location":"lang/python/Python-Django/#load-initial-data-fixtures","text":"src: https://coderwall.com/p/mvsoyg/django-dumpdata-and-loaddata #prerequisites- <app_dir>/<fixtures>/<fixture_file.json> #else provide fixture files path python manage.py loaddata <fixture_file_name>","title":"Load initial data / fixtures"},{"location":"lang/python/Python-Django/#dump-data-save-db-data","text":"src: https://coderwall.com/p/mvsoyg/django-dumpdata-and-loaddata #whole db python manage.py dumpdata > [ db.json ] #app wise python manage.py dumpdata [ app_name ] > [ app.json ] #table/model wise python manage.py dumpdata [ app.model ( in small )] > [ app_model.json ] #exclude some table python manage.py dumpdata --exclude [ app.model ( in small )] > [ db.json ] #specify indentation python manage.py dumpdata --indent 4 > [ db.json ] #specify output format python manage.py dumpdata --format [ json/xml/yaml ] > [ db.json ] #backup whole db fresh (without any Integrity Issue) python manage.py dumpdata --exclude auth.permission --exclude contenttypes > db.json","title":"dump data / save DB data"},{"location":"lang/python/Python-Django/#check-production-readyness","text":"python manage.py check --deploy","title":"Check production readyness"},{"location":"lang/python/Python-Django/#run-dev-server","text":"python manage.py runserver 0 .0.0.0:8000","title":"Run Dev server"},{"location":"lang/python/Python-Django/#makemigrations-into-files","text":"python manage.py makemifrations <app_name>","title":"makemigrations into files"},{"location":"lang/python/Python-Django/#migrate-changes-into-db","text":"python manage.py migrate","title":"migrate changes into db"},{"location":"lang/python/Python-Django/#makemigrations-into-files_1","text":"python manage.py makemifrations <app_name>","title":"makemigrations into files"},{"location":"lang/python/Python-Django/#clean-migration-files","text":"","title":"Clean Migration Files"},{"location":"lang/python/Python-Django/#features","text":"Admin Interface (CRUD: Create, Retrieve, Update, Delete) Templating Form Handling Internationalization Session, User management, role-based permissions ORM (Object-Relational Mapping) Testing Framework Best Documentation","title":"Features"},{"location":"lang/python/Python-Django/#database","text":"site folder setting.py DATABASES fill dict entries ENGINE: type of db django.db.backends.sqlite3 django.db.backends.mysql django.db.backends.postgresql_psycopg2 django.db.backends.oracle NAME: name of database USERNAME(optional) PASSWORD(optional) HOST(optional) DATABASES = { 'sqlite3' : { 'ENGINE' : 'django.db.backends.sqlite3' , 'NAME' : os . path . join ( BASE_DIR , 'db.sqlite3' ), }, 'default' : { 'ENGINE' : 'django.db.backends.mysql' , 'NAME' : 'employees' , 'USER' : 'test' , 'HOST' : 'localhost' , 'PORT' : '' , } } (optional) are required in case of DB other than sqlite.","title":"Database"},{"location":"lang/python/Python-Django/#set-charset","text":"By deafult django uses latin1 , its better to use unicode utf8 to support all types of language characters. So, Put this in settings.py: DATABASE_OPTIONS = dict ( charset = \"utf8\" )","title":"Set CharSet"},{"location":"lang/python/Python-Django/#mysql","text":"","title":"MySQL"},{"location":"lang/python/Python-Django/#prerequisites","text":"sudo apt install python-dev libmysqlclient-dev pipenv install mysqlclient login to root sudo mysql -u root -p create another user & grant all access use ` <db_name> ` CREATE USER 'dev' @ 'localhost' IDENTIFIED BY 'password' ; GRANT ALL PRIVILEGES ON *.* TO 'dev' @ 'localhost' WITH GRANT OPTION ; use dev user in django install workbench (optional) sudo apt install mysql-workbench","title":"Prerequisites"},{"location":"lang/python/Python-Django/#do-django-models-support-multiple-column-primary-keys","text":"Ans No. Only single-column primary keys are supported. But using the unique_together model option we can achieve it.","title":"Do Django models support multiple-column primary keys?"},{"location":"lang/python/Python-Django/#does-django-support-nosql-databases","text":"Ans No. Not officially. But can using 3rd party forks like Django non-rel.","title":"Does Django support NoSQL databases?"},{"location":"lang/python/Python-Django/#using-multiple-databases-in-django","text":"Different ways of using multiple databases: * QuerySet's \"using\" Method # This will run on the 'default' database. Author . objects . all () # So will this. Author . objects . using ( 'default' ) . all () # This will run on the 'other' database. Author . objects . using ( 'other' ) . all () Model.save()'s \"using\" Parameter choice_one = Choice . objects . get ( pk = 1 ) choice_one . text = \"New Text\" choice_one . save ( using = \"Polls_DB\" ) Database Routing","title":"Using Multiple Databases in Django"},{"location":"lang/python/Python-Django/#migrations-in-django","text":"applies changes in models to database tables like deleteing/adding models/fields commands makemigrations creates migration files as per changes in models inside app-->migrations-->0001_initial.py, contains Migration class with all the operations/changes does not applies changes in DB python manage . py makemigrations migrate applies migration files to DB python manage . py migrate sqlmigrate generates sql from migration files python manage . py sqlmigrate polls_app 0001 _initial","title":"Migrations in Django"},{"location":"lang/python/Python-Django/#orm-object-relational-mapper","text":"defines your data model entirely in python provides rich & dynamic database-access API","title":"ORM - Object Relational Mapper"},{"location":"lang/python/Python-Django/#queryset-features","text":"","title":"QuerySet Features:"},{"location":"lang/python/Python-Django/#iteration","text":"for e in Entry . objects . all (): print ( e . headline )","title":"Iteration"},{"location":"lang/python/Python-Django/#slicing","text":"","title":"Slicing"},{"location":"lang/python/Python-Django/#len","text":"record_count = len ( Entry . objects . all ()) # will return length of result list","title":"len()"},{"location":"lang/python/Python-Django/#list","text":"entry_list = list ( Entry . objects . all ()) # convert to list","title":"list()"},{"location":"lang/python/Python-Django/#bool","text":"bool ( Entry . objects . filter ( age = 21 )) # same as EXISTS, will return True if there are results","title":"bool()"},{"location":"lang/python/Python-Django/#queryset-operations","text":"","title":"QuerySet Operations:"},{"location":"lang/python/Python-Django/#field-lookups","text":"Parameter passed using \",\" comma == AND For OR, use exclude() field__gt: greater than field__gte: greater than equal to field__lt: less than field__lte: less than equal to list slicing [:5] == for starting 5 records list slicing some_queryset.reverse()[:5] == for last 5 records field__exact field__iexact: non-casesensitive match field__contains : Entry.objects.get(headline__contains='Lennon'), same as LIKE %Lennon% field__icontains : Entry.objects.get(headline__icontains='LeNnon'), same as ILIKE %LenNon% field__in : Entry.objects.filter(id__in=[1, 3, 4]), same as SELECT ... WHERE id IN (1, 3, 4); field__startswith: Entry.objects.filter(headline__startswith='Lennon') field__istartswith: Entry.objects.filter(headline__istartswith='LeNnon') field__endswith: Entry.objects.filter(headline__endswith='Lennon') field__iendswith: Entry.objects.filter(headline__iendswith='Lennon') field__range : Entry.objects.filter(pub_date__range=(start_date, end_date)), same as SELECT ... WHERE pub_date BETWEEN '2005-01-01' and '2005-03-31'; field__date: Entry.objects.filter(pub_date__date=datetime.date(2005, 1, 1)) Entry.objects.filter(pub_date__date__gt=datetime.date(2005, 1, 1)) year month day week week_day quarter time : Entry.objects.filter(pub_date__time=datetime.time(14, 30)) hour minute second isnull : Entry.objects.filter(pub_date__isnull=True), same as SELECT ... WHERE pub_date IS NULL; regex : Entry.objects.get(title__regex=r'^(An?|The) +') iregex : Entry.objects.get(title__iregex=r'^(An?|The) +')","title":"Field Lookups"},{"location":"lang/python/Python-Django/#custom-lookups-transforms","text":"e.g. : title__slug='first-blog' TODO","title":"Custom Lookups &amp; Transforms"},{"location":"lang/python/Python-Django/#queries-which-do-not-return-queryset","text":"get() returns object MultipleObjectsError get_or_create() update_or_create() bulk_create() count() return count in_bulk() iterator() latest() earliest() first() last() aggreagte() returns dict exists() return True/False delete() returns the number of objects deleted and a dictionary with the number of deletions per object type. update() returns the number of objects updated","title":"queries which do not return QuerySet"},{"location":"lang/python/Python-Django/#all","text":"same as SELECT *","title":"all()"},{"location":"lang/python/Python-Django/#distinct","text":"same as SELECT DISTINCT Author . objects . distinct () Entry . objects . order_by ( 'blog' ) . distinct ( 'blog' ) # write parameters in same order in both Entry . objects . order_by ( 'blog' ) . distinct ( 'blog' ) # if 'blog' is foreign Model, then by deafult order_by will take it as 'blog__name', so explicity define it as 'blog__id' or 'blog__pk', else will not produce any result","title":"distinct()"},{"location":"lang/python/Python-Django/#filter","text":"","title":"filter()"},{"location":"lang/python/Python-Django/#select_for_update","text":"will lock the row(s) till end of transaction","title":"select_for_update()"},{"location":"lang/python/Python-Django/#raw","text":"raw(raw_query, params=None, translations=None)","title":"raw()"},{"location":"lang/python/Python-Django/#f","text":"for updating (increment/decrement) column value without fetching the current value in python memory from django.db.models import F User . object . filter ( pk = 1 ) . update ( salary = F ( 'salary' ) + 1000 ) # here F is usefull","title":"F()"},{"location":"lang/python/Python-Django/#order_by","text":"User . objects . filter ( age = 21 ) . order_by ( '-salary' , 'name' ) # negative salary means in descending order User . objects . filter ( age = 21 ) . order_by ( '?' ) # random order (expensive) User . objects . order_by ( 'id' )","title":"order_by()"},{"location":"lang/python/Python-Django/#exclude","text":"Entry . objects . exclude ( pub_date__gt = datetime . date ( 2005 , 1 , 3 )) # __gt: greater than","title":"exclude()"},{"location":"lang/python/Python-Django/#annotate","text":"from django.db.models import Count u = User . objects . annotate ( Count ( '","title":"annotate()"},{"location":"lang/python/Python-Django/#reverse","text":"to reverse the order","title":"reverse()"},{"location":"lang/python/Python-Django/#values","text":"returns dictionary object instead list query result Blog . objects . values () Blog . objects . values ( 'id' , 'name' )","title":"values()"},{"location":"lang/python/Python-Django/#values_list","text":"same as values() but returns tuple","title":"values_list()"},{"location":"lang/python/Python-Django/#extra","text":"extra(select=None, where=None, params=None, tables=None, order_by=None, select_params=None) Sometimes, the Django query syntax by itself can\u2019t easily express a complex WHERE clause. For these edge cases, Django provides the extra() QuerySet modifier \u2014 a hook for injecting specific clauses into the SQL generated by a QuerySet.","title":"extra()"},{"location":"lang/python/Python-Django/#only","text":"opposite to defer name those, which should not get deferred except rest","title":"only()"},{"location":"lang/python/Python-Django/#defer","text":"to defer some fields from a large data base passing field to it will not load those columns in queryset from DB, but we can access to field if we need by calling we can never defer pk","title":"defer()"},{"location":"lang/python/Python-Django/#dates","text":"","title":"dates()"},{"location":"lang/python/Python-Django/#datetimes","text":"","title":"datetimes()"},{"location":"lang/python/Python-Django/#none","text":"returns null queryset instance of EmptyQuerySet","title":"none()"},{"location":"lang/python/Python-Django/#union","text":"same as SELECT * FROM TABLE1 UNION SELECT * FROM TABLE2 queryset1.union(queryset2)","title":"union()"},{"location":"lang/python/Python-Django/#intersection","text":"","title":"intersection()"},{"location":"lang/python/Python-Django/#difference","text":"","title":"difference()"},{"location":"lang/python/Python-Django/#select_related","text":"returns Foreign key related objects without hitting database #Hits the database. e = Entry . objects . get ( id = 5 ) #Hits the database again to get the related Blog object. b = e . blog #Hits the database. e = Entry . objects . select_related ( 'blog' ) . get ( id = 5 ) #Doesn't hit the database, because e.blog has been prepopulated #in the previous query. b = e . blog","title":"select_related()"},{"location":"lang/python/Python-Django/#prefetch_related","text":"To solve the 1 + N problem in all types of ORM after Django 1.4","title":"prefetch_related()"},{"location":"lang/python/Python-Django/#using","text":"for choosing databse for the queryset","title":"using()"},{"location":"lang/python/Python-Django/#1-n-problems","text":"TODO","title":"1 + N Problems"},{"location":"lang/python/Python-Django/#models_1","text":"","title":"Models"},{"location":"lang/python/Python-Django/#query-manager","text":"A class An interface through which database query operations are performed to Django models by default Manager for each Model is objects e.g. Questions. object .all()","title":"Query Manager"},{"location":"lang/python/Python-Django/#manager-names","text":"if you want to rename objects e.g. from django.db import models class Person ( models . Model ): #... people = models . Manager () #Uses Person . objects . all () #AttributeError Person . people . all ()","title":"Manager names"},{"location":"lang/python/Python-Django/#custom-manager","text":"if you want to define some more query methods Extend models.Manager class Code: https://gist.github.com/toransahu/62cd045891656b90f7e18a492e9b81db","title":"Custom Manager"},{"location":"lang/python/Python-Django/#inheritance-style-in-django","text":"","title":"Inheritance style in django?"},{"location":"lang/python/Python-Django/#abstract-base-class","text":"you define a base class model as a abstract class cannot instantiate cannot use as a regular model cannot create a table in db you want to reuse the code for attributes (fields/methods) of the base class into other models each child model will have their own table in db e.g. class CommonInfo ( models . Model ): name = models . CharField ( max_length = 100 ) age = models . PositiveIntegerField () class Meta : abstract = True class Student ( CommonInfo ): home_group = models . CharField ( max_length = 5 )","title":"Abstract base class"},{"location":"lang/python/Python-Django/#multi-table-inheritance","text":"This style is used when subclassing an existing model & need each model to have its own database table e.g. from django.db import models class Place ( models . Model ): name = models . CharField ( max_length = 50 ) address = models . CharField ( max_length = 80 ) class Restaurant ( Place ): serves_hot_dogs = models . BooleanField ( default = False ) serves_pizza = models . BooleanField ( default = False ) All of the fields of Place will also be available in Restaurant, although the data will reside in a different database table. So these are both possible: Place.objects.filter ( name = \"Bob's Cafe\" ) Restaurant.objects.filter ( name = \"Bob's Cafe\" ) Note: The inheritance relationship introduces links between the child model and each of its parents (via an automatically-created OneToOneField)","title":"Multi-table Inheritance"},{"location":"lang/python/Python-Django/#proxy-models","text":"You can use this model, If you only want to modify the Python level behavior of the model (means any methods/functions), without changing the models fields unlike multi-table inheritance, if we only want to add some methods change the default manager change the default ordering and at the same time we don't want to create different tables for each model we can inherit the base model & can define child models as proxy e.g. from django.db import models class Person ( models . Model ): first_name = models . CharField ( max_length = 30 ) last_name = models . CharField ( max_length = 30 ) class MyPerson ( Person ): class Meta : proxy = True def do_something ( self ): #... pass","title":"Proxy models"},{"location":"lang/python/Python-Django/#extend-user-model-custom-user-model","text":"Some modifications on top of Django's default User Model just to fit our web appplication. Source: https://simpleisbetterthancomplex.com/tutorial/2016/07/22/how-to-extend-django-user-model.html 4 Ways to extend existing User Model:","title":"Extend User Model (Custom User Model)"},{"location":"lang/python/Python-Django/#using-a-proxy-model","text":"Proxy Model: Model inheritance without creating a new table in database. Used to change the deafult behaviour of an existing model (e.g. methods, ordering by) without affecting exisitng database table When used: When you don't need to save extra information in the databse, but want to add extra methods or change query Manager Code: https://gist.github.com/toransahu/676d4a8c29b5cbd7737ff1c0a0b4dfc4","title":"Using a Proxy Model"},{"location":"lang/python/Python-Django/#using-one-to-one-link-with-a-user-model-profile","text":"One-To-One Link: one to one relationship between two Django Models Both Models are normal django model implemented using models.OneToOneField(SomeModelHere) When Should Use when you need to store some extra information about the exisitng User Model that's not related to authentication process called as User Profile How to Use Create User model & Profile model Create OneToOneField in Profile model of User model Define signals so our Profile model will be automatically created/updated when we create/update User instances We'll use post_save signals for this purpose follow e.g. https://gist.github.com/toransahu/f0bd7313c24605ce92d38a7b09caf4b4","title":"Using One-To-One Link with a User Model (Profile)"},{"location":"lang/python/Python-Django/#creating-a-custom-user-model-extending-abstractbaseuser","text":"Custom User Model Extending AbstractBaseUser a new User model inheriting AbtractBaseUser class require extra care & AUTH_USER_MODEL reference in settings.py ideally it should be done in starting of the project When Should Use when specific requirement in authentication process e.g. change identification token from username to emailId or mobile_number Code: https://gist.github.com/toransahu/4a6314f40676a75b0288953f5c0e8b1c","title":"Creating a Custom User Model Extending AbstractBaseUser"},{"location":"lang/python/Python-Django/#creating-a-custom-user-model-extending-abstractuser","text":"Custom User Model Extending AbstractUser a new User model inheriting AbtractUser class require extra care & AUTH_USER_MODEL reference in settings.py ideally it should be done in starting of the project When Should Use when we are perfectly happy with how Django handles the authentication process and we don't want to change anything on it yet we want to add some extra information directly in the User model without having to create extra class like Profile Code: https://gist.github.com/toransahu/0ce910494dedb8b9f2774b751f45b559 Whenever we define custom User Model like this from django.db import models from django.contrib.auth.models import AbstractUser class User ( AbstractUser ): name = models . CharField ( max_length = 100 , blank = True , null = True ) we need to specify custom user model in settings.py like AUTH_USER_MODEL = \u2018 your_app . User ' and we can refer this User model in our code either as User = get_user_model () or User = settings . AUTH_USER_MODEL # use when define a foreign relationship, to make it resuable app","title":"Creating a Custom User Model Extending AbstractUser"},{"location":"lang/python/Python-Django/#conclusion","text":"Proxy Model: You are happy with everything Django User provide and don\u2019t need to store extra information. User Profile: You are happy with the way Django handles the auth and need to add some non-auth related attributes to the User. Custom User Model from AbstractBaseUser: The way Django handles auth doesn\u2019t fit your project. Custom User Model from AbstractUser: The way Django handles auth is a perfect fit for your project but still you want to add extra attributes without having to create a separate Model.","title":"Conclusion"},{"location":"lang/python/Python-Django/#class-meta-options","text":"TODO:","title":"class Meta Options"},{"location":"lang/python/Python-Django/#views_1","text":"","title":"Views"},{"location":"lang/python/Python-Django/#function-based-generic-view","text":"with template (by rendering) from django.shortcuts import render def home ( request ): return render ( request , 'home.html' ) without template : using HttpResponse from django.http import HttpResponse def home ( request ): return HttpResponse ( \"Hello World\" ) Need to write conditional branch for different HTTP request type like POST, GET, PUT Need to provide view method name in URL Disadvantage: Cannot extend","title":"Function Based Generic View"},{"location":"lang/python/Python-Django/#class-based-view","text":"Module: from django.views import View Inherit View class Need to define get(), post() like HTTP methods Need to provide ClassName.as_view() in URL Advantage: Can be extended by sub classes from django.http import HttpResponse from django.views import View class MyView ( View ): def get ( self , request ): # <view logic> return HttpResponse ( 'result' ) ``` ## Class Based Generic View * Module : from django.views.generic import ListView * Can inherit ListView , TemplateView ... class * No need to define request handler methods * set model attribute to Model Class * Need to provide ClassName . as_view () in URL ``` python from django.views.generic import ListView from books.models import Publisher class PublisherList ( ListView ): model = Publisher","title":"Class Based View"},{"location":"lang/python/Python-Django/#urls","text":"","title":"URLs"},{"location":"lang/python/Python-Django/#using-view-function","text":"urlpatterns = [ path ( '/' , views . home (), name = 'home' ),]","title":"using view function"},{"location":"lang/python/Python-Django/#using-class-based-view","text":"urlpatterns = [ path ( '/' , views . IndexView . as_view (), name = 'index' ),]","title":"using class based view"},{"location":"lang/python/Python-Django/#including-app-urls","text":"from django.urls import path , include urlpatterns = [ path ( '' , include ( 'home.urls' )),]","title":"including app urls"},{"location":"lang/python/Python-Django/#django-20-using-path","text":"from django.urls import path , include","title":"django 2.0: using path"},{"location":"lang/python/Python-Django/#django-19-using-url","text":"from django.conf.urls import url","title":"django &lt;=1.9: using url"},{"location":"lang/python/Python-Django/#static-files","text":"","title":"Static files"},{"location":"lang/python/Python-Django/#in-production","text":"set STATIC_ROOT in settings.py run manage.py collectstatic","title":"In Production"},{"location":"lang/python/Python-Django/#in-developement","text":"STATICFILES_FINDERS = ( 'django.contrib.staticfiles.finders.FileSystemFinder' , 'django.contrib.staticfiles.finders.AppDirectoriesFinder' ) STATICFILES_DIRS = [ os . path . join ( BASE_DIR , 'static' ), '/var/www/static/' , ] STATIC_URL = '/static/'","title":"In Developement"},{"location":"lang/python/Python-Django/#templates_1","text":"Contains Markups JS, CSS, HTML, XML django tags Variables/Logic blocks {% extends 'home/base.html' %} {% load static %} Comments {# CSS files#}","title":"Templates"},{"location":"lang/python/Python-Django/#middlewares","text":"Middleware is framework of hooks to Django's request/response processing its light and low-level plugin system for making global changes in Django's input/output each middleware component in responsible for performing some specific task Some usage of middlewares in Django is: Session management User authentication Cross-site request forgery protection Content Gzipping, etc.","title":"Middlewares"},{"location":"lang/python/Python-Django/#custom-middleware","text":"a middleware factory (i.e. outer function or a class) is a callable it takes an argument called get_response get_response might be an actual Django view if the middleware is last listed else, get_response might be a next middleware and it returns a middleware (or ultimately a response ) a middleware is also a callable which takes an arg called request and it returns a response","title":"Custom Middleware"},{"location":"lang/python/Python-Django/#function-based-custom-middleware","text":"def simple_middleware ( get_response ): # One-time configuration and initialization. def middleware ( request ): # Code to be executed for each request before # the view (and later middleware) are called. response = get_response ( request ) # Code to be executed for each request/response after # the view is called. return response return middleware","title":"Function Based Custom Middleware"},{"location":"lang/python/Python-Django/#class-based-custom-middleware","text":"class SimpleMiddleware : def __init__ ( self , get_response ): self . get_response = get_response # One-time configuration and initialization. def __call__ ( self , request ): # Code to be executed for each request before # the view (and later middleware) are called. response = self . get_response ( request ) # Code to be executed for each request/response after # the view is called. return response","title":"Class Based Custom Middleware"},{"location":"lang/python/Python-Django/#settings","text":"","title":"Settings"},{"location":"lang/python/Python-Django/#place-in-settingspy","text":"","title":"Place in settings.py"},{"location":"lang/python/Python-Django/#separated-into-production-development-environments-like","text":"- base_settings.py - dev_settings.py - prod_settings.py - settings.py","title":"Separated into production &amp; development environments like"},{"location":"lang/python/Python-Django/#strict-seperation-from-code","text":"","title":"STRICT SEPERATION FROM CODE"},{"location":"lang/python/Python-Django/#python-decouple","text":"Source: https://pypi.org/project/python-decouple/ Usage Where the settings data are stored? Ini file Env file How it works? Understanding the CAST argument","title":"Python Decouple"},{"location":"lang/python/Python-Django/#signals","text":"Signals are a strategy to allow decoupled applications to get notified when some event occurs. Source: https://simpleisbetterthancomplex.com/tutorial/2016/07/28/how-to-create-django-signals.html where to create <signals_module>.py ? anywhere recommended: inside apps","title":"Signals"},{"location":"lang/python/Python-Django/#built-in-signals","text":"django.db.models.signals.pre_init: receiver_function(sender, *args, **kwargs) django.db.models.signals.post_init: receiver_function(sender, instance) django.db.models.signals.pre_save: receiver_function(sender, instance, raw, using, update_fields) django.db.models.signals.post_save: receiver_function(sender, instance, created, raw, using, update_fields) django.db.models.signals.pre_delete: receiver_function(sender, instance, using) django.db.models.signals.post_delete: receiver_function(sender, instance, using) django.db.models.signals.m2m_changed: receiver_function(sender, instance, action, reverse, model, pk_set, using)","title":"Built-in Signals"},{"location":"lang/python/Python-Django/#requestresponse-signals","text":"django.core.signals.request_started: receiver_function(sender, environ) django.core.signals.request_finished: receiver_function(sender, environ) django.core.signals.got_request_exception: receiver_function(sender, request)","title":"Request/Response Signals"},{"location":"lang/python/Python-Django/#way-of-connectingregistering-signals","text":"","title":"Way of connecting/registering signals"},{"location":"lang/python/Python-Django/#using-signalconnect","text":"Need to register signals inside ready() in AppConfig class in <app>.apps.py Need to define default_app_config = '<app>.apps.<App>Config' in <app>.__init__.py ignore if '<app>.apps.<App>Config' is inside INSTALLED_APPS insettings.py Issues: In django 2.0+, not working fine. Throwing error: AppRegistryNotReady: Apps aren't loaded yet. e.g.: https://gist.github.com/toransahu/c3870b4ad58bde5a9b9563f7e0883729","title":"using &lt;signal&gt;.connect"},{"location":"lang/python/Python-Django/#using-receiver-decorator","text":"Only need to import signals inside ready() in AppConfig class in <app>.apps.py Need to define default_app_config = '<app>.apps.<App>Config' in <app>.__init__.py ignore if '<app>.apps.<App>Config' is inside INSTALLED_APPS insettings.py No issues till yet e.g.: https://gist.github.com/toransahu/c3870b4ad58bde5a9b9563f7e0883729","title":"using receiver() decorator"},{"location":"lang/python/Python-Django/#asynchronous-signals-using-celery","text":"src https://simpleisbetterthancomplex.com/tutorial/2017/08/20/how-to-use-celery-with-django.html http://docs.celeryproject.org/en/latest/django/first-steps-with-django.html","title":"Asynchronous Signals Using Celery"},{"location":"lang/python/Python-Django/#installation","text":"","title":"Installation"},{"location":"lang/python/Python-Django/#task-queue-system-celery","text":"pip install celery","title":"Task Queue System - Celery"},{"location":"lang/python/Python-Django/#message-broker-system-rabbitmq","text":"src: http://docs.celeryproject.org/en/latest/getting-started/brokers/rabbitmq.html#broker-rabbitmq sudo apt install rabbitmq-server","title":"Message Broker System - RabbitMQ"},{"location":"lang/python/Python-Django/#setup","text":"no need to define any setup, but can set credentials for rabbitmq-server","title":"Setup"},{"location":"lang/python/Python-Django/#code","text":"","title":"Code"},{"location":"lang/python/Python-Django/#enable-celery","text":"Define celery instance in project level inside celery.py Load celery when django starts import the celery instance app to init .py in project package","title":"Enable Celery"},{"location":"lang/python/Python-Django/#write-task","text":"code: https://gist.github.com/toransahu/d01c7374c5317a908b99ac03cf24cc11 create tasks.py inside django app celery searches for tasks inside tasks.py modules either import celery app instance & use from backend.celery import app @app . task def foo (): pass or use shared_task from celery import shared_task @shared_task def foo (): pass set broker_url inside settings.py every celery config variables start with CELERY_ CELERY_BROKER_URL = 'amqp://localhost' start rabbitmq starts automatically on boot sudo systemctl enable rabbitmq-server sudo systemctl start rabbitmq-server start celery worker need to run inside src folder need to be in virtual env celery -A project_name worker -l info or create script to start celery cd ethereal-machines-backend/src (where manage.py is) vim start_celery.sh make sure to write #! /bin/bash in first line chmod a+x start_celery.sh start_celery.sh should look like this: https://gist.github.com/toransahu/31874def1bd661db676d0dfe02e1c651","title":"Write Task"},{"location":"lang/python/Python-Django/#celery-vs-rabiitmq","text":"Celery is a queue Wrapper/Framework which takes away the complexity of having to manage the underlying AMQP mechanisms/architecture that come with operating RabbitMQ directly Celery is just a very high level of abstraction to implement the producer / consumer of events. It takes out several painful things you need to do to work for example with rabbitmq. Celery itself is not the queue. The events queues are stored in the system of your choice, celery helps you to work with such events without having to write the producer / consumer from scratch.","title":"Celery vs RabiitMQ"},{"location":"lang/python/Python-Django/#state-management","text":"Session: Anonymous Session Cookies","title":"State Management"},{"location":"lang/python/Python-Django/#theory","text":"","title":"Theory"},{"location":"lang/python/Python-Django/#stateless","text":"Meaning navigating from one web page to another will not retain infos of first one. There is no persistence between one request and the next, and there is no way the server can tell whether successive requests come from the same person e.g. HTTP, REST This lack of state is managed using sessions.","title":"Stateless"},{"location":"lang/python/Python-Django/#session","text":"are a semi-permanent, two-way communication between your browser and the web server. The session framework lets you store and retrieve arbitrary data on a per-site-visitor basis It stores data on the server side and abstracts the sending and receiving of cookies can be implemented through middleware In client side cookies contain a session ID \u0093 not the data itself (unless youre using the cookie based backend) INSTALLED_APPS = [ 'django.contrib.sessions' , ] MIDDLEWARE = [ 'django.contrib.sessions.middleware.SessionMiddleware' , ]","title":"Session"},{"location":"lang/python/Python-Django/#anonymous-session","text":"to keep track of data relevant to your visit the web server can only record what you did, not who you are","title":"Anonymous Session"},{"location":"lang/python/Python-Django/#enabling-the-session","text":"Using middleware MIDDLEWARE_CLASSES in setting.py should contain 'django.contrib.sessions.middleware.SessionMiddleware' by deafult enabled","title":"Enabling the session"},{"location":"lang/python/Python-Django/#configuring-the-session-engine","text":"by default stored in database using the model django.contrib.sessions.models.Session can be configured to store session data on file system or in cache","title":"Configuring The Session Engine"},{"location":"lang/python/Python-Django/#using-database-backed-sessions","text":"need to add 'django.contrib.sessions' to your INSTALLED_APPS setting","title":"Using Database-Backed Sessions"},{"location":"lang/python/Python-Django/#using-cached-sessions","text":"for better performance, for making web pages more responsive local memory cache backend doesnt retain data long enough to be a good choice use third-party like Memcached cache backend, else use file system or DB based session two different implementation: Only cache Set SESSION_ENGINE to \"django.contrib.sessions.backends.cache\" Cache + DB (Persistent) set SESSION_ENGINE to \"django.contrib.sessions.backends.cached_db\" every write to the cache will also be written to the database use the database if the data is not already in the cache","title":"Using Cached Sessions"},{"location":"lang/python/Python-Django/#using-file-based-sessions","text":"have to set the SESSION_ENGINE settings to \u009cdjango.contrib.sessions.backends.file\u009d","title":"Using File-Based Sessions"},{"location":"lang/python/Python-Django/#using-cookie-based-sessions","text":"","title":"Using Cookie-Based Sessions"},{"location":"lang/python/Python-Django/#cookies","text":"","title":"Cookies"},{"location":"lang/python/Python-Django/#what","text":"An HTTP cookie (web cookie, browser cookie) is a small piece of data that a server sends to the user's web browser. The browser may store it and send it back with the next request to the same server. module: http.cookies","title":"What"},{"location":"lang/python/Python-Django/#why","text":"Typically, it's used to tell if two requests came from the same browser \u2014 keeping a user logged-in, for example.","title":"Why"},{"location":"lang/python/Python-Django/#how","text":"It remembers stateful information for the stateless HTTP protocol.","title":"How"},{"location":"lang/python/Python-Django/#uses_1","text":"Session management Logins, shopping carts, game scores, or anything else the server should remember Personalization User preferences, themes, and other settings Tracking Recording and analyzing user behavior","title":"Uses:"},{"location":"lang/python/Python-Django/#cache","text":"","title":"Cache"},{"location":"lang/python/Python-Django/#why_1","text":"The performance of web sites and applications can be significantly improved by reusing previously fetched resources. Web caches reduce latency and network traffic and thus lessen the time needed to display a representation of a resource. By making use of HTTP caching, Web sites become more responsive.","title":"Why"},{"location":"lang/python/Python-Django/#architecture-django-production-servers","text":"Source : https://www.sayonetech.com/blog/how-host-your-django-project-production-server/#.WgSKV3VL9Xo","title":"Architecture - Django Production Servers"},{"location":"lang/python/Python-Django/#web-server","text":"the outermost tier of the Backend(3-tiers) Apache, nginx, lighttpd, cherokee used as proxy, reverse proxy, load balancer, static data (css, html, images) dispatcher and cache it can't talk directly to Django applications","title":"Web Server"},{"location":"lang/python/Python-Django/#nginx-pronounced-as-engine-x","text":"","title":"nginx (Pronounced as: Engine X)"},{"location":"lang/python/Python-Django/#application-server","text":"the middle tier of the Backend(3-tiers) Gunicorn, mod_python, mod_wsgi, mod_uwsgi, FastCGI is used to handle all dynamic requests, basically based on URL pattern (view call) the Interface between the web server and the python app so that the app(or any python framework) understands the incoming requests create a Unix socket, and serve responses to nginx via the wsgi protocol - the socket passes data in both directions","title":"Application Server"},{"location":"lang/python/Python-Django/#gunicorn-pronounced-as-gee-unicorn","text":"inspired from Ruby's Unicorn","title":"gunicorn (Pronounced as: gee-unicorn)"},{"location":"lang/python/Python-Django/#db","text":"the third tier of the Backend(3-tiers) MySQL/ Postgres/ Other databases","title":"DB"},{"location":"lang/python/Python-Django/#asynchronous-task-queue","text":"","title":"Asynchronous Task Queue"},{"location":"lang/python/Python-Django/#celery","text":"Celery is an asynchronous task/job queue based on distributed message passing requires an external solution to send and receive messages i.e. Message Brokers like RabbitMQ, Redis focused on real-time operation, but supports scheduling as well","title":"Celery"},{"location":"lang/python/Python-Django/#cron-jobs","text":"","title":"Cron jobs"},{"location":"lang/python/Python-Django/#message-broker-solutions","text":"","title":"Message Broker Solutions"},{"location":"lang/python/Python-Django/#rabbitmq","text":"","title":"RabbitMQ"},{"location":"lang/python/Python-Django/#redis","text":"","title":"Redis"},{"location":"lang/python/Python-Django/#amazon-sqs","text":"","title":"Amazon SQS"},{"location":"lang/python/Python-Django/#caching-solution","text":"","title":"Caching Solution"},{"location":"lang/python/Python-Django/#memcached","text":"","title":"Memcached"},{"location":"lang/python/Python-Django/#monitoring","text":"When our project is hosted, we need to monitor it using some tools to check its performance, its error logs and user interactions.We have some tools available for this.","title":"Monitoring"},{"location":"lang/python/Python-Django/#graphite","text":"Graphite provides real-time visualization and storage of numeric time-series data on an enterprise level.","title":"Graphite"},{"location":"lang/python/Python-Django/#statsd","text":"A network daemon that runs on the Node.js platform and listens for statistics, like counters and timers, sent over UDP or TCP and sends aggregates to one or more pluggable backend services (e.g.,Graphite).","title":"Statsd"},{"location":"lang/python/Python-Django/#sentry-logging","text":"Sentry is a modern error logging and aggregation platform.","title":"Sentry - logging"},{"location":"lang/python/Python-Django/#new-relic","text":"A software analytics tool suite used by developers, ops, and software companies to understand how your applications are performing in development and production.","title":"New Relic"},{"location":"lang/python/Python-Django/#supervisor","text":"a process control system a client/server system which allows its users to monitor and control a number of process in UNIX-like OS similar to launchd , daemontools , and runit monitors projects starts on boot Supervisord starts processes as its subprocesses, and can be configured to automatically restart them on a crash accurately shows the up/down times of the processes can asign priorities to the processes can group the processes","title":"Supervisor"},{"location":"lang/python/Python-Django/#stack-flow","text":"User requests from browser. Request reaches Nginx. If (request is staic) Nginx serves the request. Else if (request is dynamic) Nginx forwards the request to Application server (Gunicorn). Gunicorn receives the request, executes corresponding python (Flask) code. Gunicorn returns the response to Nginx. Nginx serves the response to the user.","title":"Stack Flow"},{"location":"lang/python/Python-Django/#working","text":"You need both Nginx and Gunicorn (or something similar) for a proper Django deployment The complete answer is both Nginx and Gunicorn handle the request. Basically, Nginx will receive the request and if it's a dynamic request (generally based on URL patterns) then it will give that request to Gunicorn, which will process it, and then return a response to Nginx which then forwards the response back to the original client.","title":"Working"},{"location":"lang/python/Python-Django/#deployment-production-environment","text":"","title":"Deployment - Production Environment"},{"location":"lang/python/Python-Django/#how-to-deploy-django-application-in-production","text":"https://devcenter.heroku.com/articles/getting-started-with-python#introduction https://developer.mozilla.org/en-US/docs/Learn/Server-side/Django/Deployment DEBUG = False change default SECRET_KEY (used for CRSF protection) and hide it somewhere else Run manage.py check --deploy (to check the default list of changes mentioned by django) checklist https://docs.djangoproject.com/en/1.10/howto/deployment/checklist/","title":"How to deploy django application in Production"},{"location":"lang/python/Python-Django/#checklist","text":"in settings must be set properly for Django to provide the expected level of security; are expected to be different in each environment; enable optional security features; enable performance optimizations; provide error reporting. or Run manage.py check --deploy to list all the factors listed below take care of these things if releasing source code","title":"checklist"},{"location":"lang/python/Python-Django/#critical-settings","text":"SECRET_KEY Instead of hardcoding the secret key in your settings module, consider loading it from an environment variable or file import os SECRET_KEY = os . environ [ 'SECRET_KEY' ] with open ( '/etc/secret_key.txt' ) as f : SECRET_KEY = f . read () . strip () avoid committing it to source control DEBUG : set to False","title":"critical settings"},{"location":"lang/python/Python-Django/#environment-related-settings","text":"ALLOWED_HOSTS When DEBUG = False, Django doesn\u2019t work at all without a suitable value for ALLOWED_HOSTS. This setting is required to protect your site against some CSRF attacks CACHE change it for production performance otimization default for developement is 'local-memory caching' instead use cache servers like Memcached using 'cached sessions' Cache servers often have weak authentication. Make sure they only accept connections from your application servers. DATABASE Database passwords are very sensitive. Keep them in environment variable or in file same as SECRET_KEY For maximum security, make sure database servers only accept connections from your application servers. If you haven\u2019t set up backups for your database, do it right now! EMAIL_BACKEND and related settings If your site sends emails, these values need to be set correctly. modify the DEFAULT_FROM_EMAIL and SERVER_EMAIL settings By default, Django sends email from webmaster@localhost and root@localhost. STATIC_ROOT and STATIC_URL Static files are automatically served by the development server. In production, you must define a STATIC_ROOT directory where collectstatic will copy them. MEDIA_ROOT and MEDIA_URL Media files are uploaded by your users. They\u2019re untrusted! Make sure your web server never attempts to interpret them. For instance, if a user uploads a .php file, the web server shouldn\u2019t execute it.","title":"Environment Related Settings"},{"location":"lang/python/Python-Django/#https","text":"Any website which allows users to log in should enforce site-wide HTTPS to avoid transmitting access tokens in clear. In Django, access tokens include the login/password, the session cookie, and password reset tokens. Note: You can\u2019t do much to protect password reset tokens if you\u2019re sending them by email web server must redirect all HTTP traffic to HTTPS, and only transmit HTTPS requests to Django. because: the same session cookie is used for HTTP and HTTPS. Once you\u2019ve set up HTTPS, enable the following settings. CSRF_COOKIE_SECURE Set this to True to avoid transmitting the CSRF cookie over HTTP accidentally. SESSION_COOKIE_SECURE Set this to True to avoid transmitting the session cookie over HTTP accidentally.","title":"HTTPS"},{"location":"lang/python/Python-Django/#performance-optimizations","text":"DEBUG = False CONN_MAX_AGE TEMPLATES Enabling the cached template loader often improves performance drastically, as it avoids compiling each template every time it needs to be rendered.","title":"Performance Optimizations"},{"location":"lang/python/Python-Django/#error-reporting","text":"LOGGING Review your logging configuration before putting your website in production, and check that it works as expected as soon as you have received some traffic Customize the default error views Django includes default views and templates for several HTTP error codes. You may want to override the default templates by creating the following templates in your root template directory: 404.html, 500.html, 403.html, and 400.html.","title":"Error Reporting"},{"location":"lang/python/Python-Django/#testing","text":"Class level testing for each app from django.test import TestCase class QuestionModelTests ( TestCase ): def test_was_published_recently_with_future_question ( self ): #do something self . assertIs ( future_question . was_published_recently (), False )","title":"Testing"},{"location":"lang/python/Python-Django/#run-test-cases","text":"python manage.py test appname","title":"Run Test Cases"},{"location":"lang/python/Python-Django/#security","text":"","title":"Security"},{"location":"lang/python/Python-Django/#csrf-cross-site-request-forgery","text":"","title":"CSRF - Cross Site Request Forgery"},{"location":"lang/python/Python-Django/#why-csrf","text":"CSRF attack happens in presence of state It really boils down to the browsers ability to automatically present login credentials for any request by sending along cookies. If a session id is stored in a cookie the browser will automatically send it along with all requests that go back to the original website. This means that an attacker doesn't actually have to know authentication details to take an action as the victim user. Rather, the attacker just has to trick the victims browser into making a request, and the credentials to authenticate the request will ride along for free.","title":"Why CSRF?"},{"location":"lang/python/Python-Django/#is-it-required-in-rest","text":"No, it will be useless piece of code because REST is stateless at client-side a cookie-less REST endpoint is completely immune from CSRF attacks if there is cookie used for authentication, then we need CSRF protection HTTP/BasicAuthentication will also need CSRF protection also, if any app uses any tech to store state of app at clientside, then its not a RESTful app src: https://security.stackexchange.com/questions/166724/should-i-use-csrf-protection-on-rest-api-endpoints","title":"Is it required in REST"},{"location":"lang/python/Python-Django/#django-rest-framewok","text":"Django REST framework \"djangorestframework\" is powerful & flexibal toolkit for creating web APIs. - https://stackoverflow.com/questions/671118/what-exactly-is-restful-programming","title":"Django REST Framewok"},{"location":"lang/python/Python-Django/#some-reasons-you-might-want-to-use-rest-framework","text":"The Web browsable API is a huge usability win for your developers. Authentication policies including packages for OAuth1a and OAuth2. Serialization that supports both ORM and non-ORM data sources. Customizable all the way down - just use regular function-based views if you don't need the more powerful features. Extensive documentation, and great community support.","title":"Some reasons you might want to use REST framework:"},{"location":"lang/python/Python-Django/#rest-api","text":"Representation State Transfer An architectural pattern for creating an API that uses HTTP as its communication method for designing network based application Resource: If we have endpoint/URI(URL or URN), lets say https://127.0.0.1/coders then we have resource. Here coders is a resource. Its nothing new, we already used to make URLs that way Representation: When a client makes a GET request to coders/toran/ client gets following JSON response { \"nickname\" : \"toran\" , \"powerLevel\" : 5 } so, this is representation in the form of JSON having metadata representation also could be XML, HTML the same applies when a client sends a request which contains a 'coder' data, its sends representation Representational State: like browsing the web a HTML page is a representation of a resource at current state (or current data) of that resource. When we submit a form, we just send a representation back to the server Representational State Transfer a client and server exchange representations of a resource, which reflects its current state or desired state. So, REST is a way for two machines to transfer the state of a resource via representations.","title":"REST API"},{"location":"lang/python/Python-Django/#http-request-methods-http-verbs","text":"HTTP defines a set of request methods to indicate the desired action to be performed for a given resource GET The GET method requests a representation of a specified resource. GET request should only used for data retrieval. (But can also be used for submit/posting/sending data) a resource is mentioned in URL. POST Used to modify/update an existing entity of a specified resource. Do mention the object/entity of the resource in the URL to update we should use PUT and PATCH for update PUT would create a new unwanted resource when the resouce doesn't exists while updating that particular resource PATCH is perfect for partial updation But there is no restrictions using POST for updates POST /questions/<existing_question> HTTP / 1.1 Host : www.example.com/ - Used to submit a new entity/data to a specified resource. - Do not mention the object/entity of the resource in the URL while creating it. Otherwise it will give \"Resource Not Found\" error. POST /questions/ HTTP / 1.1 Host : www.example.com/ - Causes change in state of the resource - Use this if you want server to let the name, the URL object while creating a new one - Two simultaneous POST requests works fine (lets say, 1st request is updating some part & 2nd request is updating other part of an object) - The UPDATE performed by the POST method might not result in a resource that can be identified by a URI. PUT Used to create a new resource entity or overrite (Completely replaces) the existing one. For a new resource entity: PUT /questions/<new_question> HTTP / 1.1 Host : www.example.com/ To overrite an existing one PUT /questions/<existing_question> HTTP / 1.1 Host : www.example.com/ Usefull when you know the name of the entity/object Use this if you want to name the URL object while creating a new one PUT is idempotent, so if you PUT the same object twice, it has no effect (will overrite) Can create or update an object with the same URL DELETE Deletes/destroyes a specified resource object/entity/record. PATCH Used to make partial modification to an existing resource object/entity. Works differently than POST & PUT for update Need to have URL object known PATCH /users/1 HTTP / 1.1 Host : www.example.com Content-Type : application/example If-Match : \"c0b42b66e\" Content-Length : 120 [changes] where [changes] could be JSON/XML like {email:'toran.sahu@yahoo.com'} HEAD Ask for the response same as GET but without response/message body. OPTIONS Used to describe the communication option for the target resource CONNECT Establishes a tunnel to the server identified by the target resource TRACE Performs message loop-back test along the path to the target resource Note: There is a very common confusion in terminology. \"Resource\" - In URI \"app/questions/1\" here \"1\" is also know as resource and at the same time \"questions\" is also know as resource. - Some people around the globe also use \"1\" as record/entity & \"questions\" as resource. - We could generalize \"1\" as \"resource object\" and \"questions\" as \"resource class\"","title":"HTTP Request Methods (HTTP verbs)"},{"location":"lang/python/Python-Django/#http-response-codes","text":"200 (Ok) 201 (Created) 204 (No Content) 304 404 501 (Not Implemented)","title":"HTTP Response Codes"},{"location":"lang/python/Python-Django/#serializers","text":"Module: from rest_framework import serializers Provides a way to serialize & deserialize Model instances into representations like JSON. Serialization is mechanism of converting the state of an object into byte-stream, which can be displayed, stored. Deserialization is reverse mechanism of serialization. Note: In django its very similar to Django Form class and includes similar validation flags on the various fields, such as required, max_length and default.","title":"Serializers"},{"location":"lang/python/Python-Django/#implementations","text":"Inherit classes serializers.Serializer need to write all the fields mentioned in Model (only those, which we want to use here) need to define create() & update() method to create/update new Model instance from validated data (representaion/JSON) serializers.ModelSerializer Inside Meta class mention model inside Meta class; model = Snippet i.e. Class fields = ('id', ....,'title') i.e. tuple Automatically implements default create() and update() methods Note : If we want to include url in fields, then the base_name (in case of routers) in urls.py should same as the name of Model in lower case, alternatively don't mention base_name serializers.HyperlinkedModelSerializer The only difference is, as in citation you included, that primary and foreign keys are represented by URLs that point to those resources, instead of just actual key values. The benefit is that you will not have to construct resource URLs in your frontend when you want to retrieve related objects.","title":"Implementations"},{"location":"lang/python/Python-Django/#relations","text":"src: http://www.django-rest-framework.org/api-guide/relations/#serializer-relations","title":"Relations"},{"location":"lang/python/Python-Django/#writable-nested-serializers","text":"scr: http://www.django-rest-framework.org/api-guide/relations/#writable-nested-serializers code: https://gist.github.com/toransahu/221371c981c20f0b9c645019a53b90c7 by default django does not provides write access in case of nested model objects & their model serializers strategy create 2 models assign M2M/Foreign key field in one model write serializers for both the models keep foreign model serializers normal/default for other model serializer write custom code override create() method handle foreign field data explicitly create post instance from data iterate over list value of foreign field create instance of image append image instance to post instance's foreign field override update() method write normal viewset for only one : i.e. posts (both is optional) Issues faced: if nested fields are char if posting as application/json from django form : works fine if posting as multipart/form-data from django form: validation fails for required fields means data received is empty works fine with python code only iff data & files both are provided if nested fields are image cannot post using django form able to post using custom form: https://github.com/toransahu/multiple-file-upload able to post using python code","title":"Writable Nested Serializers"},{"location":"lang/python/Python-Django/#class-meta-options_1","text":"TODO:","title":"class Meta Options"},{"location":"lang/python/Python-Django/#misc","text":"Note: after serializer.is_valid() we can't save serializer if we have already accessed serializer.data; to avoid this, access serializer.validated_data custom create & update in serializer - writable nested serializers datefield attribute: auto_now vs auto_now_add auto_now: Automatically set the field to now every time the object is saved Useful for \"last-modified\" timestamps cannot be overriden auto_now_add Automatically set the field to now when the object is first created Useful for creation of timestamps cannot be overriden Postman: nested: https://medium.com/@darilldrems/how-to-send-arrays-with-get-or-post-request-in-postman-f87ca70b154e Try: https://github.com/beda-software/drf-writable-nested https://github.com/alanjds/drf-nested-routers Base64 ImageField","title":"Misc"},{"location":"lang/python/Python-Django/#views_2","text":"Function Based View Using normal functions like in Django (without using any rest_framework feature) Modules: from django.views.decorators.csrf import csrf_exempt from django.http import HttpResponse , JsonResponse from rest_framework.renderers import JSONRenderer from rest_framework.parsers import JSONParser Approach: write function with conditional branching for different http request methods write a _list function for listing all records (GET) & submiting a record (POST) write a _detail function for fetching, modifying or destroying a specific record by pk, ID or Name use JSON response & parser use @csrf_exempt decorator for safety code: https://gist.github.com/toransahu/1bad12b87dcd160c0de0d29d218d9bf6 Using @api_view() decorator Modules: from rest_framework import status from rest_framework.decorators import api_view from rest_framework.response import Response Approach: write function with conditional branching for different http request methods write a _list function for listing all records (GET) & submiting a record (POST) write a _detail function for fetching, modifying or destroying a specific record by pk, ID or Name decorate with @api_view() with parameters like ['GET'], ['GET', 'POST'], ['GET', 'PUT', 'DELETE'] etc By default @api_view() takes GET method if nothing is mentioned code: https://gist.github.com/toransahu/5c99704ec721e461b5f8fa67776a6d74 Class Based View By Inheriting APIView class Modules: from rest_framework.views import APIView from rest_framework.response import Response from rest_framework import status from django.http import Http404 Approach: write classes and define request handler methods in name of http request method for each http request method write a List class for listing all records (GET) & submiting a record (POST) write a Detail class for fetching, modifying or destroying a specific record by pk, ID or Name similar to Django's \"View\" class Note request handler methods receives REST's Request instance instead django's HttpRequest instance request handler methods may return REST's Response instance instead django's HttpResponse instance set few attributes like authentication_classes = (authentication.TokenAuthentication,) permission_classes = (permissions.IsAdminUser,) code: https://gist.github.com/toransahu/bcdb1a6beb5da0475c8c056837da940f Using mixins Modules: from rest_framework import mixins from rest_framework import generics Approach: write classes and inherit generics.GenericAPIView & mixins as per use write a List class and inherit mixins.ListModelMixin, mixins.CreateModelMixin, generics.GenericAPIView write a Detail class and inherit mixins.RetrieveModelMixin, mixins.UpdateModelMixin, mixins.DestroyModelMixin, generics.GenericAPIView base class providescore functionality & mixin classes provides actions like .list(), .create(), .retrieve(), .update() and .destroy() Code: https://gist.github.com/toransahu/dfc2666307c1628042b99edaba630c07 Using generic class-based views Modules: from rest_framework import generics Approach: write List class and inherit generics.ListCreateAPIView write Detail class and generics.RetrieveUpdateDestroyAPIView Code: https://gist.github.com/toransahu/ab21d8bf46f45616ccb9285dbd0b201a Using ViewSet Modules: from rest_framework import viewsets Approach: Only need to write a single class, named ModelNameViewSet and inhert viewsets.ModelViewSet facilitates router for URL writing Advantage: provides create, retrieve, update, and destroy in a single Class def DRY View code DRY URL code can also add custom endpoints as per our need, apart from regular create, retrieve, update, and destroy endpoint provided by ViewSet Code: https://gist.github.com/toransahu/c7d43776065aa6fda05d7389133c68f9","title":"Views"},{"location":"lang/python/Python-Django/#customdisable-request-methods-in-viewset","text":"By default ViewSets provides All the requests methods this technique will give power to override,disable those methods to do this use mixins with viewset.GenericViewSet , or override methods of ViewSet class url: https://gist.github.com/toransahu/e02fc30cd0e55e968971c46e59862acb","title":"Custom/Disable Request Methods in ViewSet"},{"location":"lang/python/Python-Django/#mapping-for-views-from-viewset-using-as_view","text":"syntax {<method>:<action>} patterns {'get': 'list'} {'get': 'retrieve'} {'post': 'create'} {'put': 'update'} {'patch': 'partial_update'} {'delete': 'destroy'}","title":"mapping for views from ViewSet using as_view()"},{"location":"lang/python/Python-Django/#adding-custom-routesaction-to-the-existing-viewset","text":"https://gist.github.com/toransahu/95781bc23f39192276d011d0aa990470 http://www.django-rest-framework.org/api-guide/routers/#customizing-dynamic-routes","title":"adding custom routes/action to the existing ViewSet"},{"location":"lang/python/Python-Django/#urls_1","text":"if using include( ) dont provide namespace if providing namespace inside include define app_name = in app/urls.py","title":"URLs"},{"location":"lang/python/Python-Django/#routers","text":"REST framework adds support for automatic URL routing to Django, and provides you with a simple, quick and consistent way of wiring your view logic to a set of URLs. from django.urls import path from .views import BlogViewSet from rest_framework.routers import DefaultRouter router = DefaultRouter () router . register ( '' , BlogViewSet , base_name = 'blogs' ) urlpatterns = router . urls Note: Try to keep base_name same as Model name, because view_name like blog-detail, blog-list comes from Model & not from app's name when we create custom actions (similar to -list, -detail) in any View using @detail_route(), we access that action using base_name in serializers. alternatively remove base_name","title":"Routers"},{"location":"lang/python/Python-Django/#actions-using-base_name","text":"<base_name>-list <base_name>-detail <base_name>-<any_custom>","title":"actions using base_name:"},{"location":"lang/python/Python-Django/#how-to-use-namespace-provided-in-url-patterns","text":"using from django.urls import reverse reverse(<namespace>:<base_name>-<action> or reverse(<namespace>:<model_name>-<action>","title":"how to use namespace (provided in url patterns)"},{"location":"lang/python/Python-Django/#adding-custom-routesaction-urls-to-the-existing-router-or-urlpatterns","text":"https://gist.github.com/toransahu/95781bc23f39192276d011d0aa990470","title":"adding custom routes/action urls to the existing Router or urlpatterns"},{"location":"lang/python/Python-Django/#api-versioning","text":"Source e.g. Its always a good idea to version your API so that you can make changes in your API without disturbing your current clients. e.g. http://127.0.0.1:8000/api/v1/blogs/","title":"API Versioning"},{"location":"lang/python/Python-Django/#configurations","text":"settings.py REST_FRAMEWORK = { 'DEFAULT_VERSIONING_CLASS' : 'rest_framework.versioning.NamespaceVersioning' } urls.py urlpatterns = [ path ( 'admin/' , admin . site . urls ), path ( 'api/v1/blogs/' , include ( 'blogs.urls' , namespace = 'v1' )), ] blogs/urls.py app_name = 'blogs' router = DefaultRouter () router . register ( '' , BlogViewSet , base_name = 'blogs' ) urlpatterns = router . urls","title":"Configurations"},{"location":"lang/python/Python-Django/#uses_2","text":"Once you have set versioning, django will be able to provide value of request.version else it will be None so, apply conditions ( if/else ) in View or serializers if there are changes in fields, then use versioning in serializers else, if there are only changes in some functionalities, (which current client cannot consume), then use versioning in veiws only, like: def get_serializer_class ( self ): if self . request . version == 'v1' : return AccountSerializerVersion1 return AccountSerializer","title":"Uses"},{"location":"lang/python/Python-Django/#allow-cors-cross-origin-resource-sharing-in-drf","text":"Source1 Source2","title":"Allow CORS (Cross Origin Resource Sharing) in DRF"},{"location":"lang/python/Python-Django/#using-custom-middleware-class","text":"need to define for each app python manage.py startapp app create app/cors.py and write class CorsMiddleware ( object ): def process_response ( self , req , resp ): response [ \"Access-Control-Allow-Origin\" ] = \"*\" return response - MIDDLEWARE_CLASSES = ['app.CorsMiddleware']","title":"Using Custom Middleware class"},{"location":"lang/python/Python-Django/#using-package-django-cors-headers","text":"works site-wide pipenv install django-cors-headers in settings.py INSTALLED_APPS = ['corsheaders'] MIDDLEWARE_CLASSES = ['corsheaders.middleware.CorsMiddleware',] , keep in top as possible as Allow using any one CORS_ORIGIN_ALLOW_ALL = True OR CORS_ORIGIN_ALLOW_ALL = False CORS_ORIGIN_WHITELIST = ['http//:localhost:8000',] also set ALLOWED_HOSTS = ['192.168.1.121'] and run server like python manage.py runserver 192.168.1.121:8000","title":"Using package django-cors-headers"},{"location":"lang/python/Python-Django/#creating-schema-from-api","text":"provides all the details about api endpoint present in site-wide urls will show all the endpoints actions fields if any authentication is needed it will show schema accordingly; if not authenticated, it will show that much api endpoints only need to configure in site-wide urls.py source: http://www.django-rest-framework.org/api-guide/schemas/ pipenv install coreapi from rest_framework.schemas import get_schema_view schema_view = get_schema_view ( title = \"Server Monitoring API\" ) urlpatterns = [ url ( '^<dollor_sign>' , schema_view ), ... ]","title":"Creating Schema from API"},{"location":"lang/python/Python-Django/#setting-media-url-root","text":"","title":"Setting Media URL &amp; ROOT"},{"location":"lang/python/Python-Django/#site-wide","text":"","title":"Site Wide"},{"location":"lang/python/Python-Django/#app-based","text":"define MEDIA_URL & MEDIA_ROOT in settings.py # Media files # https://timmyomahony.com/blog/static-vs-media-and-root-vs-path-in-django/ # the relative browser URL to be used when accessing our media files in the browser MEDIA_URL = 'media/' # the absolute path to the folder that will hold our user uploads # to get absolute path without hardcoding ENV_PATH = os . path . abspath ( os . path . dirname ( __file__ )) + os . sep + os . pardir MEDIA_ROOT = os . path . join ( ENV_PATH , 'media/' ) - add following code in app/urls.py # adding media url from django.conf import settings # from backend.settings import DEBUG from django.conf.urls.static import static # If developement env if settings . DEBUG is True : urlpatterns += static ( settings . MEDIA_URL , document_root = settings . MEDIA_ROOT ) want to set upload_to directory dynamically: code: https://gist.github.com/toransahu/8f9407250cee7a729473335bdd7a3f3b here comes, signal things, pre_save, post_save","title":"App Based"},{"location":"lang/python/Python-Django/#permission","text":"","title":"Permission"},{"location":"lang/python/Python-Django/#request-methods-level-permissions-in-viewset","text":"this needs when \"a user must post only or admin must post only\" type of requirements comes url-view: https://gist.github.com/toransahu/e02fc30cd0e55e968971c46e59862acb url-permission: https://gist.github.com/toransahu/c40b625165a395fabf772700f3ab2e04","title":"request methods level permissions (in ViewSet)"},{"location":"lang/python/Python-Django/#objects-level-permission","text":"TODO","title":"objects level permission"},{"location":"lang/python/Python-Django/#exceptionhttp-response","text":"When the permissions checks fail either a \"403 Forbidden\" or a \"401 Unauthorized\" response will be returned, according to the following rules: The request was successfully authenticated, but permission was denied. \u2014 An HTTP 403 Forbidden response will be returned. The request was not successfully authenticated, and the highest priority authentication class does not use WWW-Authenticate headers. \u2014 An HTTP 403 Forbidden response will be returned. The request was not successfully authenticated, and the highest priority authentication class does use WWW-Authenticate headers. \u2014 An HTTP 401 Unauthorized response, with an appropriate WWW-Authenticate header will be returned.","title":"Exception/Http response"},{"location":"lang/python/Python-Django/#authentication","text":"Source: http://www.django-rest-framework.org/api-guide/authentication/","title":"Authentication"},{"location":"lang/python/Python-Django/#basic-auth","text":"module: from rest_framework.authentication import BasicAuthentication By default used in DRF, whether you mention it in settings.py or views.py or not is only suitable for testing purpose, don't use in production if using in production you need to stick to Django Admin Login form page, can't use JSON need to be HTTPS","title":"Basic Auth"},{"location":"lang/python/Python-Django/#session-auth","text":"module from rest_framework.authentication import SessionAuthentication TODO","title":"Session Auth"},{"location":"lang/python/Python-Django/#token-auth","text":"Source: https://stackoverflow.com/questions/14838128/django-rest-framework-token-authentication module `from rest_framework.authentication import TokenAuthentication Prerequisites add 'rest_framework.authtoken' to INSTALLED_APPS in settings.py mention TokenAuthentication class in views or function based @authentication_classes ([ TokenAuthentication , ]) def abcd - detail (): pass class based class Abcd (): authentication_classes = [ TokenAuthentication , ] settings.py REST_FRAMEWORK = { 'DEFAULT_VERSIONING_CLASS' : 'rest_framework.versioning.NamespaceVersioning' , 'DEFAULT_AUTHENTICATION_CLASSES' : ( # 'rest_framework.authentication.BasicAuthentication', # 'rest_framework.authentication.SessionAuthentication', 'rest_framework.authentication.TokenAuthentication' , ), } Obtain Token DRF provides a view which returns a token on correct username & password. include following in urls.py from rest_framework.authtoken.views import obtain_auth_token urlpatterns = [ path ( 'api-auth-token/' , obtain_auth_token ),] - call the view as: http POST 127.0.0.1:8000/api-token-auth/ username='admin' password='whatever' will get token like: { \"token\" : \"blah_blah_blah\" } Use the Token in API call put the following in Header key: Authorization value: Token token_value Please mind the space between Token & token_value http GET 127.0.0.1:8000/whatever 'Authorization: Token your_token_value'","title":"Token Auth"},{"location":"lang/python/Python-Django/#jwt-json-web-token","text":"src: http://getblimp.github.io/django-rest-framework-jwt/ quick replacement of Default Token Auth Basic Changes Needed: pip install djangorestframework-jwt add in REST_FRAMEWORK setting 'DEFAULT_AUTHENTICATION_CLASSES': ( 'rest_framework_jwt.authentication.JSONWebTokenAuthentication', ) add view in url from rest_framework_jwt.views import obtain_jwt_token #... urlpatterns = [ '' , # ... url ( r '^api-token-auth/' , obtain_jwt_token ), ] jwt setting variables JWT_AUTH = { 'JWT_ENCODE_HANDLER' : 'rest_framework_jwt.utils.jwt_encode_handler' , 'JWT_DECODE_HANDLER' : 'rest_framework_jwt.utils.jwt_decode_handler' , 'JWT_PAYLOAD_HANDLER' : 'rest_framework_jwt.utils.jwt_payload_handler' , 'JWT_PAYLOAD_GET_USER_ID_HANDLER' : 'rest_framework_jwt.utils.jwt_get_user_id_from_payload_handler' , 'JWT_RESPONSE_PAYLOAD_HANDLER' : 'rest_framework_jwt.utils.jwt_response_payload_handler' , #'JWT_SECRET_KEY': settings.SECRET_KEY, #will take from settings.py by default 'JWT_GET_USER_SECRET_KEY' : None , 'JWT_PUBLIC_KEY' : None , 'JWT_PRIVATE_KEY' : None , 'JWT_ALGORITHM' : 'HS256' , 'JWT_VERIFY' : True , 'JWT_VERIFY_EXPIRATION' : True , 'JWT_LEEWAY' : 0 , 'JWT_EXPIRATION_DELTA' : datetime . timedelta ( seconds = 300 ), 'JWT_AUDIENCE' : None , 'JWT_ISSUER' : None , 'JWT_ALLOW_REFRESH' : True , #allowing it to refresh 'JWT_REFRESH_EXPIRATION_DELTA' : datetime . timedelta ( days = 7 ), 'JWT_AUTH_HEADER_PREFIX' : 'Token' , 'JWT_AUTH_COOKIE' : None , }","title":"JWT (JSON Web Token)"},{"location":"lang/python/Python-Django/#django-rest-auth-register-login-logout-reset-change","text":"src http://django-rest-auth.readthedocs.io/en/latest/api_endpoints.html https://michaelwashburnjr.com/django-user-authentication/ not recommanded, is not completely RESTful have issues with password/reset & password/reset/confirm/ depends on django-allauth for email things","title":"django-rest-auth (Register, Login, Logout, Reset, Change..)"},{"location":"lang/python/Python-Django/#djoser","text":"src: http://djoser.readthedocs.io/en/stable/sample_usage.html djoser uses following settings for email configuration (which is also used by django's default mail module from django.core.mail import send_mail CONFIG_PATH = os . path . join ( ENV_PATH , '../configs/' ) EMAIL_USE_TLS = True #EMAIL_USE_SSL = True #Use any one from TLS, SSL EMAIL_BACKEND = 'django.core.mail.backends.smtp.EmailBackend' #default one, production #EMAIL_BACKEND = 'django.core.mail.backends.console.EmailBackend' #for development EMAIL_HOST = 'smtp.gmail.com' with open ( os . path . join ( CONFIG_PATH , 'email_pwd' )) as f : EMAIL_HOST_PASSWORD = f . readline () EMAIL_HOST_USER = 'noreply.etherealmachines@gmail.com' EMAIL_PORT = 587 DEFAULT_FROM_EMAIL = EMAIL_HOST_USER EMAIL_ADMIN = ( 'toran.ethereal@gmail.com' , ) - djoser setting variables DJOSER = { 'PASSWORD_RESET_CONFIRM_URL' : 'auth/password/reset/confirm/ {uid} / {token} ' , 'ACTIVATION_URL' : 'auth/password/reset/confirm/ {uid} / {token} ' , 'EMAIL' : { 'activation' : 'djoser.email.ActivationEmail' , 'confirmation' : 'djoser.email.ConfirmationEmail' , 'password_reset' : 'djoser.email.PasswordResetEmail' , }, # DEFAULT; no need to define here 'SERIALIZERS' : { 'activation' : 'djoser.serializers.ActivationSerializer' , 'password_reset' : 'djoser.serializers.PasswordResetSerializer' , 'password_reset_confirm' : 'djoser.serializers.PasswordResetConfirmSerializer' , 'password_reset_confirm_retype' : 'djoser.serializers.PasswordResetConfirmRetypeSerializer' , 'set_password' : 'djoser.serializers.SetPasswordSerializer' , 'set_password_retype' : 'djoser.serializers.SetPasswordRetypeSerializer' , 'set_username' : 'djoser.serializers.SetUsernameSerializer' , 'set_username_retype' : 'djoser.serializers.SetUsernameRetypeSerializer' , 'user_create' : 'djoser.serializers.UserCreateSerializer' , 'user_delete' : 'djoser.serializers.UserDeleteSerializer' , 'user' : 'djoser.serializers.UserSerializer' , 'token' : 'djoser.serializers.TokenSerializer' , 'token_create' : 'djoser.serializers.TokenCreateSerializer' , }, }","title":"djoser"},{"location":"lang/python/Python-Django/#django-templated-mail","text":"djoser uses it to create mail template & send mails few setting variables: DOMAIN SITE_NAME","title":"django-templated-mail"},{"location":"lang/python/Python-Django/#testing_1","text":"","title":"Testing"},{"location":"lang/python/Python-Django/#testing-viewset-using","text":"APITestCase Token Authentication APIRequestFactory Source: https://gist.github.com/toransahu/706bd1de705e21f3be000e1517f7cae8","title":"Testing ViewSet using:"},{"location":"lang/python/Python-Django/#security_1","text":"https://stormpath.com/blog/where-to-store-your-jwts-cookies-vs-html5-web-storage http://kylebebak.github.io/post/django-rest-framework-auth-csrf django-jwt (JWT_AUTH_COOKIE ) is not safe https://github.com/GetBlimp/django-rest-framework-jwt/issues/338 if SessionAuthentication is enabled, then CSRF will be used (if ON) https://stackoverflow.com/questions/30871033/django-rest-framework-remove-csrf if JWTAuthentications is enabled, then CSRF is automatically disabled","title":"Security"},{"location":"lang/python/Python-Django/#vulnerabilities","text":"","title":"Vulnerabilities"},{"location":"lang/python/Python-Django/#csrf-cross-site-request-forgery_1","text":"","title":"CSRF (Cross Site Request Forgery)"},{"location":"lang/python/Python-Django/#xss-cross-site-script","text":"","title":"XSS (Cross Site Script)"},{"location":"lang/python/Python-Django/#vulnerables","text":"","title":"Vulnerables"},{"location":"lang/python/Python-Django/#web-client-local-session-storage","text":"XSS","title":"Web Client Local/ Session Storage"},{"location":"lang/python/Python-Django/#cookies-jwtauth","text":"CSRF ajax call : https://gist.github.com/bengolder/aa9033efc8959dc38e5d","title":"Cookies (JWT/Auth)"},{"location":"lang/python/Python-Django/#misc_1","text":"","title":"Misc"},{"location":"lang/python/Python-Django/#running-multiple-host-website-from-single-django-project","text":"source: http://effbot.org/zone/django-multihost.htm","title":"Running Multiple Host (website) from Single Django Project"},{"location":"lang/python/Python-Django/#get-request-url-string","text":"from django.contrib.sites.shortcuts import get_current_site print ( 'query_params are:' , request . build_absolute_uri ()) #returns url with domain print ( request . get_full_path ()) #returns url without domain print ( get_current_site ( request ) . domain , request . get_host ()) #both returns host or domain","title":"Get request URL string"},{"location":"lang/python/Python-Django/#get-slugs-from-url","text":"if you have any - url like: http://127.0.0.1:8000/auth/password/reset/confirm/Mw/4vw-d9cdc8954482ecf8e253/ - url pattern like: path('password/reset/confirm/ / /', password_reset_confirm, name='password_reset_confirm_custom_get') then code to fetch uid & token will be: https://gist.github.com/toransahu/68663e302f87a9c32a1dcd0654408577","title":"Get slugs from url"},{"location":"lang/python/Python-Django/#microservice-based-on-rest","text":"https://www.fullstackpython.com/microservices.html https://martinfowler.com/articles/microservices.html https://dev.otto.de/2016/03/20/why-microservices/ with flask: https://medium.com/@ssola/building-microservices-with-python-part-i-5240a8dcc2fb django to flask based microservice - https://medium.com/greedygame-media/how-we-broke-up-our-monolithic-django-service-into-microservices-8ad6ff4db9d4 https://blog.rapid7.com/2016/09/15/microservices-please-dont/","title":"Microservice Based on REST"},{"location":"lang/python/Python-OOPs/","text":"OOPs Basics UML 2.x (Unified Modeling Language) ERD (Entity Relation Diagram) OOPs Features Abstraction Ex Encapsulation Ex. Difference between Abstraction and Encapsulation: Implementation in Class using Access Modifiers Polymorphism Static Polymorphism (Method-Overloading) Runtime Polymorphism (Method-Overriding) Inheritance Types Diamond Problem Need of super() Other relationships Association Weak Association (Aggregation) Strong Association (Composition) Aggregation Association vs Aggregation Composition (Not-Shared Association) Realization Dependency Implementations of OOPs class type metaclass __new__() __init__() __call__() instance Old vs New Style object keyword MRO Old MRO Algorithm (Based on Old-Style Class) C3 New MRO Algorithm (Based on New-Style Class) Impossible Method Resolution Abstract Base Class (Abstract Class) Bottom Line Class Decorators Class Decorators versus metaclass Interface Variables Instance Variable Static or Class Variable Instance vs Class/Static attribute lookup order Methods Abstract Method Method vs Function Static Method What How Why Code Class Method What How Why Code Magic Method Class Internal Methods __new__ __init__ __call__ __get__ __set__ __del__ __slots__ __getattribute__ __getattr__ __getattr__ vs __getattribute__ __enter__ __exit__ __repr__ __str__ __format__ __iter__ __next__ __reversed__ __dir__ __setattr__ __delattr__ __len__ __contains__ __getitem__ Properties Descriptors Protocol Simple Implemetation Property implementation Misc Ways to call a class member function __slots__ : reduce RAM usage Unbound vs Bound Method Unbound Method (Simple Function in Python 3.x) Bound Method Closure TODO: stack queue class design class custom metaclass creation OOPs Basics # UML 2.x (Unified Modeling Language) # UML can be used for many diagrams other then ERD sequence diagram state diagram more for the funcionality of the application (what user can do, who does it, when he does it, before what step, what table he use to do it) other then the tables description. many more (http://agilemodeling.com/essays/umlDiagrams.htm) read more: https://www.omg.org/spec/UML https://en.wikipedia.org/wiki/Unified_Modeling_Language#UML_2 ERD (Entity Relation Diagram) # Gives image of how the tables should connect what fields are going to be on each table the tables connection, if many-to-many, one-to-many. OOPs Features # Inheritance Polymorphism Encapsulation Abstraction Abstraction # (Implementation hiding) * Core concept in all of computer science. * Without abstraction, we would still be programming in machine code or worse not have computers * Give names to things, so that the name captures the core of what a function or a whole program does. * Used to hide internal details and show only functionalities. * e.g : Any Verb Ex # Imagine a graphics library \"nicepic\" that contains pre-defined functions for: rectangles, squares, triangles, house, village. import nicepic draw_house () Suppose an ATM. You simply insert your card and click some buttons and get the money. You dont know what is happening internally on press of these buttons. Encapsulation # (Information hiding) * Is a characteristic to bind data members and functions in single unit. * Is packing of data and functions operating on that data into a single component and restricting the access to some of the objects components. * Is a mechanism which represent the essential features without including implementation details. * e.g : Any Noun Ex. # A class is an example of encapsulation as it encapsulates all the data that is member functions,variables etc. Suppose there is a tree. Tree can have root, stem, branches, leaves, flowers and fruits. But in a single unit we call it a tree. Difference between Abstraction and Encapsulation: # Abstraction:Implementation hiding. Encapsulation:Information hiding. Implementation in Class using Access Modifiers # Python has no privacy model, there are no access modifiers like in C++, C# or Java. There are no truly 'protected' or 'private' attributes. Public: Protected members: Accessible outside the class and from its subclasses. By prefixing the name of your member with a single underscore Accessing using: obj._protected_mem Just a convention to show, the variable is protected class Person : def __init__ ( self ): self . name = 'Toran' self . _lastname = 'Sahu' # protected self . __gender = 'Male' def PrintName ( self ): return self . name + ' ' + self . _lastname #Outside of class p = Person () print ( p . name ) # Out - Toran print ( p . PrintName ()) # Out - Toran Sahu # print(p._lastname) # Out - Sahu Private members: Add ____ (double underscore ) in front of the variable and function name Accessing private member : Using name mangling : obj._classname__private_mem # print(p.__gender) # AttributeError - no attribute '__gender' print ( p . _Person__gender ) # name-mangling : Out - Male Polymorphism # In general: The ability to appear in many forms. Specifically: The ability to redefine methods for derived classes. Static Polymorphism (Method-Overloading) # Multiple times method with same name does not support in Python (its always takes the last definition) We can achieve this in python in Single method itself By passing default parameters or by using *arg , **kwargs Runtime Polymorphism (Method-Overriding) # Supports using Inheritance Inheritance # keyword: is-a sign: Types # Single Multilevel Multiple Hierchical Diamond Problem # resolved in python using order-preference (Method Resolution Order\" MRO) in multiplle inheritance preference order Search Path using Depth first search with linear search (old style python 2 classes) Search Path with optimization using Depth first search & linear search (new style python3 classes + python2 classes whicj inherits object ) class A : def m ( self ): print ( \"m of A called\" ) class B ( A ): pass class C ( A ): def m ( self ): print ( \"m of C called\" ) class D ( B , C ): pass d = D () d . m () Out: m of C called Need of super() # lets avoid referring to the base class explicitly (i.e. just one class above) e.g. python 3.x: super().__init__() python 2.x: super(<ChildClassName>, self.__init__()) 2 Basic Uses In class hierarchy with single inheritance used to refer to parent classes without naming them explicitly thus making code more maintainable similar in other languages Support cooperative multiple inheritance in dynamic execution environment unique to python only implements diamond diagram Magic happens like: m of A called printed once instead twice e.g. as shown below https://stackoverflow.com/questions/5033903/python-super-method-and-calling-alternatives applications useful for accessing inherited methods that have been overridden in a child class Note: uses MRO, in case of multiple inheritance, e.g. of class D Facts: if super().m() is used in a member functions of a sub-class D to call its parent's member function, where class D inherits class B and C then super().m() will instantiate both the parent class B and C and will call method m() in both also, if B and C 's method m() calls its super().m(), where B & C inherits class A then only one time m() of A will be called (the smartest decision) class A : def m ( self ): print ( \"m of A called\" ) class B ( A ): def m ( self ): print ( \"m of B called\" ) # A.m(self) super () . m () class C ( A ): def m ( self ): print ( \"m of C called\" ) # A.m(self) super () . m () class D ( B , C ): def m ( self ): print ( \"m of D called\" ) # B.m(self) # C.m(self) super () . m () d = D () d . m () Out: m of D called m of B called m of C called m of A called Other relationships # src: https://javapapers.com/oops/association-aggregation-composition-abstraction-generalization-realization-dependency/ These relationships are totally implementation based how you want to function relationship between two or more classes & their instances Association Aggregation Composition Generalization Specialization Dependency Note: uses-a has-a / uses-a part-of (contains-a, consists-a) / has-a / uses-a i.e. a part-of relation can always use words like has-a, uses-a so, to find out a perfect relationship, try to approach in a top-to-down manner, to make the relationship more specific Association # keyword: uses-a sign: single line with arrow unidirectional if class A uses instance of class B arrow will point towards class B bidirectional explanation defines the multiplicity (cardianality) between objects one-to-one, one-to-many, many-to-one, many-to-many all classes/instances have their own life cycle (in general cases) no body have ownership over another (in general cases) e.g. house uses-an internet provider Weak Association (Aggregation) # explanation: Lets say we have class A & B class A has-an (or uses-an) instance class B means class A's any method uses instance of class B as a parameter or returns the instance or if an instance of class A calls a member function (an operation) of an instance of the class B or class A holds instance of class B but instance of class B doesn't get destroyed when instance of class B is created & passed to constructor of class A Strong Association (Composition) # explanation: Lets say we have class A & B class A has-an instance of class B / class B is part-of class A / class A consists of class B means class A holds instance of class B & the instance gets destroyed with destruction of instance of class A i.e. instance of class B is created & gets destroyed inside class A Aggregation # aka Shared Association Weak Association keyword: has-a (uses-a) sign: a line with hollow diamond \"whole\" end have a hollow diamond shaped arrow-head cardianality: one-to-one, one-to-many, many-to-many explanation Classes Within Classes When an object \u2018has-a\u2019 another object when one object is an attribute of another whole/part relationship (i.e. part of relationship) special form of Association e.g. a library has-a student a student can exist without a library a Text-editor has-a file opened if text editor is closed, file still exists conditional e.g. if parts of a car are reusable car uses-a/has-a engine if car is scrapped, engine still exists note: It\u2019s always safe to call a relationship an association,but if class A contains objects of class B , and is organizationally superior to class B , it\u2019s a good candidate for aggregation. Association vs Aggregation # The association link can replace aggregation link in every situation Composition (Not-Shared Association) # keyword: has-a (part-of, consists-of, composed-of) sign: a line with solid diamond unidirectional only \"whole\" end have a solid diamond shaped arrow-head cardianality: one-to-many, many-to-many explanation: When an object contains the other object (The part may belong to only one whole) if the contained object cannot exist without the existence of container object i.e. The lifetime of the part is the same as the lifetime of the whole. special form of Aggregation Stronger/restricted aggregation ownership relation e.g a house has-a room if house is destroyed, room also gets a class has (contains) students students cannot exist without a class a text editor has a buffer if text editor is closed, buffer also gets destroyed conditional e.g. if parts of a car are NOT reusable a car has-a wheel if a car is destroyed, wheel also gets destroyed Realization # Dependency # Implementations of OOPs # class # in python everything is object of some class classes are first-class objects they can be created at runtime, passed as parameters and returned from functions, and assigned to variables even class is object of something this something by default is type class we can create a class which is an object of type class read metaclass for deep knowledge cls_a = type ( 'A' , ( object ,), dict ({ 'foo' : 2 , 'bar' : 3 })) # type(class_name_str, base_classes_tuple, body_dict) this way we can create a class at runtime type # type is the class of python classes class Example : pass e = Example () e . __class__ # prints: <class __main__.Example> Example . __class__ # prints: <type 'type'> so in above code, e is object of class Example and Example is object of class type in python3 we can use type and class interchangabely which was not used in python2 so, whenever we write keyword class while defining a class, an object of class type gets created metaclass # source: https://eli.thegreenplace.net/2011/08/14/python-metaclasses-by-example/ https://realpython.com/python-metaclasses/#defining-a-class-dynamically a metaclass is defined as the class of a class Any class whose instances are themselves classes, is a metaclass so, type is also a kind of metaclass (which is by default for all python classes and mostly used), but not always we can define a metaclass for a class class Example ( metaclass = SomeMetaclass ): # in python2 define metaclass here like # __metaclass__ = SomeMetaclass pass Since a metaclass is the class of a class it is used to construct classes (just as a class is used to construct objects) as we have already seen, class keyword invokes type function to create a class it was because, type is default metaclass in reality class keyword do followings when python encounters class definiton, it collects all the attributes in a dict when collection is over, python determines metaclass of the class, lets say SomeMetaclass using SomeClass.__metaclass__ then python calls Metaclass(class_name, (base_classes, ), body_dict) , where class_name is the name of the class (string ) (base_clasees, ) is the tuple of base classes, if it was empty in class definition, then by dafault it is object body_dict is a python dict contaning all the class attribute names metaclass defines structure/metadata of the class Methods of metaclass to create & initialize a class are: __new__() # used to perform some basic stuff like memory allocation called on creation of an object of the class __init__() # works as contructor in python used to perform initialization of data called on creation of an object of the class it is called after above methods __new__() so in case of creation of class (suppose A ), it is called when we call type() __call__() # it is called after above two methods in case of creation of class, it is called when an object (suppose a = A() ) of the class (created from above two steps) is created. instance # TODO: - confusion in magic method call orders - how a class instance are created - as a class is object of a metaclass ```python #here class A A = type('A', (object,), {\"a\":1}) ``` - whenever we call any object/instance of any class, it calls the `__call__` of that class ```python a = A() #here A() will call the __call__ of metaclass type ``` - so, a is created by A(), where A() means calling `__call__` of `type` metaclass - if we provide A() parameters, like A(1,2), then `__call__(self, *args, **kwargs)__` handles those parameters - then inside metaclass's `__call__` , `__init__` of the class is called by passing all the parameters passed to `__call__` so, whenever we create an object/instance of a class, following things happens: metaclass's __new__ is called; creates memory (object) for class metaclass's __init__ is called; intializes class with its name and body when class, lets say Example is called Example(), then metaclass's __call__ is called to initialize the object of Example class, Example.__init__ is called Old vs New Style # in python realm, there are two varities of classes Old-Style object of a class is always a in python 2.x , classes are old-style by deafult due to compatibility issues in python 2.x, New-Style classes are created by inheriting other New-style classes or top-level type object here object is a keyword which is instance of class type , and we know that type is a metaclass and metaclass is a class of class hence instance of a metaclass is always a class hence object keyword is a kind of class, which is created already in python just to implement a New-Style class syntax are like class A ( object ): pass New-Style object of a class is always a in python 3.x has new-style classes only hence no need to inherit object in class class Example : pass introduced in python2.2 to unify the concepts of class and type in new-style type(x) and x.__class__ are always same a new-style class is simply a user-defined type more differences at https://stackoverflow.com/questions/4015417/python-class-inherits-object TODO: object keyword # object is a keyword which is instance of class type , and we know that type is a metaclass and metaclass is a class of class hence instance of a metaclass is always a class hence object keyword is a kind of class, which is created already in python just to implement a New-Style class MRO # (Method Resolution Order) - source: - https://makina-corpus.com/blog/metier/2014/python-tutorial-understanding-python-mro-class-search-path - class.__mro__ is only available in New-Style class Script: 1 class A : def m ( self ): print ( \"m of A called\" ) class B ( A ): def m ( self ): print ( \"m of B called\" ) class C ( A ): #def m(self): # print(\"m of C called\") pass class D ( B , C ): #def m(self): # print(\"m of D called\") pass d = D () d . m () Script: 2 class A1 (): # def who_am_i(self): # print(\"I am a A1\") pass class A2 (): def who_am_i ( self ): print ( \"I am a A2\" ) class B ( A1 , A2 ): # def who_am_i(self): # print(\"I am a B\") pass class C ( A2 ): def who_am_i ( self ): print ( \"I am a C\" ) class D ( B , C ): # def who_am_i(self): # print(\"I am a D\") pass d1 = D () d1 . who_am_i () Old MRO Algorithm (Based on Old-Style Class) # uses depth-first serach followed by linear search (left to right) we call this order search path in script 1 Looking in D If not found, looking in B If not found, looking un B first parent A If not found, going back in B others parents (none) If not found, looking in D others parents : C in script 2 search path will be D, B, A1, A2, C, A2 C3 New MRO Algorithm (Based on New-Style Class) # default in python3 works in python2 with classes who inherits object Algo defines search path same as old algorithm then simplifies the search path like this iterate through the original search path put pointer on current class check if any classes after the pointer are child of current class (in other words, check if any classes after the pointer inherits the current class) if yes, then remove the current class from search path if no, then move the pointer to next class in the right do the same till end of search path list in script 1 original search path will be D, B, A, C, A then simplified search path will be D, B, C, A in script 2 search path will be D, B, A1, A2, C, A2 then simplified search path should be D, B, A1, C, A2 Impossible Method Resolution # Script: class X (): def who_am_i ( self ): print ( \"I am a X\" ) class Y (): def who_am_i ( self ): print ( \"I am a Y\" ) class A ( X , Y ): def who_am_i ( self ): print ( \"I am a A\" ) class B ( Y , X ): def who_am_i ( self ): print ( \"I am a B\" ) class F ( A , B ): def who_am_i ( self ): print ( \"I am a F\" ) In Old MRO algo, search path is F, A, X, Y, B, Y, X In New MRO algo, simplified search path is F, A, B, Y, X but New MRO algo fails to give __mro__ and throws following exception TypeError: Cannot create a consistent method resolution Abstract Base Class (Abstract Class) # Classes that contains one or more abstract methods as well as concrete methods. A normal class cannot have abstract methods. Cannot instantiate an abstract class that has abstract methods Subclass which implements all the abstract method can be instantiated Python Implementation: # Python 3.4+ from abc import ABC , abstractmethod class Abstract ( ABC ): @abstractmethod def foo ( self ): pass # Python 3.0+ from abc import ABCMeta , abstractmethod class Abstract ( metaclass = ABCMeta ): @abstractmethod def foo ( self ): pass # Python 2 from abc import ABCMeta , abstractmethod class Abstract : __metaclass__ = ABCMeta @abstractmethod def foo ( self ): pass Bottom Line # in python3: base class of classes are: object metaclass of classes are: type type of classes are: type classes are instance of class: type Class Decorators # e.g. https://github.com/toransahu/py-misc/blob/master/class_based_class_decorator_with_pre_post.py TODO: Class Decorators versus metaclass # source: https://jfine-python-classes.readthedocs.io/en/latest/decorators-versus-metaclass.html nothing different other than implementation style Interface # Doesn't need in Python (bcoz, it was need in other lang. to full-fill the Multiple inheritance) Concept: * A class with all the methods abstract * Contains Methods signature * Do not contain definition/method body * Constant variables (which must be Static + Final in other langs.) - in python there is no final or const keyword * Cannot instantiated * Behaviour/methods which must be implemented by classes * Class which implement interface should implement all the methods OR be an abstract class Python Implementation: class Engine (): \"\"\" Engine Interface\"\"\" def ignition ( self ): raise NotImplementedError ( \"Ingnition should have implemented.\" ) def fuel ( self ): raise NotImplementedError ( \"Fuel should have implemented.\" ) Variables # Instance Variable # variable defined inside class methods different for different objects every object have its own copy Static or Class Variable # defined in class level shared by all the objects can be accessed by Class name as well as objects with the same name, there can be one class level variable and one instance level variable, see in e.g. in this case, Class.variable will definitely access the static var but instance.variable will access the instance variable accessing inside methods it can be accessed using Class.var & self.var if there is instance variable with the same name then self.var will access the instance variable class A : variable = 'Static/class Variable' # static/class variable var = 'Static/class Var' # static/class variable def __init__ ( self ): self . variable = 'Instance Variable' def foo ( self ): print ( A . variable , self . variable , self . var ) print ( A . variable ) a = A () a . foo () Out: Static/class Variable Instance Variable Static/class Var Static/class Variable Instance Variable Instance vs Class/Static attribute lookup order # instance/object > static/class > base class which is: a. dict ['x'] > type(a). dict ['x'] > type(a) Methods # Abstract Method # a method without definition (only declared) only signature In python: a method decorated with @abstractmethod Method vs Function # Method works exactly same as a simple function. But a method's first argument always receives the instance object: Code: def outside_foo (): pass def outside_foo ( self ,): pass Static Method # What # an organization/stylistic feature functionality-wise same as normal module level functions except, module level func can access an instance and hence instance variables, but static method cannot designed to work on class attributes can be called using class as well as instance A static method has no self argument Never receive an automatic self argument, whether called through a class or an instance. can access/modify class or static variables using class_name.var How # two way of declaration using decorator @staticmethod [fn_name] = staticmethod([fn_name]) Why # to restrict access of instance attributes (unlike a normal method have access) to fix the access of static variable of a that particular class only because it is hardcoded like A.static_variable src: http://radek.io/2011/07/21/static-variables-and-methods-in-python/ Code # class A : static_variable = 'Static/class Variable of class A' # static/class variable def __init__ ( self ): self . instance_variable = 'Instance Variable' @staticmethod def static_method (): print ( 'Inside static_method()' , A . static_variable ) # works # print('Inside static_method()', A.instance_variable) # error, static method can't access instance attributes # static method def way2 (): pass # making way2() a static method way2 = staticmethod ( way2 ) class B ( A ): static_variable = 'Static/class Variable of class B' # static/class variable # but a module level func can access an instance attribute def module_level_func (): a1 = A () print ( a1 . instance_variable ) a2 = A () a2 . static_method () A . static_method () B . static_method () # still accessing static_variable from class A Out: Inside static_method() Static/class Variable of class A Inside static_method() Static/class Variable of class A Inside static_method() Static/class Variable of class A Class Method # What # an organization/stylistic feature not different from static method, only signature diff it receives one mandatory arguement: a class name it was called from apart from this first parameter, there is no any functionality diff between class & static method designed to work on class attributes can be called using class as well as instance can access/modify class or static variables using cls.var where cls is first parameter provided to a classmethod How # implemented using decorator @classmethod assigning to function i.e., method_name = classmethod(method_name) Why # to restrict access of instance attributes (unlike a normal method have access) to make code more maintanable than static methods Code # class A : static_variable = 'Static/class Variable of class A' # static/class variable def __init__ ( self ): self . instance_variable = 'Instance Variable' @classmethod def class_method ( cls ): print ( 'Inside class_method()' , cls . static_variable ) # works # print('Inside class_method()', cls.instance_variable) # error, class method can't access instance attributes # static method def way2 ( cls ): pass # making way2() a static method way2 = classmethod ( way2 ) class B ( A ): static_variable = 'Static/class Variable of class B' # static/class variable # but a module level func can access an instance attribute def module_level_func (): a1 = A () print ( a1 . instance_variable ) a2 = A () a2 . class_method () A . class_method () B . class_method () # now it will access static variable of class B Out: Inside class_method() Static/class Variable of class A Inside class_method() Static/class Variable of class A Inside class_method() Static/class Variable of class B Magic Method # TODO: Source: https://www.python-course.eu/python3_magic_methods.php https://rszalski.github.io/magicmethods/ Methods with dunders (+) : __add()__ (-) : __sub()__ Can be used for operator overloading, as class Calc ( int ): def __init__ ( self , x ): self . x = x def __add__ ( self , other ): return self . x + other . x + 1 a = Calc ( 1 ) b = Calc ( 1 ) a + b Out: 3 Class Internal Methods # TODO: Source: http://www.diveintopython3.net/special-method-names.html https://rszalski.github.io/magicmethods/ Some famous magic methods / internal methods of a class __new__ # allocates memory to class instance __init__ # initializes instance with some values __call__ # called upon calling an instance (e.g. a = A(); a()) __get__ # get descriptor method __set__ # set descriptor method __del__ # del descriptor method __slots__ # allows us to explicitly declare data members (like properties) and deny the creation of __dict__ & __weakref__ (unless explicitly declared in __slots__ ) __getattribute__ # called when accessing any attribute via class instance c = C () c . name __getattr__ # same as __getattribute__ but gets called only when attribiute is not found via __getattribute__ __getattr__ vs __getattribute__ # Source: http://www.diveintopython3.net/special-method-names.html __enter__ # __exit__ # __repr__ # __str__ # __format__ # __iter__ # __next__ # __reversed__ # __dir__ # __setattr__ # __delattr__ # __len__ # __contains__ # __getitem__ # Properties # Source: https://www.journaldev.com/14893/python-property-decorator https://docs.python.org/3/howto/descriptor.html#properties https://medium.com/shecodeafrica/managing-class-attributes-in-python-c42d501c5ee0 Why to manage access to an attribute to outer world can only allow get can only allow set can only allow del can perform something more while doing above operations to solve problem like this (dependent attribute value issue) e.g. class Example : def __init__ ( self , ap , bp ): self . _a = ap self . _b = bp self . c = self . _a + self . _b def get_c ( self ): return self . c e = Example ( 1 , 2 ) print ( e . _a ) print ( e . _b ) print ( e . c ) print ( e . get_c ()) e . _a = 5 print ( e . _a ) print ( e . c ) print ( e . get_c ()) solution e.g. class Example : def __init__ ( self , ap , bp ): self . _a = ap self . _b = bp @property def c ( self ): return self . _a + self . _b e = Example ( 1 , 2 ) print ( e . _a ) print ( e . _b ) print ( e . c ) e . _a = 5 print ( e . _a ) print ( e . c ) What property are built -in python decorators provides 3 methods get set del How property in python are implemented using Descriptors uses : pattern 1 class Example : def __init__ ( self , ap ): self . _a = ap @property def a ( self ): return self . _a @a . setter def a ( self , value ): self . _a = value @a . deleter def a ( self ): del self . _a e = Example ( 1 ) print ( e . a ) e . a = 5 print ( e . a ) del ( e . a ) print ( e . a ) #AttributeError: 'Example' object has no attribute '_a' uses : pattern 2 class Example : def __init__ ( self , ap ): self . _a = ap def get_a ( self ): return self . _a def set_a ( self , value ): self . _a = value def del_a ( self ): del self . _a # will give only get access a = property ( fget = get_a ) # will give only set access a = property ( fset = set_a ) # will give only del access a = property ( fdel = del_a ) #will give all access of var `a` a = property ( get_a , set_a , del_a ) #property(fget=None, fset=None, fdel=None, doc=None) e = Example ( 1 ) print ( e . a ) e . a = 5 print ( e . a ) del ( e . a ) print ( e . a ) # AttributeError: 'Example' object has no attribute '_a' Descriptors # TODO: Source: https://docs.python.org/3/howto/descriptor.html descriptor is an object attribute with \u201cbinding behavior\u201d, one whose attribute access has been overridden by methods in the descriptor protocol Those methods are get (), set (), and delete () Basic default behavior for attribute access is to get, set, or delete For instance, a.x has a lookup chain starting with a. dict ['x'], then type(a). dict ['x'], and continuing through the base classes of type(a) excluding metaclasses If there is descriptor x defined, then descriptor will override the lookup order and will become number one Use Cases They are the mechanism behind properties, methods, static methods, class methods, and super() They are used throughout Python itself to implement the new style classes introduced in version 2.2 Protocol # descr . __get__ ( self , obj , type = None ) --> value descr . __set__ ( self , obj , value ) --> None descr . __delete__ ( self , obj ) --> None define any of the above in any class, and object will considered as descriptor and descriptor will override the default attribute lookup behavior (in class dictionary lookup) if object defines both __get__ and __set__ ; then its data descriptor if instance have attribute (means entry in instance dict) with same name as descriptor, then here lookup order will become data descriptor > instance dict if object defines only __get__ ; then its non-data descriptor in this case if instance have attribute with same name as descriptor, then here lookup order will become instance dict > data descriptor Simple Implemetation # TODO - Issue with __del__ ; not explained in python doc class ExampleDescriptor : def __init__ ( self , val ): self . val = val def __get__ ( self , obj , objtype = None ): print ( \"getting\" ) return self . val def __set__ ( self , obj , val ): print ( \"setting\" ) self . val = val class Example : name = ExampleDescriptor ( \"toran\" ) if __name__ == \"__main__\" : e = Example () print ( e . name ) e . name = \"sahu\" print ( e . name ) Property implementation # class Property ( object ): \"Emulate PyProperty_Type() in Objects/descrobject.c\" def __init__ ( self , fget = None , fset = None , fdel = None , doc = None ): self . fget = fget self . fset = fset self . fdel = fdel if doc is None and fget is not None : doc = fget . __doc__ self . __doc__ = doc def __get__ ( self , obj , objtype = None ): if obj is None : return self if self . fget is None : raise AttributeError ( \"unreadable attribute\" ) return self . fget ( obj ) def __set__ ( self , obj , value ): if self . fset is None : raise AttributeError ( \"can't set attribute\" ) self . fset ( obj , value ) def __delete__ ( self , obj ): if self . fdel is None : raise AttributeError ( \"can't delete attribute\" ) self . fdel ( obj ) def getter ( self , fget ): return type ( self )( fget , self . fset , self . fdel , self . __doc__ ) def setter ( self , fset ): return type ( self )( self . fget , fset , self . fdel , self . __doc__ ) def deleter ( self , fdel ): return type ( self )( self . fget , self . fset , fdel , self . __doc__ ) Misc # Ways to call a class member function # a = A () a . foo ( args ) a = A () A . foo ( a , args ) __slots__ : reduce RAM usage # source http://book.pythontips.com/en/latest/__slots__magic.html Unbound vs Bound Method # Unbound Method (Simple Function in Python 3.x) # Unbound means not bound to any instance i.e. callable using class name Bound Method # Bound methods are bound to some instance Need an instance to call it. Note: In Python 3.x, the notion of Unbound Method has been dropped and we treat it as Simple Function. Closure # A combination of code and scope. It's about nested function and the scope of the function Code: def startAt ( start ): def incrementBy ( inc ): return start + inc return incrementBy f = startAt ( 10 ) g = startAt ( 100 ) print ( f ( 1 ), g ( 2 )) # Using lamba def startAt ( start ): return lambda inc : start + inc f = startAt ( 10 ) g = startAt ( 100 ) print ( f ( 1 ), g ( 2 )) Out: 11 102 11 102","title":"Python OOPs"},{"location":"lang/python/Python-OOPs/#oops-basics","text":"","title":"OOPs Basics"},{"location":"lang/python/Python-OOPs/#uml-2x-unified-modeling-language","text":"UML can be used for many diagrams other then ERD sequence diagram state diagram more for the funcionality of the application (what user can do, who does it, when he does it, before what step, what table he use to do it) other then the tables description. many more (http://agilemodeling.com/essays/umlDiagrams.htm) read more: https://www.omg.org/spec/UML https://en.wikipedia.org/wiki/Unified_Modeling_Language#UML_2","title":"UML 2.x (Unified Modeling Language)"},{"location":"lang/python/Python-OOPs/#erd-entity-relation-diagram","text":"Gives image of how the tables should connect what fields are going to be on each table the tables connection, if many-to-many, one-to-many.","title":"ERD (Entity Relation Diagram)"},{"location":"lang/python/Python-OOPs/#oops-features","text":"Inheritance Polymorphism Encapsulation Abstraction","title":"OOPs Features"},{"location":"lang/python/Python-OOPs/#abstraction","text":"(Implementation hiding) * Core concept in all of computer science. * Without abstraction, we would still be programming in machine code or worse not have computers * Give names to things, so that the name captures the core of what a function or a whole program does. * Used to hide internal details and show only functionalities. * e.g : Any Verb","title":"Abstraction"},{"location":"lang/python/Python-OOPs/#ex","text":"Imagine a graphics library \"nicepic\" that contains pre-defined functions for: rectangles, squares, triangles, house, village. import nicepic draw_house () Suppose an ATM. You simply insert your card and click some buttons and get the money. You dont know what is happening internally on press of these buttons.","title":"Ex"},{"location":"lang/python/Python-OOPs/#encapsulation","text":"(Information hiding) * Is a characteristic to bind data members and functions in single unit. * Is packing of data and functions operating on that data into a single component and restricting the access to some of the objects components. * Is a mechanism which represent the essential features without including implementation details. * e.g : Any Noun","title":"Encapsulation"},{"location":"lang/python/Python-OOPs/#ex_1","text":"A class is an example of encapsulation as it encapsulates all the data that is member functions,variables etc. Suppose there is a tree. Tree can have root, stem, branches, leaves, flowers and fruits. But in a single unit we call it a tree.","title":"Ex."},{"location":"lang/python/Python-OOPs/#difference-between-abstraction-and-encapsulation","text":"Abstraction:Implementation hiding. Encapsulation:Information hiding.","title":"Difference between Abstraction and Encapsulation:"},{"location":"lang/python/Python-OOPs/#implementation-in-class-using-access-modifiers","text":"Python has no privacy model, there are no access modifiers like in C++, C# or Java. There are no truly 'protected' or 'private' attributes. Public: Protected members: Accessible outside the class and from its subclasses. By prefixing the name of your member with a single underscore Accessing using: obj._protected_mem Just a convention to show, the variable is protected class Person : def __init__ ( self ): self . name = 'Toran' self . _lastname = 'Sahu' # protected self . __gender = 'Male' def PrintName ( self ): return self . name + ' ' + self . _lastname #Outside of class p = Person () print ( p . name ) # Out - Toran print ( p . PrintName ()) # Out - Toran Sahu # print(p._lastname) # Out - Sahu Private members: Add ____ (double underscore ) in front of the variable and function name Accessing private member : Using name mangling : obj._classname__private_mem # print(p.__gender) # AttributeError - no attribute '__gender' print ( p . _Person__gender ) # name-mangling : Out - Male","title":"Implementation in Class using Access Modifiers"},{"location":"lang/python/Python-OOPs/#polymorphism","text":"In general: The ability to appear in many forms. Specifically: The ability to redefine methods for derived classes.","title":"Polymorphism"},{"location":"lang/python/Python-OOPs/#static-polymorphism-method-overloading","text":"Multiple times method with same name does not support in Python (its always takes the last definition) We can achieve this in python in Single method itself By passing default parameters or by using *arg , **kwargs","title":"Static Polymorphism (Method-Overloading)"},{"location":"lang/python/Python-OOPs/#runtime-polymorphism-method-overriding","text":"Supports using Inheritance","title":"Runtime Polymorphism (Method-Overriding)"},{"location":"lang/python/Python-OOPs/#inheritance","text":"keyword: is-a sign:","title":"Inheritance"},{"location":"lang/python/Python-OOPs/#types","text":"Single Multilevel Multiple Hierchical","title":"Types"},{"location":"lang/python/Python-OOPs/#diamond-problem","text":"resolved in python using order-preference (Method Resolution Order\" MRO) in multiplle inheritance preference order Search Path using Depth first search with linear search (old style python 2 classes) Search Path with optimization using Depth first search & linear search (new style python3 classes + python2 classes whicj inherits object ) class A : def m ( self ): print ( \"m of A called\" ) class B ( A ): pass class C ( A ): def m ( self ): print ( \"m of C called\" ) class D ( B , C ): pass d = D () d . m () Out: m of C called","title":"Diamond Problem"},{"location":"lang/python/Python-OOPs/#need-of-super","text":"lets avoid referring to the base class explicitly (i.e. just one class above) e.g. python 3.x: super().__init__() python 2.x: super(<ChildClassName>, self.__init__()) 2 Basic Uses In class hierarchy with single inheritance used to refer to parent classes without naming them explicitly thus making code more maintainable similar in other languages Support cooperative multiple inheritance in dynamic execution environment unique to python only implements diamond diagram Magic happens like: m of A called printed once instead twice e.g. as shown below https://stackoverflow.com/questions/5033903/python-super-method-and-calling-alternatives applications useful for accessing inherited methods that have been overridden in a child class Note: uses MRO, in case of multiple inheritance, e.g. of class D Facts: if super().m() is used in a member functions of a sub-class D to call its parent's member function, where class D inherits class B and C then super().m() will instantiate both the parent class B and C and will call method m() in both also, if B and C 's method m() calls its super().m(), where B & C inherits class A then only one time m() of A will be called (the smartest decision) class A : def m ( self ): print ( \"m of A called\" ) class B ( A ): def m ( self ): print ( \"m of B called\" ) # A.m(self) super () . m () class C ( A ): def m ( self ): print ( \"m of C called\" ) # A.m(self) super () . m () class D ( B , C ): def m ( self ): print ( \"m of D called\" ) # B.m(self) # C.m(self) super () . m () d = D () d . m () Out: m of D called m of B called m of C called m of A called","title":"Need of super()"},{"location":"lang/python/Python-OOPs/#other-relationships","text":"src: https://javapapers.com/oops/association-aggregation-composition-abstraction-generalization-realization-dependency/ These relationships are totally implementation based how you want to function relationship between two or more classes & their instances Association Aggregation Composition Generalization Specialization Dependency Note: uses-a has-a / uses-a part-of (contains-a, consists-a) / has-a / uses-a i.e. a part-of relation can always use words like has-a, uses-a so, to find out a perfect relationship, try to approach in a top-to-down manner, to make the relationship more specific","title":"Other relationships"},{"location":"lang/python/Python-OOPs/#association","text":"keyword: uses-a sign: single line with arrow unidirectional if class A uses instance of class B arrow will point towards class B bidirectional explanation defines the multiplicity (cardianality) between objects one-to-one, one-to-many, many-to-one, many-to-many all classes/instances have their own life cycle (in general cases) no body have ownership over another (in general cases) e.g. house uses-an internet provider","title":"Association"},{"location":"lang/python/Python-OOPs/#weak-association-aggregation","text":"explanation: Lets say we have class A & B class A has-an (or uses-an) instance class B means class A's any method uses instance of class B as a parameter or returns the instance or if an instance of class A calls a member function (an operation) of an instance of the class B or class A holds instance of class B but instance of class B doesn't get destroyed when instance of class B is created & passed to constructor of class A","title":"Weak Association (Aggregation)"},{"location":"lang/python/Python-OOPs/#strong-association-composition","text":"explanation: Lets say we have class A & B class A has-an instance of class B / class B is part-of class A / class A consists of class B means class A holds instance of class B & the instance gets destroyed with destruction of instance of class A i.e. instance of class B is created & gets destroyed inside class A","title":"Strong Association (Composition)"},{"location":"lang/python/Python-OOPs/#aggregation","text":"aka Shared Association Weak Association keyword: has-a (uses-a) sign: a line with hollow diamond \"whole\" end have a hollow diamond shaped arrow-head cardianality: one-to-one, one-to-many, many-to-many explanation Classes Within Classes When an object \u2018has-a\u2019 another object when one object is an attribute of another whole/part relationship (i.e. part of relationship) special form of Association e.g. a library has-a student a student can exist without a library a Text-editor has-a file opened if text editor is closed, file still exists conditional e.g. if parts of a car are reusable car uses-a/has-a engine if car is scrapped, engine still exists note: It\u2019s always safe to call a relationship an association,but if class A contains objects of class B , and is organizationally superior to class B , it\u2019s a good candidate for aggregation.","title":"Aggregation"},{"location":"lang/python/Python-OOPs/#association-vs-aggregation","text":"The association link can replace aggregation link in every situation","title":"Association vs Aggregation"},{"location":"lang/python/Python-OOPs/#composition-not-shared-association","text":"keyword: has-a (part-of, consists-of, composed-of) sign: a line with solid diamond unidirectional only \"whole\" end have a solid diamond shaped arrow-head cardianality: one-to-many, many-to-many explanation: When an object contains the other object (The part may belong to only one whole) if the contained object cannot exist without the existence of container object i.e. The lifetime of the part is the same as the lifetime of the whole. special form of Aggregation Stronger/restricted aggregation ownership relation e.g a house has-a room if house is destroyed, room also gets a class has (contains) students students cannot exist without a class a text editor has a buffer if text editor is closed, buffer also gets destroyed conditional e.g. if parts of a car are NOT reusable a car has-a wheel if a car is destroyed, wheel also gets destroyed","title":"Composition (Not-Shared Association)"},{"location":"lang/python/Python-OOPs/#realization","text":"","title":"Realization"},{"location":"lang/python/Python-OOPs/#dependency","text":"","title":"Dependency"},{"location":"lang/python/Python-OOPs/#implementations-of-oops","text":"","title":"Implementations of OOPs"},{"location":"lang/python/Python-OOPs/#class","text":"in python everything is object of some class classes are first-class objects they can be created at runtime, passed as parameters and returned from functions, and assigned to variables even class is object of something this something by default is type class we can create a class which is an object of type class read metaclass for deep knowledge cls_a = type ( 'A' , ( object ,), dict ({ 'foo' : 2 , 'bar' : 3 })) # type(class_name_str, base_classes_tuple, body_dict) this way we can create a class at runtime","title":"class"},{"location":"lang/python/Python-OOPs/#type","text":"type is the class of python classes class Example : pass e = Example () e . __class__ # prints: <class __main__.Example> Example . __class__ # prints: <type 'type'> so in above code, e is object of class Example and Example is object of class type in python3 we can use type and class interchangabely which was not used in python2 so, whenever we write keyword class while defining a class, an object of class type gets created","title":"type"},{"location":"lang/python/Python-OOPs/#metaclass","text":"source: https://eli.thegreenplace.net/2011/08/14/python-metaclasses-by-example/ https://realpython.com/python-metaclasses/#defining-a-class-dynamically a metaclass is defined as the class of a class Any class whose instances are themselves classes, is a metaclass so, type is also a kind of metaclass (which is by default for all python classes and mostly used), but not always we can define a metaclass for a class class Example ( metaclass = SomeMetaclass ): # in python2 define metaclass here like # __metaclass__ = SomeMetaclass pass Since a metaclass is the class of a class it is used to construct classes (just as a class is used to construct objects) as we have already seen, class keyword invokes type function to create a class it was because, type is default metaclass in reality class keyword do followings when python encounters class definiton, it collects all the attributes in a dict when collection is over, python determines metaclass of the class, lets say SomeMetaclass using SomeClass.__metaclass__ then python calls Metaclass(class_name, (base_classes, ), body_dict) , where class_name is the name of the class (string ) (base_clasees, ) is the tuple of base classes, if it was empty in class definition, then by dafault it is object body_dict is a python dict contaning all the class attribute names metaclass defines structure/metadata of the class Methods of metaclass to create & initialize a class are:","title":"metaclass"},{"location":"lang/python/Python-OOPs/#__new__","text":"used to perform some basic stuff like memory allocation called on creation of an object of the class","title":"__new__()"},{"location":"lang/python/Python-OOPs/#__init__","text":"works as contructor in python used to perform initialization of data called on creation of an object of the class it is called after above methods __new__() so in case of creation of class (suppose A ), it is called when we call type()","title":"__init__()"},{"location":"lang/python/Python-OOPs/#__call__","text":"it is called after above two methods in case of creation of class, it is called when an object (suppose a = A() ) of the class (created from above two steps) is created.","title":"__call__()"},{"location":"lang/python/Python-OOPs/#instance","text":"TODO: - confusion in magic method call orders - how a class instance are created - as a class is object of a metaclass ```python #here class A A = type('A', (object,), {\"a\":1}) ``` - whenever we call any object/instance of any class, it calls the `__call__` of that class ```python a = A() #here A() will call the __call__ of metaclass type ``` - so, a is created by A(), where A() means calling `__call__` of `type` metaclass - if we provide A() parameters, like A(1,2), then `__call__(self, *args, **kwargs)__` handles those parameters - then inside metaclass's `__call__` , `__init__` of the class is called by passing all the parameters passed to `__call__` so, whenever we create an object/instance of a class, following things happens: metaclass's __new__ is called; creates memory (object) for class metaclass's __init__ is called; intializes class with its name and body when class, lets say Example is called Example(), then metaclass's __call__ is called to initialize the object of Example class, Example.__init__ is called","title":"instance"},{"location":"lang/python/Python-OOPs/#old-vs-new-style","text":"in python realm, there are two varities of classes Old-Style object of a class is always a in python 2.x , classes are old-style by deafult due to compatibility issues in python 2.x, New-Style classes are created by inheriting other New-style classes or top-level type object here object is a keyword which is instance of class type , and we know that type is a metaclass and metaclass is a class of class hence instance of a metaclass is always a class hence object keyword is a kind of class, which is created already in python just to implement a New-Style class syntax are like class A ( object ): pass New-Style object of a class is always a in python 3.x has new-style classes only hence no need to inherit object in class class Example : pass introduced in python2.2 to unify the concepts of class and type in new-style type(x) and x.__class__ are always same a new-style class is simply a user-defined type more differences at https://stackoverflow.com/questions/4015417/python-class-inherits-object TODO:","title":"Old vs New Style"},{"location":"lang/python/Python-OOPs/#object-keyword","text":"object is a keyword which is instance of class type , and we know that type is a metaclass and metaclass is a class of class hence instance of a metaclass is always a class hence object keyword is a kind of class, which is created already in python just to implement a New-Style class","title":"object keyword"},{"location":"lang/python/Python-OOPs/#mro","text":"(Method Resolution Order) - source: - https://makina-corpus.com/blog/metier/2014/python-tutorial-understanding-python-mro-class-search-path - class.__mro__ is only available in New-Style class Script: 1 class A : def m ( self ): print ( \"m of A called\" ) class B ( A ): def m ( self ): print ( \"m of B called\" ) class C ( A ): #def m(self): # print(\"m of C called\") pass class D ( B , C ): #def m(self): # print(\"m of D called\") pass d = D () d . m () Script: 2 class A1 (): # def who_am_i(self): # print(\"I am a A1\") pass class A2 (): def who_am_i ( self ): print ( \"I am a A2\" ) class B ( A1 , A2 ): # def who_am_i(self): # print(\"I am a B\") pass class C ( A2 ): def who_am_i ( self ): print ( \"I am a C\" ) class D ( B , C ): # def who_am_i(self): # print(\"I am a D\") pass d1 = D () d1 . who_am_i ()","title":"MRO"},{"location":"lang/python/Python-OOPs/#old-mro-algorithm-based-on-old-style-class","text":"uses depth-first serach followed by linear search (left to right) we call this order search path in script 1 Looking in D If not found, looking in B If not found, looking un B first parent A If not found, going back in B others parents (none) If not found, looking in D others parents : C in script 2 search path will be D, B, A1, A2, C, A2","title":"Old MRO Algorithm (Based on Old-Style Class)"},{"location":"lang/python/Python-OOPs/#c3-new-mro-algorithm-based-on-new-style-class","text":"default in python3 works in python2 with classes who inherits object Algo defines search path same as old algorithm then simplifies the search path like this iterate through the original search path put pointer on current class check if any classes after the pointer are child of current class (in other words, check if any classes after the pointer inherits the current class) if yes, then remove the current class from search path if no, then move the pointer to next class in the right do the same till end of search path list in script 1 original search path will be D, B, A, C, A then simplified search path will be D, B, C, A in script 2 search path will be D, B, A1, A2, C, A2 then simplified search path should be D, B, A1, C, A2","title":"C3 New MRO Algorithm (Based on New-Style Class)"},{"location":"lang/python/Python-OOPs/#impossible-method-resolution","text":"Script: class X (): def who_am_i ( self ): print ( \"I am a X\" ) class Y (): def who_am_i ( self ): print ( \"I am a Y\" ) class A ( X , Y ): def who_am_i ( self ): print ( \"I am a A\" ) class B ( Y , X ): def who_am_i ( self ): print ( \"I am a B\" ) class F ( A , B ): def who_am_i ( self ): print ( \"I am a F\" ) In Old MRO algo, search path is F, A, X, Y, B, Y, X In New MRO algo, simplified search path is F, A, B, Y, X but New MRO algo fails to give __mro__ and throws following exception TypeError: Cannot create a consistent method resolution","title":"Impossible Method Resolution"},{"location":"lang/python/Python-OOPs/#abstract-base-class-abstract-class","text":"Classes that contains one or more abstract methods as well as concrete methods. A normal class cannot have abstract methods. Cannot instantiate an abstract class that has abstract methods Subclass which implements all the abstract method can be instantiated Python Implementation: # Python 3.4+ from abc import ABC , abstractmethod class Abstract ( ABC ): @abstractmethod def foo ( self ): pass # Python 3.0+ from abc import ABCMeta , abstractmethod class Abstract ( metaclass = ABCMeta ): @abstractmethod def foo ( self ): pass # Python 2 from abc import ABCMeta , abstractmethod class Abstract : __metaclass__ = ABCMeta @abstractmethod def foo ( self ): pass","title":"Abstract Base Class (Abstract Class)"},{"location":"lang/python/Python-OOPs/#bottom-line","text":"in python3: base class of classes are: object metaclass of classes are: type type of classes are: type classes are instance of class: type","title":"Bottom Line"},{"location":"lang/python/Python-OOPs/#class-decorators","text":"e.g. https://github.com/toransahu/py-misc/blob/master/class_based_class_decorator_with_pre_post.py TODO:","title":"Class Decorators"},{"location":"lang/python/Python-OOPs/#class-decorators-versus-metaclass","text":"source: https://jfine-python-classes.readthedocs.io/en/latest/decorators-versus-metaclass.html nothing different other than implementation style","title":"Class Decorators versus metaclass"},{"location":"lang/python/Python-OOPs/#interface","text":"Doesn't need in Python (bcoz, it was need in other lang. to full-fill the Multiple inheritance) Concept: * A class with all the methods abstract * Contains Methods signature * Do not contain definition/method body * Constant variables (which must be Static + Final in other langs.) - in python there is no final or const keyword * Cannot instantiated * Behaviour/methods which must be implemented by classes * Class which implement interface should implement all the methods OR be an abstract class Python Implementation: class Engine (): \"\"\" Engine Interface\"\"\" def ignition ( self ): raise NotImplementedError ( \"Ingnition should have implemented.\" ) def fuel ( self ): raise NotImplementedError ( \"Fuel should have implemented.\" )","title":"Interface"},{"location":"lang/python/Python-OOPs/#variables","text":"","title":"Variables"},{"location":"lang/python/Python-OOPs/#instance-variable","text":"variable defined inside class methods different for different objects every object have its own copy","title":"Instance Variable"},{"location":"lang/python/Python-OOPs/#static-or-class-variable","text":"defined in class level shared by all the objects can be accessed by Class name as well as objects with the same name, there can be one class level variable and one instance level variable, see in e.g. in this case, Class.variable will definitely access the static var but instance.variable will access the instance variable accessing inside methods it can be accessed using Class.var & self.var if there is instance variable with the same name then self.var will access the instance variable class A : variable = 'Static/class Variable' # static/class variable var = 'Static/class Var' # static/class variable def __init__ ( self ): self . variable = 'Instance Variable' def foo ( self ): print ( A . variable , self . variable , self . var ) print ( A . variable ) a = A () a . foo () Out: Static/class Variable Instance Variable Static/class Var Static/class Variable Instance Variable","title":"Static or Class Variable"},{"location":"lang/python/Python-OOPs/#instance-vs-classstatic-attribute-lookup-order","text":"instance/object > static/class > base class which is: a. dict ['x'] > type(a). dict ['x'] > type(a)","title":"Instance vs Class/Static attribute lookup order"},{"location":"lang/python/Python-OOPs/#methods","text":"","title":"Methods"},{"location":"lang/python/Python-OOPs/#abstract-method","text":"a method without definition (only declared) only signature In python: a method decorated with @abstractmethod","title":"Abstract Method"},{"location":"lang/python/Python-OOPs/#method-vs-function","text":"Method works exactly same as a simple function. But a method's first argument always receives the instance object: Code: def outside_foo (): pass def outside_foo ( self ,): pass","title":"Method vs Function"},{"location":"lang/python/Python-OOPs/#static-method","text":"","title":"Static Method"},{"location":"lang/python/Python-OOPs/#what","text":"an organization/stylistic feature functionality-wise same as normal module level functions except, module level func can access an instance and hence instance variables, but static method cannot designed to work on class attributes can be called using class as well as instance A static method has no self argument Never receive an automatic self argument, whether called through a class or an instance. can access/modify class or static variables using class_name.var","title":"What"},{"location":"lang/python/Python-OOPs/#how","text":"two way of declaration using decorator @staticmethod [fn_name] = staticmethod([fn_name])","title":"How"},{"location":"lang/python/Python-OOPs/#why","text":"to restrict access of instance attributes (unlike a normal method have access) to fix the access of static variable of a that particular class only because it is hardcoded like A.static_variable src: http://radek.io/2011/07/21/static-variables-and-methods-in-python/","title":"Why"},{"location":"lang/python/Python-OOPs/#code","text":"class A : static_variable = 'Static/class Variable of class A' # static/class variable def __init__ ( self ): self . instance_variable = 'Instance Variable' @staticmethod def static_method (): print ( 'Inside static_method()' , A . static_variable ) # works # print('Inside static_method()', A.instance_variable) # error, static method can't access instance attributes # static method def way2 (): pass # making way2() a static method way2 = staticmethod ( way2 ) class B ( A ): static_variable = 'Static/class Variable of class B' # static/class variable # but a module level func can access an instance attribute def module_level_func (): a1 = A () print ( a1 . instance_variable ) a2 = A () a2 . static_method () A . static_method () B . static_method () # still accessing static_variable from class A Out: Inside static_method() Static/class Variable of class A Inside static_method() Static/class Variable of class A Inside static_method() Static/class Variable of class A","title":"Code"},{"location":"lang/python/Python-OOPs/#class-method","text":"","title":"Class Method"},{"location":"lang/python/Python-OOPs/#what_1","text":"an organization/stylistic feature not different from static method, only signature diff it receives one mandatory arguement: a class name it was called from apart from this first parameter, there is no any functionality diff between class & static method designed to work on class attributes can be called using class as well as instance can access/modify class or static variables using cls.var where cls is first parameter provided to a classmethod","title":"What"},{"location":"lang/python/Python-OOPs/#how_1","text":"implemented using decorator @classmethod assigning to function i.e., method_name = classmethod(method_name)","title":"How"},{"location":"lang/python/Python-OOPs/#why_1","text":"to restrict access of instance attributes (unlike a normal method have access) to make code more maintanable than static methods","title":"Why"},{"location":"lang/python/Python-OOPs/#code_1","text":"class A : static_variable = 'Static/class Variable of class A' # static/class variable def __init__ ( self ): self . instance_variable = 'Instance Variable' @classmethod def class_method ( cls ): print ( 'Inside class_method()' , cls . static_variable ) # works # print('Inside class_method()', cls.instance_variable) # error, class method can't access instance attributes # static method def way2 ( cls ): pass # making way2() a static method way2 = classmethod ( way2 ) class B ( A ): static_variable = 'Static/class Variable of class B' # static/class variable # but a module level func can access an instance attribute def module_level_func (): a1 = A () print ( a1 . instance_variable ) a2 = A () a2 . class_method () A . class_method () B . class_method () # now it will access static variable of class B Out: Inside class_method() Static/class Variable of class A Inside class_method() Static/class Variable of class A Inside class_method() Static/class Variable of class B","title":"Code"},{"location":"lang/python/Python-OOPs/#magic-method","text":"TODO: Source: https://www.python-course.eu/python3_magic_methods.php https://rszalski.github.io/magicmethods/ Methods with dunders (+) : __add()__ (-) : __sub()__ Can be used for operator overloading, as class Calc ( int ): def __init__ ( self , x ): self . x = x def __add__ ( self , other ): return self . x + other . x + 1 a = Calc ( 1 ) b = Calc ( 1 ) a + b Out: 3","title":"Magic Method"},{"location":"lang/python/Python-OOPs/#class-internal-methods","text":"TODO: Source: http://www.diveintopython3.net/special-method-names.html https://rszalski.github.io/magicmethods/ Some famous magic methods / internal methods of a class","title":"Class Internal Methods"},{"location":"lang/python/Python-OOPs/#__new___1","text":"allocates memory to class instance","title":"__new__"},{"location":"lang/python/Python-OOPs/#__init___1","text":"initializes instance with some values","title":"__init__"},{"location":"lang/python/Python-OOPs/#__call___1","text":"called upon calling an instance (e.g. a = A(); a())","title":"__call__"},{"location":"lang/python/Python-OOPs/#__get__","text":"get descriptor method","title":"__get__"},{"location":"lang/python/Python-OOPs/#__set__","text":"set descriptor method","title":"__set__"},{"location":"lang/python/Python-OOPs/#__del__","text":"del descriptor method","title":"__del__"},{"location":"lang/python/Python-OOPs/#__slots__","text":"allows us to explicitly declare data members (like properties) and deny the creation of __dict__ & __weakref__ (unless explicitly declared in __slots__ )","title":"__slots__"},{"location":"lang/python/Python-OOPs/#__getattribute__","text":"called when accessing any attribute via class instance c = C () c . name","title":"__getattribute__"},{"location":"lang/python/Python-OOPs/#__getattr__","text":"same as __getattribute__ but gets called only when attribiute is not found via __getattribute__","title":"__getattr__"},{"location":"lang/python/Python-OOPs/#__getattr__-vs-__getattribute__","text":"Source: http://www.diveintopython3.net/special-method-names.html","title":"__getattr__ vs  __getattribute__"},{"location":"lang/python/Python-OOPs/#__enter__","text":"","title":"__enter__"},{"location":"lang/python/Python-OOPs/#__exit__","text":"","title":"__exit__"},{"location":"lang/python/Python-OOPs/#__repr__","text":"","title":"__repr__"},{"location":"lang/python/Python-OOPs/#__str__","text":"","title":"__str__"},{"location":"lang/python/Python-OOPs/#__format__","text":"","title":"__format__"},{"location":"lang/python/Python-OOPs/#__iter__","text":"","title":"__iter__"},{"location":"lang/python/Python-OOPs/#__next__","text":"","title":"__next__"},{"location":"lang/python/Python-OOPs/#__reversed__","text":"","title":"__reversed__"},{"location":"lang/python/Python-OOPs/#__dir__","text":"","title":"__dir__"},{"location":"lang/python/Python-OOPs/#__setattr__","text":"","title":"__setattr__"},{"location":"lang/python/Python-OOPs/#__delattr__","text":"","title":"__delattr__"},{"location":"lang/python/Python-OOPs/#__len__","text":"","title":"__len__"},{"location":"lang/python/Python-OOPs/#__contains__","text":"","title":"__contains__"},{"location":"lang/python/Python-OOPs/#__getitem__","text":"","title":"__getitem__"},{"location":"lang/python/Python-OOPs/#properties","text":"Source: https://www.journaldev.com/14893/python-property-decorator https://docs.python.org/3/howto/descriptor.html#properties https://medium.com/shecodeafrica/managing-class-attributes-in-python-c42d501c5ee0 Why to manage access to an attribute to outer world can only allow get can only allow set can only allow del can perform something more while doing above operations to solve problem like this (dependent attribute value issue) e.g. class Example : def __init__ ( self , ap , bp ): self . _a = ap self . _b = bp self . c = self . _a + self . _b def get_c ( self ): return self . c e = Example ( 1 , 2 ) print ( e . _a ) print ( e . _b ) print ( e . c ) print ( e . get_c ()) e . _a = 5 print ( e . _a ) print ( e . c ) print ( e . get_c ()) solution e.g. class Example : def __init__ ( self , ap , bp ): self . _a = ap self . _b = bp @property def c ( self ): return self . _a + self . _b e = Example ( 1 , 2 ) print ( e . _a ) print ( e . _b ) print ( e . c ) e . _a = 5 print ( e . _a ) print ( e . c ) What property are built -in python decorators provides 3 methods get set del How property in python are implemented using Descriptors uses : pattern 1 class Example : def __init__ ( self , ap ): self . _a = ap @property def a ( self ): return self . _a @a . setter def a ( self , value ): self . _a = value @a . deleter def a ( self ): del self . _a e = Example ( 1 ) print ( e . a ) e . a = 5 print ( e . a ) del ( e . a ) print ( e . a ) #AttributeError: 'Example' object has no attribute '_a' uses : pattern 2 class Example : def __init__ ( self , ap ): self . _a = ap def get_a ( self ): return self . _a def set_a ( self , value ): self . _a = value def del_a ( self ): del self . _a # will give only get access a = property ( fget = get_a ) # will give only set access a = property ( fset = set_a ) # will give only del access a = property ( fdel = del_a ) #will give all access of var `a` a = property ( get_a , set_a , del_a ) #property(fget=None, fset=None, fdel=None, doc=None) e = Example ( 1 ) print ( e . a ) e . a = 5 print ( e . a ) del ( e . a ) print ( e . a ) # AttributeError: 'Example' object has no attribute '_a'","title":"Properties"},{"location":"lang/python/Python-OOPs/#descriptors","text":"TODO: Source: https://docs.python.org/3/howto/descriptor.html descriptor is an object attribute with \u201cbinding behavior\u201d, one whose attribute access has been overridden by methods in the descriptor protocol Those methods are get (), set (), and delete () Basic default behavior for attribute access is to get, set, or delete For instance, a.x has a lookup chain starting with a. dict ['x'], then type(a). dict ['x'], and continuing through the base classes of type(a) excluding metaclasses If there is descriptor x defined, then descriptor will override the lookup order and will become number one Use Cases They are the mechanism behind properties, methods, static methods, class methods, and super() They are used throughout Python itself to implement the new style classes introduced in version 2.2","title":"Descriptors"},{"location":"lang/python/Python-OOPs/#protocol","text":"descr . __get__ ( self , obj , type = None ) --> value descr . __set__ ( self , obj , value ) --> None descr . __delete__ ( self , obj ) --> None define any of the above in any class, and object will considered as descriptor and descriptor will override the default attribute lookup behavior (in class dictionary lookup) if object defines both __get__ and __set__ ; then its data descriptor if instance have attribute (means entry in instance dict) with same name as descriptor, then here lookup order will become data descriptor > instance dict if object defines only __get__ ; then its non-data descriptor in this case if instance have attribute with same name as descriptor, then here lookup order will become instance dict > data descriptor","title":"Protocol"},{"location":"lang/python/Python-OOPs/#simple-implemetation","text":"TODO - Issue with __del__ ; not explained in python doc class ExampleDescriptor : def __init__ ( self , val ): self . val = val def __get__ ( self , obj , objtype = None ): print ( \"getting\" ) return self . val def __set__ ( self , obj , val ): print ( \"setting\" ) self . val = val class Example : name = ExampleDescriptor ( \"toran\" ) if __name__ == \"__main__\" : e = Example () print ( e . name ) e . name = \"sahu\" print ( e . name )","title":"Simple Implemetation"},{"location":"lang/python/Python-OOPs/#property-implementation","text":"class Property ( object ): \"Emulate PyProperty_Type() in Objects/descrobject.c\" def __init__ ( self , fget = None , fset = None , fdel = None , doc = None ): self . fget = fget self . fset = fset self . fdel = fdel if doc is None and fget is not None : doc = fget . __doc__ self . __doc__ = doc def __get__ ( self , obj , objtype = None ): if obj is None : return self if self . fget is None : raise AttributeError ( \"unreadable attribute\" ) return self . fget ( obj ) def __set__ ( self , obj , value ): if self . fset is None : raise AttributeError ( \"can't set attribute\" ) self . fset ( obj , value ) def __delete__ ( self , obj ): if self . fdel is None : raise AttributeError ( \"can't delete attribute\" ) self . fdel ( obj ) def getter ( self , fget ): return type ( self )( fget , self . fset , self . fdel , self . __doc__ ) def setter ( self , fset ): return type ( self )( self . fget , fset , self . fdel , self . __doc__ ) def deleter ( self , fdel ): return type ( self )( self . fget , self . fset , fdel , self . __doc__ )","title":"Property implementation"},{"location":"lang/python/Python-OOPs/#misc","text":"","title":"Misc"},{"location":"lang/python/Python-OOPs/#ways-to-call-a-class-member-function","text":"a = A () a . foo ( args ) a = A () A . foo ( a , args )","title":"Ways to call a class member function"},{"location":"lang/python/Python-OOPs/#__slots__-reduce-ram-usage","text":"source http://book.pythontips.com/en/latest/__slots__magic.html","title":"__slots__ : reduce RAM usage"},{"location":"lang/python/Python-OOPs/#unbound-vs-bound-method","text":"","title":"Unbound vs Bound Method"},{"location":"lang/python/Python-OOPs/#unbound-method-simple-function-in-python-3x","text":"Unbound means not bound to any instance i.e. callable using class name","title":"Unbound Method (Simple Function in Python 3.x)"},{"location":"lang/python/Python-OOPs/#bound-method","text":"Bound methods are bound to some instance Need an instance to call it. Note: In Python 3.x, the notion of Unbound Method has been dropped and we treat it as Simple Function.","title":"Bound Method"},{"location":"lang/python/Python-OOPs/#closure","text":"A combination of code and scope. It's about nested function and the scope of the function Code: def startAt ( start ): def incrementBy ( inc ): return start + inc return incrementBy f = startAt ( 10 ) g = startAt ( 100 ) print ( f ( 1 ), g ( 2 )) # Using lamba def startAt ( start ): return lambda inc : start + inc f = startAt ( 10 ) g = startAt ( 100 ) print ( f ( 1 ), g ( 2 )) Out: 11 102 11 102","title":"Closure"},{"location":"lang/python/Python-Production-Servers/","text":"Basics Web Server ngnix Application Server django developement server gunicorn Database MySQL PostgreSQL Github Pages Hosting PythonAnywhere Settings WSGI Static Files: Heroku Pre-requisites Install heroku CLI Create app Add Procfile Dependencies Push code Add .env file Add app.json file Troubleshoot AWS Create AMI (Amazon Machine Instance) SSH to your instance Update Set Password Install Prerequisites Python Stuff Recommanded Way Original Way Test your project by starting up the Django development server with this command: Server Stuff Gunicorn celery supervisor nginx Setup Database AWS RDS MySQL (Free Tier) RDS Config Installation Django Configuration Test Django with RDS MySQL Run Confirm before run Enable HTTPS in aws ec2 with nginx Make sure HTTP & HTTPS are opened in Security Groups Setup domain's CNAME record to the public DNS of ec2 Install Certbot in aws instance Stop any existing servers running on the port 80 and 443 Generate certificates Change nginx configurations in /etc/nginx/nginx.conf to enable SSL Reload nginx config Finish Check Certificate Expiry Date Renew Certificate delete the certificate Troubleshoots AWS S3 Storage Cloudflare Manage DNS Manage Cache Purge Cache TODO: Basics # Web Server # ngnix # Application Server # django developement server # gunicorn # Database # MySQL # PostgreSQL # Github Pages Hosting # Source1: https://medium.freecodecamp.org/hosting-custom-domain-on-github-pages-8c598248d2bc Source2: https://medium.com/employbl/launch-a-website-with-a-custom-url-using-github-pages-and-google-domains-3dd8d90cc33b PythonAnywhere # Settings # WSGI # Static Files: # make a folder sitewide say 'allstatic' by default in settings.py STATIC_URL = '/static/' (don't change it) in pythonanywhere web, set URL = /static/ same as above & Directory = path to the dir 'allstatic' Heroku # Pre-requisites # a working django app app in a git repo Install heroku CLI # Create app # create heroku app from existing code (it will only create empty git repo in heroku's private git) heroku create appname add heroku remote to your local git repo git remote add heroku https://git.heroku.<app_name>.git Add Procfile # its starter script which heroku follows add web: gunicorn --pythonpath toransahu-site toransahu.wsgi (here --pythonpath is used if toransahu is not root dir, or if wsgi.py is not directly under toransahu-site) Dependencies # add all requirements inside requirements.txt including gunicorn Push code # push code to heroku's git repo named git push heroku dev:master here heroku is remote name (same as origin by deafult) dev is local repo's brach name from which we want to push code master is heroku's master branch (in master branch only build happens) Add .env file # Unknown Add app.json file # Unknown Troubleshoot # using heroku local heroku local web heroku logs disable static files heroku config:set DISABLE_COLLECTSTATIC=1 AWS # https://pipelines.puppet.com/docs/tutorials/how-to-set-up-aws-ec2/ https://www.agiliq.com/blog/2014/08/deploying-a-django-app-on-amazon-ec2-instance/ https://medium.com/@bsadkhin/deploying-a-django-app-to-amazon-ec2-3f17a735a561 Create AMI (Amazon Machine Instance) # choose os, server edit configs (optional) launch create/choose private key name it download it put it in your ~/.ssh/ dir change permission to read only chmod 400 notedown DNS of your instance ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com if os was ubuntu, default user will be ubuntu create security group & make changes in inbound tab like: |Type|Port|Source| |----------------| |HTTP|80|Anywhere| |HTTPS|443|Anywhere| |SSH|22|Anywhere| |Custom TCP|8000|Anywhere| SSH to your instance # using instance dns ssh -i ~/.ssh/ethereal-site-backend.pem ubuntu@ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com or use public ip ssh -i ~/.ssh/ethereal-site-backend.pem ubuntu@18.136.106.117 if .pem file is downloaded from some storage, then give proper permission chmod 600 ~/.ssh/ethereal-site-backend.pem Update # sudo apt-get update sudo apt-get upgrade Set Password # Source: https://comtechies.com/password-authentication-aws-ec2.html #1.open sudo vi /etc/ssh/sshd_config #2.edit no to yes PasswordAuthentication yes #3.save and close #4.change/set password sudo passwd ubuntu #5.restart service sudo service sshd restart Install Prerequisites # Python Stuff # Recommanded Way # Using miniconda #download miniconda - for deployment, testing, build wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh #install sudo sh Miniconda3-latest-Linux-x86_64.sh #alias & activate miniconda echo \"alias anaconda='. ~/miniconda3/bin/activate'\" >> ~/.bashrc anaconda ( base ) sudo /home/ubuntu/miniconda3/bin/python3.6 -m pip install -U pipenv #clone repo ( base ) git clone https://toransahu@bitbucket.org/toransahu/ethereal-machines-backend.git #cd to repo & create venv using pipenv & install dependencies ( base ) pipenv --python 3 install Original Way # sudo wget https://www.python.org/ftp/python/3.6.4/Python-3.6.4.tar.xz sudo tar xJf Python-3.6.4.tar.xz cd Python-3.6.4/ ./configure sudo make sudo make install cd .. sudo rm Python-3.6.4.tar.xz sudo rm -rf Python-3.6.4 sudo apt install python3-pip #link pip, python cd /usr/bin unlink python unlink pip unlink virtualenv ln -s python35 python ln -s pip-3.5 pip ln -s virtualenv-3.5 virtualenv #clone repo git clone https://toransahu@bitbucket.org/toransahu/ethereal-machines-backend.git if sudo ./configure gives error Error: no acceptable C compiler found in PATH when installing python install build-essential sudo apt install build-essential Test your project by starting up the Django development server with this command: # before this, disable other https/secure settings in prod_settings.py or test with dev_settings.py allow server to listen on port 8000 sudo ufw allow 8000 python manage.py runserver 0.0.0.0:8000 if you get error, add host to allowed host. ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com hit the website ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com:8000 (without http://) Server Stuff # Gunicorn # will server dynamic contents of the site (works as app server) install in venv using pipenv --python 3 (app-venv) pipenv --python 3 install gunicorn test django app with gunicorn allow server to listen on port 8000 sudo ufw allow 8000 cd ethereal-machines-backend/src (where manage.py is) disable other https/secure settings in prod_settings.py to degug, enable DEBUG gunicorn --bind 0.0.0.0:8000 backend.wsgi (try website with http://), create script to start gunicorn cd ethereal-machines-backend/src (where manage.py is) vim start_gunicorn.sh make sure to write #! /bin/bash in first line chmod a+x start_gunicorn.sh start_gunicorn.sh should look like this: https://gist.github.com/toransahu/31874def1bd661db676d0dfe02e1c651 celery # start rabbitmq starts automatically on boot sudo systemctl enable rabbitmq-server sudo systemctl start rabbitmq-server #- in WSL do this sudo service rabbitmq-server start start celery worker need to run inside src folder need to be in virtual env celery -A project_name worker -l info or create script to start celery cd ethereal-machines-backend/src (where manage.py is) vim start_celery.sh make sure to write #! /bin/bash in first line chmod a+x start_celery.sh start_celery.sh should look like this: https://gist.github.com/toransahu/31874def1bd661db676d0dfe02e1c651 supervisor # chmod a+x all the start.sh scripts copy gunicorn.conf & celery.conf to /etc/supervisor/conf.d/ create logs folder inside repo dir sudo supervisorctl reread sudo supervisorctl update sudo supervisorctl reload sudo supervisorctl status sudo supervisorctl restart gunicorn sudo supervisorctl restart celery src: https://gist.github.com/toransahu/31874def1bd661db676d0dfe02e1c651 nginx # will create proxy and redirect to gunicorn for dynamic contents will server static & media contents src: https://www.digitalocean.com/community/tutorials/how-to-set-up-django-with-postgres-nginx-and-gunicorn-on-ubuntu-16-04 install sudo apt install nginx start nginx sudo service nginx start hit the site ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com check whether you are getting a msg Welcome to nginx! or not stop nginx sudo service nginx stop Configure nginx to proxy pass to gunicorn configuration file : https://gist.github.com/toransahu/f5a38976967715e31543dbcf9b01c7d9 sudo vim /etc/nginx/sites-available/ethereal_backend open up new server block should listen on normal port 80 should respond to our server domain name or ip i.e. 18.136.106.117 (try both) for longer name you may have to increase buffer by editing sudo vim /etc/nginx/nginx.conf change count at server_names_hash_bucket_size 512; didn't find it usefull without custom domain create a location / {} block to tell Nginx to ignore any problems with finding a favicon tell Nginx to find static files here prefix will be same as STATIC_URL and alias will be same as STATIC_ROOT tell Nginx to find media files here prefix will be same as MEDIA_URL and alias will be same as MEDIA_ROOT didn't find it usefull without custom domain create a location / {} block to match all other requests include the standard proxy_params file included with the Nginx installation then pass the traffic to the socket that our Gunicorn process created i.e. http://0.0.0.0:8000 or may be now you need to provide link with server_name and different port on which application is running e.g http://server_name:8000 enable the file by linking it to the sites-enabled directory sudo ln -s /etc/nginx/sites-available/ethereal_backend /etc/nginx/sites-enabled test nginx config for syntax errors sudo nginx -t if no errors reported then go ahead & restart nginx sudo systemctl restart nginx Finally, we need to open up our firewall to normal traffic on port 80. Since we no longer need access to the development server, we can remove the rule to open port 8000 as well sudo ufw delete allow 8000 sudo ufw allow 'Nginx Full' set host (for custom root/domain url for hyperlinks inside django app) e.g. https://api.etherealmachines.com/file/media/1/djklfjkdflkfsdaf.png need to set in /etc/nginx/sites-available/ethereal_backend proxy_set_header Host \"api.etherealmachines.com\" refer: https://gist.github.com/toransahu/f5a38976967715e31543dbcf9b01c7d9 make sure \"api.etherealmachines.com\" is included in ALLOWED_HOSTS in prod_settings.py for size limit issues if total cient body exceeds defined limit in nginx.conf file, it (web server) throws HTTP error 413, request before reaching to the application server to handle the size limit, mention client_max_body_size 10M; in nginx.conf inside http {} block Note: comment out SSL on and redirect HTTPS line in ethereal_backend file if don't using ssl & https Setup Database # AWS RDS MySQL (Free Tier) # RDS Config # source: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateInstance.html in selected security group add Type:MYSQL/Aurora;Protocol:TCP;Range:3306;Source:Anywhere(0.0.0.0/0) enable public use/access to access db over internet http://ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com:8000/api/v1/ (optional) Installation # install mysqlclient in venv pipenv install mysqlclient if it gives error: mysql_config not found install following sudo apt-get install libmysqlclient-dev Django Configuration # instance etherealbackend db ethereal host etherealbackend.cg17v7dkjshh.ap-southeast-1.rds.amazonaws.com port 3306 master user ethereal master pwd machines Test Django with RDS MySQL # python manage.py makemigrations python manage.py migrate python manage.py runserver 0.0.0.0:8000 Run # Confirm before run # python manage.py makemigrations <apps> python manage.py migrate python manage.py createsuperuser python manage.py collectstatic cd /home/ubuntu/ethereal-machines/ethereal-machines-backend/ ./start_gunicorn.sh sudo systemctl restart nginx Enable HTTPS in aws ec2 with nginx # Blog source Official Source- Ubuntu 16.04 + nginx using lets-encrypt CA (certificate authority) provides free SSL certificates for few weeks/ 3 months using Certbot - the official lets-encrypt client automatically fetches & deploys SSL/TLS certificates in the server Make sure HTTP & HTTPS are opened in Security Groups # inside inbound rules note down public IP & DNS of the aws ec2 instance Setup domain's CNAME record to the public DNS of ec2 # here domain is: etherealmachines.com public dns is: ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com Go to your DNS config in CloudFlare & create an entry in DNS Records type: CNAME Name: api.etherealmachines.com value: ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com TTL: Automatic Install Certbot in aws instance # cd to your home or project root wget https://dl.eff.org/certbot-auto chmod a+x certbot-auto Stop any existing servers running on the port 80 and 443 # because those will be used by certbot to verify the domain & generate certificates after generating certificates, restart servers Generate certificates # ./certbot-auto certonly --standalone -d api.etherealmachines.com we can generate certificates for multiple domains also, like ./certbot-auto certonly --standalone -d api.etherealmachines.com -d www.etherealmachines.com Change nginx configurations in /etc/nginx/nginx.conf to enable SSL # https://gist.github.com/toransahu/7b546d1d1a6afdf51dfa6602ecda22fc The Strict-Transport-Security (HSTS) header ensures that any internal links that are not HTTPS will automatically be routed to the HTTPS version during a HTTPS session Reload nginx config # test config for syntaxt errors: sudo nginx -t sudo service nginx reload Finish # now https://api.etherealmachines.com will redirect requests to http://ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com/ Check Certificate Expiry Date # Install ssl-cert-check sudo apt install ssl-cert-check Run sudo ssl-cert-check -c /etc/letsencrypt/live/api.etherealmachines.com/fullchain.pem or awk the final result sudo ssl-cert-check -c /etc/letsencrypt/live/api.etherealmachines.com/fullchain.pem | awk 'END { print <dollar_sign>NF }' Renew Certificate # if cloudflare DNS + HTTP proxy is configured, then it will interfere while renewal and creation of ssl certificate so, disable http proxy (DNS only should be there in status column) from status column source: https://www.tautvidas.com/blog/2018/06/certbot-renewal-of-letsencrypt-certificate-fails-with-failed-authorization-procedure/ Let's encrypt certificates are only valid for 3 months after issue. So renewal is required. before using renew command turn off nginx to open the port 80 to check/dry run renewal do: sudo certbot renew --dry-run automate autonewal using cron job: 0 6 * * * /path/to/certbot/certbot-auto renew --text >> /path/to/certbot/certbot-cron.log && sudo service nginx reload delete the certificate # sudo certbot delete --cert-name api.etherealmachines.com Troubleshoots # while certificate renew/new if it fails with TLS handshake/auth issue: remove certificate entry from /etc/nginx/nginx.conf while renew/new if you get too many request / auth failure / blocked then wait for 1 hr and retry there is 5 limit per account AWS S3 Storage # Source: - https://simpleisbetterthancomplex.com/tutorial/2017/08/01/how-to-setup-amazon-s3-in-a-django-project.html - http://django-storages.readthedocs.io/en/latest/backends/amazon-S3.html#model - http://boto3.readthedocs.io/en/latest/guide/quickstart.html#configuration https://ethereal-erp.s3.amazonaws.com Credentials - Users with AWS Management Console access can sign-in at: - https://908866068066.signin.aws.amazon.com/console - username - ethereal - group - erp-programatic - access key id - AKIAIBBFQZVDCT7BR6QA - secret access key - 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 Cloudflare # Manage DNS # Manage Cache # Purge Cache # By API curl -X DELETE \"https://api.cloudflare.com/client/v4/zones/<site-id>/purge_cache\" \\ -H \"X-Auth-Email: <email>\" \\ -H \"X-Auth-Key: <apikey>\" \\ -H \"Content-Type: application/json\" \\ --data '{\"purge_everything\":true}' ) \" source: https://www.supertechcrew.com/clear-cloudflare-cache-when-pushing-from-git-github-pages/ By Git while Pushing Sources: https://www.supertechcrew.com/clear-cloudflare-cache-when-pushing-from-git-github-pages/ https://www.binarymoon.co.uk/2017/06/using-git-hooks-clear-cloudflares-cache/ By Website TODO: # before nginx ~~correct start_gunicorn.sh with log & workers~~ ~~if possible see pipenv shell~~ ~~MySQL setup~~ nginx ~~proxy~~ ~~static issue~~ ~~try by removing STATIC_FINDER in PROD_.py~~ ~~media issue~~ ~~bind with https://api.etherealmachines.com~~ in code: utils/ init .py ~~mysql case: db name dynamic~~ ~~dev & prod settings~~ ~~media url append in urls.py ~~ ~~remove DEBUG is True condition~~ implement task queue using Celery to make post_save faster http://www.dougalmatthews.com/2011/Oct/10/making-djangos-signals-async-with-celery/ configure https in django+aws level","title":"Python Production Servers"},{"location":"lang/python/Python-Production-Servers/#basics","text":"","title":"Basics"},{"location":"lang/python/Python-Production-Servers/#web-server","text":"","title":"Web Server"},{"location":"lang/python/Python-Production-Servers/#ngnix","text":"","title":"ngnix"},{"location":"lang/python/Python-Production-Servers/#application-server","text":"","title":"Application Server"},{"location":"lang/python/Python-Production-Servers/#django-developement-server","text":"","title":"django developement server"},{"location":"lang/python/Python-Production-Servers/#gunicorn","text":"","title":"gunicorn"},{"location":"lang/python/Python-Production-Servers/#database","text":"","title":"Database"},{"location":"lang/python/Python-Production-Servers/#mysql","text":"","title":"MySQL"},{"location":"lang/python/Python-Production-Servers/#postgresql","text":"","title":"PostgreSQL"},{"location":"lang/python/Python-Production-Servers/#github-pages-hosting","text":"Source1: https://medium.freecodecamp.org/hosting-custom-domain-on-github-pages-8c598248d2bc Source2: https://medium.com/employbl/launch-a-website-with-a-custom-url-using-github-pages-and-google-domains-3dd8d90cc33b","title":"Github Pages Hosting"},{"location":"lang/python/Python-Production-Servers/#pythonanywhere","text":"","title":"PythonAnywhere"},{"location":"lang/python/Python-Production-Servers/#settings","text":"","title":"Settings"},{"location":"lang/python/Python-Production-Servers/#wsgi","text":"","title":"WSGI"},{"location":"lang/python/Python-Production-Servers/#static-files","text":"make a folder sitewide say 'allstatic' by default in settings.py STATIC_URL = '/static/' (don't change it) in pythonanywhere web, set URL = /static/ same as above & Directory = path to the dir 'allstatic'","title":"Static Files:"},{"location":"lang/python/Python-Production-Servers/#heroku","text":"","title":"Heroku"},{"location":"lang/python/Python-Production-Servers/#pre-requisites","text":"a working django app app in a git repo","title":"Pre-requisites"},{"location":"lang/python/Python-Production-Servers/#install-heroku-cli","text":"","title":"Install heroku CLI"},{"location":"lang/python/Python-Production-Servers/#create-app","text":"create heroku app from existing code (it will only create empty git repo in heroku's private git) heroku create appname add heroku remote to your local git repo git remote add heroku https://git.heroku.<app_name>.git","title":"Create app"},{"location":"lang/python/Python-Production-Servers/#add-procfile","text":"its starter script which heroku follows add web: gunicorn --pythonpath toransahu-site toransahu.wsgi (here --pythonpath is used if toransahu is not root dir, or if wsgi.py is not directly under toransahu-site)","title":"Add Procfile"},{"location":"lang/python/Python-Production-Servers/#dependencies","text":"add all requirements inside requirements.txt including gunicorn","title":"Dependencies"},{"location":"lang/python/Python-Production-Servers/#push-code","text":"push code to heroku's git repo named git push heroku dev:master here heroku is remote name (same as origin by deafult) dev is local repo's brach name from which we want to push code master is heroku's master branch (in master branch only build happens)","title":"Push code"},{"location":"lang/python/Python-Production-Servers/#add-env-file","text":"Unknown","title":"Add .env file"},{"location":"lang/python/Python-Production-Servers/#add-appjson-file","text":"Unknown","title":"Add app.json file"},{"location":"lang/python/Python-Production-Servers/#troubleshoot","text":"using heroku local heroku local web heroku logs disable static files heroku config:set DISABLE_COLLECTSTATIC=1","title":"Troubleshoot"},{"location":"lang/python/Python-Production-Servers/#aws","text":"https://pipelines.puppet.com/docs/tutorials/how-to-set-up-aws-ec2/ https://www.agiliq.com/blog/2014/08/deploying-a-django-app-on-amazon-ec2-instance/ https://medium.com/@bsadkhin/deploying-a-django-app-to-amazon-ec2-3f17a735a561","title":"AWS"},{"location":"lang/python/Python-Production-Servers/#create-ami-amazon-machine-instance","text":"choose os, server edit configs (optional) launch create/choose private key name it download it put it in your ~/.ssh/ dir change permission to read only chmod 400 notedown DNS of your instance ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com if os was ubuntu, default user will be ubuntu create security group & make changes in inbound tab like: |Type|Port|Source| |----------------| |HTTP|80|Anywhere| |HTTPS|443|Anywhere| |SSH|22|Anywhere| |Custom TCP|8000|Anywhere|","title":"Create AMI (Amazon Machine Instance)"},{"location":"lang/python/Python-Production-Servers/#ssh-to-your-instance","text":"using instance dns ssh -i ~/.ssh/ethereal-site-backend.pem ubuntu@ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com or use public ip ssh -i ~/.ssh/ethereal-site-backend.pem ubuntu@18.136.106.117 if .pem file is downloaded from some storage, then give proper permission chmod 600 ~/.ssh/ethereal-site-backend.pem","title":"SSH to your instance"},{"location":"lang/python/Python-Production-Servers/#update","text":"sudo apt-get update sudo apt-get upgrade","title":"Update"},{"location":"lang/python/Python-Production-Servers/#set-password","text":"Source: https://comtechies.com/password-authentication-aws-ec2.html #1.open sudo vi /etc/ssh/sshd_config #2.edit no to yes PasswordAuthentication yes #3.save and close #4.change/set password sudo passwd ubuntu #5.restart service sudo service sshd restart","title":"Set Password"},{"location":"lang/python/Python-Production-Servers/#install-prerequisites","text":"","title":"Install Prerequisites"},{"location":"lang/python/Python-Production-Servers/#python-stuff","text":"","title":"Python Stuff"},{"location":"lang/python/Python-Production-Servers/#recommanded-way","text":"Using miniconda #download miniconda - for deployment, testing, build wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh #install sudo sh Miniconda3-latest-Linux-x86_64.sh #alias & activate miniconda echo \"alias anaconda='. ~/miniconda3/bin/activate'\" >> ~/.bashrc anaconda ( base ) sudo /home/ubuntu/miniconda3/bin/python3.6 -m pip install -U pipenv #clone repo ( base ) git clone https://toransahu@bitbucket.org/toransahu/ethereal-machines-backend.git #cd to repo & create venv using pipenv & install dependencies ( base ) pipenv --python 3 install","title":"Recommanded Way"},{"location":"lang/python/Python-Production-Servers/#original-way","text":"sudo wget https://www.python.org/ftp/python/3.6.4/Python-3.6.4.tar.xz sudo tar xJf Python-3.6.4.tar.xz cd Python-3.6.4/ ./configure sudo make sudo make install cd .. sudo rm Python-3.6.4.tar.xz sudo rm -rf Python-3.6.4 sudo apt install python3-pip #link pip, python cd /usr/bin unlink python unlink pip unlink virtualenv ln -s python35 python ln -s pip-3.5 pip ln -s virtualenv-3.5 virtualenv #clone repo git clone https://toransahu@bitbucket.org/toransahu/ethereal-machines-backend.git if sudo ./configure gives error Error: no acceptable C compiler found in PATH when installing python install build-essential sudo apt install build-essential","title":"Original Way"},{"location":"lang/python/Python-Production-Servers/#test-your-project-by-starting-up-the-django-development-server-with-this-command","text":"before this, disable other https/secure settings in prod_settings.py or test with dev_settings.py allow server to listen on port 8000 sudo ufw allow 8000 python manage.py runserver 0.0.0.0:8000 if you get error, add host to allowed host. ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com hit the website ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com:8000 (without http://)","title":"Test your project by starting up the Django development server with this command:"},{"location":"lang/python/Python-Production-Servers/#server-stuff","text":"","title":"Server Stuff"},{"location":"lang/python/Python-Production-Servers/#gunicorn_1","text":"will server dynamic contents of the site (works as app server) install in venv using pipenv --python 3 (app-venv) pipenv --python 3 install gunicorn test django app with gunicorn allow server to listen on port 8000 sudo ufw allow 8000 cd ethereal-machines-backend/src (where manage.py is) disable other https/secure settings in prod_settings.py to degug, enable DEBUG gunicorn --bind 0.0.0.0:8000 backend.wsgi (try website with http://), create script to start gunicorn cd ethereal-machines-backend/src (where manage.py is) vim start_gunicorn.sh make sure to write #! /bin/bash in first line chmod a+x start_gunicorn.sh start_gunicorn.sh should look like this: https://gist.github.com/toransahu/31874def1bd661db676d0dfe02e1c651","title":"Gunicorn"},{"location":"lang/python/Python-Production-Servers/#celery","text":"start rabbitmq starts automatically on boot sudo systemctl enable rabbitmq-server sudo systemctl start rabbitmq-server #- in WSL do this sudo service rabbitmq-server start start celery worker need to run inside src folder need to be in virtual env celery -A project_name worker -l info or create script to start celery cd ethereal-machines-backend/src (where manage.py is) vim start_celery.sh make sure to write #! /bin/bash in first line chmod a+x start_celery.sh start_celery.sh should look like this: https://gist.github.com/toransahu/31874def1bd661db676d0dfe02e1c651","title":"celery"},{"location":"lang/python/Python-Production-Servers/#supervisor","text":"chmod a+x all the start.sh scripts copy gunicorn.conf & celery.conf to /etc/supervisor/conf.d/ create logs folder inside repo dir sudo supervisorctl reread sudo supervisorctl update sudo supervisorctl reload sudo supervisorctl status sudo supervisorctl restart gunicorn sudo supervisorctl restart celery src: https://gist.github.com/toransahu/31874def1bd661db676d0dfe02e1c651","title":"supervisor"},{"location":"lang/python/Python-Production-Servers/#nginx","text":"will create proxy and redirect to gunicorn for dynamic contents will server static & media contents src: https://www.digitalocean.com/community/tutorials/how-to-set-up-django-with-postgres-nginx-and-gunicorn-on-ubuntu-16-04 install sudo apt install nginx start nginx sudo service nginx start hit the site ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com check whether you are getting a msg Welcome to nginx! or not stop nginx sudo service nginx stop Configure nginx to proxy pass to gunicorn configuration file : https://gist.github.com/toransahu/f5a38976967715e31543dbcf9b01c7d9 sudo vim /etc/nginx/sites-available/ethereal_backend open up new server block should listen on normal port 80 should respond to our server domain name or ip i.e. 18.136.106.117 (try both) for longer name you may have to increase buffer by editing sudo vim /etc/nginx/nginx.conf change count at server_names_hash_bucket_size 512; didn't find it usefull without custom domain create a location / {} block to tell Nginx to ignore any problems with finding a favicon tell Nginx to find static files here prefix will be same as STATIC_URL and alias will be same as STATIC_ROOT tell Nginx to find media files here prefix will be same as MEDIA_URL and alias will be same as MEDIA_ROOT didn't find it usefull without custom domain create a location / {} block to match all other requests include the standard proxy_params file included with the Nginx installation then pass the traffic to the socket that our Gunicorn process created i.e. http://0.0.0.0:8000 or may be now you need to provide link with server_name and different port on which application is running e.g http://server_name:8000 enable the file by linking it to the sites-enabled directory sudo ln -s /etc/nginx/sites-available/ethereal_backend /etc/nginx/sites-enabled test nginx config for syntax errors sudo nginx -t if no errors reported then go ahead & restart nginx sudo systemctl restart nginx Finally, we need to open up our firewall to normal traffic on port 80. Since we no longer need access to the development server, we can remove the rule to open port 8000 as well sudo ufw delete allow 8000 sudo ufw allow 'Nginx Full' set host (for custom root/domain url for hyperlinks inside django app) e.g. https://api.etherealmachines.com/file/media/1/djklfjkdflkfsdaf.png need to set in /etc/nginx/sites-available/ethereal_backend proxy_set_header Host \"api.etherealmachines.com\" refer: https://gist.github.com/toransahu/f5a38976967715e31543dbcf9b01c7d9 make sure \"api.etherealmachines.com\" is included in ALLOWED_HOSTS in prod_settings.py for size limit issues if total cient body exceeds defined limit in nginx.conf file, it (web server) throws HTTP error 413, request before reaching to the application server to handle the size limit, mention client_max_body_size 10M; in nginx.conf inside http {} block Note: comment out SSL on and redirect HTTPS line in ethereal_backend file if don't using ssl & https","title":"nginx"},{"location":"lang/python/Python-Production-Servers/#setup-database","text":"","title":"Setup Database"},{"location":"lang/python/Python-Production-Servers/#aws-rds-mysql-free-tier","text":"","title":"AWS RDS MySQL (Free Tier)"},{"location":"lang/python/Python-Production-Servers/#rds-config","text":"source: https://docs.aws.amazon.com/AmazonRDS/latest/UserGuide/USER_CreateInstance.html in selected security group add Type:MYSQL/Aurora;Protocol:TCP;Range:3306;Source:Anywhere(0.0.0.0/0) enable public use/access to access db over internet http://ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com:8000/api/v1/ (optional)","title":"RDS Config"},{"location":"lang/python/Python-Production-Servers/#installation","text":"install mysqlclient in venv pipenv install mysqlclient if it gives error: mysql_config not found install following sudo apt-get install libmysqlclient-dev","title":"Installation"},{"location":"lang/python/Python-Production-Servers/#django-configuration","text":"instance etherealbackend db ethereal host etherealbackend.cg17v7dkjshh.ap-southeast-1.rds.amazonaws.com port 3306 master user ethereal master pwd machines","title":"Django Configuration"},{"location":"lang/python/Python-Production-Servers/#test-django-with-rds-mysql","text":"python manage.py makemigrations python manage.py migrate python manage.py runserver 0.0.0.0:8000","title":"Test Django with RDS MySQL"},{"location":"lang/python/Python-Production-Servers/#run","text":"","title":"Run"},{"location":"lang/python/Python-Production-Servers/#confirm-before-run","text":"python manage.py makemigrations <apps> python manage.py migrate python manage.py createsuperuser python manage.py collectstatic cd /home/ubuntu/ethereal-machines/ethereal-machines-backend/ ./start_gunicorn.sh sudo systemctl restart nginx","title":"Confirm before run"},{"location":"lang/python/Python-Production-Servers/#enable-https-in-aws-ec2-with-nginx","text":"Blog source Official Source- Ubuntu 16.04 + nginx using lets-encrypt CA (certificate authority) provides free SSL certificates for few weeks/ 3 months using Certbot - the official lets-encrypt client automatically fetches & deploys SSL/TLS certificates in the server","title":"Enable HTTPS in aws ec2 with nginx"},{"location":"lang/python/Python-Production-Servers/#make-sure-http-https-are-opened-in-security-groups","text":"inside inbound rules note down public IP & DNS of the aws ec2 instance","title":"Make sure HTTP &amp; HTTPS are opened in Security Groups"},{"location":"lang/python/Python-Production-Servers/#setup-domains-cname-record-to-the-public-dns-of-ec2","text":"here domain is: etherealmachines.com public dns is: ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com Go to your DNS config in CloudFlare & create an entry in DNS Records type: CNAME Name: api.etherealmachines.com value: ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com TTL: Automatic","title":"Setup domain's CNAME record to the public DNS of ec2"},{"location":"lang/python/Python-Production-Servers/#install-certbot-in-aws-instance","text":"cd to your home or project root wget https://dl.eff.org/certbot-auto chmod a+x certbot-auto","title":"Install Certbot in aws instance"},{"location":"lang/python/Python-Production-Servers/#stop-any-existing-servers-running-on-the-port-80-and-443","text":"because those will be used by certbot to verify the domain & generate certificates after generating certificates, restart servers","title":"Stop any existing servers running on the port 80 and 443"},{"location":"lang/python/Python-Production-Servers/#generate-certificates","text":"./certbot-auto certonly --standalone -d api.etherealmachines.com we can generate certificates for multiple domains also, like ./certbot-auto certonly --standalone -d api.etherealmachines.com -d www.etherealmachines.com","title":"Generate certificates"},{"location":"lang/python/Python-Production-Servers/#change-nginx-configurations-in-etcnginxnginxconf-to-enable-ssl","text":"https://gist.github.com/toransahu/7b546d1d1a6afdf51dfa6602ecda22fc The Strict-Transport-Security (HSTS) header ensures that any internal links that are not HTTPS will automatically be routed to the HTTPS version during a HTTPS session","title":"Change nginx configurations in /etc/nginx/nginx.conf to enable SSL"},{"location":"lang/python/Python-Production-Servers/#reload-nginx-config","text":"test config for syntaxt errors: sudo nginx -t sudo service nginx reload","title":"Reload nginx config"},{"location":"lang/python/Python-Production-Servers/#finish","text":"now https://api.etherealmachines.com will redirect requests to http://ec2-18-136-106-117.ap-southeast-1.compute.amazonaws.com/","title":"Finish"},{"location":"lang/python/Python-Production-Servers/#check-certificate-expiry-date","text":"Install ssl-cert-check sudo apt install ssl-cert-check Run sudo ssl-cert-check -c /etc/letsencrypt/live/api.etherealmachines.com/fullchain.pem or awk the final result sudo ssl-cert-check -c /etc/letsencrypt/live/api.etherealmachines.com/fullchain.pem | awk 'END { print <dollar_sign>NF }'","title":"Check Certificate Expiry Date"},{"location":"lang/python/Python-Production-Servers/#renew-certificate","text":"if cloudflare DNS + HTTP proxy is configured, then it will interfere while renewal and creation of ssl certificate so, disable http proxy (DNS only should be there in status column) from status column source: https://www.tautvidas.com/blog/2018/06/certbot-renewal-of-letsencrypt-certificate-fails-with-failed-authorization-procedure/ Let's encrypt certificates are only valid for 3 months after issue. So renewal is required. before using renew command turn off nginx to open the port 80 to check/dry run renewal do: sudo certbot renew --dry-run automate autonewal using cron job: 0 6 * * * /path/to/certbot/certbot-auto renew --text >> /path/to/certbot/certbot-cron.log && sudo service nginx reload","title":"Renew Certificate"},{"location":"lang/python/Python-Production-Servers/#delete-the-certificate","text":"sudo certbot delete --cert-name api.etherealmachines.com","title":"delete the certificate"},{"location":"lang/python/Python-Production-Servers/#troubleshoots","text":"while certificate renew/new if it fails with TLS handshake/auth issue: remove certificate entry from /etc/nginx/nginx.conf while renew/new if you get too many request / auth failure / blocked then wait for 1 hr and retry there is 5 limit per account","title":"Troubleshoots"},{"location":"lang/python/Python-Production-Servers/#aws-s3-storage","text":"Source: - https://simpleisbetterthancomplex.com/tutorial/2017/08/01/how-to-setup-amazon-s3-in-a-django-project.html - http://django-storages.readthedocs.io/en/latest/backends/amazon-S3.html#model - http://boto3.readthedocs.io/en/latest/guide/quickstart.html#configuration https://ethereal-erp.s3.amazonaws.com Credentials - Users with AWS Management Console access can sign-in at: - https://908866068066.signin.aws.amazon.com/console - username - ethereal - group - erp-programatic - access key id - AKIAIBBFQZVDCT7BR6QA - secret access key - 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","title":"AWS S3 Storage"},{"location":"lang/python/Python-Production-Servers/#cloudflare","text":"","title":"Cloudflare"},{"location":"lang/python/Python-Production-Servers/#manage-dns","text":"","title":"Manage DNS"},{"location":"lang/python/Python-Production-Servers/#manage-cache","text":"","title":"Manage Cache"},{"location":"lang/python/Python-Production-Servers/#purge-cache","text":"By API curl -X DELETE \"https://api.cloudflare.com/client/v4/zones/<site-id>/purge_cache\" \\ -H \"X-Auth-Email: <email>\" \\ -H \"X-Auth-Key: <apikey>\" \\ -H \"Content-Type: application/json\" \\ --data '{\"purge_everything\":true}' ) \" source: https://www.supertechcrew.com/clear-cloudflare-cache-when-pushing-from-git-github-pages/ By Git while Pushing Sources: https://www.supertechcrew.com/clear-cloudflare-cache-when-pushing-from-git-github-pages/ https://www.binarymoon.co.uk/2017/06/using-git-hooks-clear-cloudflares-cache/ By Website","title":"Purge Cache"},{"location":"lang/python/Python-Production-Servers/#todo","text":"before nginx ~~correct start_gunicorn.sh with log & workers~~ ~~if possible see pipenv shell~~ ~~MySQL setup~~ nginx ~~proxy~~ ~~static issue~~ ~~try by removing STATIC_FINDER in PROD_.py~~ ~~media issue~~ ~~bind with https://api.etherealmachines.com~~ in code: utils/ init .py ~~mysql case: db name dynamic~~ ~~dev & prod settings~~ ~~media url append in urls.py ~~ ~~remove DEBUG is True condition~~ implement task queue using Celery to make post_save faster http://www.dougalmatthews.com/2011/Oct/10/making-djangos-signals-async-with-celery/ configure https in django+aws level","title":"TODO:"},{"location":"lang/python/Python-Testing/","text":"Testing Framework Possible Ways Of Doing 1. unittest Testing Framework Intro mock Library (Python 2.x) & unittest.mock Library (Python 3.x) Intro Features Why 2. pytest Framework Types assert Running multiple tests Asserting that a certain exception is raised Grouping multiple tests in a class Resource Setup Features 3. coverage.py Tool Intro Quick Start Testing Framework # Possible Ways Of Doing # Python Using assert; no module require Using assert with setup_module(module) & teardown_module(module) methods for resource setup (define global variables) unittest framework class level: inherit unittest.TestCase override setUP(self) method for resource setup as class members use self.assertEqual(var1, var2) or self.assertNotEqual(var1, var2) pytest framework by functions: using assert & @pytest.fixture(scope=\"module\") for resource setup by classes: (define all test cases inside) using assert & @pytest.fixture(scope=\"class\") for resource setup Django Using django.test from django.test import TestCase same as unittest define class and inherit TestCase define test_cases(self) method use self.assertIs(var, bool) 1. unittest Testing Framework # Intro # Inbuilt Class based import class unittest.TestCase define setUp method for setup resources define testcase method for assertion/testing execution: run the module or python -m unittest test_module_name.py Note: Module & method should have 'test_' prefix & class have 'Test' prefix e.g. import unittest try : from .binary_tree import in_order , Node except : from binary_tree import in_order , Node class TestBinaryTree ( unittest . TestCase ): def setUp ( self ): self . root = Node ( 1 ) self . root . left = Node ( 2 ) self . root . right = Node ( 3 ) self . root . left . left = Node ( 4 ) self . root . left . right = Node ( 5 ) self . result = [] self . func_in_order = in_order ( self . root , self . result ) def test_in_order_positive ( self ): self . assertEqual ( self . func_in_order , [ 4 , 2 , 5 , 1 , 3 ], msg = None ) def test_in_order_negative ( self ): self . assertNotEqual ( self . func_in_order , [], msg = None ) if __name__ == '__main__' : root = None unittest . main () mock Library (Python 2.x) & unittest.mock Library (Python 3.x) # Intro # unittest.mock is a library for testing in Python. It allows us to replace parts of our system under test with mock objects and make assertions about how they have been used. It is based on the 'action --> assertion' pattern instead of 'record --> replay' used by many mocking framework. Features # Mock class patch() decorator MagicMock class Why # Increased speed \u00e2\u0080\u0094 Tests that run quickly are extremely beneficial. E.g. if you have a very resource intensive function, a mock of that function would cut down on unnecessary resource usage during testing, therefore reducing test run time. Avoiding undesired side effects during testing \u00e2\u0080\u0094 If you are testing a function which makes calls to an external API, you may not want to make an actual API call every time you run your tests. You'd have to change your code every time that API changes, or there may be some rate limits, but mocking helps you avoid that. 2. pytest Framework # Introduction: The pytest framework makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries. Source: https://pypi.python.org/pypi/pytest/3.2.3 https://docs.pytest.org/en/latest/contents.html#toc Installation: pip install pytest execution: execute: pytest pytest_ex1.py Types # assert # It's an standard python statement for verifying expectations and values. Input type: logical conditions Output: * Nothing/blank, if true * Raise AssertionError exception, if false e.g. # py-misc/py-testing-examples/pytest_ex1.py def add ( x , y ): return x + y def test_add_positive (): assert add ( 3 , 4 ) == 7 def test_add_negative (): assert add ( 3 , 3 ) == 7 Running multiple tests # pytest will run all files in the current directory and its subdirectories of the form test_ .py or _test.py. More generally, it follows standard test discovery rules. Asserting that a certain exception is raised # If you want to assert that some code raises an exception you can use the raises helper: # content of pytest_ex2.py import pytest def f (): raise SystemExit ( 1 ) def test_mytest (): with pytest . raises ( SystemExit ): f () Grouping multiple tests in a class # Once you start to have more than a few tests it often makes sense to group tests logically, in classes and modules. Let\u00e2\u0080\u0099s write a class containing two tests: # content of test_class.py class TestClass ( object ): def test_one ( self ): x = \"this\" assert 'h' in x def test_two ( self ): x = \"hello\" assert hasattr ( x , 'check' ) The two tests are found because of the standard Conventions for Python test discovery. There is no need to subclass anything. We can simply run the module by passing its filename: pytest -q test_class.py Resource Setup # setup & teardown (classic xunit style) fixture (recommended) complies with dependency injection Features # Detailed informations on assert statements Auto-discovery of test modules and functions to study Modular fixtures for managing small or parameterized long-lived test resources to study 3. coverage.py Tool # Intro # a tool for measuring code coverage of Python programs It monitors your program, noting which parts of the code have been executed, then analyzes the source to identify code that could have been executed but was not Use typically used to gauge the effectiveness of tests. It can show which parts of your code are being exercised by tests, and which are not. Quick Start # Install using pip install coverage 2. run the module coverage run my_program.py arg1 arg2 3. get coverage report coverage report -m get coverage report in html coverage html","title":"Python Testing"},{"location":"lang/python/Python-Testing/#testing-framework","text":"","title":"Testing Framework"},{"location":"lang/python/Python-Testing/#possible-ways-of-doing","text":"Python Using assert; no module require Using assert with setup_module(module) & teardown_module(module) methods for resource setup (define global variables) unittest framework class level: inherit unittest.TestCase override setUP(self) method for resource setup as class members use self.assertEqual(var1, var2) or self.assertNotEqual(var1, var2) pytest framework by functions: using assert & @pytest.fixture(scope=\"module\") for resource setup by classes: (define all test cases inside) using assert & @pytest.fixture(scope=\"class\") for resource setup Django Using django.test from django.test import TestCase same as unittest define class and inherit TestCase define test_cases(self) method use self.assertIs(var, bool)","title":"Possible Ways Of Doing"},{"location":"lang/python/Python-Testing/#1-unittest-testing-framework","text":"","title":"1. unittest Testing Framework"},{"location":"lang/python/Python-Testing/#intro","text":"Inbuilt Class based import class unittest.TestCase define setUp method for setup resources define testcase method for assertion/testing execution: run the module or python -m unittest test_module_name.py Note: Module & method should have 'test_' prefix & class have 'Test' prefix e.g. import unittest try : from .binary_tree import in_order , Node except : from binary_tree import in_order , Node class TestBinaryTree ( unittest . TestCase ): def setUp ( self ): self . root = Node ( 1 ) self . root . left = Node ( 2 ) self . root . right = Node ( 3 ) self . root . left . left = Node ( 4 ) self . root . left . right = Node ( 5 ) self . result = [] self . func_in_order = in_order ( self . root , self . result ) def test_in_order_positive ( self ): self . assertEqual ( self . func_in_order , [ 4 , 2 , 5 , 1 , 3 ], msg = None ) def test_in_order_negative ( self ): self . assertNotEqual ( self . func_in_order , [], msg = None ) if __name__ == '__main__' : root = None unittest . main ()","title":"Intro"},{"location":"lang/python/Python-Testing/#mock-library-python-2x-unittestmock-library-python-3x","text":"","title":"mock Library (Python 2.x) &amp; unittest.mock Library (Python 3.x)"},{"location":"lang/python/Python-Testing/#intro_1","text":"unittest.mock is a library for testing in Python. It allows us to replace parts of our system under test with mock objects and make assertions about how they have been used. It is based on the 'action --> assertion' pattern instead of 'record --> replay' used by many mocking framework.","title":"Intro"},{"location":"lang/python/Python-Testing/#features","text":"Mock class patch() decorator MagicMock class","title":"Features"},{"location":"lang/python/Python-Testing/#why","text":"Increased speed \u00e2\u0080\u0094 Tests that run quickly are extremely beneficial. E.g. if you have a very resource intensive function, a mock of that function would cut down on unnecessary resource usage during testing, therefore reducing test run time. Avoiding undesired side effects during testing \u00e2\u0080\u0094 If you are testing a function which makes calls to an external API, you may not want to make an actual API call every time you run your tests. You'd have to change your code every time that API changes, or there may be some rate limits, but mocking helps you avoid that.","title":"Why"},{"location":"lang/python/Python-Testing/#2-pytest-framework","text":"Introduction: The pytest framework makes it easy to write small tests, yet scales to support complex functional testing for applications and libraries. Source: https://pypi.python.org/pypi/pytest/3.2.3 https://docs.pytest.org/en/latest/contents.html#toc Installation: pip install pytest execution: execute: pytest pytest_ex1.py","title":"2. pytest Framework"},{"location":"lang/python/Python-Testing/#types","text":"","title":"Types"},{"location":"lang/python/Python-Testing/#assert","text":"It's an standard python statement for verifying expectations and values. Input type: logical conditions Output: * Nothing/blank, if true * Raise AssertionError exception, if false e.g. # py-misc/py-testing-examples/pytest_ex1.py def add ( x , y ): return x + y def test_add_positive (): assert add ( 3 , 4 ) == 7 def test_add_negative (): assert add ( 3 , 3 ) == 7","title":"assert"},{"location":"lang/python/Python-Testing/#running-multiple-tests","text":"pytest will run all files in the current directory and its subdirectories of the form test_ .py or _test.py. More generally, it follows standard test discovery rules.","title":"Running multiple tests"},{"location":"lang/python/Python-Testing/#asserting-that-a-certain-exception-is-raised","text":"If you want to assert that some code raises an exception you can use the raises helper: # content of pytest_ex2.py import pytest def f (): raise SystemExit ( 1 ) def test_mytest (): with pytest . raises ( SystemExit ): f ()","title":"Asserting that a certain exception is raised"},{"location":"lang/python/Python-Testing/#grouping-multiple-tests-in-a-class","text":"Once you start to have more than a few tests it often makes sense to group tests logically, in classes and modules. Let\u00e2\u0080\u0099s write a class containing two tests: # content of test_class.py class TestClass ( object ): def test_one ( self ): x = \"this\" assert 'h' in x def test_two ( self ): x = \"hello\" assert hasattr ( x , 'check' ) The two tests are found because of the standard Conventions for Python test discovery. There is no need to subclass anything. We can simply run the module by passing its filename: pytest -q test_class.py","title":"Grouping multiple tests in a class"},{"location":"lang/python/Python-Testing/#resource-setup","text":"setup & teardown (classic xunit style) fixture (recommended) complies with dependency injection","title":"Resource Setup"},{"location":"lang/python/Python-Testing/#features_1","text":"Detailed informations on assert statements Auto-discovery of test modules and functions to study Modular fixtures for managing small or parameterized long-lived test resources to study","title":"Features"},{"location":"lang/python/Python-Testing/#3-coveragepy-tool","text":"","title":"3. coverage.py Tool"},{"location":"lang/python/Python-Testing/#intro_2","text":"a tool for measuring code coverage of Python programs It monitors your program, noting which parts of the code have been executed, then analyzes the source to identify code that could have been executed but was not Use typically used to gauge the effectiveness of tests. It can show which parts of your code are being exercised by tests, and which are not.","title":"Intro"},{"location":"lang/python/Python-Testing/#quick-start","text":"Install using pip install coverage 2. run the module coverage run my_program.py arg1 arg2 3. get coverage report coverage report -m get coverage report in html coverage html","title":"Quick Start"},{"location":"music/Piano/","text":"Piano Basics Keys Black Keys White Keys Notes Type Observations Octave Types Notes Practice Chords Types Observation How to find chords Piano Basics # https://www.key-notes.com/blog/piano-key-chart https://spinditty.com/learning/chord-building-for-musicians Keys # Keys are not notes Sharps and flats are not the black keys. All black keys are either a sharp or flat, but not all sharps and flats are black keys e.g. E# is a white key Black Keys # half notes White Keys # pure notes Notes # each next key is half note higher than the prev one Type # pure/natural \u266e flat \u266d half notes low sharp \u266f half notes up Observations # there is no sharp of B there is no sharp of E Octave # C (white key before 2 black) to next C (8 keys in total) are called octave Types # middle octave (middle one) higher octave (right one) lower octave (left one) Notes Practice # Chords # Types # Major (3rd, 5th) Minor (2nd, 5th) 7th (If 4th finger used) Observation # all 3 fingers on alternate white keys gives: CM,Dm,Em,FM,GM,Am,BM... minor chords gives sadness most of the time major chords gives happiness most of the time How to find chords # (based of notes) - if a song starts from C, then most probably the sca -","title":"Piano"},{"location":"music/Piano/#piano-basics","text":"https://www.key-notes.com/blog/piano-key-chart https://spinditty.com/learning/chord-building-for-musicians","title":"Piano Basics"},{"location":"music/Piano/#keys","text":"Keys are not notes Sharps and flats are not the black keys. All black keys are either a sharp or flat, but not all sharps and flats are black keys e.g. E# is a white key","title":"Keys"},{"location":"music/Piano/#black-keys","text":"half notes","title":"Black Keys"},{"location":"music/Piano/#white-keys","text":"pure notes","title":"White Keys"},{"location":"music/Piano/#notes","text":"each next key is half note higher than the prev one","title":"Notes"},{"location":"music/Piano/#type","text":"pure/natural \u266e flat \u266d half notes low sharp \u266f half notes up","title":"Type"},{"location":"music/Piano/#observations","text":"there is no sharp of B there is no sharp of E","title":"Observations"},{"location":"music/Piano/#octave","text":"C (white key before 2 black) to next C (8 keys in total) are called octave","title":"Octave"},{"location":"music/Piano/#types","text":"middle octave (middle one) higher octave (right one) lower octave (left one)","title":"Types"},{"location":"music/Piano/#notes-practice","text":"","title":"Notes Practice"},{"location":"music/Piano/#chords","text":"","title":"Chords"},{"location":"music/Piano/#types_1","text":"Major (3rd, 5th) Minor (2nd, 5th) 7th (If 4th finger used)","title":"Types"},{"location":"music/Piano/#observation","text":"all 3 fingers on alternate white keys gives: CM,Dm,Em,FM,GM,Am,BM... minor chords gives sadness most of the time major chords gives happiness most of the time","title":"Observation"},{"location":"music/Piano/#how-to-find-chords","text":"(based of notes) - if a song starts from C, then most probably the sca -","title":"How to find chords"}]}